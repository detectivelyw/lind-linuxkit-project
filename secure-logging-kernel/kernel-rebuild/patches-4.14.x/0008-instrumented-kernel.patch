From 8d1f0ce86a173f37d1f4bcaf52cbe282db6e15c3 Mon Sep 17 00:00:00 2001
From: Yiwen Li <detectivelyw@gmail.com>
Date: Tue, 4 Jun 2019 15:17:48 -0400
Subject: [PATCH 08/11] instrumented kernel.

---
 kernel/acct.c                        |  20 ++
 kernel/async.c                       |  15 ++
 kernel/audit.c                       | 212 +++++++++++++++
 kernel/audit_fsnotify.c              |  14 +
 kernel/audit_tree.c                  |  36 +++
 kernel/audit_watch.c                 |  32 +++
 kernel/auditfilter.c                 |  52 ++++
 kernel/auditsc.c                     |  21 ++
 kernel/bpf/cgroup.c                  |   2 +
 kernel/bpf/core.c                    |  34 +++
 kernel/bpf/devmap.c                  |   2 +
 kernel/bpf/inode.c                   |   2 +
 kernel/capability.c                  |  17 ++
 kernel/cgroup/cgroup-internal.h      |   2 +
 kernel/cgroup/cgroup-v1.c            | 129 +++++++++
 kernel/cgroup/cgroup.c               | 414 +++++++++++++++++++++++++++++
 kernel/cgroup/cpuset.c               | 166 ++++++++++++
 kernel/cgroup/freezer.c              |  45 ++++
 kernel/cgroup/namespace.c            |  19 ++
 kernel/cgroup/pids.c                 |   2 +
 kernel/cgroup/rdma.c                 |   2 +
 kernel/configs.c                     |   2 +
 kernel/cpu.c                         | 123 +++++++++
 kernel/cred.c                        |  37 +++
 kernel/delayacct.c                   |   5 +
 kernel/dma.c                         |   6 +
 kernel/events/core.c                 | 501 +++++++++++++++++++++++++++++++++++
 kernel/events/hw_breakpoint.c        |  45 ++++
 kernel/events/uprobes.c              | 136 ++++++++++
 kernel/exec_domain.c                 |   7 +-
 kernel/exit.c                        | 165 ++++++++++++
 kernel/extable.c                     |  25 ++
 kernel/fork.c                        |  90 +++++++
 kernel/freezer.c                     |  17 ++
 kernel/futex.c                       | 178 +++++++++++++
 kernel/gcov/base.c                   |   2 +
 kernel/gcov/fs.c                     |   2 +
 kernel/gcov/gcc_4_7.c                |   2 +
 kernel/groups.c                      |  35 +++
 kernel/hung_task.c                   |   2 +
 kernel/irq/chip.c                    |  57 ++++
 kernel/irq/devres.c                  |  13 +
 kernel/irq/handle.c                  |   7 +
 kernel/irq/internals.h               |   2 +
 kernel/irq/irqdesc.c                 |  26 ++
 kernel/irq/irqdomain.c               |  90 +++++++
 kernel/irq/manage.c                  | 141 ++++++++++
 kernel/irq/migration.c               |  14 +
 kernel/irq/msi.c                     |  52 ++++
 kernel/irq/pm.c                      |  19 ++
 kernel/irq/proc.c                    |  30 +++
 kernel/irq/resend.c                  |   4 +
 kernel/irq/settings.h                |   2 +
 kernel/irq/spurious.c                |  34 +++
 kernel/irq_work.c                    |  15 ++
 kernel/jump_label.c                  |   2 +
 kernel/kallsyms.c                    |  53 ++++
 kernel/kcmp.c                        |   2 +
 kernel/kmod.c                        |  12 +
 kernel/kprobes.c                     | 130 +++++++++
 kernel/ksysfs.c                      |  22 ++
 kernel/kthread.c                     |  40 +++
 kernel/locking/mutex.c               | 101 +++++++
 kernel/locking/percpu-rwsem.c        |  12 +
 kernel/locking/rtmutex.c             |   9 +
 kernel/locking/rwsem-xadd.c          |  41 +++
 kernel/locking/rwsem.c               |  14 +
 kernel/locking/rwsem.h               |   2 +
 kernel/locking/semaphore.c           |   9 +
 kernel/locking/spinlock.c            |  10 +
 kernel/memremap.c                    |  18 ++
 kernel/module.c                      | 168 ++++++++++++
 kernel/notifier.c                    |  20 ++
 kernel/nsproxy.c                     |  37 +++
 kernel/panic.c                       |  21 ++
 kernel/params.c                      |  70 +++++
 kernel/pid.c                         |  42 +++
 kernel/pid_namespace.c               |  26 ++
 kernel/power/main.c                  |  47 ++++
 kernel/power/poweroff.c              |   3 +
 kernel/power/qos.c                   |  32 +++
 kernel/printk/printk.c               | 141 ++++++++++
 kernel/printk/printk_safe.c          |  15 ++
 kernel/profile.c                     |  42 +++
 kernel/ptrace.c                      | 119 +++++++++
 kernel/range.c                       |  18 ++
 kernel/rcu/rcu.h                     |   2 +
 kernel/rcu/rcu_segcblist.c           |  33 +++
 kernel/rcu/rcu_segcblist.h           |   2 +
 kernel/rcu/srcutree.c                |  88 ++++++
 kernel/rcu/sync.c                    |  18 ++
 kernel/rcu/tree.c                    | 287 ++++++++++++++++++++
 kernel/rcu/tree_exp.h                |   2 +
 kernel/rcu/tree_plugin.h             |   2 +
 kernel/rcu/update.c                  |  26 ++
 kernel/reboot.c                      |  30 +++
 kernel/resource.c                    | 125 +++++++++
 kernel/sched/autogroup.c             |   2 +
 kernel/sched/autogroup.h             |   2 +
 kernel/sched/clock.c                 |  24 ++
 kernel/sched/completion.c            |  17 ++
 kernel/sched/core.c                  | 300 +++++++++++++++++++++
 kernel/sched/cpuacct.c               |  24 ++
 kernel/sched/cpudeadline.c           |  18 ++
 kernel/sched/cpupri.c                |  16 ++
 kernel/sched/cputime.c               |  12 +
 kernel/sched/deadline.c              |  48 ++++
 kernel/sched/debug.c                 |   2 +
 kernel/sched/fair.c                  | 288 ++++++++++++++++++++
 kernel/sched/idle.c                  |  26 ++
 kernel/sched/idle_task.c             |  10 +
 kernel/sched/loadavg.c               |  21 ++
 kernel/sched/rt.c                    |  15 ++
 kernel/sched/sched.h                 |   2 +
 kernel/sched/stats.h                 |   2 +
 kernel/sched/stop_task.c             |  13 +
 kernel/sched/swait.c                 |   9 +
 kernel/sched/topology.c              | 157 +++++++++++
 kernel/sched/wait.c                  |  33 +++
 kernel/sched/wait_bit.c              |  14 +
 kernel/seccomp.c                     |  32 +++
 kernel/signal.c                      | 298 +++++++++++++++++++++
 kernel/smp.c                         |  55 ++++
 kernel/smpboot.c                     |  42 +++
 kernel/softirq.c                     |  37 +++
 kernel/stop_machine.c                |  32 +++
 kernel/sys.c                         | 233 ++++++++++++++++
 kernel/sys_ni.c                      |   2 +
 kernel/sysctl.c                      | 104 ++++++++
 kernel/task_work.c                   |   8 +
 kernel/taskstats.c                   |  35 +++
 kernel/time/alarmtimer.c             |  34 +++
 kernel/time/clockevents.c            |  59 +++++
 kernel/time/clocksource.c            |  29 ++
 kernel/time/hrtimer.c                |  15 ++
 kernel/time/itimer.c                 |  23 +-
 kernel/time/jiffies.c                |   2 +
 kernel/time/ntp.c                    |  29 ++
 kernel/time/posix-cpu-timers.c       |  52 ++++
 kernel/time/posix-timers.c           |   4 +
 kernel/time/tick-broadcast.c         |   2 +
 kernel/time/tick-common.c            |  59 +++++
 kernel/time/tick-internal.h          |   2 +
 kernel/time/tick-oneshot.c           |  10 +
 kernel/time/tick-sched.c             |  49 ++++
 kernel/time/time.c                   |  73 ++++-
 kernel/time/timekeeping.c            |  85 ++++++
 kernel/time/timekeeping_debug.c      |   6 +
 kernel/time/timekeeping_internal.h   |   2 +
 kernel/time/timer.c                  |   2 +
 kernel/time/timer_list.c             |  20 ++
 kernel/trace/blktrace.c              |  96 +++++++
 kernel/trace/ftrace.c                |   2 +
 kernel/trace/ring_buffer.c           |  18 ++
 kernel/trace/trace.c                 | 342 ++++++++++++++++++++++++
 kernel/trace/trace.h                 |   2 +
 kernel/trace/trace_clock.c           |   6 +
 kernel/trace/trace_entries.h         |   2 +
 kernel/trace/trace_events.c          | 186 +++++++++++++
 kernel/trace/trace_events_filter.c   | 101 +++++++
 kernel/trace/trace_events_trigger.c  |  75 ++++++
 kernel/trace/trace_functions.c       |   2 +
 kernel/trace/trace_functions_graph.c |   2 +
 kernel/trace/trace_kprobe.c          |  61 +++++
 kernel/trace/trace_mmiotrace.c       |   2 +
 kernel/trace/trace_output.c          |  64 +++++
 kernel/trace/trace_printk.c          |  29 ++
 kernel/trace/trace_stack.c           |   2 +
 kernel/trace/trace_stat.c            |  35 +++
 kernel/trace/trace_syscalls.c        |   2 +
 kernel/trace/trace_uprobe.c          |  56 ++++
 kernel/tracepoint.c                  |  28 ++
 kernel/tsacct.c                      |   8 +
 kernel/ucount.c                      |  28 ++
 kernel/umh.c                         |  19 ++
 kernel/user.c                        |  11 +
 kernel/user_namespace.c              |   2 +
 kernel/utsname.c                     |  15 ++
 kernel/utsname_sysctl.c              |   5 +
 kernel/watchdog.c                    |   2 +
 kernel/watchdog_hld.c                |   2 +
 kernel/workqueue.c                   | 176 ++++++++++++
 kernel/workqueue_internal.h          |   2 +
 183 files changed, 8886 insertions(+), 4 deletions(-)

diff --git a/kernel/acct.c b/kernel/acct.c
index 354578d..246ec9e 100644
--- a/kernel/acct.c
+++ b/kernel/acct.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 /*
  *  linux/kernel/acct.c
@@ -102,6 +104,7 @@ static int check_free_space(struct bsd_acct_struct *acct)
 {
 	struct kstatfs sbuf;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (time_is_after_jiffies(acct->needcheck))
 		goto out;
 
@@ -132,12 +135,14 @@ static int check_free_space(struct bsd_acct_struct *acct)
 
 static void acct_put(struct bsd_acct_struct *p)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (atomic_long_dec_and_test(&p->count))
 		kfree_rcu(p, rcu);
 }
 
 static inline struct bsd_acct_struct *to_acct(struct fs_pin *p)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return p ? container_of(p, struct bsd_acct_struct, pin) : NULL;
 }
 
@@ -169,6 +174,7 @@ static struct bsd_acct_struct *acct_get(struct pid_namespace *ns)
 
 static void acct_pin_kill(struct fs_pin *pin)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct bsd_acct_struct *acct = to_acct(pin);
 	mutex_lock(&acct->lock);
 	do_acct_process(acct);
@@ -182,6 +188,7 @@ static void acct_pin_kill(struct fs_pin *pin)
 
 static void close_work(struct work_struct *work)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct bsd_acct_struct *acct = container_of(work, struct bsd_acct_struct, work);
 	struct file *file = acct->file;
 	if (file->f_op->flush)
@@ -201,7 +208,9 @@ static int acct_on(struct filename *pathname)
 
 	acct = kzalloc(sizeof(struct bsd_acct_struct), GFP_KERNEL);
 	if (!acct)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 
 	/* Difference from BSD - they don't do O_APPEND */
 	file = file_open_name(pathname, O_WRONLY|O_APPEND|O_LARGEFILE, 0);
@@ -275,7 +284,9 @@ SYSCALL_DEFINE1(acct, const char __user *, name)
 	int error = 0;
 
 	if (!capable(CAP_SYS_PACCT))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EPERM;
+}
 
 	if (name) {
 		struct filename *tmp = getname(name);
@@ -296,6 +307,7 @@ SYSCALL_DEFINE1(acct, const char __user *, name)
 
 void acct_exit_ns(struct pid_namespace *ns)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rcu_read_lock();
 	pin_kill(ns->bacct);
 }
@@ -317,6 +329,7 @@ static comp_t encode_comp_t(unsigned long value)
 	int exp, rnd;
 
 	exp = rnd = 0;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	while (value > MAXFRACT) {
 		rnd = value & (1 << (EXPSIZE - 1));	/* Round up? */
 		value >>= EXPSIZE;	/* Base 8 exponent == 3 bit shift. */
@@ -360,6 +373,7 @@ static comp2_t encode_comp2_t(u64 value)
 
 	exp = (value > (MAXFRACT2>>1));
 	rnd = 0;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	while (value > MAXFRACT2) {
 		rnd = value & 1;
 		value >>= 1;
@@ -414,6 +428,7 @@ static u32 encode_float(u64 value)
 
 static void fill_ac(acct_t *ac)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct pacct_struct *pacct = &current->signal->pacct;
 	u64 elapsed, run_time;
 	struct tty_struct *tty;
@@ -490,6 +505,7 @@ static void do_acct_process(struct bsd_acct_struct *acct)
 	if (!check_free_space(acct))
 		goto out;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	fill_ac(&ac);
 	/* we really need to bite the bullet and change layout */
 	ac.ac_uid = from_kuid_munged(file->f_cred->user_ns, orig_cred->uid);
@@ -563,6 +579,7 @@ void acct_collect(long exitcode, int group_dead)
 	if (current->flags & PF_SIGNALED)
 		pacct->ac_flag |= AXSIG;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	task_cputime(current, &utime, &stime);
 	pacct->ac_utime += utime;
 	pacct->ac_stime += stime;
@@ -573,6 +590,7 @@ void acct_collect(long exitcode, int group_dead)
 
 static void slow_acct_process(struct pid_namespace *ns)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for ( ; ns; ns = ns->parent) {
 		struct bsd_acct_struct *acct = acct_get(ns);
 		if (acct) {
@@ -602,5 +620,7 @@ void acct_process(void)
 			break;
 	}
 	if (unlikely(ns))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		slow_acct_process(ns);
 }
+}
diff --git a/kernel/async.c b/kernel/async.c
index a893d61..891f8f3 100644
--- a/kernel/async.c
+++ b/kernel/async.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * async.c: Asynchronous function calls for boot performance
  *
@@ -103,6 +105,7 @@ static async_cookie_t lowest_in_progress(struct async_domain *domain)
 	if (first)
 		ret = first->cookie;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_unlock_irqrestore(&async_lock, flags);
 	return ret;
 }
@@ -119,6 +122,7 @@ static void async_run_entry_fn(struct work_struct *work)
 
 	/* 1) run (and print duration) */
 	if (initcall_debug && system_state < SYSTEM_RUNNING) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_debug("calling  %lli_%pF @ %i\n",
 			(long long)entry->cookie,
 			entry->func, task_pid_nr(current));
@@ -126,8 +130,10 @@ static void async_run_entry_fn(struct work_struct *work)
 	}
 	entry->func(entry->data, entry->cookie);
 	if (initcall_debug && system_state < SYSTEM_RUNNING) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		rettime = ktime_get();
 		delta = ktime_sub(rettime, calltime);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_debug("initcall %lli_%pF returned 0 after %lld usecs\n",
 			(long long)entry->cookie,
 			entry->func,
@@ -163,8 +169,11 @@ static async_cookie_t __async_schedule(async_func_t func, void *data, struct asy
 	 * pending already, we execute synchronously.
 	 */
 	if (!entry || atomic_read(&entry_count) > MAX_WORK) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		kfree(entry);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		spin_lock_irqsave(&async_lock, flags);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		newcookie = next_cookie++;
 		spin_unlock_irqrestore(&async_lock, flags);
 
@@ -188,6 +197,7 @@ static async_cookie_t __async_schedule(async_func_t func, void *data, struct asy
 	if (domain->registered)
 		list_add_tail(&entry->global_list, &async_global_pending);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	atomic_inc(&entry_count);
 	spin_unlock_irqrestore(&async_lock, flags);
 
@@ -229,6 +239,7 @@ EXPORT_SYMBOL_GPL(async_schedule);
 async_cookie_t async_schedule_domain(async_func_t func, void *data,
 				     struct async_domain *domain)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return __async_schedule(func, data, domain);
 }
 EXPORT_SYMBOL_GPL(async_schedule_domain);
@@ -255,6 +266,7 @@ EXPORT_SYMBOL_GPL(async_synchronize_full);
  */
 void async_unregister_domain(struct async_domain *domain)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_lock_irq(&async_lock);
 	WARN_ON(!domain->registered || !list_empty(&domain->pending));
 	domain->registered = 0;
@@ -289,6 +301,7 @@ void async_synchronize_cookie_domain(async_cookie_t cookie, struct async_domain
 	ktime_t uninitialized_var(starttime), delta, endtime;
 
 	if (initcall_debug && system_state < SYSTEM_RUNNING) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_debug("async_waiting @ %i\n", task_pid_nr(current));
 		starttime = ktime_get();
 	}
@@ -296,9 +309,11 @@ void async_synchronize_cookie_domain(async_cookie_t cookie, struct async_domain
 	wait_event(async_done, lowest_in_progress(domain) >= cookie);
 
 	if (initcall_debug && system_state < SYSTEM_RUNNING) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		endtime = ktime_get();
 		delta = ktime_sub(endtime, starttime);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_debug("async_continuing @ %i after %lli usec\n",
 			task_pid_nr(current),
 			(long long)ktime_to_ns(delta) >> 10);
diff --git a/kernel/audit.c b/kernel/audit.c
index 5b34d31..e7de140 100644
--- a/kernel/audit.c
+++ b/kernel/audit.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /* audit.c -- Auditing support
  * Gateway between the kernel (e.g., selinux) and the user-space audit daemon.
  * System-call specific features have moved to auditsc.c
@@ -238,6 +240,7 @@ static pid_t auditd_pid_vnr(void)
 	const struct auditd_connection *ac;
 
 	rcu_read_lock();
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	ac = rcu_dereference(auditd_conn);
 	if (!ac || !ac->pid)
 		pid = 0;
@@ -261,7 +264,9 @@ static struct sock *audit_get_sk(const struct net *net)
 	struct audit_net *aunet;
 
 	if (!net)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 
 	aunet = net_generic(net, audit_net_id);
 	return aunet->sk;
@@ -269,6 +274,7 @@ static struct sock *audit_get_sk(const struct net *net)
 
 void audit_panic(const char *message)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	switch (audit_failure) {
 	case AUDIT_FAIL_SILENT:
 		break;
@@ -294,18 +300,24 @@ static inline int audit_rate_check(void)
 
 	if (!audit_rate_limit) return 1;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_lock_irqsave(&lock, flags);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (++messages < audit_rate_limit) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		retval = 1;
 	} else {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		now     = jiffies;
 		elapsed = now - last_check;
 		if (elapsed > HZ) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			last_check = now;
 			messages   = 0;
 			retval     = 1;
 		}
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_unlock_irqrestore(&lock, flags);
 
 	return retval;
@@ -329,6 +341,7 @@ void audit_log_lost(const char *message)
 
 	atomic_inc(&audit_lost);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	print = (audit_failure == AUDIT_FAIL_PANIC || !audit_rate_limit);
 
 	if (!print) {
@@ -359,7 +372,9 @@ static int audit_log_config_change(char *function_name, u32 new, u32 old,
 
 	ab = audit_log_start(NULL, GFP_KERNEL, AUDIT_CONFIG_CHANGE);
 	if (unlikely(!ab))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return rc;
+}
 	audit_log_format(ab, "%s=%u old=%u", function_name, new, old);
 	audit_log_session_info(ab);
 	rc = audit_log_task_context(ab);
@@ -377,7 +392,9 @@ static int audit_do_config_change(char *function_name, u32 *to_change, u32 new)
 
 	/* check if we are locked */
 	if (audit_enabled == AUDIT_LOCKED)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		allow_changes = 0;
+}
 	else
 		allow_changes = 1;
 
@@ -398,16 +415,19 @@ static int audit_do_config_change(char *function_name, u32 *to_change, u32 new)
 
 static int audit_set_rate_limit(u32 limit)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return audit_do_config_change("audit_rate_limit", &audit_rate_limit, limit);
 }
 
 static int audit_set_backlog_limit(u32 limit)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return audit_do_config_change("audit_backlog_limit", &audit_backlog_limit, limit);
 }
 
 static int audit_set_backlog_wait_time(u32 timeout)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return audit_do_config_change("audit_backlog_wait_time",
 				      &audit_backlog_wait_time, timeout);
 }
@@ -416,7 +436,9 @@ static int audit_set_enabled(u32 state)
 {
 	int rc;
 	if (state > AUDIT_LOCKED)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	rc =  audit_do_config_change("audit_enabled", &audit_enabled, state);
 	if (!rc)
@@ -427,6 +449,7 @@ static int audit_set_enabled(u32 state)
 
 static int audit_set_failure(u32 state)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (state != AUDIT_FAIL_SILENT
 	    && state != AUDIT_FAIL_PRINTK
 	    && state != AUDIT_FAIL_PANIC)
@@ -447,6 +470,7 @@ static int audit_set_failure(u32 state)
  {
 	struct auditd_connection *ac;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	ac = container_of(rcu, struct auditd_connection, rcu);
 	put_pid(ac->pid);
 	put_net(ac->net);
@@ -468,6 +492,7 @@ static int auditd_set(struct pid *pid, u32 portid, struct net *net)
 	unsigned long flags;
 	struct auditd_connection *ac_old, *ac_new;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!pid || !net)
 		return -EINVAL;
 
@@ -499,6 +524,7 @@ static int auditd_set(struct pid *pid, u32 portid, struct net *net)
  */
 static void kauditd_printk_skb(struct sk_buff *skb)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct nlmsghdr *nlh = nlmsg_hdr(skb);
 	char *data = nlmsg_data(nlh);
 
@@ -547,6 +573,7 @@ static void kauditd_hold_skb(struct sk_buff *skb)
 	/* if we have room, queue the message */
 	if (!audit_backlog_limit ||
 	    skb_queue_len(&audit_hold_queue) < audit_backlog_limit) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		skb_queue_tail(&audit_hold_queue, skb);
 		return;
 	}
@@ -638,6 +665,7 @@ static int auditd_send_unicast_skb(struct sk_buff *skb)
 	 *       section netlink_unicast() should safely return an error */
 
 	rcu_read_lock();
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	ac = rcu_dereference(auditd_conn);
 	if (!ac) {
 		rcu_read_unlock();
@@ -713,7 +741,10 @@ static int kauditd_send_queue(struct sock *sk, u32 portid,
 				/* yes - error processing for the queue */
 				sk = NULL;
 				if (err_hook)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 					(*err_hook)(skb);
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				if (!skb_hook)
 					goto out;
 				/* keep processing with the skb_hook */
@@ -751,7 +782,9 @@ static void kauditd_send_multicast_skb(struct sk_buff *skb)
 	 *       we don't have to worry about it going away */
 
 	if (!netlink_has_listeners(sock, AUDIT_NLGRP_READLOG))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	/*
 	 * The seemingly wasteful skb_copy() rather than bumping the refcount
@@ -765,7 +798,10 @@ static void kauditd_send_multicast_skb(struct sk_buff *skb)
 	 */
 	copy = skb_copy(skb, GFP_KERNEL);
 	if (!copy)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	nlh = nlmsg_hdr(copy);
 	nlh->nlmsg_len = skb->len;
 
@@ -792,9 +828,11 @@ static int kauditd_thread(void *dummy)
 		rcu_read_lock();
 		ac = rcu_dereference(auditd_conn);
 		if (!ac) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			rcu_read_unlock();
 			goto main_queue;
 		}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		net = get_net(ac->net);
 		sk = audit_get_sk(net);
 		portid = ac->portid;
@@ -804,7 +842,9 @@ static int kauditd_thread(void *dummy)
 		rc = kauditd_send_queue(sk, portid,
 					&audit_hold_queue, UNICAST_RETRIES,
 					NULL, kauditd_rehold_skb);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (ac && rc < 0) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			sk = NULL;
 			auditd_reset(ac);
 			goto main_queue;
@@ -814,7 +854,9 @@ static int kauditd_thread(void *dummy)
 		rc = kauditd_send_queue(sk, portid,
 					&audit_retry_queue, UNICAST_RETRIES,
 					NULL, kauditd_hold_skb);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (ac && rc < 0) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			sk = NULL;
 			auditd_reset(ac);
 			goto main_queue;
@@ -830,11 +872,15 @@ static int kauditd_thread(void *dummy)
 					(sk ?
 					 kauditd_retry_skb : kauditd_hold_skb));
 		if (ac && rc < 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			auditd_reset(ac);
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		sk = NULL;
 
 		/* drop our netns reference, no auditd sends past this line */
 		if (net) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			put_net(net);
 			net = NULL;
 		}
@@ -850,6 +896,7 @@ static int kauditd_thread(void *dummy)
 				     (skb_queue_len(&audit_queue) ? 1 : 0));
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
@@ -863,6 +910,7 @@ int audit_send_list(void *_dest)
 	mutex_lock(&audit_cmd_mutex);
 	mutex_unlock(&audit_cmd_mutex);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	while ((skb = __skb_dequeue(&dest->q)) != NULL)
 		netlink_unicast(sk, skb, dest->portid, 0);
 
@@ -878,6 +926,7 @@ struct sk_buff *audit_make_reply(int seq, int type, int done,
 	struct sk_buff	*skb;
 	struct nlmsghdr	*nlh;
 	void		*data;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	int		flags = multi ? NLM_F_MULTI : 0;
 	int		t     = done  ? NLMSG_DONE  : type;
 
@@ -929,6 +978,7 @@ static int audit_send_reply_thread(void *arg)
 static void audit_send_reply(struct sk_buff *request_skb, int seq, int type, int done,
 			     int multi, const void *payload, int size)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct net *net = sock_net(NETLINK_CB(request_skb).sk);
 	struct sk_buff *skb;
 	struct task_struct *tsk;
@@ -974,7 +1024,9 @@ static int audit_netlink_ok(struct sk_buff *skb, u16 msg_type)
 	 * support non init namespaces!!
 	 */
 	if (current_user_ns() != &init_user_ns)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ECONNREFUSED;
+}
 
 	switch (msg_type) {
 	case AUDIT_LIST:
@@ -996,26 +1048,35 @@ static int audit_netlink_ok(struct sk_buff *skb, u16 msg_type)
 		/* Only support auditd and auditctl in initial pid namespace
 		 * for now. */
 		if (task_active_pid_ns(current) != &init_pid_ns)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -EPERM;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (!netlink_capable(skb, CAP_AUDIT_CONTROL))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			err = -EPERM;
+}
 		break;
 	case AUDIT_USER:
 	case AUDIT_FIRST_USER_MSG ... AUDIT_LAST_USER_MSG:
 	case AUDIT_FIRST_USER_MSG2 ... AUDIT_LAST_USER_MSG2:
 		if (!netlink_capable(skb, CAP_AUDIT_WRITE))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			err = -EPERM;
+}
 		break;
 	default:  /* bad msg */
 		err = -EINVAL;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return err;
 }
 
 static void audit_log_common_recv_msg(struct audit_buffer **ab, u16 msg_type)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	uid_t uid = from_kuid(&init_user_ns, current_uid());
 	pid_t pid = task_tgid_nr(current);
 
@@ -1034,6 +1095,7 @@ static void audit_log_common_recv_msg(struct audit_buffer **ab, u16 msg_type)
 
 int is_audit_feature_set(int i)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return af.features & AUDIT_FEATURE_TO_MASK(i);
 }
 
@@ -1055,7 +1117,9 @@ static void audit_log_feature_change(int which, u32 old_feature, u32 new_feature
 	struct audit_buffer *ab;
 
 	if (audit_enabled == AUDIT_OFF)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	ab = audit_log_start(NULL, GFP_KERNEL, AUDIT_FEATURE_CHANGE);
 	audit_log_task_info(ab, current);
@@ -1070,6 +1134,7 @@ static int audit_set_feature(struct sk_buff *skb)
 	struct audit_features *uaf;
 	int i;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	BUILD_BUG_ON(AUDIT_LAST_FEATURE + 1 > ARRAY_SIZE(audit_feature_names));
 	uaf = nlmsg_data(nlmsg_hdr(skb));
 
@@ -1131,7 +1196,9 @@ static int audit_replace(struct pid *pid)
 	pvnr = pid_vnr(pid);
 	skb = audit_make_reply(0, AUDIT_REPLACE, 0, 0, &pvnr, sizeof(pvnr));
 	if (!skb)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 	return auditd_send_unicast_skb(skb);
 }
 
@@ -1148,7 +1215,9 @@ static int audit_receive_msg(struct sk_buff *skb, struct nlmsghdr *nlh)
 
 	err = audit_netlink_ok(skb, msg_type);
 	if (err)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return err;
+}
 
 	seq  = nlh->nlmsg_seq;
 	data = nlmsg_data(nlh);
@@ -1177,15 +1246,23 @@ static int audit_receive_msg(struct sk_buff *skb, struct nlmsghdr *nlh)
 		/* guard against past and future API changes */
 		memcpy(&s, data, min_t(size_t, sizeof(s), nlmsg_len(nlh)));
 		if (s.mask & AUDIT_STATUS_ENABLED) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			err = audit_set_enabled(s.enabled);
 			if (err < 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				return err;
+}
 		}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (s.mask & AUDIT_STATUS_FAILURE) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			err = audit_set_failure(s.failure);
 			if (err < 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				return err;
+}
 		}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (s.mask & AUDIT_STATUS_PID) {
 			/* NOTE: we are using the vnr PID functions below
 			 *       because the s.pid value is relative to the
@@ -1200,7 +1277,9 @@ static int audit_receive_msg(struct sk_buff *skb, struct nlmsghdr *nlh)
 			/* Sanity check - PID values must match. Setting
 			 * pid to 0 is how auditd ends auditing. */
 			if (new_pid && (new_pid != pid_vnr(req_pid)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				return -EINVAL;
+}
 
 			/* test the auditd connection */
 			audit_replace(req_pid);
@@ -1209,18 +1288,21 @@ static int audit_receive_msg(struct sk_buff *skb, struct nlmsghdr *nlh)
 			if (auditd_pid) {
 				/* replacing a healthy auditd is not allowed */
 				if (new_pid) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 					audit_log_config_change("audit_pid",
 							new_pid, auditd_pid, 0);
 					return -EEXIST;
 				}
 				/* only current auditd can unregister itself */
 				if (pid_vnr(req_pid) != auditd_pid) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 					audit_log_config_change("audit_pid",
 							new_pid, auditd_pid, 0);
 					return -EACCES;
 				}
 			}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			if (new_pid) {
 				/* register a new auditd connection */
 				err = auditd_set(req_pid,
@@ -1231,41 +1313,67 @@ static int audit_receive_msg(struct sk_buff *skb, struct nlmsghdr *nlh)
 								new_pid,
 								auditd_pid,
 								err ? 0 : 1);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				if (err)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 					return err;
+}
 
 				/* try to process any backlog */
 				wake_up_interruptible(&kauditd_wait);
 			} else {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				if (audit_enabled != AUDIT_OFF)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 					audit_log_config_change("audit_pid",
 								new_pid,
 								auditd_pid, 1);
+}
 
 				/* unregister the auditd connection */
 				auditd_reset(NULL);
 			}
 		}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (s.mask & AUDIT_STATUS_RATE_LIMIT) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			err = audit_set_rate_limit(s.rate_limit);
 			if (err < 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				return err;
+}
 		}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (s.mask & AUDIT_STATUS_BACKLOG_LIMIT) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			err = audit_set_backlog_limit(s.backlog_limit);
 			if (err < 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				return err;
+}
 		}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (s.mask & AUDIT_STATUS_BACKLOG_WAIT_TIME) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			if (sizeof(s) > (size_t)nlh->nlmsg_len)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				return -EINVAL;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			if (s.backlog_wait_time > 10*AUDIT_BACKLOG_WAIT_TIME)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				return -EINVAL;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			err = audit_set_backlog_wait_time(s.backlog_wait_time);
 			if (err < 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				return err;
+}
 		}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (s.mask == AUDIT_STATUS_LOST) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			u32 lost = atomic_xchg(&audit_lost, 0);
 
 			audit_log_config_change("lost", 0, lost, 1);
@@ -1276,32 +1384,44 @@ static int audit_receive_msg(struct sk_buff *skb, struct nlmsghdr *nlh)
 	case AUDIT_GET_FEATURE:
 		err = audit_get_feature(skb);
 		if (err)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return err;
+}
 		break;
 	case AUDIT_SET_FEATURE:
 		err = audit_set_feature(skb);
 		if (err)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return err;
+}
 		break;
 	case AUDIT_USER:
 	case AUDIT_FIRST_USER_MSG ... AUDIT_LAST_USER_MSG:
 	case AUDIT_FIRST_USER_MSG2 ... AUDIT_LAST_USER_MSG2:
 		if (!audit_enabled && msg_type != AUDIT_USER_AVC)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return 0;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		err = audit_filter(msg_type, AUDIT_FILTER_USER);
 		if (err == 1) { /* match or error */
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			err = 0;
 			if (msg_type == AUDIT_USER_TTY) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				err = tty_audit_push();
 				if (err)
 					break;
 			}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			audit_log_common_recv_msg(&ab, msg_type);
 			if (msg_type != AUDIT_USER_TTY)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				audit_log_format(ab, " msg='%.*s'",
 						 AUDIT_MESSAGE_TEXT_MAX,
 						 (char *)data);
+}
 			else {
 				int size;
 
@@ -1310,21 +1430,28 @@ static int audit_receive_msg(struct sk_buff *skb, struct nlmsghdr *nlh)
 				if (size > 0 &&
 				    ((unsigned char *)data)[size - 1] == '\0')
 					size--;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				audit_log_n_untrustedstring(ab, data, size);
 			}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			audit_log_end(ab);
 		}
 		break;
 	case AUDIT_ADD_RULE:
 	case AUDIT_DEL_RULE:
 		if (nlmsg_len(nlh) < sizeof(struct audit_rule_data))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -EINVAL;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (audit_enabled == AUDIT_LOCKED) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			audit_log_common_recv_msg(&ab, AUDIT_CONFIG_CHANGE);
 			audit_log_format(ab, " audit_enabled=%d res=0", audit_enabled);
 			audit_log_end(ab);
 			return -EPERM;
 		}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		err = audit_rule_change(msg_type, seq, data, nlmsg_len(nlh));
 		break;
 	case AUDIT_LIST_RULES:
@@ -1345,16 +1472,20 @@ static int audit_receive_msg(struct sk_buff *skb, struct nlmsghdr *nlh)
 		err = -EINVAL;
 		if (msglen < 2 * sizeof(u32))
 			break;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		memcpy(sizes, bufp, 2 * sizeof(u32));
 		bufp += 2 * sizeof(u32);
 		msglen -= 2 * sizeof(u32);
 		old = audit_unpack_string(&bufp, &msglen, sizes[0]);
 		if (IS_ERR(old)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			err = PTR_ERR(old);
 			break;
 		}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		new = audit_unpack_string(&bufp, &msglen, sizes[1]);
 		if (IS_ERR(new)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			err = PTR_ERR(new);
 			kfree(old);
 			break;
@@ -1377,22 +1508,33 @@ static int audit_receive_msg(struct sk_buff *skb, struct nlmsghdr *nlh)
 	case AUDIT_SIGNAL_INFO:
 		len = 0;
 		if (audit_sig_sid) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			err = security_secid_to_secctx(audit_sig_sid, &ctx, &len);
 			if (err)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				return err;
+}
 		}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		sig_data = kmalloc(sizeof(*sig_data) + len, GFP_KERNEL);
 		if (!sig_data) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			if (audit_sig_sid)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				security_release_secctx(ctx, len);
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -ENOMEM;
 		}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		sig_data->uid = from_kuid(&init_user_ns, audit_sig_uid);
 		sig_data->pid = audit_sig_pid;
 		if (audit_sig_sid) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			memcpy(sig_data->ctx, ctx, len);
 			security_release_secctx(ctx, len);
 		}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		audit_send_reply(skb, seq, AUDIT_SIGNAL_INFO, 0, 0,
 				 sig_data, sizeof(*sig_data) + len);
 		kfree(sig_data);
@@ -1401,6 +1543,7 @@ static int audit_receive_msg(struct sk_buff *skb, struct nlmsghdr *nlh)
 		struct audit_tty_status s;
 		unsigned int t;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		t = READ_ONCE(current->signal->audit_tty);
 		s.enabled = t & AUDIT_TTY_ENABLE;
 		s.log_passwd = !!(t & AUDIT_TTY_LOG_PASSWD);
@@ -1421,12 +1564,18 @@ static int audit_receive_msg(struct sk_buff *skb, struct nlmsghdr *nlh)
 		    (s.log_passwd != 0 && s.log_passwd != 1))
 			err = -EINVAL;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (err)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			t = READ_ONCE(current->signal->audit_tty);
+}
 		else {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			t = s.enabled | (-s.log_passwd & AUDIT_TTY_LOG_PASSWD);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			t = xchg(&current->signal->audit_tty, t);
 		}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		old.enabled = t & AUDIT_TTY_ENABLE;
 		old.log_passwd = !!(t & AUDIT_TTY_LOG_PASSWD);
 
@@ -1443,6 +1592,7 @@ static int audit_receive_msg(struct sk_buff *skb, struct nlmsghdr *nlh)
 		break;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return err < 0 ? err : 0;
 }
 
@@ -1481,6 +1631,7 @@ static void audit_receive(struct sk_buff  *skb)
 /* Run custom bind function on netlink socket group connect or bind requests. */
 static int audit_bind(struct net *net, int group)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!capable(CAP_AUDIT_READ))
 		return -EPERM;
 
@@ -1500,6 +1651,7 @@ static int __net_init audit_net_init(struct net *net)
 
 	aunet->sk = netlink_kernel_create(net, NETLINK_AUDIT, &cfg);
 	if (aunet->sk == NULL) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		audit_panic("cannot initialize netlink socket in namespace");
 		return -ENOMEM;
 	}
@@ -1534,7 +1686,9 @@ static int __init audit_init(void)
 	int i;
 
 	if (audit_initialized == AUDIT_DISABLED)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	audit_buffer_cache = kmem_cache_create("audit_buffer",
 					       sizeof(struct audit_buffer),
@@ -1555,6 +1709,7 @@ static int __init audit_init(void)
 
 	kauditd_task = kthread_run(kauditd_thread, NULL, "kauditd");
 	if (IS_ERR(kauditd_task)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		int err = PTR_ERR(kauditd_task);
 		panic("audit: failed to start the kauditd thread (%d)\n", err);
 	}
@@ -1570,6 +1725,7 @@ __initcall(audit_init);
 /* Process kernel command-line parameter at boot time.  audit=0 or audit=1. */
 static int __init audit_enable(char *str)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	audit_default = !!simple_strtol(str, NULL, 0);
 	if (!audit_default)
 		audit_initialized = AUDIT_DISABLED;
@@ -1591,6 +1747,7 @@ static int __init audit_backlog_limit_set(char *str)
 
 	pr_info("audit_backlog_limit: ");
 	if (kstrtouint(str, 0, &audit_backlog_limit_arg)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_cont("using default of %u, unable to parse %s\n",
 			audit_backlog_limit, str);
 		return 1;
@@ -1606,7 +1763,9 @@ __setup("audit_backlog_limit=", audit_backlog_limit_set);
 static void audit_buffer_free(struct audit_buffer *ab)
 {
 	if (!ab)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	kfree_skb(ab->skb);
 	kmem_cache_free(audit_buffer_cache, ab);
@@ -1619,7 +1778,9 @@ static struct audit_buffer *audit_buffer_alloc(struct audit_context *ctx,
 
 	ab = kmem_cache_alloc(audit_buffer_cache, gfp_mask);
 	if (!ab)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 
 	ab->skb = nlmsg_new(AUDIT_BUFSIZ, gfp_mask);
 	if (!ab->skb)
@@ -1693,10 +1854,14 @@ struct audit_buffer *audit_log_start(struct audit_context *ctx, gfp_t gfp_mask,
 	unsigned int uninitialized_var(serial);
 
 	if (audit_initialized != AUDIT_INITIALIZED)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 
 	if (unlikely(!audit_filter(type, AUDIT_FILTER_TYPE)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 
 	/* NOTE: don't ever fail/sleep on these two conditions:
 	 * 1. auditd generated record - since we need auditd to drain the
@@ -1717,18 +1882,24 @@ struct audit_buffer *audit_log_start(struct audit_context *ctx, gfp_t gfp_mask,
 			/* sleep if we are allowed and we haven't exhausted our
 			 * backlog wait limit */
 			if (gfpflags_allow_blocking(gfp_mask) && (stime > 0)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				DECLARE_WAITQUEUE(wait, current);
 
 				add_wait_queue_exclusive(&audit_backlog_wait,
 							 &wait);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				set_current_state(TASK_UNINTERRUPTIBLE);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				stime = schedule_timeout(stime);
 				remove_wait_queue(&audit_backlog_wait, &wait);
 			} else {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				if (audit_rate_check() && printk_ratelimit())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 					pr_warn("audit_backlog=%d > audit_backlog_limit=%d\n",
 						skb_queue_len(&audit_queue),
 						audit_backlog_limit);
+}
 				audit_log_lost("backlog limit exceeded");
 				return NULL;
 			}
@@ -1737,6 +1908,7 @@ struct audit_buffer *audit_log_start(struct audit_context *ctx, gfp_t gfp_mask,
 
 	ab = audit_buffer_alloc(ctx, gfp_mask, type);
 	if (!ab) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		audit_log_lost("out of memory in audit_log_start");
 		return NULL;
 	}
@@ -1764,6 +1936,7 @@ static inline int audit_expand(struct audit_buffer *ab, int extra)
 	int newtail = skb_tailroom(skb);
 
 	if (ret < 0) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		audit_log_lost("out of memory in audit_expand");
 		return 0;
 	}
@@ -1786,12 +1959,16 @@ static void audit_log_vformat(struct audit_buffer *ab, const char *fmt,
 	va_list args2;
 
 	if (!ab)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	BUG_ON(!ab->skb);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	skb = ab->skb;
 	avail = skb_tailroom(skb);
 	if (avail == 0) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		avail = audit_expand(ab, AUDIT_BUFSIZ);
 		if (!avail)
 			goto out;
@@ -1806,6 +1983,7 @@ static void audit_log_vformat(struct audit_buffer *ab, const char *fmt,
 			max_t(unsigned, AUDIT_BUFSIZ, 1+len-avail));
 		if (!avail)
 			goto out_va_end;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		len = vsnprintf(skb_tail_pointer(skb), avail, fmt, args2);
 	}
 	if (len > 0)
@@ -1829,7 +2007,9 @@ void audit_log_format(struct audit_buffer *ab, const char *fmt, ...)
 	va_list args;
 
 	if (!ab)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 	va_start(args, fmt);
 	audit_log_vformat(ab, fmt, args);
 	va_end(args);
@@ -1854,7 +2034,9 @@ void audit_log_n_hex(struct audit_buffer *ab, const unsigned char *buf,
 	struct sk_buff *skb;
 
 	if (!ab)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	BUG_ON(!ab->skb);
 	skb = ab->skb;
@@ -1887,7 +2069,9 @@ void audit_log_n_string(struct audit_buffer *ab, const char *string,
 	struct sk_buff *skb;
 
 	if (!ab)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	BUG_ON(!ab->skb);
 	skb = ab->skb;
@@ -1915,6 +2099,7 @@ void audit_log_n_string(struct audit_buffer *ab, const char *string,
 bool audit_string_contains_control(const char *string, size_t len)
 {
 	const unsigned char *p;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (p = string; p < (const unsigned char *)string + len; p++) {
 		if (*p == '"' || *p < 0x21 || *p > 0x7e)
 			return true;
@@ -1939,6 +2124,7 @@ bool audit_string_contains_control(const char *string, size_t len)
 void audit_log_n_untrustedstring(struct audit_buffer *ab, const char *string,
 				 size_t len)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (audit_string_contains_control(string, len))
 		audit_log_n_hex(ab, string, len);
 	else
@@ -1955,6 +2141,7 @@ void audit_log_n_untrustedstring(struct audit_buffer *ab, const char *string,
  */
 void audit_log_untrustedstring(struct audit_buffer *ab, const char *string)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	audit_log_n_untrustedstring(ab, string, strlen(string));
 }
 
@@ -1965,7 +2152,9 @@ void audit_log_d_path(struct audit_buffer *ab, const char *prefix,
 	char *p, *pathname;
 
 	if (prefix)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		audit_log_format(ab, "%s", prefix);
+}
 
 	/* We will allow 11 spaces for ' (deleted)' to be appended */
 	pathname = kmalloc(PATH_MAX+11, ab->gfp_mask);
@@ -1984,6 +2173,7 @@ void audit_log_d_path(struct audit_buffer *ab, const char *prefix,
 
 void audit_log_session_info(struct audit_buffer *ab)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	unsigned int sessionid = audit_get_sessionid(current);
 	uid_t auid = from_kuid(&init_user_ns, audit_get_loginuid(current));
 
@@ -1992,6 +2182,7 @@ void audit_log_session_info(struct audit_buffer *ab)
 
 void audit_log_key(struct audit_buffer *ab, char *key)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	audit_log_format(ab, " key=");
 	if (key)
 		audit_log_untrustedstring(ab, key);
@@ -2004,6 +2195,7 @@ void audit_log_cap(struct audit_buffer *ab, char *prefix, kernel_cap_t *cap)
 	int i;
 
 	audit_log_format(ab, " %s=", prefix);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	CAP_FOR_EACH_U32(i) {
 		audit_log_format(ab, "%08x",
 				 cap->cap[CAP_LAST_U32 - i]);
@@ -2012,6 +2204,7 @@ void audit_log_cap(struct audit_buffer *ab, char *prefix, kernel_cap_t *cap)
 
 static void audit_log_fcaps(struct audit_buffer *ab, struct audit_names *name)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	audit_log_cap(ab, "cap_fp", &name->fcap.permitted);
 	audit_log_cap(ab, "cap_fi", &name->fcap.inheritable);
 	audit_log_format(ab, " cap_fe=%d cap_fver=%x",
@@ -2025,7 +2218,9 @@ static inline int audit_copy_fcaps(struct audit_names *name,
 	int rc;
 
 	if (!dentry)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	rc = get_vfs_caps_from_disk(dentry, &caps);
 	if (rc)
@@ -2044,6 +2239,7 @@ static inline int audit_copy_fcaps(struct audit_names *name,
 void audit_copy_inode(struct audit_names *name, const struct dentry *dentry,
 		      struct inode *inode)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	name->ino   = inode->i_ino;
 	name->dev   = inode->i_sb->s_dev;
 	name->mode  = inode->i_mode;
@@ -2068,7 +2264,9 @@ void audit_log_name(struct audit_context *context, struct audit_names *n,
 	struct audit_buffer *ab;
 	ab = audit_log_start(context, GFP_KERNEL, AUDIT_PATH);
 	if (!ab)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	audit_log_format(ab, "item=%d", record_num);
 
@@ -2154,7 +2352,9 @@ int audit_log_task_context(struct audit_buffer *ab)
 
 	security_task_getsecid(current, &sid);
 	if (!sid)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	error = security_secid_to_secctx(sid, &ctx, &len);
 	if (error) {
@@ -2181,6 +2381,7 @@ void audit_log_d_path_exe(struct audit_buffer *ab,
 	if (!mm)
 		goto out_null;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	exe_file = get_mm_exe_file(mm);
 	if (!exe_file)
 		goto out_null;
@@ -2197,6 +2398,7 @@ struct tty_struct *audit_get_tty(struct task_struct *tsk)
 	struct tty_struct *tty = NULL;
 	unsigned long flags;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_lock_irqsave(&tsk->sighand->siglock, flags);
 	if (tsk->signal)
 		tty = tty_kref_get(tsk->signal->tty);
@@ -2206,6 +2408,7 @@ struct tty_struct *audit_get_tty(struct task_struct *tsk)
 
 void audit_put_tty(struct tty_struct *tty)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	tty_kref_put(tty);
 }
 
@@ -2216,7 +2419,9 @@ void audit_log_task_info(struct audit_buffer *ab, struct task_struct *tsk)
 	struct tty_struct *tty;
 
 	if (!ab)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	/* tsk == current */
 	cred = current_cred();
@@ -2258,7 +2463,9 @@ void audit_log_link_denied(const char *operation, const struct path *link)
 
 	name = kzalloc(sizeof(*name), GFP_NOFS);
 	if (!name)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	/* Generate AUDIT_ANOM_LINK with subject, operation, outcome. */
 	ab = audit_log_start(current->audit_context, GFP_KERNEL,
@@ -2293,7 +2500,9 @@ void audit_log_end(struct audit_buffer *ab)
 	struct nlmsghdr *nlh;
 
 	if (!ab)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	if (audit_rate_check()) {
 		skb = ab->skb;
@@ -2308,7 +2517,9 @@ void audit_log_end(struct audit_buffer *ab)
 		skb_queue_tail(&audit_queue, skb);
 		wake_up_interruptible(&kauditd_wait);
 	} else
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		audit_log_lost("rate limit exceeded");
+}
 
 	audit_buffer_free(ab);
 }
@@ -2357,6 +2568,7 @@ void audit_log_secctx(struct audit_buffer *ab, u32 secid)
 	char *secctx;
 
 	if (security_secid_to_secctx(secid, &secctx, &len)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		audit_panic("Cannot convert secid to context");
 	} else {
 		audit_log_format(ab, " obj=%s", secctx);
diff --git a/kernel/audit_fsnotify.c b/kernel/audit_fsnotify.c
index 52f368b..cd23505 100644
--- a/kernel/audit_fsnotify.c
+++ b/kernel/audit_fsnotify.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /* audit_fsnotify.c -- tracking inodes
  *
  * Copyright 2003-2009,2014-2015 Red Hat, Inc.
@@ -49,6 +51,7 @@ static struct fsnotify_group *audit_fsnotify_group;
 
 static void audit_fsnotify_mark_free(struct audit_fsnotify_mark *audit_mark)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	kfree(audit_mark->path);
 	kfree(audit_mark);
 }
@@ -57,17 +60,20 @@ static void audit_fsnotify_free_mark(struct fsnotify_mark *mark)
 {
 	struct audit_fsnotify_mark *audit_mark;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	audit_mark = container_of(mark, struct audit_fsnotify_mark, mark);
 	audit_fsnotify_mark_free(audit_mark);
 }
 
 char *audit_mark_path(struct audit_fsnotify_mark *mark)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return mark->path;
 }
 
 int audit_mark_compare(struct audit_fsnotify_mark *mark, unsigned long ino, dev_t dev)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (mark->ino == AUDIT_INO_UNSET)
 		return 0;
 	return (mark->ino == ino) && (mark->dev == dev);
@@ -76,6 +82,7 @@ int audit_mark_compare(struct audit_fsnotify_mark *mark, unsigned long ino, dev_
 static void audit_update_mark(struct audit_fsnotify_mark *audit_mark,
 			     const struct inode *inode)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	audit_mark->dev = inode ? inode->i_sb->s_dev : AUDIT_DEV_UNSET;
 	audit_mark->ino = inode ? inode->i_ino : AUDIT_INO_UNSET;
 }
@@ -88,6 +95,7 @@ struct audit_fsnotify_mark *audit_alloc_mark(struct audit_krule *krule, char *pa
 	struct inode *inode;
 	int ret;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (pathname[0] != '/' || pathname[len-1] == '/')
 		return ERR_PTR(-EINVAL);
 
@@ -126,7 +134,9 @@ static void audit_mark_log_rule_change(struct audit_fsnotify_mark *audit_mark, c
 	struct audit_krule *rule = audit_mark->rule;
 
 	if (!audit_enabled)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 	ab = audit_log_start(NULL, GFP_NOFS, AUDIT_CONFIG_CHANGE);
 	if (unlikely(!ab))
 		return;
@@ -142,6 +152,7 @@ static void audit_mark_log_rule_change(struct audit_fsnotify_mark *audit_mark, c
 
 void audit_remove_mark(struct audit_fsnotify_mark *audit_mark)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	fsnotify_destroy_mark(&audit_mark->mark, audit_fsnotify_group);
 	fsnotify_put_mark(&audit_mark->mark);
 }
@@ -156,6 +167,7 @@ void audit_remove_mark_rule(struct audit_krule *krule)
 static void audit_autoremove_mark_rule(struct audit_fsnotify_mark *audit_mark)
 {
 	struct audit_krule *rule = audit_mark->rule;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct audit_entry *entry = container_of(rule, struct audit_entry, rule);
 
 	audit_mark_log_rule_change(audit_mark, "autoremove_rule");
@@ -174,6 +186,7 @@ static int audit_mark_handle_event(struct fsnotify_group *group,
 	struct audit_fsnotify_mark *audit_mark;
 	const struct inode *inode = NULL;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	audit_mark = container_of(inode_mark, struct audit_fsnotify_mark, mark);
 
 	BUG_ON(group != audit_fsnotify_group);
@@ -209,6 +222,7 @@ static int __init audit_fsnotify_init(void)
 {
 	audit_fsnotify_group = fsnotify_alloc_group(&audit_mark_fsnotify_ops);
 	if (IS_ERR(audit_fsnotify_group)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		audit_fsnotify_group = NULL;
 		audit_panic("cannot create audit fsnotify group");
 	}
diff --git a/kernel/audit_tree.c b/kernel/audit_tree.c
index d4b050d..f3fca30 100644
--- a/kernel/audit_tree.c
+++ b/kernel/audit_tree.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 #include "audit.h"
 #include <linux/fsnotify_backend.h>
@@ -168,6 +170,7 @@ static __cacheline_aligned_in_smp DEFINE_SPINLOCK(hash_lock);
 /* Function to return search key in our hash from inode. */
 static unsigned long inode_to_key(const struct inode *inode)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return (unsigned long)inode;
 }
 
@@ -195,6 +198,7 @@ static inline struct list_head *chunk_hash(unsigned long key)
 /* hash_lock & entry->lock is held by caller */
 static void insert_hash(struct audit_chunk *chunk)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	unsigned long key = chunk_to_key(chunk);
 	struct list_head *list;
 
@@ -207,6 +211,7 @@ static void insert_hash(struct audit_chunk *chunk)
 /* called under rcu_read_lock */
 struct audit_chunk *audit_tree_lookup(const struct inode *inode)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	unsigned long key = inode_to_key(inode);
 	struct list_head *list = chunk_hash(key);
 	struct audit_chunk *p;
@@ -223,6 +228,7 @@ struct audit_chunk *audit_tree_lookup(const struct inode *inode)
 bool audit_tree_match(struct audit_chunk *chunk, struct audit_tree *tree)
 {
 	int n;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (n = 0; n < chunk->count; n++)
 		if (chunk->owners[n].owner == tree)
 			return true;
@@ -235,11 +241,13 @@ static struct audit_chunk *find_chunk(struct node *p)
 {
 	int index = p->index & ~(1U<<31);
 	p -= index;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return container_of(p, struct audit_chunk, owners[0]);
 }
 
 static void untag_chunk(struct node *p)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct audit_chunk *chunk = find_chunk(p);
 	struct fsnotify_mark *entry = &chunk->mark;
 	struct audit_chunk *new = NULL;
@@ -351,7 +359,9 @@ static int create_chunk(struct inode *inode, struct audit_tree *tree)
 	struct fsnotify_mark *entry;
 	struct audit_chunk *chunk = alloc_chunk(1);
 	if (!chunk)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 
 	entry = &chunk->mark;
 	if (fsnotify_add_mark(entry, inode, NULL, 0)) {
@@ -396,7 +406,9 @@ static int tag_chunk(struct inode *inode, struct audit_tree *tree)
 	old_entry = fsnotify_find_mark(&inode->i_fsnotify_marks,
 				       audit_tree_group);
 	if (!old_entry)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return create_chunk(inode, tree);
+}
 
 	old = container_of(old_entry, struct audit_chunk, mark);
 
@@ -499,7 +511,9 @@ static void audit_tree_log_remove_rule(struct audit_krule *rule)
 
 	ab = audit_log_start(NULL, GFP_KERNEL, AUDIT_CONFIG_CHANGE);
 	if (unlikely(!ab))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 	audit_log_format(ab, "op=remove_rule");
 	audit_log_format(ab, " dir=");
 	audit_log_untrustedstring(ab, rule->tree->pathname);
@@ -513,6 +527,7 @@ static void kill_rules(struct audit_tree *tree)
 	struct audit_krule *rule, *next;
 	struct audit_entry *entry;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry_safe(rule, next, &tree->rules, rlist) {
 		entry = container_of(rule, struct audit_entry, rule);
 
@@ -535,6 +550,7 @@ static void kill_rules(struct audit_tree *tree)
  */
 static void prune_one(struct audit_tree *victim)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_lock(&hash_lock);
 	while (!list_empty(&victim->chunks)) {
 		struct node *p;
@@ -554,6 +570,7 @@ static void trim_marked(struct audit_tree *tree)
 	struct list_head *p, *q;
 	spin_lock(&hash_lock);
 	if (tree->goner) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		spin_unlock(&hash_lock);
 		return;
 	}
@@ -599,6 +616,7 @@ int audit_remove_tree_rule(struct audit_krule *rule)
 	struct audit_tree *tree;
 	tree = rule->tree;
 	if (tree) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		spin_lock(&hash_lock);
 		list_del_init(&rule->rlist);
 		if (list_empty(&tree->rules) && !tree->goner) {
@@ -620,6 +638,7 @@ int audit_remove_tree_rule(struct audit_krule *rule)
 
 static int compare_root(struct vfsmount *mnt, void *arg)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return inode_to_key(d_backing_inode(mnt->mnt_root)) ==
 	       (unsigned long)arg;
 }
@@ -630,6 +649,7 @@ void audit_trim_trees(void)
 
 	mutex_lock(&audit_filter_mutex);
 	list_add(&cursor, &tree_list);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	while (cursor.next != &tree_list) {
 		struct audit_tree *tree;
 		struct path path;
@@ -676,6 +696,7 @@ void audit_trim_trees(void)
 int audit_make_tree(struct audit_krule *rule, char *pathname, u32 op)
 {
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (pathname[0] != '/' ||
 	    rule->listnr != AUDIT_FILTER_EXIT ||
 	    op != Audit_equal ||
@@ -689,11 +710,13 @@ int audit_make_tree(struct audit_krule *rule, char *pathname, u32 op)
 
 void audit_put_tree(struct audit_tree *tree)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	put_tree(tree);
 }
 
 static int tag_mount(struct vfsmount *mnt, void *arg)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return tag_chunk(d_backing_inode(mnt->mnt_root), arg);
 }
 
@@ -704,6 +727,7 @@ static int tag_mount(struct vfsmount *mnt, void *arg)
 static int prune_tree_thread(void *unused)
 {
 	for (;;) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (list_empty(&prune_list)) {
 			set_current_state(TASK_INTERRUPTIBLE);
 			schedule();
@@ -734,6 +758,7 @@ static int prune_tree_thread(void *unused)
 
 static int audit_launch_prune(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (prune_thread)
 		return 0;
 	prune_thread = kthread_run(prune_tree_thread, NULL,
@@ -755,6 +780,7 @@ int audit_add_tree_rule(struct audit_krule *rule)
 	int err;
 
 	rule->tree = NULL;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry(tree, &tree_list, list) {
 		if (!strcmp(seed->pathname, tree->pathname)) {
 			put_tree(seed);
@@ -827,7 +853,9 @@ int audit_tag_tree(char *old, char *new)
 
 	err = kern_path(new, 0, &path2);
 	if (err)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return err;
+}
 	tagged = collect_mounts(&path2);
 	path_put(&path2);
 	if (IS_ERR(tagged))
@@ -915,6 +943,7 @@ int audit_tag_tree(char *old, char *new)
 
 static void audit_schedule_prune(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	wake_up_process(prune_thread);
 }
 
@@ -924,6 +953,7 @@ static void audit_schedule_prune(void)
  */
 void audit_kill_trees(struct list_head *list)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	mutex_lock(&audit_cmd_mutex);
 	mutex_lock(&audit_filter_mutex);
 
@@ -957,7 +987,9 @@ static void evict_chunk(struct audit_chunk *chunk)
 	int n;
 
 	if (chunk->dead)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	chunk->dead = 1;
 	mutex_lock(&audit_filter_mutex);
@@ -995,11 +1027,13 @@ static int audit_tree_handle_event(struct fsnotify_group *group,
 				   const unsigned char *file_name, u32 cookie,
 				   struct fsnotify_iter_info *iter_info)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
 static void audit_tree_freeing_mark(struct fsnotify_mark *entry, struct fsnotify_group *group)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct audit_chunk *chunk = container_of(entry, struct audit_chunk, mark);
 
 	evict_chunk(chunk);
@@ -1023,7 +1057,9 @@ static int __init audit_tree_init(void)
 
 	audit_tree_group = fsnotify_alloc_group(&audit_tree_ops);
 	if (IS_ERR(audit_tree_group))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		audit_panic("cannot initialize fsnotify group for rectree watches");
+}
 
 	for (i = 0; i < HASH_SIZE; i++)
 		INIT_LIST_HEAD(&chunk_hash_heads[i]);
diff --git a/kernel/audit_watch.c b/kernel/audit_watch.c
index 9eb8b35..24a3a325 100644
--- a/kernel/audit_watch.c
+++ b/kernel/audit_watch.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /* audit_watch.c -- watching inodes
  *
  * Copyright 2003-2009 Red Hat, Inc.
@@ -70,6 +72,7 @@ static struct fsnotify_group *audit_watch_group;
 
 static void audit_free_parent(struct audit_parent *parent)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WARN_ON(!list_empty(&parent->watches));
 	kfree(parent);
 }
@@ -78,18 +81,21 @@ static void audit_watch_free_mark(struct fsnotify_mark *entry)
 {
 	struct audit_parent *parent;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	parent = container_of(entry, struct audit_parent, mark);
 	audit_free_parent(parent);
 }
 
 static void audit_get_parent(struct audit_parent *parent)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (likely(parent))
 		fsnotify_get_mark(&parent->mark);
 }
 
 static void audit_put_parent(struct audit_parent *parent)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (likely(parent))
 		fsnotify_put_mark(&parent->mark);
 }
@@ -105,18 +111,22 @@ static inline struct audit_parent *audit_find_parent(struct inode *inode)
 
 	entry = fsnotify_find_mark(&inode->i_fsnotify_marks, audit_watch_group);
 	if (entry)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		parent = container_of(entry, struct audit_parent, mark);
+}
 
 	return parent;
 }
 
 void audit_get_watch(struct audit_watch *watch)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	refcount_inc(&watch->count);
 }
 
 void audit_put_watch(struct audit_watch *watch)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (refcount_dec_and_test(&watch->count)) {
 		WARN_ON(watch->parent);
 		WARN_ON(!list_empty(&watch->rules));
@@ -127,6 +137,7 @@ void audit_put_watch(struct audit_watch *watch)
 
 static void audit_remove_watch(struct audit_watch *watch)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_del(&watch->wlist);
 	audit_put_parent(watch->parent);
 	watch->parent = NULL;
@@ -135,11 +146,13 @@ static void audit_remove_watch(struct audit_watch *watch)
 
 char *audit_watch_path(struct audit_watch *watch)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return watch->path;
 }
 
 int audit_watch_compare(struct audit_watch *watch, unsigned long ino, dev_t dev)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return (watch->ino != AUDIT_INO_UNSET) &&
 		(watch->ino == ino) &&
 		(watch->dev == dev);
@@ -148,6 +161,7 @@ int audit_watch_compare(struct audit_watch *watch, unsigned long ino, dev_t dev)
 /* Initialize a parent watch entry. */
 static struct audit_parent *audit_init_parent(struct path *path)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct inode *inode = d_backing_inode(path->dentry);
 	struct audit_parent *parent;
 	int ret;
@@ -176,7 +190,9 @@ static struct audit_watch *audit_init_watch(char *path)
 
 	watch = kzalloc(sizeof(*watch), GFP_KERNEL);
 	if (unlikely(!watch))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ERR_PTR(-ENOMEM);
+}
 
 	INIT_LIST_HEAD(&watch->rules);
 	refcount_set(&watch->count, 1);
@@ -193,7 +209,9 @@ int audit_to_watch(struct audit_krule *krule, char *path, int len, u32 op)
 	struct audit_watch *watch;
 
 	if (!audit_watch_group)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EOPNOTSUPP;
+}
 
 	if (path[0] != '/' || path[len-1] == '/' ||
 	    krule->listnr != AUDIT_FILTER_EXIT ||
@@ -219,7 +237,9 @@ static struct audit_watch *audit_dupe_watch(struct audit_watch *old)
 
 	path = kstrdup(old->path, GFP_KERNEL);
 	if (unlikely(!path))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ERR_PTR(-ENOMEM);
+}
 
 	new = audit_init_watch(path);
 	if (IS_ERR(new)) {
@@ -238,6 +258,7 @@ static struct audit_watch *audit_dupe_watch(struct audit_watch *old)
 
 static void audit_watch_log_rule_change(struct audit_krule *r, struct audit_watch *w, char *op)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (audit_enabled) {
 		struct audit_buffer *ab;
 		ab = audit_log_start(NULL, GFP_NOFS, AUDIT_CONFIG_CHANGE);
@@ -341,6 +362,7 @@ static void audit_remove_parent_watches(struct audit_parent *parent)
 	struct audit_entry *e;
 
 	mutex_lock(&audit_filter_mutex);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry_safe(w, nextw, &parent->watches, wlist) {
 		list_for_each_entry_safe(r, nextr, &w->rules, rlist) {
 			e = container_of(r, struct audit_entry, rule);
@@ -362,6 +384,7 @@ static void audit_remove_parent_watches(struct audit_parent *parent)
 /* Get path information necessary for adding watches. */
 static int audit_get_nd(struct audit_watch *watch, struct path *parent)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct dentry *d = kern_path_locked(watch->path, parent);
 	if (IS_ERR(d))
 		return PTR_ERR(d);
@@ -383,6 +406,7 @@ static void audit_add_to_parent(struct audit_krule *krule,
 	struct audit_watch *w, *watch = krule->watch;
 	int watch_found = 0;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	BUG_ON(!mutex_is_locked(&audit_filter_mutex));
 
 	list_for_each_entry(w, &parent->watches, wlist) {
@@ -428,7 +452,9 @@ int audit_add_watch(struct audit_krule *krule, struct list_head **list)
 	mutex_lock(&audit_filter_mutex);
 
 	if (ret)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ret;
+}
 
 	/* either find an old parent or attach a new one */
 	parent = audit_find_parent(d_backing_inode(parent_path.dentry));
@@ -481,6 +507,7 @@ static int audit_watch_handle_event(struct fsnotify_group *group,
 	const struct inode *inode;
 	struct audit_parent *parent;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	parent = container_of(inode_mark, struct audit_parent, mark);
 
 	BUG_ON(group != audit_watch_group);
@@ -517,6 +544,7 @@ static int __init audit_watch_init(void)
 {
 	audit_watch_group = fsnotify_alloc_group(&audit_watch_fsnotify_ops);
 	if (IS_ERR(audit_watch_group)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		audit_watch_group = NULL;
 		audit_panic("cannot create audit fsnotify group");
 	}
@@ -531,7 +559,9 @@ int audit_dupe_exe(struct audit_krule *new, struct audit_krule *old)
 
 	pathname = kstrdup(audit_mark_path(old->exe), GFP_KERNEL);
 	if (!pathname)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 
 	audit_mark = audit_alloc_mark(new, pathname, strlen(pathname));
 	if (IS_ERR(audit_mark)) {
@@ -551,7 +581,9 @@ int audit_exe_compare(struct task_struct *tsk, struct audit_fsnotify_mark *mark)
 
 	exe_file = get_task_exe_file(tsk);
 	if (!exe_file)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 	ino = file_inode(exe_file)->i_ino;
 	dev = file_inode(exe_file)->i_sb->s_dev;
 	fput(exe_file);
diff --git a/kernel/auditfilter.c b/kernel/auditfilter.c
index 0b0aa58..dd9452f 100644
--- a/kernel/auditfilter.c
+++ b/kernel/auditfilter.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /* auditfilter.c -- filtering of audit events
  *
  * Copyright 2003-2004 Red Hat, Inc.
@@ -73,6 +75,7 @@ DEFINE_MUTEX(audit_filter_mutex);
 
 static void audit_free_lsm_field(struct audit_field *f)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	switch (f->type) {
 	case AUDIT_SUBJ_USER:
 	case AUDIT_SUBJ_ROLE:
@@ -96,7 +99,9 @@ static inline void audit_free_rule(struct audit_entry *e)
 
 	/* some rules don't have associated watches */
 	if (erule->watch)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		audit_put_watch(erule->watch);
+}
 	if (erule->fields)
 		for (i = 0; i < erule->field_count; i++)
 			audit_free_lsm_field(&erule->fields[i]);
@@ -107,6 +112,7 @@ static inline void audit_free_rule(struct audit_entry *e)
 
 void audit_free_rule_rcu(struct rcu_head *head)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct audit_entry *e = container_of(head, struct audit_entry, rcu);
 	audit_free_rule(e);
 }
@@ -119,7 +125,9 @@ static inline struct audit_entry *audit_init_entry(u32 field_count)
 
 	entry = kzalloc(sizeof(*entry), GFP_KERNEL);
 	if (unlikely(!entry))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 
 	fields = kcalloc(field_count, sizeof(*fields), GFP_KERNEL);
 	if (unlikely(!fields)) {
@@ -137,6 +145,7 @@ char *audit_unpack_string(void **bufp, size_t *remain, size_t len)
 {
 	char *str;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!*bufp || (len == 0) || (len > *remain))
 		return ERR_PTR(-EINVAL);
 
@@ -162,6 +171,7 @@ char *audit_unpack_string(void **bufp, size_t *remain, size_t len)
 static inline int audit_to_inode(struct audit_krule *krule,
 				 struct audit_field *f)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (krule->listnr != AUDIT_FILTER_EXIT ||
 	    krule->inode_f || krule->watch || krule->tree ||
 	    (f->op != Audit_equal && f->op != Audit_not_equal))
@@ -175,18 +185,23 @@ static __u32 *classes[AUDIT_SYSCALL_CLASSES];
 
 int __init audit_register_class(int class, unsigned *list)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	__u32 *p = kcalloc(AUDIT_BITMASK_SIZE, sizeof(__u32), GFP_KERNEL);
 	if (!p)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 	while (*list != ~0U) {
 		unsigned n = *list++;
 		if (n >= AUDIT_BITMASK_SIZE * 32 - AUDIT_SYSCALL_CLASSES) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			kfree(p);
 			return -EINVAL;
 		}
 		p[AUDIT_WORD(n)] |= AUDIT_BIT(n);
 	}
 	if (class >= AUDIT_SYSCALL_CLASSES || classes[class]) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		kfree(p);
 		return -EINVAL;
 	}
@@ -196,6 +211,7 @@ int __init audit_register_class(int class, unsigned *list)
 
 int audit_match_class(int class, unsigned syscall)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (unlikely(syscall >= AUDIT_BITMASK_SIZE * 32))
 		return 0;
 	if (unlikely(class >= AUDIT_SYSCALL_CLASSES || !classes[class]))
@@ -209,6 +225,7 @@ static inline int audit_match_class_bits(int class, u32 *mask)
 	int i;
 
 	if (classes[class]) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		for (i = 0; i < AUDIT_BITMASK_SIZE; i++)
 			if (mask[i] & classes[class][i])
 				return 0;
@@ -324,6 +341,7 @@ static u32 audit_ops[] =
 static u32 audit_to_op(u32 op)
 {
 	u32 n;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (n = Audit_equal; n < Audit_bad && audit_ops[n] != op; n++)
 		;
 	return n;
@@ -332,6 +350,7 @@ static u32 audit_to_op(u32 op)
 /* check if an audit field is valid */
 static int audit_field_valid(struct audit_entry *entry, struct audit_field *f)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	switch(f->type) {
 	case AUDIT_MSGTYPE:
 		if (entry->rule.listnr != AUDIT_FILTER_TYPE &&
@@ -432,6 +451,7 @@ static struct audit_entry *audit_data_to_entry(struct audit_rule_data *data,
 	if (IS_ERR(entry))
 		goto exit_nofree;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	bufp = data->buf;
 	for (i = 0; i < data->field_count; i++) {
 		struct audit_field *f = &entry->rule.fields[i];
@@ -587,6 +607,7 @@ static struct audit_entry *audit_data_to_entry(struct audit_rule_data *data,
 /* Pack a filter field's string representation into data block. */
 static inline size_t audit_pack_string(void **bufp, const char *str)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	size_t len = strlen(str);
 
 	memcpy(*bufp, str, len);
@@ -604,7 +625,9 @@ static struct audit_rule_data *audit_krule_to_data(struct audit_krule *krule)
 
 	data = kmalloc(sizeof(*data) + krule->buflen, GFP_KERNEL);
 	if (unlikely(!data))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 	memset(data, 0, sizeof(*data));
 
 	data->flags = krule->flags | krule->listnr;
@@ -758,7 +781,9 @@ static inline int audit_dupe_lsm_field(struct audit_field *df,
 	/* our own copy of lsm_str */
 	lsm_str = kstrdup(sf->lsm_str, GFP_KERNEL);
 	if (unlikely(!lsm_str))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 	df->lsm_str = lsm_str;
 
 	/* our own (refreshed) copy of lsm_rule */
@@ -791,7 +816,9 @@ struct audit_entry *audit_dupe_rule(struct audit_krule *old)
 
 	entry = audit_init_entry(fcount);
 	if (unlikely(!entry))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ERR_PTR(-ENOMEM);
+}
 
 	new = &entry->rule;
 	new->flags = old->flags;
@@ -869,6 +896,7 @@ static struct audit_entry *audit_find_rule(struct audit_entry *entry,
 	int h;
 
 	if (entry->rule.inode_f) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		h = audit_hash_ino(entry->rule.inode_f->val);
 		*p = list = &audit_inode_hash[h];
 	} else if (entry->rule.watch) {
@@ -1069,7 +1097,9 @@ static void audit_log_rule_change(char *action, struct audit_krule *rule, int re
 	unsigned int sessionid = audit_get_sessionid(current);
 
 	if (!audit_enabled)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	ab = audit_log_start(NULL, GFP_KERNEL, AUDIT_CONFIG_CHANGE);
 	if (!ab)
@@ -1096,7 +1126,9 @@ int audit_rule_change(int type, int seq, void *data, size_t datasz)
 
 	entry = audit_data_to_entry(data, datasz);
 	if (IS_ERR(entry))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return PTR_ERR(entry);
+}
 
 	switch (type) {
 	case AUDIT_ADD_RULE:
@@ -1142,7 +1174,9 @@ int audit_list_rules_send(struct sk_buff *request_skb, int seq)
 
 	dest = kmalloc(sizeof(struct audit_netlink_list), GFP_KERNEL);
 	if (!dest)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 	dest->net = get_net(net);
 	dest->portid = portid;
 	skb_queue_head_init(&dest->q);
@@ -1163,6 +1197,7 @@ int audit_list_rules_send(struct sk_buff *request_skb, int seq)
 
 int audit_comparator(u32 left, u32 op, u32 right)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	switch (op) {
 	case Audit_equal:
 		return (left == right);
@@ -1188,6 +1223,7 @@ int audit_comparator(u32 left, u32 op, u32 right)
 
 int audit_uid_comparator(kuid_t left, u32 op, kuid_t right)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	switch (op) {
 	case Audit_equal:
 		return uid_eq(left, right);
@@ -1211,6 +1247,7 @@ int audit_uid_comparator(kuid_t left, u32 op, kuid_t right)
 
 int audit_gid_comparator(kgid_t left, u32 op, kgid_t right)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	switch (op) {
 	case Audit_equal:
 		return gid_eq(left, right);
@@ -1244,7 +1281,9 @@ int parent_len(const char *path)
 	plen = strlen(path);
 
 	if (plen == 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return plen;
+}
 
 	/* disregard trailing slashes */
 	p = path + plen - 1;
@@ -1278,7 +1317,9 @@ int audit_compare_dname_path(const char *dname, const char *path, int parentlen)
 	dlen = strlen(dname);
 	pathlen = strlen(path);
 	if (pathlen < dlen)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 1;
+}
 
 	parentlen = parentlen == AUDIT_NAME_FULL ? parent_len(path) : parentlen;
 	if (pathlen - parentlen != dlen)
@@ -1297,9 +1338,11 @@ int audit_filter(int msgtype, unsigned int listtype)
 	rcu_read_lock();
 	if (list_empty(&audit_filter_list[listtype]))
 		goto unlock_and_return;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry_rcu(e, &audit_filter_list[listtype], list) {
 		int i, result = 0;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		for (i = 0; i < e->rule.field_count; i++) {
 			struct audit_field *f = &e->rule.fields[i];
 			pid_t pid;
@@ -1333,6 +1376,7 @@ int audit_filter(int msgtype, unsigned int listtype)
 			case AUDIT_SUBJ_SEN:
 			case AUDIT_SUBJ_CLR:
 				if (f->lsm_rule) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 					security_task_getsecid(current, &sid);
 					result = security_audit_rule_match(sid,
 							f->type, f->op, f->lsm_rule, NULL);
@@ -1341,14 +1385,20 @@ int audit_filter(int msgtype, unsigned int listtype)
 			default:
 				goto unlock_and_return;
 			}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			if (result < 0) /* error */
 				goto unlock_and_return;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			if (!result)
 				break;
 		}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (result > 0) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			if (e->rule.action == AUDIT_NEVER || listtype == AUDIT_FILTER_TYPE)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				ret = 0;
+}
 			break;
 		}
 	}
@@ -1359,6 +1409,7 @@ int audit_filter(int msgtype, unsigned int listtype)
 
 static int update_lsm_rule(struct audit_krule *r)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct audit_entry *entry = container_of(r, struct audit_entry, rule);
 	struct audit_entry *nentry;
 	int err = 0;
@@ -1402,6 +1453,7 @@ int audit_update_lsm_rules(void)
 	/* audit_filter_mutex synchronizes the writers */
 	mutex_lock(&audit_filter_mutex);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (i = 0; i < AUDIT_NR_FILTERS; i++) {
 		list_for_each_entry_safe(r, n, &audit_rules_list[i], list) {
 			int res = update_lsm_rule(r);
diff --git a/kernel/auditsc.c b/kernel/auditsc.c
index ecc23e2..0897b33 100644
--- a/kernel/auditsc.c
+++ b/kernel/auditsc.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /* auditsc.c -- System-call auditing support
  * Handles all system-call specific auditing features.
  *
@@ -134,7 +136,9 @@ static int audit_match_perm(struct audit_context *ctx, int mask)
 {
 	unsigned n;
 	if (unlikely(!ctx))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 	n = ctx->major;
 
 	switch (audit_classify_syscall(ctx->arch, n)) {
@@ -179,7 +183,9 @@ static int audit_match_filetype(struct audit_context *ctx, int val)
 	umode_t mode = (umode_t)val;
 
 	if (unlikely(!ctx))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	list_for_each_entry(n, &ctx->names_list, list) {
 		if ((n->ino != AUDIT_INO_UNSET) &&
@@ -203,6 +209,7 @@ static int audit_match_filetype(struct audit_context *ctx, int val)
 #ifdef CONFIG_AUDIT_TREE
 static void audit_set_auditable(struct audit_context *ctx)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!ctx->prio) {
 		ctx->prio = 1;
 		ctx->current_state = AUDIT_RECORD_CONTEXT;
@@ -214,6 +221,7 @@ static int put_tree_ref(struct audit_context *ctx, struct audit_chunk *chunk)
 	struct audit_tree_refs *p = ctx->trees;
 	int left = ctx->tree_count;
 	if (likely(left)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		p->c[--left] = chunk;
 		ctx->tree_count = left;
 		return 1;
@@ -235,6 +243,7 @@ static int grow_tree_refs(struct audit_context *ctx)
 	struct audit_tree_refs *p = ctx->trees;
 	ctx->trees = kzalloc(sizeof(struct audit_tree_refs), GFP_KERNEL);
 	if (!ctx->trees) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ctx->trees = p;
 		return 0;
 	}
@@ -280,6 +289,7 @@ static void unroll_tree_refs(struct audit_context *ctx,
 static void free_tree_refs(struct audit_context *ctx)
 {
 	struct audit_tree_refs *p, *q;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (p = ctx->first_trees; p; p = q) {
 		q = p->next;
 		kfree(p);
@@ -292,7 +302,9 @@ static int match_tree_refs(struct audit_context *ctx, struct audit_tree *tree)
 	struct audit_tree_refs *p;
 	int n;
 	if (!tree)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 	/* full ones */
 	for (p = ctx->first_trees; p != ctx->trees; p = p->next) {
 		for (n = 0; n < 31; n++)
@@ -318,6 +330,7 @@ static int audit_compare_uid(kuid_t uid,
 	int rc;
  
 	if (name) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		rc = audit_uid_comparator(uid, f->op, name->uid);
 		if (rc)
 			return rc;
@@ -342,6 +355,7 @@ static int audit_compare_gid(kgid_t gid,
 	int rc;
  
 	if (name) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		rc = audit_gid_comparator(gid, f->op, name->gid);
 		if (rc)
 			return rc;
@@ -363,6 +377,7 @@ static int audit_field_compare(struct task_struct *tsk,
 			       struct audit_context *ctx,
 			       struct audit_names *name)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	switch (f->val) {
 	/* process to file object comparisons */
 	case AUDIT_COMPARE_UID_TO_OBJ_UID:
@@ -449,6 +464,7 @@ static int audit_filter_rules(struct task_struct *tsk,
 	u32 sid;
 	unsigned int sessionid;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	cred = rcu_dereference_check(tsk->cred, tsk == current || task_creation);
 
 	for (i = 0; i < rule->field_count; i++) {
@@ -722,6 +738,7 @@ static enum audit_state audit_filter_task(struct task_struct *tsk, char **key)
 	enum audit_state   state;
 
 	rcu_read_lock();
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry_rcu(e, &audit_filter_list[AUDIT_FILTER_TASK], list) {
 		if (audit_filter_rules(tsk, &e->rule, NULL, NULL,
 				       &state, true)) {
@@ -740,7 +757,9 @@ static int audit_in_mask(const struct audit_krule *rule, unsigned long val)
 	int word, bit;
 
 	if (val > 0xffffffff)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return false;
+}
 
 	word = AUDIT_WORD(val);
 	if (word >= AUDIT_BITMASK_SIZE)
@@ -764,7 +783,9 @@ static enum audit_state audit_filter_syscall(struct task_struct *tsk,
 	enum audit_state state;
 
 	if (auditd_test_task(tsk))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return AUDIT_DISABLED;
+}
 
 	rcu_read_lock();
 	if (!list_empty(list)) {
diff --git a/kernel/bpf/cgroup.c b/kernel/bpf/cgroup.c
index 5461134..1e57fbf 100644
--- a/kernel/bpf/cgroup.c
+++ b/kernel/bpf/cgroup.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * Functions to manage eBPF programs attached to cgroups
  *
diff --git a/kernel/bpf/core.c b/kernel/bpf/core.c
index d203a5d6..5aa41e1 100644
--- a/kernel/bpf/core.c
+++ b/kernel/bpf/core.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * Linux Socket Filter - Kernel level socket filtering
  *
@@ -64,7 +66,9 @@ void *bpf_internal_load_pointer_neg_helper(const struct sk_buff *skb, int k, uns
 	u8 *ptr = NULL;
 
 	if (k >= SKF_NET_OFF)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ptr = skb_network_header(skb) + k - SKF_NET_OFF;
+}
 	else if (k >= SKF_LL_OFF)
 		ptr = skb_mac_header(skb) + k - SKF_LL_OFF;
 
@@ -83,10 +87,13 @@ struct bpf_prog *bpf_prog_alloc(unsigned int size, gfp_t gfp_extra_flags)
 	size = round_up(size, PAGE_SIZE);
 	fp = __vmalloc(size, gfp_flags, PAGE_KERNEL);
 	if (fp == NULL)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 
 	aux = kzalloc(sizeof(*aux), GFP_KERNEL | gfp_extra_flags);
 	if (aux == NULL) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		vfree(fp);
 		return NULL;
 	}
@@ -114,17 +121,25 @@ struct bpf_prog *bpf_prog_realloc(struct bpf_prog *fp_old, unsigned int size,
 	size = round_up(size, PAGE_SIZE);
 	pages = size / PAGE_SIZE;
 	if (pages <= fp_old->pages)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return fp_old;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	delta = pages - fp_old->pages;
 	ret = __bpf_prog_charge(fp_old->aux->user, delta);
 	if (ret)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	fp = __vmalloc(size, gfp_flags, PAGE_KERNEL);
 	if (fp == NULL) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		__bpf_prog_uncharge(fp_old->aux->user, delta);
 	} else {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		memcpy(fp, fp_old, fp_old->pages * PAGE_SIZE);
 		fp->pages = pages;
 		fp->aux->prog = fp;
@@ -136,6 +151,7 @@ struct bpf_prog *bpf_prog_realloc(struct bpf_prog *fp_old, unsigned int size,
 		__bpf_prog_free(fp_old);
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return fp;
 }
 
@@ -160,7 +176,9 @@ int bpf_prog_calc_tag(struct bpf_prog *fp)
 
 	raw = vmalloc(raw_size);
 	if (!raw)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 
 	sha_init(digest);
 	memset(ws, 0, sizeof(ws));
@@ -219,6 +237,7 @@ int bpf_prog_calc_tag(struct bpf_prog *fp)
 
 static bool bpf_is_jmp_and_has_target(const struct bpf_insn *insn)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return BPF_CLASS(insn->code) == BPF_JMP  &&
 	       /* Call and Exit are both special jumps with no
 		* target inside the BPF instruction image.
@@ -232,6 +251,7 @@ static void bpf_adj_branches(struct bpf_prog *prog, u32 pos, u32 delta)
 	struct bpf_insn *insn = prog->insnsi;
 	u32 i, insn_cnt = prog->len;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (i = 0; i < insn_cnt; i++, insn++) {
 		if (!bpf_is_jmp_and_has_target(insn))
 			continue;
@@ -252,6 +272,7 @@ struct bpf_prog *bpf_patch_insn_single(struct bpf_prog *prog, u32 off,
 
 	/* Since our patchlet doesn't expand the image, we're done. */
 	if (insn_delta == 0) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		memcpy(prog->insnsi + off, patch, sizeof(*patch));
 		return prog;
 	}
@@ -1316,6 +1337,7 @@ static unsigned int __bpf_prog_ret0(const void *ctx,
 bool bpf_prog_array_compatible(struct bpf_array *array,
 			       const struct bpf_prog *fp)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!array->owner_prog_type) {
 		/* There's no owner yet where we could check for
 		 * compatibility.
@@ -1342,11 +1364,15 @@ static int bpf_check_tail_call(const struct bpf_prog *fp)
 		if (map->map_type != BPF_MAP_TYPE_PROG_ARRAY)
 			continue;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		array = container_of(map, struct bpf_array, map);
 		if (!bpf_prog_array_compatible(array, fp))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -EINVAL;
+}
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
@@ -1398,6 +1424,7 @@ static void bpf_prog_free_deferred(struct work_struct *work)
 {
 	struct bpf_prog_aux *aux;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	aux = container_of(work, struct bpf_prog_aux, work);
 	bpf_jit_free(aux->prog);
 }
@@ -1417,6 +1444,7 @@ static DEFINE_PER_CPU(struct rnd_state, bpf_user_rnd_state);
 
 void bpf_user_rnd_init_once(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	prandom_init_once(&bpf_user_rnd_state);
 }
 
@@ -1435,6 +1463,7 @@ BPF_CALL_0(bpf_user_rnd_u32)
 	res = prandom_u32_state(state);
 	put_cpu_var(bpf_user_rnd_state);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return res;
 }
 
@@ -1455,6 +1484,7 @@ const struct bpf_func_proto bpf_sock_map_update_proto __weak;
 
 const struct bpf_func_proto * __weak bpf_get_trace_printk_proto(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return NULL;
 }
 
@@ -1462,6 +1492,7 @@ u64 __weak
 bpf_event_output(struct bpf_map *map, u64 flags, void *meta, u64 meta_size,
 		 void *ctx, u64 ctx_size, bpf_ctx_copy_t ctx_copy)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return -ENOTSUPP;
 }
 
@@ -1481,6 +1512,7 @@ const struct bpf_func_proto bpf_tail_call_proto = {
  */
 struct bpf_prog * __weak bpf_int_jit_compile(struct bpf_prog *prog)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return prog;
 }
 
@@ -1493,6 +1525,7 @@ void __weak bpf_jit_compile(struct bpf_prog *prog)
 
 bool __weak bpf_helper_changes_pkt_data(void *func)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return false;
 }
 
@@ -1502,6 +1535,7 @@ bool __weak bpf_helper_changes_pkt_data(void *func)
 int __weak skb_copy_bits(const struct sk_buff *skb, int offset, void *to,
 			 int len)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return -EFAULT;
 }
 
diff --git a/kernel/bpf/devmap.c b/kernel/bpf/devmap.c
index e745d6a..b30334a 100644
--- a/kernel/bpf/devmap.c
+++ b/kernel/bpf/devmap.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /* Copyright (c) 2017 Covalent IO, Inc. http://covalent.io
  *
  * This program is free software; you can redistribute it and/or
diff --git a/kernel/bpf/inode.c b/kernel/bpf/inode.c
index be1dde9..282cbd4 100644
--- a/kernel/bpf/inode.c
+++ b/kernel/bpf/inode.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * Minimal file system backend for holding eBPF maps and programs,
  * used by bpf(2) object pinning.
diff --git a/kernel/capability.c b/kernel/capability.c
index 1e1c023..84e38d1 100644
--- a/kernel/capability.c
+++ b/kernel/capability.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 /*
  * linux/kernel/capability.c
@@ -31,6 +33,7 @@ int file_caps_enabled = 1;
 
 static int __init file_caps_disable(char *str)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	file_caps_enabled = 0;
 	return 1;
 }
@@ -47,6 +50,7 @@ static void warn_legacy_capability_use(void)
 {
 	char name[sizeof(current->comm)];
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pr_info_once("warning: `%s' uses 32-bit capabilities (legacy support in use)\n",
 		     get_task_comm(name, current));
 }
@@ -71,6 +75,7 @@ static void warn_deprecated_v2(void)
 {
 	char name[sizeof(current->comm)];
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pr_info_once("warning: `%s' uses deprecated v2 capabilities in a way that may be insecure\n",
 		     get_task_comm(name, current));
 }
@@ -84,7 +89,9 @@ static int cap_validate_magic(cap_user_header_t header, unsigned *tocopy)
 	__u32 version;
 
 	if (get_user(version, &header->version))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EFAULT;
+}
 
 	switch (version) {
 	case _LINUX_CAPABILITY_VERSION_1:
@@ -101,10 +108,13 @@ static int cap_validate_magic(cap_user_header_t header, unsigned *tocopy)
 		break;
 	default:
 		if (put_user((u32)_KERNEL_CAPABILITY_VERSION, &header->version))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -EFAULT;
+}
 		return -EINVAL;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
@@ -127,10 +137,13 @@ static inline int cap_get_target_pid(pid_t pid, kernel_cap_t *pEp,
 
 		target = find_task_by_vpid(pid);
 		if (!target)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			ret = -ESRCH;
+}
 		else
 			ret = security_capget(target, pEp, pIp, pPp);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		rcu_read_unlock();
 	} else
 		ret = security_capget(current, pEp, pIp, pPp);
@@ -159,10 +172,14 @@ SYSCALL_DEFINE2(capget, cap_user_header_t, header, cap_user_data_t, dataptr)
 		return ((dataptr == NULL) && (ret == -EINVAL)) ? 0 : ret;
 
 	if (get_user(pid, &header->pid))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EFAULT;
+}
 
 	if (pid < 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	ret = cap_get_target_pid(pid, &pE, &pI, &pP);
 	if (!ret) {
diff --git a/kernel/cgroup/cgroup-internal.h b/kernel/cgroup/cgroup-internal.h
index bf54ade..5083646 100644
--- a/kernel/cgroup/cgroup-internal.h
+++ b/kernel/cgroup/cgroup-internal.h
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /* SPDX-License-Identifier: GPL-2.0 */
 #ifndef __CGROUP_INTERNAL_H
 #define __CGROUP_INTERNAL_H
diff --git a/kernel/cgroup/cgroup-v1.c b/kernel/cgroup/cgroup-v1.c
index a2c05d2..d222c777 100644
--- a/kernel/cgroup/cgroup-v1.c
+++ b/kernel/cgroup/cgroup-v1.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 #include "cgroup-internal.h"
 
 #include <linux/ctype.h>
@@ -56,6 +58,7 @@ int cgroup_attach_task_all(struct task_struct *from, struct task_struct *tsk)
 
 	mutex_lock(&cgroup_mutex);
 	percpu_down_write(&cgroup_threadgroup_rwsem);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for_each_root(root) {
 		struct cgroup *from_cgrp;
 
@@ -97,7 +100,9 @@ int cgroup_transfer_tasks(struct cgroup *to, struct cgroup *from)
 	int ret;
 
 	if (cgroup_on_dfl(to))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	ret = cgroup_migrate_vet_dst(to);
 	if (ret)
@@ -195,7 +200,9 @@ struct cgroup_pidlist {
 static void *pidlist_allocate(int count)
 {
 	if (PIDLIST_TOO_LARGE(count))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return vmalloc(count * sizeof(pid_t));
+}
 	else
 		return kmalloc(count * sizeof(pid_t), GFP_KERNEL);
 }
@@ -214,6 +221,7 @@ void cgroup1_pidlist_destroy_all(struct cgroup *cgrp)
 	struct cgroup_pidlist *l, *tmp_l;
 
 	mutex_lock(&cgrp->pidlist_mutex);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry_safe(l, tmp_l, &cgrp->pidlists, links)
 		mod_delayed_work(cgroup_pidlist_destroy_wq, &l->destroy_dwork, 0);
 	mutex_unlock(&cgrp->pidlist_mutex);
@@ -224,6 +232,7 @@ void cgroup1_pidlist_destroy_all(struct cgroup *cgrp)
 
 static void cgroup_pidlist_destroy_work_fn(struct work_struct *work)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct delayed_work *dwork = to_delayed_work(work);
 	struct cgroup_pidlist *l = container_of(dwork, struct cgroup_pidlist,
 						destroy_dwork);
@@ -259,11 +268,15 @@ static int pidlist_uniq(pid_t *list, int length)
 	 * edge cases first; no work needs to be done for either
 	 */
 	if (length == 0 || length == 1)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return length;
+}
 	/* src and dest walk down the list; dest counts unique elements */
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (src = 1; src < length; src++) {
 		/* find next unique element */
 		while (list[src] == list[src-1]) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			src++;
 			if (src == length)
 				goto after;
@@ -287,6 +300,7 @@ static int pidlist_uniq(pid_t *list, int length)
  */
 static int cmppid(const void *a, const void *b)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return *(pid_t *)a - *(pid_t *)b;
 }
 
@@ -297,11 +311,15 @@ static struct cgroup_pidlist *cgroup_pidlist_find(struct cgroup *cgrp,
 	/* don't need task_nsproxy() if we're looking at ourself */
 	struct pid_namespace *ns = task_active_pid_ns(current);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&cgrp->pidlist_mutex);
 
 	list_for_each_entry(l, &cgrp->pidlists, links)
 		if (l->key.type == type && l->key.ns == ns)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return l;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return NULL;
 }
 
@@ -316,16 +334,21 @@ static struct cgroup_pidlist *cgroup_pidlist_find_create(struct cgroup *cgrp,
 {
 	struct cgroup_pidlist *l;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&cgrp->pidlist_mutex);
 
 	l = cgroup_pidlist_find(cgrp, type);
 	if (l)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return l;
+}
 
 	/* entry not found; create a new one */
 	l = kzalloc(sizeof(struct cgroup_pidlist), GFP_KERNEL);
 	if (!l)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return l;
+}
 
 	INIT_DELAYED_WORK(&l->destroy_dwork, cgroup_pidlist_destroy_work_fn);
 	l->key.type = type;
@@ -348,6 +371,7 @@ int cgroup_task_count(const struct cgroup *cgrp)
 	spin_lock_irq(&css_set_lock);
 	list_for_each_entry(link, &cgrp->cset_links, cset_link)
 		count += link->cset->nr_tasks;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_unlock_irq(&css_set_lock);
 	return count;
 }
@@ -365,6 +389,7 @@ static int pidlist_array_load(struct cgroup *cgrp, enum cgroup_filetype type,
 	struct task_struct *tsk;
 	struct cgroup_pidlist *l;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&cgrp->pidlist_mutex);
 
 	/*
@@ -376,19 +401,27 @@ static int pidlist_array_load(struct cgroup *cgrp, enum cgroup_filetype type,
 	length = cgroup_task_count(cgrp);
 	array = pidlist_allocate(length);
 	if (!array)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 	/* now, populate the array */
 	css_task_iter_start(&cgrp->self, 0, &it);
 	while ((tsk = css_task_iter_next(&it))) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (unlikely(n == length))
 			break;
 		/* get tgid or pid for procs or tasks file respectively */
 		if (type == CGROUP_FILE_PROCS)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			pid = task_tgid_vnr(tsk);
+}
 		else
 			pid = task_pid_vnr(tsk);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (pid > 0) /* make sure to only use valid results */
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			array[n++] = pid;
+}
 	}
 	css_task_iter_end(&it);
 	length = n;
@@ -399,6 +432,7 @@ static int pidlist_array_load(struct cgroup *cgrp, enum cgroup_filetype type,
 
 	l = cgroup_pidlist_find_create(cgrp, type);
 	if (!l) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pidlist_free(array);
 		return -ENOMEM;
 	}
@@ -441,7 +475,9 @@ static void *cgroup_pidlist_start(struct seq_file *s, loff_t *pos)
 	 * could already have been destroyed.
 	 */
 	if (of->priv)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		of->priv = cgroup_pidlist_find(cgrp, type);
+}
 
 	/*
 	 * Either this is the first start() after open or the matching
@@ -451,19 +487,24 @@ static void *cgroup_pidlist_start(struct seq_file *s, loff_t *pos)
 		ret = pidlist_array_load(cgrp, type,
 					 (struct cgroup_pidlist **)&of->priv);
 		if (ret)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return ERR_PTR(ret);
+}
 	}
 	l = of->priv;
 
 	if (pid) {
 		int end = l->length;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		while (index < end) {
 			int mid = (index + end) / 2;
 			if (l->list[mid] == pid) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				index = mid;
 				break;
 			} else if (l->list[mid] <= pid)
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				index = mid + 1;
 			else
 				end = mid;
@@ -471,7 +512,9 @@ static void *cgroup_pidlist_start(struct seq_file *s, loff_t *pos)
 	}
 	/* If we're off the end of the array, we're done */
 	if (index >= l->length)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 	/* Update the abstract position to be the actual pid that we found */
 	iter = l->list + index;
 	*pos = *iter;
@@ -501,6 +544,7 @@ static void *cgroup_pidlist_next(struct seq_file *s, void *v, loff_t *pos)
 	 */
 	p++;
 	if (p >= end) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
 	} else {
 		*pos = *p;
@@ -510,6 +554,7 @@ static void *cgroup_pidlist_next(struct seq_file *s, void *v, loff_t *pos)
 
 static int cgroup_pidlist_show(struct seq_file *s, void *v)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	seq_printf(s, "%d\n", *(int *)v);
 
 	return 0;
@@ -526,7 +571,9 @@ static ssize_t __cgroup1_procs_write(struct kernfs_open_file *of,
 
 	cgrp = cgroup_kn_lock_live(of->kn, false);
 	if (!cgrp)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENODEV;
+}
 
 	task = cgroup_procs_write_start(buf, threadgroup);
 	ret = PTR_ERR_OR_ZERO(task);
@@ -566,6 +613,7 @@ static ssize_t cgroup1_procs_write(struct kernfs_open_file *of,
 static ssize_t cgroup1_tasks_write(struct kernfs_open_file *of,
 				   char *buf, size_t nbytes, loff_t off)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return __cgroup1_procs_write(of, buf, nbytes, off, false);
 }
 
@@ -574,6 +622,7 @@ static ssize_t cgroup_release_agent_write(struct kernfs_open_file *of,
 {
 	struct cgroup *cgrp;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	BUILD_BUG_ON(sizeof(cgrp->root->release_agent_path) < PATH_MAX);
 
 	cgrp = cgroup_kn_lock_live(of->kn, false);
@@ -589,6 +638,7 @@ static ssize_t cgroup_release_agent_write(struct kernfs_open_file *of,
 
 static int cgroup_release_agent_show(struct seq_file *seq, void *v)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cgroup *cgrp = seq_css(seq)->cgroup;
 
 	spin_lock(&release_agent_path_lock);
@@ -600,6 +650,7 @@ static int cgroup_release_agent_show(struct seq_file *seq, void *v)
 
 static int cgroup_sane_behavior_show(struct seq_file *seq, void *v)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	seq_puts(seq, "0\n");
 	return 0;
 }
@@ -607,12 +658,14 @@ static int cgroup_sane_behavior_show(struct seq_file *seq, void *v)
 static u64 cgroup_read_notify_on_release(struct cgroup_subsys_state *css,
 					 struct cftype *cft)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return notify_on_release(css->cgroup);
 }
 
 static int cgroup_write_notify_on_release(struct cgroup_subsys_state *css,
 					  struct cftype *cft, u64 val)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (val)
 		set_bit(CGRP_NOTIFY_ON_RELEASE, &css->cgroup->flags);
 	else
@@ -623,12 +676,14 @@ static int cgroup_write_notify_on_release(struct cgroup_subsys_state *css,
 static u64 cgroup_clone_children_read(struct cgroup_subsys_state *css,
 				      struct cftype *cft)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return test_bit(CGRP_CPUSET_CLONE_CHILDREN, &css->cgroup->flags);
 }
 
 static int cgroup_clone_children_write(struct cgroup_subsys_state *css,
 				       struct cftype *cft, u64 val)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (val)
 		set_bit(CGRP_CPUSET_CLONE_CHILDREN, &css->cgroup->flags);
 	else
@@ -728,6 +783,7 @@ const struct file_operations proc_cgroupstats_operations = {
  */
 int cgroupstats_build(struct cgroupstats *stats, struct dentry *dentry)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct kernfs_node *kn = kernfs_node_from_dentry(dentry);
 	struct cgroup *cgrp;
 	struct css_task_iter it;
@@ -861,7 +917,9 @@ static int cgroup1_rename(struct kernfs_node *kn, struct kernfs_node *new_parent
 	int ret;
 
 	if (kernfs_type(kn) != KERNFS_DIR)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOTDIR;
+}
 	if (kn->parent != new_parent)
 		return -EIO;
 
@@ -896,20 +954,31 @@ static int cgroup1_show_options(struct seq_file *seq, struct kernfs_root *kf_roo
 		if (root->subsys_mask & (1 << ssid))
 			seq_show_option(seq, ss->legacy_name, NULL);
 	if (root->flags & CGRP_ROOT_NOPREFIX)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		seq_puts(seq, ",noprefix");
+}
 	if (root->flags & CGRP_ROOT_XATTR)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		seq_puts(seq, ",xattr");
+}
 	if (root->flags & CGRP_ROOT_CPUSET_V2_MODE)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		seq_puts(seq, ",cpuset_v2_mode");
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_lock(&release_agent_path_lock);
 	if (strlen(root->release_agent_path))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		seq_show_option(seq, "release_agent",
 				root->release_agent_path);
+}
 	spin_unlock(&release_agent_path_lock);
 
 	if (test_bit(CGRP_CPUSET_CLONE_CHILDREN, &root->cgrp.flags))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		seq_puts(seq, ",clone_children");
+}
 	if (strlen(root->name))
 		seq_show_option(seq, "name", root->name);
 	return 0;
@@ -931,10 +1000,13 @@ static int parse_cgroupfs_options(char *data, struct cgroup_sb_opts *opts)
 	memset(opts, 0, sizeof(*opts));
 
 	while ((token = strsep(&o, ",")) != NULL) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		nr_opts++;
 
 		if (!*token)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -EINVAL;
+}
 		if (!strcmp(token, "none")) {
 			/* Explicitly have no subsystems */
 			opts->none = true;
@@ -943,58 +1015,77 @@ static int parse_cgroupfs_options(char *data, struct cgroup_sb_opts *opts)
 		if (!strcmp(token, "all")) {
 			/* Mutually exclusive option 'all' + subsystem name */
 			if (one_ss)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				return -EINVAL;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			all_ss = true;
 			continue;
 		}
 		if (!strcmp(token, "noprefix")) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			opts->flags |= CGRP_ROOT_NOPREFIX;
 			continue;
 		}
 		if (!strcmp(token, "clone_children")) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			opts->cpuset_clone_children = true;
 			continue;
 		}
 		if (!strcmp(token, "cpuset_v2_mode")) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			opts->flags |= CGRP_ROOT_CPUSET_V2_MODE;
 			continue;
 		}
 		if (!strcmp(token, "xattr")) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			opts->flags |= CGRP_ROOT_XATTR;
 			continue;
 		}
 		if (!strncmp(token, "release_agent=", 14)) {
 			/* Specifying two release agents is forbidden */
 			if (opts->release_agent)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				return -EINVAL;
+}
 			opts->release_agent =
 				kstrndup(token + 14, PATH_MAX - 1, GFP_KERNEL);
 			if (!opts->release_agent)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				return -ENOMEM;
+}
 			continue;
 		}
 		if (!strncmp(token, "name=", 5)) {
 			const char *name = token + 5;
 			/* Can't specify an empty name */
 			if (!strlen(name))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				return -EINVAL;
+}
 			/* Must match [\w.-]+ */
 			for (i = 0; i < strlen(name); i++) {
 				char c = name[i];
 				if (isalnum(c))
 					continue;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				if ((c == '.') || (c == '-') || (c == '_'))
 					continue;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				return -EINVAL;
 			}
 			/* Specifying two names is forbidden */
 			if (opts->name)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				return -EINVAL;
+}
 			opts->name = kstrndup(name,
 					      MAX_CGROUP_ROOT_NAMELEN - 1,
 					      GFP_KERNEL);
 			if (!opts->name)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				return -ENOMEM;
+}
 
 			continue;
 		}
@@ -1009,14 +1100,18 @@ static int parse_cgroupfs_options(char *data, struct cgroup_sb_opts *opts)
 
 			/* Mutually exclusive option 'all' + subsystem name */
 			if (all_ss)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				return -EINVAL;
+}
 			opts->subsys_mask |= (1 << i);
 			one_ss = true;
 
 			break;
 		}
 		if (i == CGROUP_SUBSYS_COUNT)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -ENOENT;
+}
 	}
 
 	/*
@@ -1025,16 +1120,20 @@ static int parse_cgroupfs_options(char *data, struct cgroup_sb_opts *opts)
 	 * not specified, let's default to 'all'
 	 */
 	if (all_ss || (!one_ss && !opts->none && !opts->name))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		for_each_subsys(ss, i)
 			if (cgroup_ssid_enabled(i) && !cgroup1_ssid_disabled(i))
 				opts->subsys_mask |= (1 << i);
+}
 
 	/*
 	 * We either have to specify by name or by subsystems. (So all
 	 * empty hierarchies must have a name).
 	 */
 	if (!opts->subsys_mask && !opts->name)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	/*
 	 * Option noprefix was introduced just for backward compatibility
@@ -1042,11 +1141,15 @@ static int parse_cgroupfs_options(char *data, struct cgroup_sb_opts *opts)
 	 * the cpuset subsystem.
 	 */
 	if ((opts->flags & CGRP_ROOT_NOPREFIX) && (opts->subsys_mask & mask))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	/* Can't specify "none" and some subsystems */
 	if (opts->subsys_mask && opts->none)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	return 0;
 }
@@ -1065,6 +1168,7 @@ static int cgroup1_remount(struct kernfs_root *kf_root, int *flags, char *data)
 	if (ret)
 		goto out_unlock;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (opts.subsys_mask != root->subsys_mask || opts.release_agent)
 		pr_warn("option changes via remount are deprecated (pid=%d comm=%s)\n",
 			task_tgid_nr(current), current->comm);
@@ -1148,12 +1252,15 @@ struct dentry *cgroup1_mount(struct file_system_type *fs_type, int flags,
 		    ss->root == &cgrp_dfl_root)
 			continue;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (!percpu_ref_tryget_live(&ss->root->cgrp.self.refcnt)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			mutex_unlock(&cgroup_mutex);
 			msleep(10);
 			ret = restart_syscall();
 			goto out_free;
 		}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		cgroup_put(&ss->root->cgrp);
 	}
 
@@ -1171,6 +1278,7 @@ struct dentry *cgroup1_mount(struct file_system_type *fs_type, int flags,
 		if (opts.name) {
 			if (strcmp(opts.name, root->name))
 				continue;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			name_match = true;
 		}
 
@@ -1182,12 +1290,16 @@ struct dentry *cgroup1_mount(struct file_system_type *fs_type, int flags,
 		    (opts.subsys_mask != root->subsys_mask)) {
 			if (!name_match)
 				continue;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			ret = -EBUSY;
 			goto out_unlock;
 		}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (root->flags ^ opts.flags)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			pr_warn("new mount options do not match the existing superblock, will be ignored\n");
+}
 
 		/*
 		 * We want to reuse @root whose lifetime is governed by its
@@ -1204,14 +1316,19 @@ struct dentry *cgroup1_mount(struct file_system_type *fs_type, int flags,
 		pinned_sb = kernfs_pin_sb(root->kf_root, NULL);
 		if (IS_ERR(pinned_sb) ||
 		    !percpu_ref_tryget_live(&root->cgrp.self.refcnt)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			mutex_unlock(&cgroup_mutex);
 			if (!IS_ERR_OR_NULL(pinned_sb))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				deactivate_super(pinned_sb);
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			msleep(10);
 			ret = restart_syscall();
 			goto out_free;
 		}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ret = 0;
 		goto out_unlock;
 	}
@@ -1222,28 +1339,34 @@ struct dentry *cgroup1_mount(struct file_system_type *fs_type, int flags,
 	 * can't create new one without subsys specification.
 	 */
 	if (!opts.subsys_mask && !opts.none) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ret = -EINVAL;
 		goto out_unlock;
 	}
 
 	/* Hierarchies may only be created in the initial cgroup namespace. */
 	if (ns != &init_cgroup_ns) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ret = -EPERM;
 		goto out_unlock;
 	}
 
 	root = kzalloc(sizeof(*root), GFP_KERNEL);
 	if (!root) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ret = -ENOMEM;
 		goto out_unlock;
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	new_root = true;
 
 	init_cgroup_root(root, &opts);
 
 	ret = cgroup_setup_root(root, opts.subsys_mask, PERCPU_REF_INIT_DEAD);
 	if (ret)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		cgroup_free_root(root);
+}
 
 out_unlock:
 	mutex_unlock(&cgroup_mutex);
@@ -1252,7 +1375,9 @@ struct dentry *cgroup1_mount(struct file_system_type *fs_type, int flags,
 	kfree(opts.name);
 
 	if (ret)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ERR_PTR(ret);
+}
 
 	dentry = cgroup_do_mount(&cgroup_fs_type, flags, root,
 				 CGROUP_SUPER_MAGIC, ns);
@@ -1274,8 +1399,11 @@ struct dentry *cgroup1_mount(struct file_system_type *fs_type, int flags,
 	 * extra ref on its sb.  Mount is complete.  Put the extra ref.
 	 */
 	if (pinned_sb)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		deactivate_super(pinned_sb);
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return dentry;
 }
 
@@ -1298,6 +1426,7 @@ static int __init cgroup_no_v1(char *str)
 	char *token;
 	int i;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	while ((token = strsep(&str, ",")) != NULL) {
 		if (!*token)
 			continue;
diff --git a/kernel/cgroup/cgroup.c b/kernel/cgroup/cgroup.c
index 030e428..bef91af 100644
--- a/kernel/cgroup/cgroup.c
+++ b/kernel/cgroup/cgroup.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  *  Generic process-grouping system.
  *
@@ -224,8 +226,11 @@ static int cgroup_addrm_files(struct cgroup_subsys_state *css,
  */
 bool cgroup_ssid_enabled(int ssid)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (CGROUP_SUBSYS_COUNT == 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return false;
+}
 
 	return static_key_enabled(cgroup_subsys_enabled_key[ssid]);
 }
@@ -314,6 +319,7 @@ static void *cgroup_idr_replace(struct idr *idr, void *ptr, int id)
 
 static void cgroup_idr_remove(struct idr *idr, int id)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_lock_bh(&cgroup_idr_lock);
 	idr_remove(idr, id);
 	spin_unlock_bh(&cgroup_idr_lock);
@@ -321,6 +327,7 @@ static void cgroup_idr_remove(struct idr *idr, int id)
 
 static bool cgroup_has_tasks(struct cgroup *cgrp)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return cgrp->nr_populated_csets;
 }
 
@@ -405,6 +412,7 @@ static bool cgroup_is_valid_domain(struct cgroup *cgrp)
 /* subsystems visibly enabled on a cgroup */
 static u16 cgroup_control(struct cgroup *cgrp)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cgroup *parent = cgroup_parent(cgrp);
 	u16 root_ss_mask = cgrp->root->subsys_mask;
 
@@ -413,19 +421,24 @@ static u16 cgroup_control(struct cgroup *cgrp)
 
 		/* threaded cgroups can only have threaded controllers */
 		if (cgroup_is_threaded(cgrp))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			ss_mask &= cgrp_dfl_threaded_ss_mask;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ss_mask;
 	}
 
 	if (cgroup_on_dfl(cgrp))
 		root_ss_mask &= ~(cgrp_dfl_inhibit_ss_mask |
 				  cgrp_dfl_implicit_ss_mask);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return root_ss_mask;
 }
 
 /* subsystems enabled on a cgroup */
 static u16 cgroup_ss_mask(struct cgroup *cgrp)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cgroup *parent = cgroup_parent(cgrp);
 
 	if (parent) {
@@ -433,7 +446,10 @@ static u16 cgroup_ss_mask(struct cgroup *cgrp)
 
 		/* threaded cgroups can only have threaded controllers */
 		if (cgroup_is_threaded(cgrp))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			ss_mask &= cgrp_dfl_threaded_ss_mask;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ss_mask;
 	}
 
@@ -474,19 +490,25 @@ static struct cgroup_subsys_state *cgroup_css(struct cgroup *cgrp,
 static struct cgroup_subsys_state *cgroup_e_css(struct cgroup *cgrp,
 						struct cgroup_subsys *ss)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&cgroup_mutex);
 
 	if (!ss)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return &cgrp->self;
+}
 
 	/*
 	 * This function is used while updating css associations and thus
 	 * can't test the csses directly.  Test ss_mask.
 	 */
 	while (!(cgroup_ss_mask(cgrp) & (1 << ss->id))) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		cgrp = cgroup_parent(cgrp);
 		if (!cgrp)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return NULL;
+}
 	}
 
 	return cgroup_css(cgrp, ss);
@@ -511,6 +533,7 @@ struct cgroup_subsys_state *cgroup_get_e_css(struct cgroup *cgrp,
 	rcu_read_lock();
 
 	do {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		css = cgroup_css(cgrp, ss);
 
 		if (css && css_tryget_online(css))
@@ -667,6 +690,7 @@ static bool css_set_threaded(struct css_set *cset)
  */
 static bool css_set_populated(struct css_set *cset)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&css_set_lock);
 
 	return !list_empty(&cset->tasks) || !list_empty(&cset->mg_tasks);
@@ -694,6 +718,7 @@ static void cgroup_update_populated(struct cgroup *cgrp, bool populated)
 	struct cgroup *child = NULL;
 	int adj = populated ? 1 : -1;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&css_set_lock);
 
 	do {
@@ -703,7 +728,9 @@ static void cgroup_update_populated(struct cgroup *cgrp, bool populated)
 			cgrp->nr_populated_csets += adj;
 		} else {
 			if (cgroup_is_threaded(child))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				cgrp->nr_populated_threaded_children += adj;
+}
 			else
 				cgrp->nr_populated_domain_children += adj;
 		}
@@ -731,6 +758,7 @@ static void css_set_update_populated(struct css_set *cset, bool populated)
 {
 	struct cgrp_cset_link *link;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&css_set_lock);
 
 	list_for_each_entry(link, &cset->cgrp_links, cgrp_link)
@@ -756,6 +784,7 @@ static void css_set_move_task(struct task_struct *task,
 			      struct css_set *from_cset, struct css_set *to_cset,
 			      bool use_mg_tasks)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&css_set_lock);
 
 	if (to_cset && !css_set_populated(to_cset))
@@ -776,7 +805,9 @@ static void css_set_move_task(struct task_struct *task,
 		list_for_each_entry_safe(it, pos, &from_cset->task_iters,
 					 iters_node)
 			if (it->task_pos == &task->cg_list)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				css_task_iter_advance(it);
+}
 
 		list_del_init(&task->cg_list);
 		if (!css_set_populated(from_cset))
@@ -827,10 +858,13 @@ void put_css_set_locked(struct css_set *cset)
 	struct cgroup_subsys *ss;
 	int ssid;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&css_set_lock);
 
 	if (!refcount_dec_and_test(&cset->refcount))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	WARN_ON_ONCE(!list_empty(&cset->threaded_csets));
 
@@ -846,11 +880,14 @@ void put_css_set_locked(struct css_set *cset)
 		list_del(&link->cset_link);
 		list_del(&link->cgrp_link);
 		if (cgroup_parent(link->cgrp))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			cgroup_put(link->cgrp);
+}
 		kfree(link);
 	}
 
 	if (css_set_threaded(cset)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		list_del(&cset->threaded_csets_node);
 		put_css_set_locked(cset->dom_cset);
 	}
@@ -882,17 +919,23 @@ static bool compare_css_sets(struct css_set *cset,
 	 * Let's first ensure that csses match.
 	 */
 	if (memcmp(template, cset->subsys, sizeof(cset->subsys)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return false;
+}
 
 
 	/* @cset's domain should match the default cgroup's */
 	if (cgroup_on_dfl(new_cgrp))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		new_dfl_cgrp = new_cgrp;
+}
 	else
 		new_dfl_cgrp = old_cset->dfl_cgrp;
 
 	if (new_dfl_cgrp->dom_cgrp != cset->dom_cset->dfl_cgrp)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return false;
+}
 
 	/*
 	 * Compare cgroup pointers in order to distinguish between
@@ -902,6 +945,7 @@ static bool compare_css_sets(struct css_set *cset,
 	 */
 	l1 = &cset->cgrp_links;
 	l2 = &old_cset->cgrp_links;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	while (1) {
 		struct cgrp_cset_link *link1, *link2;
 		struct cgroup *cgrp1, *cgrp2;
@@ -917,6 +961,7 @@ static bool compare_css_sets(struct css_set *cset,
 		}
 		/* Locate the cgroups associated with these links. */
 		link1 = list_entry(l1, struct cgrp_cset_link, cgrp_link);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		link2 = list_entry(l2, struct cgrp_cset_link, cgrp_link);
 		cgrp1 = link1->cgrp;
 		cgrp2 = link2->cgrp;
@@ -932,12 +977,17 @@ static bool compare_css_sets(struct css_set *cset,
 		 */
 		if (cgrp1->root == new_cgrp->root) {
 			if (cgrp1 != new_cgrp)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				return false;
+}
 		} else {
 			if (cgrp1 != cgrp2)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				return false;
+}
 		}
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return true;
 }
 
@@ -1019,11 +1069,13 @@ static int allocate_cgrp_cset_links(int count, struct list_head *tmp_links)
 	for (i = 0; i < count; i++) {
 		link = kzalloc(sizeof(*link), GFP_KERNEL);
 		if (!link) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			free_cgrp_cset_links(tmp_links);
 			return -ENOMEM;
 		}
 		list_add(&link->cset_link, tmp_links);
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
@@ -1077,6 +1129,7 @@ static struct css_set *find_css_set(struct css_set *old_cset,
 	unsigned long key;
 	int ssid;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&cgroup_mutex);
 
 	/* First see if we already have a cgroup group that matches
@@ -1084,22 +1137,31 @@ static struct css_set *find_css_set(struct css_set *old_cset,
 	spin_lock_irq(&css_set_lock);
 	cset = find_existing_css_set(old_cset, cgrp, template);
 	if (cset)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		get_css_set(cset);
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_unlock_irq(&css_set_lock);
 
 	if (cset)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return cset;
+}
 
 	cset = kzalloc(sizeof(*cset), GFP_KERNEL);
 	if (!cset)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 
 	/* Allocate all the cgrp_cset_link objects that we'll need */
 	if (allocate_cgrp_cset_links(cgroup_root_count, &tmp_links) < 0) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		kfree(cset);
 		return NULL;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	refcount_set(&cset->refcount, 1);
 	cset->dom_cset = cset;
 	INIT_LIST_HEAD(&cset->tasks);
@@ -1121,7 +1183,9 @@ static struct css_set *find_css_set(struct css_set *old_cset,
 		struct cgroup *c = link->cgrp;
 
 		if (c->root == cgrp->root)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			c = cgrp;
+}
 		link_css_set(&tmp_links, cset, c);
 	}
 
@@ -1141,6 +1205,7 @@ static struct css_set *find_css_set(struct css_set *old_cset,
 		css_get(css);
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_unlock_irq(&css_set_lock);
 
 	/*
@@ -1154,10 +1219,12 @@ static struct css_set *find_css_set(struct css_set *old_cset,
 
 		dcset = find_css_set(cset, cset->dfl_cgrp->dom_cgrp);
 		if (!dcset) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			put_css_set(cset);
 			return NULL;
 		}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		spin_lock_irq(&css_set_lock);
 		cset->dom_cset = dcset;
 		list_add_tail(&cset->threaded_csets_node,
@@ -1165,6 +1232,7 @@ static struct css_set *find_css_set(struct css_set *old_cset,
 		spin_unlock_irq(&css_set_lock);
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return cset;
 }
 
@@ -1179,11 +1247,14 @@ static int cgroup_init_root_id(struct cgroup_root *root)
 {
 	int id;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&cgroup_mutex);
 
 	id = idr_alloc_cyclic(&cgroup_hierarchy_idr, root, 0, 0, GFP_KERNEL);
 	if (id < 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return id;
+}
 
 	root->hierarchy_id = id;
 	return 0;
@@ -1191,6 +1262,7 @@ static int cgroup_init_root_id(struct cgroup_root *root)
 
 static void cgroup_exit_root_id(struct cgroup_root *root)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&cgroup_mutex);
 
 	idr_remove(&cgroup_hierarchy_idr, root->hierarchy_id);
@@ -1198,6 +1270,7 @@ static void cgroup_exit_root_id(struct cgroup_root *root)
 
 void cgroup_free_root(struct cgroup_root *root)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (root) {
 		idr_destroy(&root->cgroup_idr);
 		kfree(root);
@@ -1213,6 +1286,7 @@ static void cgroup_destroy_root(struct cgroup_root *root)
 
 	cgroup_lock_and_drain_offline(&cgrp_dfl_root.cgrp);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	BUG_ON(atomic_read(&root->nr_cgrps));
 	BUG_ON(!list_empty(&cgrp->self.children));
 
@@ -1256,8 +1330,10 @@ current_cgns_cgroup_from_root(struct cgroup_root *root)
 	struct cgroup *res = NULL;
 	struct css_set *cset;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&css_set_lock);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rcu_read_lock();
 
 	cset = current->nsproxy->cgroup_ns->root_cset;
@@ -1266,15 +1342,18 @@ current_cgns_cgroup_from_root(struct cgroup_root *root)
 	} else {
 		struct cgrp_cset_link *link;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		list_for_each_entry(link, &cset->cgrp_links, cgrp_link) {
 			struct cgroup *c = link->cgrp;
 
 			if (c->root == root) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				res = c;
 				break;
 			}
 		}
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rcu_read_unlock();
 
 	BUG_ON(!res);
@@ -1287,12 +1366,15 @@ static struct cgroup *cset_cgroup_from_root(struct css_set *cset,
 {
 	struct cgroup *res = NULL;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&cgroup_mutex);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&css_set_lock);
 
 	if (cset == &init_css_set) {
 		res = &root->cgrp;
 	} else if (root == &cgrp_dfl_root) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		res = cset->dfl_cgrp;
 	} else {
 		struct cgrp_cset_link *link;
@@ -1301,6 +1383,7 @@ static struct cgroup *cset_cgroup_from_root(struct css_set *cset,
 			struct cgroup *c = link->cgrp;
 
 			if (c->root == root) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				res = c;
 				break;
 			}
@@ -1380,7 +1463,9 @@ static umode_t cgroup_file_mode(const struct cftype *cft)
 	umode_t mode = 0;
 
 	if (cft->read_u64 || cft->read_s64 || cft->seq_show)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		mode |= S_IRUGO;
+}
 
 	if (cft->write_u64 || cft->write_s64 || cft->write) {
 		if (cft->flags & CFTYPE_WORLD_WRITABLE)
@@ -1410,15 +1495,18 @@ static u16 cgroup_calc_subtree_ss_mask(u16 subtree_control, u16 this_ss_mask)
 	struct cgroup_subsys *ss;
 	int ssid;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&cgroup_mutex);
 
 	cur_ss_mask |= cgrp_dfl_implicit_ss_mask;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	while (true) {
 		u16 new_ss_mask = cur_ss_mask;
 
 		do_each_subsys_mask(ss, ssid, cur_ss_mask) {
 			new_ss_mask |= ss->depends_on;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		} while_each_subsys_mask();
 
 		/*
@@ -1430,6 +1518,7 @@ static u16 cgroup_calc_subtree_ss_mask(u16 subtree_control, u16 this_ss_mask)
 
 		if (new_ss_mask == cur_ss_mask)
 			break;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		cur_ss_mask = new_ss_mask;
 	}
 
@@ -1494,17 +1583,24 @@ struct cgroup *cgroup_kn_lock_live(struct kernfs_node *kn, bool drain_offline)
 	 * break the active_ref protection.
 	 */
 	if (!cgroup_tryget(cgrp))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 	kernfs_break_active_protection(kn);
 
 	if (drain_offline)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		cgroup_lock_and_drain_offline(cgrp);
+}
 	else
 		mutex_lock(&cgroup_mutex);
 
 	if (!cgroup_is_dead(cgrp))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return cgrp;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	cgroup_kn_unlock(kn);
 	return NULL;
 }
@@ -1513,6 +1609,7 @@ static void cgroup_rm_file(struct cgroup *cgrp, const struct cftype *cft)
 {
 	char name[CGROUP_FILE_NAME_MAX];
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&cgroup_mutex);
 
 	if (cft->file_offset) {
@@ -1537,7 +1634,9 @@ static void css_clear_dir(struct cgroup_subsys_state *css)
 	struct cftype *cfts;
 
 	if (!(css->flags & CSS_VISIBLE))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	css->flags &= ~CSS_VISIBLE;
 
@@ -1558,11 +1657,15 @@ static int css_populate_dir(struct cgroup_subsys_state *css)
 	int ret;
 
 	if ((css->flags & CSS_VISIBLE) || !cgrp->kn)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	if (!css->ss) {
 		if (cgroup_on_dfl(cgrp))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			cfts = cgroup_base_files;
+}
 		else
 			cfts = cgroup1_base_files;
 
@@ -1572,6 +1675,7 @@ static int css_populate_dir(struct cgroup_subsys_state *css)
 	list_for_each_entry(cfts, &css->ss->cfts, node) {
 		ret = cgroup_addrm_files(css, cgrp, cfts, true);
 		if (ret < 0) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			failed_cfts = cfts;
 			goto err;
 		}
@@ -1582,10 +1686,13 @@ static int css_populate_dir(struct cgroup_subsys_state *css)
 	return 0;
 err:
 	list_for_each_entry(cfts, &css->ss->cfts, node) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (cfts == failed_cfts)
 			break;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		cgroup_addrm_files(css, cgrp, cfts, false);
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return ret;
 }
 
@@ -1595,6 +1702,7 @@ int rebind_subsystems(struct cgroup_root *dst_root, u16 ss_mask)
 	struct cgroup_subsys *ss;
 	int ssid, i, ret;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&cgroup_mutex);
 
 	do_each_subsys_mask(ss, ssid, ss_mask) {
@@ -1609,7 +1717,10 @@ int rebind_subsystems(struct cgroup_root *dst_root, u16 ss_mask)
 
 		/* can't move between two non-dummy roots either */
 		if (ss->root != &cgrp_dfl_root && dst_root != &cgrp_dfl_root)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -EBUSY;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	} while_each_subsys_mask();
 
 	do_each_subsys_mask(ss, ssid, ss_mask) {
@@ -1635,11 +1746,13 @@ int rebind_subsystems(struct cgroup_root *dst_root, u16 ss_mask)
 		hash_for_each(css_set_table, i, cset, hlist)
 			list_move_tail(&cset->e_cset_node[ss->id],
 				       &dcgrp->e_csets[ss->id]);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		spin_unlock_irq(&css_set_lock);
 
 		/* default hierarchy doesn't enable controllers by default */
 		dst_root->subsys_mask |= 1 << ssid;
 		if (dst_root == &cgrp_dfl_root) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			static_branch_enable(cgroup_subsys_on_dfl_key[ssid]);
 		} else {
 			dcgrp->subtree_control |= 1 << ssid;
@@ -1648,11 +1761,14 @@ int rebind_subsystems(struct cgroup_root *dst_root, u16 ss_mask)
 
 		ret = cgroup_apply_control(dcgrp);
 		if (ret)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			pr_warn("partial failure to rebind %s controller (err=%d)\n",
 				ss->name, ret);
+}
 
 		if (ss->bind)
 			ss->bind(css);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	} while_each_subsys_mask();
 
 	kernfs_activate(dcgrp->kn);
@@ -1669,15 +1785,20 @@ int cgroup_show_path(struct seq_file *sf, struct kernfs_node *kf_node,
 
 	buf = kmalloc(PATH_MAX, GFP_KERNEL);
 	if (!buf)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_lock_irq(&css_set_lock);
 	ns_cgroup = current_cgns_cgroup_from_root(kf_cgroot);
 	len = kernfs_path_from_node(kf_node, ns_cgroup->kn, buf, PATH_MAX);
 	spin_unlock_irq(&css_set_lock);
 
 	if (len >= PATH_MAX)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		len = -ERANGE;
+}
 	else if (len > 0) {
 		seq_escape(sf, buf, " \t\n\\");
 		len = 0;
@@ -1693,7 +1814,9 @@ static int parse_cgroup_root_flags(char *data, unsigned int *root_flags)
 	*root_flags = 0;
 
 	if (!data)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	while ((token = strsep(&data, ",")) != NULL) {
 		if (!strcmp(token, "nsdelegate")) {
@@ -1710,6 +1833,7 @@ static int parse_cgroup_root_flags(char *data, unsigned int *root_flags)
 
 static void apply_cgroup_root_flags(unsigned int root_flags)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (current->nsproxy->cgroup_ns == &init_cgroup_ns) {
 		if (root_flags & CGRP_ROOT_NS_DELEGATE)
 			cgrp_dfl_root.flags |= CGRP_ROOT_NS_DELEGATE;
@@ -1720,6 +1844,7 @@ static void apply_cgroup_root_flags(unsigned int root_flags)
 
 static int cgroup_show_options(struct seq_file *seq, struct kernfs_root *kf_root)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (cgrp_dfl_root.flags & CGRP_ROOT_NS_DELEGATE)
 		seq_puts(seq, ",nsdelegate");
 	return 0;
@@ -1732,7 +1857,9 @@ static int cgroup_remount(struct kernfs_root *kf_root, int *flags, char *data)
 
 	ret = parse_cgroup_root_flags(data, &root_flags);
 	if (ret)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ret;
+}
 
 	apply_cgroup_root_flags(root_flags);
 	return 0;
@@ -1782,6 +1909,7 @@ static void cgroup_enable_task_cg_lists(void)
 		 */
 		spin_lock(&p->sighand->siglock);
 		if (!(p->flags & PF_EXITING)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			struct css_set *cset = task_css_set(p);
 
 			if (!css_set_populated(cset))
@@ -1792,6 +1920,7 @@ static void cgroup_enable_task_cg_lists(void)
 		}
 		spin_unlock(&p->sighand->siglock);
 	} while_each_thread(g, p);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	read_unlock(&tasklist_lock);
 out_unlock:
 	spin_unlock_irq(&css_set_lock);
@@ -1832,12 +1961,16 @@ void init_cgroup_root(struct cgroup_root *root, struct cgroup_sb_opts *opts)
 
 	root->flags = opts->flags;
 	if (opts->release_agent)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		strcpy(root->release_agent_path, opts->release_agent);
+}
 	if (opts->name)
 		strcpy(root->name, opts->name);
 	if (opts->cpuset_clone_children)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		set_bit(CGRP_CPUSET_CLONE_CHILDREN, &root->cgrp.flags);
 }
+}
 
 int cgroup_setup_root(struct cgroup_root *root, u16 ss_mask, int ref_flags)
 {
@@ -1847,6 +1980,7 @@ int cgroup_setup_root(struct cgroup_root *root, u16 ss_mask, int ref_flags)
 	struct css_set *cset;
 	int i, ret;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&cgroup_mutex);
 
 	ret = cgroup_idr_alloc(&root->cgroup_idr, root_cgrp, 1, 2, GFP_KERNEL);
@@ -1875,6 +2009,7 @@ int cgroup_setup_root(struct cgroup_root *root, u16 ss_mask, int ref_flags)
 	if (ret)
 		goto cancel_ref;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	kf_sops = root == &cgrp_dfl_root ?
 		&cgroup_kf_syscall_ops : &cgroup1_kf_syscall_ops;
 
@@ -1883,6 +2018,7 @@ int cgroup_setup_root(struct cgroup_root *root, u16 ss_mask, int ref_flags)
 					   KERNFS_ROOT_SUPPORT_EXPORTOP,
 					   root_cgrp);
 	if (IS_ERR(root->kf_root)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ret = PTR_ERR(root->kf_root);
 		goto exit_root_id;
 	}
@@ -1916,6 +2052,7 @@ int cgroup_setup_root(struct cgroup_root *root, u16 ss_mask, int ref_flags)
 		if (css_set_populated(cset))
 			cgroup_update_populated(root_cgrp, true);
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_unlock_irq(&css_set_lock);
 
 	BUG_ON(!list_empty(&root_cgrp->self.children));
@@ -1968,7 +2105,9 @@ struct dentry *cgroup_do_mount(struct file_system_type *fs_type, int flags,
 	}
 
 	if (IS_ERR(dentry) || !new_sb)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		cgroup_put(&root->cgrp);
+}
 
 	return dentry;
 }
@@ -1985,6 +2124,7 @@ static struct dentry *cgroup_mount(struct file_system_type *fs_type,
 
 	/* Check if the caller has permission to mount. */
 	if (!ns_capable(ns->user_ns, CAP_SYS_ADMIN)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		put_cgroup_ns(ns);
 		return ERR_PTR(-EPERM);
 	}
@@ -2001,17 +2141,21 @@ static struct dentry *cgroup_mount(struct file_system_type *fs_type,
 
 		ret = parse_cgroup_root_flags(data, &root_flags);
 		if (ret) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			put_cgroup_ns(ns);
 			return ERR_PTR(ret);
 		}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		cgrp_dfl_visible = true;
 		cgroup_get_live(&cgrp_dfl_root.cgrp);
 
 		dentry = cgroup_do_mount(&cgroup2_fs_type, flags, &cgrp_dfl_root,
 					 CGROUP2_SUPER_MAGIC, ns);
 		if (!IS_ERR(dentry))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			apply_cgroup_root_flags(root_flags);
+}
 	} else {
 		dentry = cgroup1_mount(&cgroup_fs_type, flags, data,
 				       CGROUP_SUPER_MAGIC, ns);
@@ -2023,6 +2167,7 @@ static struct dentry *cgroup_mount(struct file_system_type *fs_type,
 
 static void cgroup_kill_sb(struct super_block *sb)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct kernfs_root *kf_root = kernfs_root_from_sb(sb);
 	struct cgroup_root *root = cgroup_root_from_kf(kf_root);
 
@@ -2107,6 +2252,7 @@ int task_cgroup_path(struct task_struct *task, char *buf, size_t buflen)
 	root = idr_get_next(&cgroup_hierarchy_idr, &hierarchy_id);
 
 	if (root) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		cgrp = task_cgroup_from_root(task, root);
 		ret = cgroup_path_ns_locked(cgrp, buf, buflen, &init_cgroup_ns);
 	} else {
@@ -2135,19 +2281,27 @@ static void cgroup_migrate_add_task(struct task_struct *task,
 {
 	struct css_set *cset;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&css_set_lock);
 
 	/* @task either already exited or can't exit until the end */
 	if (task->flags & PF_EXITING)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	/* leave @task alone if post_fork() hasn't linked it yet */
 	if (list_empty(&task->cg_list))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	cset = task_css_set(task);
 	if (!cset->mg_src_cgrp)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	mgctx->tset.nr_tasks++;
 
@@ -2212,6 +2366,7 @@ struct task_struct *cgroup_taskset_next(struct cgroup_taskset *tset,
 			else
 				*dst_cssp = cset->subsys[tset->ssid];
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return task;
 		}
 
@@ -2219,6 +2374,7 @@ struct task_struct *cgroup_taskset_next(struct cgroup_taskset *tset,
 		task = NULL;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return NULL;
 }
 
@@ -2246,10 +2402,12 @@ static int cgroup_migrate_execute(struct cgroup_mgctx *mgctx)
 				tset->ssid = ssid;
 				ret = ss->can_attach(tset);
 				if (ret) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 					failed_ssid = ssid;
 					goto out_cancel_attach;
 				}
 			}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		} while_each_subsys_mask();
 	}
 
@@ -2261,6 +2419,7 @@ static int cgroup_migrate_execute(struct cgroup_mgctx *mgctx)
 	spin_lock_irq(&css_set_lock);
 	list_for_each_entry(cset, &tset->src_csets, mg_node) {
 		list_for_each_entry_safe(task, tmp_task, &cset->mg_tasks, cg_list) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			struct css_set *from_cset = task_css_set(task);
 			struct css_set *to_cset = cset->mg_dst_cset;
 
@@ -2271,6 +2430,7 @@ static int cgroup_migrate_execute(struct cgroup_mgctx *mgctx)
 			from_cset->nr_tasks--;
 		}
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_unlock_irq(&css_set_lock);
 
 	/*
@@ -2286,21 +2446,27 @@ static int cgroup_migrate_execute(struct cgroup_mgctx *mgctx)
 				tset->ssid = ssid;
 				ss->attach(tset);
 			}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		} while_each_subsys_mask();
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	ret = 0;
 	goto out_release_tset;
 
 out_cancel_attach:
 	if (tset->nr_tasks) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		do_each_subsys_mask(ss, ssid, mgctx->ss_mask) {
 			if (ssid == failed_ssid)
 				break;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			if (ss->cancel_attach) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				tset->ssid = ssid;
 				ss->cancel_attach(tset);
 			}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		} while_each_subsys_mask();
 	}
 out_release_tset:
@@ -2310,6 +2476,7 @@ static int cgroup_migrate_execute(struct cgroup_mgctx *mgctx)
 		list_splice_tail_init(&cset->mg_tasks, &cset->tasks);
 		list_del_init(&cset->mg_node);
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_unlock_irq(&css_set_lock);
 
 	/*
@@ -2335,27 +2502,38 @@ int cgroup_migrate_vet_dst(struct cgroup *dst_cgrp)
 {
 	/* v1 doesn't have any restriction */
 	if (!cgroup_on_dfl(dst_cgrp))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	/* verify @dst_cgrp can host resources */
 	if (!cgroup_is_valid_domain(dst_cgrp->dom_cgrp))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EOPNOTSUPP;
+}
 
 	/* mixables don't care */
 	if (cgroup_is_mixable(dst_cgrp))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	/*
 	 * If @dst_cgrp is already or can become a thread root or is
 	 * threaded, it doesn't matter.
 	 */
 	if (cgroup_can_be_thread_root(dst_cgrp) || cgroup_is_threaded(dst_cgrp))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	/* apply no-internal-process constraint */
 	if (dst_cgrp->subtree_control)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EBUSY;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
@@ -2371,8 +2549,10 @@ void cgroup_migrate_finish(struct cgroup_mgctx *mgctx)
 	LIST_HEAD(preloaded);
 	struct css_set *cset, *tmp_cset;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&cgroup_mutex);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_lock_irq(&css_set_lock);
 
 	list_splice_tail_init(&mgctx->preloaded_src_csets, &preloaded);
@@ -2386,6 +2566,7 @@ void cgroup_migrate_finish(struct cgroup_mgctx *mgctx)
 		put_css_set_locked(cset);
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_unlock_irq(&css_set_lock);
 }
 
@@ -2411,7 +2592,9 @@ void cgroup_migrate_add_src(struct css_set *src_cset,
 {
 	struct cgroup *src_cgrp;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&cgroup_mutex);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&css_set_lock);
 
 	/*
@@ -2420,12 +2603,16 @@ void cgroup_migrate_add_src(struct css_set *src_cset,
 	 * that the rest of migration path doesn't get confused by it.
 	 */
 	if (src_cset->dead)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	src_cgrp = cset_cgroup_from_root(src_cset, dst_cgrp->root);
 
 	if (!list_empty(&src_cset->mg_preload_node))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	WARN_ON(src_cset->mg_src_cgrp);
 	WARN_ON(src_cset->mg_dst_cgrp);
@@ -2456,6 +2643,7 @@ int cgroup_migrate_prepare_dst(struct cgroup_mgctx *mgctx)
 {
 	struct css_set *src_cset, *tmp_cset;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&cgroup_mutex);
 
 	/* look up the dst cset for each src cset and link it to src */
@@ -2498,6 +2686,7 @@ int cgroup_migrate_prepare_dst(struct cgroup_mgctx *mgctx)
 				mgctx->ss_mask |= 1 << ssid;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 err:
 	cgroup_migrate_finish(mgctx);
@@ -2540,6 +2729,7 @@ int cgroup_migrate(struct task_struct *leader, bool threadgroup,
 		if (!threadgroup)
 			break;
 	} while_each_thread(leader, task);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rcu_read_unlock();
 	spin_unlock_irq(&css_set_lock);
 
@@ -2563,7 +2753,9 @@ int cgroup_attach_task(struct cgroup *dst_cgrp, struct task_struct *leader,
 
 	ret = cgroup_migrate_vet_dst(dst_cgrp);
 	if (ret)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ret;
+}
 
 	/* look up all src csets */
 	spin_lock_irq(&css_set_lock);
@@ -2574,6 +2766,7 @@ int cgroup_attach_task(struct cgroup *dst_cgrp, struct task_struct *leader,
 		if (!threadgroup)
 			break;
 	} while_each_thread(leader, task);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rcu_read_unlock();
 	spin_unlock_irq(&css_set_lock);
 
@@ -2587,6 +2780,7 @@ int cgroup_attach_task(struct cgroup *dst_cgrp, struct task_struct *leader,
 	if (!ret)
 		trace_cgroup_attach_task(dst_cgrp, leader, threadgroup);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return ret;
 }
 
@@ -2597,7 +2791,9 @@ struct task_struct *cgroup_procs_write_start(char *buf, bool threadgroup)
 	pid_t pid;
 
 	if (kstrtoint(strstrip(buf), 0, &pid) || pid < 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ERR_PTR(-EINVAL);
+}
 
 	percpu_down_write(&cgroup_threadgroup_rwsem);
 
@@ -2605,10 +2801,12 @@ struct task_struct *cgroup_procs_write_start(char *buf, bool threadgroup)
 	if (pid) {
 		tsk = find_task_by_vpid(pid);
 		if (!tsk) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			tsk = ERR_PTR(-ESRCH);
 			goto out_unlock_threadgroup;
 		}
 	} else {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		tsk = current;
 	}
 
@@ -2622,6 +2820,7 @@ struct task_struct *cgroup_procs_write_start(char *buf, bool threadgroup)
 	 * cgroup with no rt_runtime allocated.  Just say no.
 	 */
 	if (tsk->no_cgroup_migration || (tsk->flags & PF_NO_SETAFFINITY)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		tsk = ERR_PTR(-EINVAL);
 		goto out_unlock_threadgroup;
 	}
@@ -2657,6 +2856,7 @@ static void cgroup_print_ss_mask(struct seq_file *seq, u16 ss_mask)
 	bool printed = false;
 	int ssid;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	do_each_subsys_mask(ss, ssid, ss_mask) {
 		if (printed)
 			seq_putc(seq, ' ');
@@ -2670,6 +2870,7 @@ static void cgroup_print_ss_mask(struct seq_file *seq, u16 ss_mask)
 /* show controllers which are enabled from the parent */
 static int cgroup_controllers_show(struct seq_file *seq, void *v)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cgroup *cgrp = seq_css(seq)->cgroup;
 
 	cgroup_print_ss_mask(seq, cgroup_control(cgrp));
@@ -2679,6 +2880,7 @@ static int cgroup_controllers_show(struct seq_file *seq, void *v)
 /* show controllers which are enabled for a given cgroup's children */
 static int cgroup_subtree_control_show(struct seq_file *seq, void *v)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cgroup *cgrp = seq_css(seq)->cgroup;
 
 	cgroup_print_ss_mask(seq, cgrp->subtree_control);
@@ -2702,6 +2904,7 @@ static int cgroup_update_dfl_csses(struct cgroup *cgrp)
 	struct css_set *src_cset;
 	int ret;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&cgroup_mutex);
 
 	percpu_down_write(&cgroup_threadgroup_rwsem);
@@ -2714,6 +2917,7 @@ static int cgroup_update_dfl_csses(struct cgroup *cgrp)
 		list_for_each_entry(link, &dsct->cset_links, cset_link)
 			cgroup_migrate_add_src(link->cset, dsct, &mgctx);
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_unlock_irq(&css_set_lock);
 
 	/* NULL dst indicates self on default hierarchy */
@@ -2721,6 +2925,7 @@ static int cgroup_update_dfl_csses(struct cgroup *cgrp)
 	if (ret)
 		goto out_finish;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_lock_irq(&css_set_lock);
 	list_for_each_entry(src_cset, &mgctx.preloaded_src_csets, mg_preload_node) {
 		struct task_struct *task, *ntask;
@@ -2729,6 +2934,7 @@ static int cgroup_update_dfl_csses(struct cgroup *cgrp)
 		list_for_each_entry_safe(task, ntask, &src_cset->tasks, cg_list)
 			cgroup_migrate_add_task(task, &mgctx);
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_unlock_irq(&css_set_lock);
 
 	ret = cgroup_migrate_execute(&mgctx);
@@ -2759,12 +2965,14 @@ void cgroup_lock_and_drain_offline(struct cgroup *cgrp)
 
 	cgroup_for_each_live_descendant_post(dsct, d_css, cgrp) {
 		for_each_subsys(ss, ssid) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			struct cgroup_subsys_state *css = cgroup_css(dsct, ss);
 			DEFINE_WAIT(wait);
 
 			if (!css || !percpu_ref_is_dying(&css->refcnt))
 				continue;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			cgroup_get_live(dsct);
 			prepare_to_wait(&dsct->offline_waitq, &wait,
 					TASK_UNINTERRUPTIBLE);
@@ -2791,6 +2999,7 @@ static void cgroup_save_control(struct cgroup *cgrp)
 	struct cgroup *dsct;
 	struct cgroup_subsys_state *d_css;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	cgroup_for_each_live_descendant_pre(dsct, d_css, cgrp) {
 		dsct->old_subtree_control = dsct->subtree_control;
 		dsct->old_subtree_ss_mask = dsct->subtree_ss_mask;
@@ -2830,6 +3039,7 @@ static void cgroup_restore_control(struct cgroup *cgrp)
 	struct cgroup *dsct;
 	struct cgroup_subsys_state *d_css;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	cgroup_for_each_live_descendant_post(dsct, d_css, cgrp) {
 		dsct->subtree_control = dsct->old_subtree_control;
 		dsct->subtree_ss_mask = dsct->old_subtree_ss_mask;
@@ -2842,9 +3052,13 @@ static bool css_visible(struct cgroup_subsys_state *css)
 	struct cgroup *cgrp = css->cgroup;
 
 	if (cgroup_control(cgrp) & (1 << ss->id))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return true;
+}
 	if (!(cgroup_ss_mask(cgrp) & (1 << ss->id)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return false;
+}
 	return cgroup_on_dfl(cgrp) && ss->implicit_on_dfl;
 }
 
@@ -2870,6 +3084,7 @@ static int cgroup_apply_control_enable(struct cgroup *cgrp)
 
 	cgroup_for_each_live_descendant_pre(dsct, d_css, cgrp) {
 		for_each_subsys(ss, ssid) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			struct cgroup_subsys_state *css = cgroup_css(dsct, ss);
 
 			WARN_ON_ONCE(css && percpu_ref_is_dying(&css->refcnt));
@@ -2880,17 +3095,22 @@ static int cgroup_apply_control_enable(struct cgroup *cgrp)
 			if (!css) {
 				css = css_create(dsct, ss);
 				if (IS_ERR(css))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 					return PTR_ERR(css);
+}
 			}
 
 			if (css_visible(css)) {
 				ret = css_populate_dir(css);
 				if (ret)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 					return ret;
+}
 			}
 		}
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
@@ -2916,6 +3136,7 @@ static void cgroup_apply_control_disable(struct cgroup *cgrp)
 
 	cgroup_for_each_live_descendant_post(dsct, d_css, cgrp) {
 		for_each_subsys(ss, ssid) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			struct cgroup_subsys_state *css = cgroup_css(dsct, ss);
 
 			WARN_ON_ONCE(css && percpu_ref_is_dying(&css->refcnt));
@@ -2925,6 +3146,7 @@ static void cgroup_apply_control_disable(struct cgroup *cgrp)
 
 			if (css->parent &&
 			    !(cgroup_ss_mask(dsct) & (1 << ss->id))) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				kill_css(css);
 			} else if (!css_visible(css)) {
 				css_clear_dir(css);
@@ -2960,7 +3182,9 @@ static int cgroup_apply_control(struct cgroup *cgrp)
 
 	ret = cgroup_apply_control_enable(cgrp);
 	if (ret)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ret;
+}
 
 	/*
 	 * At this point, cgroup_e_css() results reflect the new csses
@@ -2969,7 +3193,9 @@ static int cgroup_apply_control(struct cgroup *cgrp)
 	 */
 	ret = cgroup_update_dfl_csses(cgrp);
 	if (ret)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ret;
+}
 
 	return 0;
 }
@@ -2983,7 +3209,9 @@ static int cgroup_apply_control(struct cgroup *cgrp)
  */
 static void cgroup_finalize_control(struct cgroup *cgrp, int ret)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (ret) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		cgroup_restore_control(cgrp);
 		cgroup_propagate_control(cgrp);
 	}
@@ -2997,7 +3225,9 @@ static int cgroup_vet_subtree_control_enable(struct cgroup *cgrp, u16 enable)
 
 	/* if nothing is getting enabled, nothing to worry about */
 	if (!enable)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	/* can @cgrp host any resources? */
 	if (!cgroup_is_valid_domain(cgrp->dom_cgrp))
@@ -3047,6 +3277,7 @@ static ssize_t cgroup_subtree_control_write(struct kernfs_open_file *of,
 	 * with either + or -.
 	 */
 	buf = strstrip(buf);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	while ((tok = strsep(&buf, " "))) {
 		if (tok[0] == '\0')
 			continue;
@@ -3138,6 +3369,7 @@ static ssize_t cgroup_subtree_control_write(struct kernfs_open_file *of,
  */
 static int cgroup_enable_threaded(struct cgroup *cgrp)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cgroup *parent = cgroup_parent(cgrp);
 	struct cgroup *dom_cgrp = parent->dom_cgrp;
 	int ret;
@@ -3172,6 +3404,7 @@ static int cgroup_enable_threaded(struct cgroup *cgrp)
 
 static int cgroup_type_show(struct seq_file *seq, void *v)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cgroup *cgrp = seq_css(seq)->cgroup;
 
 	if (cgroup_is_threaded(cgrp))
@@ -3194,7 +3427,9 @@ static ssize_t cgroup_type_write(struct kernfs_open_file *of, char *buf,
 
 	/* only switching to threaded mode is supported */
 	if (strcmp(strstrip(buf), "threaded"))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	cgrp = cgroup_kn_lock_live(of->kn, false);
 	if (!cgrp)
@@ -3209,6 +3444,7 @@ static ssize_t cgroup_type_write(struct kernfs_open_file *of, char *buf,
 
 static int cgroup_max_descendants_show(struct seq_file *seq, void *v)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cgroup *cgrp = seq_css(seq)->cgroup;
 	int descendants = READ_ONCE(cgrp->max_descendants);
 
@@ -3229,6 +3465,7 @@ static ssize_t cgroup_max_descendants_write(struct kernfs_open_file *of,
 
 	buf = strstrip(buf);
 	if (!strcmp(buf, "max")) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		descendants = INT_MAX;
 	} else {
 		ret = kstrtoint(buf, 0, &descendants);
@@ -3252,6 +3489,7 @@ static ssize_t cgroup_max_descendants_write(struct kernfs_open_file *of,
 
 static int cgroup_max_depth_show(struct seq_file *seq, void *v)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cgroup *cgrp = seq_css(seq)->cgroup;
 	int depth = READ_ONCE(cgrp->max_depth);
 
@@ -3272,6 +3510,7 @@ static ssize_t cgroup_max_depth_write(struct kernfs_open_file *of,
 
 	buf = strstrip(buf);
 	if (!strcmp(buf, "max")) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		depth = INT_MAX;
 	} else {
 		ret = kstrtoint(buf, 0, &depth);
@@ -3302,6 +3541,7 @@ static int cgroup_events_show(struct seq_file *seq, void *v)
 
 static int cgroup_stat_show(struct seq_file *seq, void *v)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cgroup *cgroup = seq_css(seq)->cgroup;
 
 	seq_printf(seq, "nr_descendants %d\n",
@@ -3317,7 +3557,10 @@ static int cgroup_file_open(struct kernfs_open_file *of)
 	struct cftype *cft = of->kn->priv;
 
 	if (cft->open)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return cft->open(of);
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
@@ -3326,8 +3569,10 @@ static void cgroup_file_release(struct kernfs_open_file *of)
 	struct cftype *cft = of->kn->priv;
 
 	if (cft->release)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		cft->release(of);
 }
+}
 
 static ssize_t cgroup_file_write(struct kernfs_open_file *of, char *buf,
 				 size_t nbytes, loff_t off)
@@ -3371,8 +3616,11 @@ static ssize_t cgroup_file_write(struct kernfs_open_file *of, char *buf,
 		long long v;
 		ret = kstrtoll(buf, 0, &v);
 		if (!ret)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			ret = cft->write_s64(css, cft, v);
+}
 	} else {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ret = -EINVAL;
 	}
 
@@ -3386,6 +3634,7 @@ static void *cgroup_seqfile_start(struct seq_file *seq, loff_t *ppos)
 
 static void *cgroup_seqfile_next(struct seq_file *seq, void *v, loff_t *ppos)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return seq_cft(seq)->seq_next(seq, v, ppos);
 }
 
@@ -3397,6 +3646,7 @@ static void cgroup_seqfile_stop(struct seq_file *seq, void *v)
 
 static int cgroup_seqfile_show(struct seq_file *m, void *arg)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cftype *cft = seq_cft(m);
 	struct cgroup_subsys_state *css = seq_css(m);
 
@@ -3409,6 +3659,7 @@ static int cgroup_seqfile_show(struct seq_file *m, void *arg)
 		seq_printf(m, "%lld\n", cft->read_s64(css, cft));
 	else
 		return -EINVAL;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
@@ -3442,6 +3693,7 @@ static int cgroup_kn_set_ugid(struct kernfs_node *kn)
 	    gid_eq(iattr.ia_gid, GLOBAL_ROOT_GID))
 		return 0;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return kernfs_setattr(kn, &iattr);
 }
 
@@ -3460,10 +3712,13 @@ static int cgroup_add_file(struct cgroup_subsys_state *css, struct cgroup *cgrp,
 				  cgroup_file_mode(cft), 0, cft->kf_ops, cft,
 				  NULL, key);
 	if (IS_ERR(kn))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return PTR_ERR(kn);
+}
 
 	ret = cgroup_kn_set_ugid(kn);
 	if (ret) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		kernfs_remove(kn);
 		return ret;
 	}
@@ -3476,6 +3731,7 @@ static int cgroup_add_file(struct cgroup_subsys_state *css, struct cgroup *cgrp,
 		spin_unlock_irq(&cgroup_file_kn_lock);
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
@@ -3496,6 +3752,7 @@ static int cgroup_addrm_files(struct cgroup_subsys_state *css,
 	struct cftype *cft, *cft_end = NULL;
 	int ret = 0;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&cgroup_mutex);
 
 restart:
@@ -3513,6 +3770,7 @@ static int cgroup_addrm_files(struct cgroup_subsys_state *css,
 		if (is_add) {
 			ret = cgroup_add_file(css, cgrp, cft);
 			if (ret) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				pr_warn("%s: failed to add %s, err=%d\n",
 					__func__, cft->name, ret);
 				cft_end = cft;
@@ -3520,6 +3778,7 @@ static int cgroup_addrm_files(struct cgroup_subsys_state *css,
 				goto restart;
 			}
 		} else {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			cgroup_rm_file(cgrp, cft);
 		}
 	}
@@ -3533,6 +3792,7 @@ static int cgroup_apply_cftypes(struct cftype *cfts, bool is_add)
 	struct cgroup_subsys_state *css;
 	int ret = 0;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&cgroup_mutex);
 
 	/* add/rm files for all cgroups created before */
@@ -3556,6 +3816,7 @@ static void cgroup_exit_cftypes(struct cftype *cfts)
 {
 	struct cftype *cft;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (cft = cfts; cft->name[0] != '\0'; cft++) {
 		/* free copy for custom atomic_write_len, see init_cftypes() */
 		if (cft->max_write_len && cft->max_write_len != PAGE_SIZE)
@@ -3578,7 +3839,9 @@ static int cgroup_init_cftypes(struct cgroup_subsys *ss, struct cftype *cfts)
 		WARN_ON(cft->ss || cft->kf_ops);
 
 		if (cft->seq_start)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			kf_ops = &cgroup_kf_ops;
+}
 		else
 			kf_ops = &cgroup_kf_single_ops;
 
@@ -3587,8 +3850,10 @@ static int cgroup_init_cftypes(struct cgroup_subsys *ss, struct cftype *cfts)
 		 * make a copy of kf_ops to set its atomic_write_len.
 		 */
 		if (cft->max_write_len && cft->max_write_len != PAGE_SIZE) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			kf_ops = kmemdup(kf_ops, sizeof(*kf_ops), GFP_KERNEL);
 			if (!kf_ops) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				cgroup_exit_cftypes(cfts);
 				return -ENOMEM;
 			}
@@ -3599,11 +3864,13 @@ static int cgroup_init_cftypes(struct cgroup_subsys *ss, struct cftype *cfts)
 		cft->ss = ss;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
 static int cgroup_rm_cftypes_locked(struct cftype *cfts)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&cgroup_mutex);
 
 	if (!cfts || !cfts[0].ss)
@@ -3655,21 +3922,29 @@ static int cgroup_add_cftypes(struct cgroup_subsys *ss, struct cftype *cfts)
 	int ret;
 
 	if (!cgroup_ssid_enabled(ss->id))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	if (!cfts || cfts[0].name[0] == '\0')
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	ret = cgroup_init_cftypes(ss, cfts);
 	if (ret)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ret;
+}
 
 	mutex_lock(&cgroup_mutex);
 
 	list_add_tail(&cfts->node, &ss->cfts);
 	ret = cgroup_apply_cftypes(cfts, true);
 	if (ret)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		cgroup_rm_cftypes_locked(cfts);
+}
 
 	mutex_unlock(&cgroup_mutex);
 	return ret;
@@ -3721,7 +3996,10 @@ void cgroup_file_notify(struct cgroup_file *cfile)
 
 	spin_lock_irqsave(&cgroup_file_kn_lock, flags);
 	if (cfile->kn)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		kernfs_notify(cfile->kn);
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_unlock_irqrestore(&cgroup_file_kn_lock, flags);
 }
 
@@ -3747,6 +4025,7 @@ struct cgroup_subsys_state *css_next_child(struct cgroup_subsys_state *pos,
 {
 	struct cgroup_subsys_state *next;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	cgroup_assert_mutex_or_rcu_locked();
 
 	/*
@@ -3774,6 +4053,7 @@ struct cgroup_subsys_state *css_next_child(struct cgroup_subsys_state *pos,
 	} else if (likely(!(pos->flags & CSS_RELEASED))) {
 		next = list_entry_rcu(pos->sibling.next, struct cgroup_subsys_state, sibling);
 	} else {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		list_for_each_entry_rcu(next, &parent->children, sibling)
 			if (next->serial_nr > pos->serial_nr)
 				break;
@@ -3784,7 +4064,9 @@ struct cgroup_subsys_state *css_next_child(struct cgroup_subsys_state *pos,
 	 * the next sibling.
 	 */
 	if (&next->sibling != &parent->children)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return next;
+}
 	return NULL;
 }
 
@@ -3815,25 +4097,33 @@ css_next_descendant_pre(struct cgroup_subsys_state *pos,
 {
 	struct cgroup_subsys_state *next;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	cgroup_assert_mutex_or_rcu_locked();
 
 	/* if first iteration, visit @root */
 	if (!pos)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return root;
+}
 
 	/* visit the first child if exists */
 	next = css_next_child(NULL, pos);
 	if (next)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return next;
+}
 
 	/* no child, visit my or the closest ancestor's next sibling */
 	while (pos != root) {
 		next = css_next_child(pos, pos->parent);
 		if (next)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return next;
+}
 		pos = pos->parent;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return NULL;
 }
 
@@ -3855,6 +4145,7 @@ css_rightmost_descendant(struct cgroup_subsys_state *pos)
 {
 	struct cgroup_subsys_state *last, *tmp;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	cgroup_assert_mutex_or_rcu_locked();
 
 	do {
@@ -3874,6 +4165,7 @@ css_leftmost_descendant(struct cgroup_subsys_state *pos)
 	struct cgroup_subsys_state *last;
 
 	do {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		last = pos;
 		pos = css_next_child(NULL, pos);
 	} while (pos);
@@ -3909,6 +4201,7 @@ css_next_descendant_post(struct cgroup_subsys_state *pos,
 {
 	struct cgroup_subsys_state *next;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	cgroup_assert_mutex_or_rcu_locked();
 
 	/* if first iteration, visit leftmost descendant which may be @root */
@@ -3917,12 +4210,16 @@ css_next_descendant_post(struct cgroup_subsys_state *pos,
 
 	/* if we visited @root, we're done */
 	if (pos == root)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 
 	/* if there's an unvisited sibling, visit its leftmost descendant */
 	next = css_next_child(pos, pos->parent);
 	if (next)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return css_leftmost_descendant(next);
+}
 
 	/* no sibling left, visit parent */
 	return pos->parent;
@@ -3942,6 +4239,7 @@ bool css_has_online_children(struct cgroup_subsys_state *css)
 	bool ret = false;
 
 	rcu_read_lock();
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	css_for_each_child(child, css) {
 		if (child->flags & CSS_ONLINE) {
 			ret = true;
@@ -3958,18 +4256,23 @@ static struct css_set *css_task_iter_next_css_set(struct css_task_iter *it)
 	struct cgrp_cset_link *link;
 	struct css_set *cset;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&css_set_lock);
 
 	/* find the next threaded cset */
 	if (it->tcset_pos) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		l = it->tcset_pos->next;
 
 		if (l != it->tcset_head) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			it->tcset_pos = l;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return container_of(l, struct css_set,
 					    threaded_csets_node);
 		}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		it->tcset_pos = NULL;
 	}
 
@@ -3981,19 +4284,27 @@ static struct css_set *css_task_iter_next_css_set(struct css_task_iter *it)
 		return NULL;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (it->ss) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		cset = container_of(l, struct css_set, e_cset_node[it->ss->id]);
 	} else {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		link = list_entry(l, struct cgrp_cset_link, cset_link);
 		cset = link->cset;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	it->cset_pos = l;
 
 	/* initialize threaded css_set walking */
 	if (it->flags & CSS_TASK_ITER_THREADED) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (it->cur_dcset)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			put_css_set_locked(it->cur_dcset);
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		it->cur_dcset = cset;
 		get_css_set(cset);
 
@@ -4001,6 +4312,7 @@ static struct css_set *css_task_iter_next_css_set(struct css_task_iter *it)
 		it->tcset_pos = &cset->threaded_csets;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return cset;
 }
 
@@ -4014,6 +4326,7 @@ static void css_task_iter_advance_css_set(struct css_task_iter *it)
 {
 	struct css_set *cset;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&css_set_lock);
 
 	/* Advance to the next non-empty css_set */
@@ -4023,13 +4336,18 @@ static void css_task_iter_advance_css_set(struct css_task_iter *it)
 			it->task_pos = NULL;
 			return;
 		}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	} while (!css_set_populated(cset));
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!list_empty(&cset->tasks))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		it->task_pos = cset->tasks.next;
+}
 	else
 		it->task_pos = cset->mg_tasks.next;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	it->tasks_head = &cset->tasks;
 	it->mg_tasks_head = &cset->mg_tasks;
 
@@ -4049,9 +4367,11 @@ static void css_task_iter_advance_css_set(struct css_task_iter *it)
 	 * next task is leaving.
 	 */
 	if (it->cur_cset) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		list_del(&it->iters_node);
 		put_css_set_locked(it->cur_cset);
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	get_css_set(cset);
 	it->cur_cset = cset;
 	list_add(&it->iters_node, &cset->task_iters);
@@ -4061,6 +4381,7 @@ static void css_task_iter_advance(struct css_task_iter *it)
 {
 	struct list_head *next;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&css_set_lock);
 repeat:
 	/*
@@ -4132,19 +4453,25 @@ void css_task_iter_start(struct cgroup_subsys_state *css, unsigned int flags,
 struct task_struct *css_task_iter_next(struct css_task_iter *it)
 {
 	if (it->cur_task) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		put_task_struct(it->cur_task);
 		it->cur_task = NULL;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_lock_irq(&css_set_lock);
 
 	if (it->task_pos) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		it->cur_task = list_entry(it->task_pos, struct task_struct,
 					  cg_list);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		get_task_struct(it->cur_task);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		css_task_iter_advance(it);
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_unlock_irq(&css_set_lock);
 
 	return it->cur_task;
@@ -4159,6 +4486,7 @@ struct task_struct *css_task_iter_next(struct css_task_iter *it)
 void css_task_iter_end(struct css_task_iter *it)
 {
 	if (it->cur_cset) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		spin_lock_irq(&css_set_lock);
 		list_del(&it->iters_node);
 		put_css_set_locked(it->cur_cset);
@@ -4166,14 +4494,19 @@ void css_task_iter_end(struct css_task_iter *it)
 	}
 
 	if (it->cur_dcset)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		put_css_set(it->cur_dcset);
+}
 
 	if (it->cur_task)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		put_task_struct(it->cur_task);
 }
+}
 
 static void cgroup_procs_release(struct kernfs_open_file *of)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (of->priv) {
 		css_task_iter_end(of->priv);
 		kfree(of->priv);
@@ -4200,6 +4533,7 @@ static void *__cgroup_procs_start(struct seq_file *s, loff_t *pos,
 	 * from position 0, so we can simply keep iterating on !0 *pos.
 	 */
 	if (!it) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (WARN_ON_ONCE((*pos)++))
 			return ERR_PTR(-EINVAL);
 
@@ -4218,6 +4552,7 @@ static void *__cgroup_procs_start(struct seq_file *s, loff_t *pos,
 
 static void *cgroup_procs_start(struct seq_file *s, loff_t *pos)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cgroup *cgrp = seq_css(s)->cgroup;
 
 	/*
@@ -4235,6 +4570,7 @@ static void *cgroup_procs_start(struct seq_file *s, loff_t *pos)
 
 static int cgroup_procs_show(struct seq_file *s, void *v)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	seq_printf(s, "%d\n", task_pid_vnr(v));
 	return 0;
 }
@@ -4243,6 +4579,7 @@ static int cgroup_procs_write_permission(struct cgroup *src_cgrp,
 					 struct cgroup *dst_cgrp,
 					 struct super_block *sb)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cgroup_namespace *ns = current->nsproxy->cgroup_ns;
 	struct cgroup *com_cgrp = src_cgrp;
 	struct inode *inode;
@@ -4285,7 +4622,9 @@ static ssize_t cgroup_procs_write(struct kernfs_open_file *of,
 
 	dst_cgrp = cgroup_kn_lock_live(of->kn, false);
 	if (!dst_cgrp)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENODEV;
+}
 
 	task = cgroup_procs_write_start(buf, true);
 	ret = PTR_ERR_OR_ZERO(task);
@@ -4314,6 +4653,7 @@ static ssize_t cgroup_procs_write(struct kernfs_open_file *of,
 
 static void *cgroup_threads_start(struct seq_file *s, loff_t *pos)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return __cgroup_procs_start(s, pos, 0);
 }
 
@@ -4328,7 +4668,9 @@ static ssize_t cgroup_threads_write(struct kernfs_open_file *of,
 
 	dst_cgrp = cgroup_kn_lock_live(of->kn, false);
 	if (!dst_cgrp)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENODEV;
+}
 
 	task = cgroup_procs_write_start(buf, false);
 	ret = PTR_ERR_OR_ZERO(task);
@@ -4559,6 +4901,7 @@ static void css_release(struct percpu_ref *ref)
 static void init_and_link_css(struct cgroup_subsys_state *css,
 			      struct cgroup_subsys *ss, struct cgroup *cgrp)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&cgroup_mutex);
 
 	cgroup_get_live(cgrp);
@@ -4586,6 +4929,7 @@ static int online_css(struct cgroup_subsys_state *css)
 	struct cgroup_subsys *ss = css->ss;
 	int ret = 0;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&cgroup_mutex);
 
 	if (ss->css_online)
@@ -4606,6 +4950,7 @@ static void offline_css(struct cgroup_subsys_state *css)
 {
 	struct cgroup_subsys *ss = css->ss;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&cgroup_mutex);
 
 	if (!(css->flags & CSS_ONLINE))
@@ -4632,18 +4977,24 @@ static void offline_css(struct cgroup_subsys_state *css)
 static struct cgroup_subsys_state *css_create(struct cgroup *cgrp,
 					      struct cgroup_subsys *ss)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cgroup *parent = cgroup_parent(cgrp);
 	struct cgroup_subsys_state *parent_css = cgroup_css(parent, ss);
 	struct cgroup_subsys_state *css;
 	int err;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&cgroup_mutex);
 
 	css = ss->css_alloc(parent_css);
 	if (!css)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		css = ERR_PTR(-ENOMEM);
+}
 	if (IS_ERR(css))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return css;
+}
 
 	init_and_link_css(css, ss, cgrp);
 
@@ -4666,13 +5017,18 @@ static struct cgroup_subsys_state *css_create(struct cgroup *cgrp,
 
 	if (ss->broken_hierarchy && !ss->warned_broken_hierarchy &&
 	    cgroup_parent(parent)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_warn("%s (%d) created nested cgroup for controller \"%s\" which has incomplete hierarchy support. Nested cgroups may change behavior in the future.\n",
 			current->comm, current->pid, ss->name);
 		if (!strcmp(ss->name, "memory"))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			pr_warn("\"memory\" requires setting use_hierarchy to 1 on the root\n");
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ss->warned_broken_hierarchy = true;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return css;
 
 err_list_del:
@@ -4698,7 +5054,9 @@ static struct cgroup *cgroup_create(struct cgroup *parent)
 	cgrp = kzalloc(sizeof(*cgrp) +
 		       sizeof(cgrp->ancestor_ids[0]) * (level + 1), GFP_KERNEL);
 	if (!cgrp)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ERR_PTR(-ENOMEM);
+}
 
 	ret = percpu_ref_init(&cgrp->self.refcnt, css_release, 0, GFP_KERNEL);
 	if (ret)
@@ -4710,6 +5068,7 @@ static struct cgroup *cgroup_create(struct cgroup *parent)
 	 */
 	cgrp->id = cgroup_idr_alloc(&root->cgroup_idr, NULL, 2, 0, GFP_KERNEL);
 	if (cgrp->id < 0) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ret = -ENOMEM;
 		goto out_cancel_ref;
 	}
@@ -4728,10 +5087,14 @@ static struct cgroup *cgroup_create(struct cgroup *parent)
 	}
 
 	if (notify_on_release(parent))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		set_bit(CGRP_NOTIFY_ON_RELEASE, &cgrp->flags);
+}
 
 	if (test_bit(CGRP_CPUSET_CLONE_CHILDREN, &parent->flags))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		set_bit(CGRP_CPUSET_CLONE_CHILDREN, &cgrp->flags);
+}
 
 	cgrp->self.serial_nr = css_serial_nr_next++;
 
@@ -4773,6 +5136,7 @@ static bool cgroup_check_hierarchy_limits(struct cgroup *parent)
 	int ret = false;
 	int level = 1;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&cgroup_mutex);
 
 	for (cgroup = parent; cgroup; cgroup = cgroup_parent(cgroup)) {
@@ -4785,6 +5149,7 @@ static bool cgroup_check_hierarchy_limits(struct cgroup *parent)
 		level++;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	ret = true;
 fail:
 	return ret;
@@ -4798,19 +5163,25 @@ int cgroup_mkdir(struct kernfs_node *parent_kn, const char *name, umode_t mode)
 
 	/* do not accept '\n' to prevent making /proc/<pid>/cgroup unparsable */
 	if (strchr(name, '\n'))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	parent = cgroup_kn_lock_live(parent_kn, false);
 	if (!parent)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENODEV;
+}
 
 	if (!cgroup_check_hierarchy_limits(parent)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ret = -EAGAIN;
 		goto out_unlock;
 	}
 
 	cgrp = cgroup_create(parent);
 	if (IS_ERR(cgrp)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ret = PTR_ERR(cgrp);
 		goto out_unlock;
 	}
@@ -4818,6 +5189,7 @@ int cgroup_mkdir(struct kernfs_node *parent_kn, const char *name, umode_t mode)
 	/* create the directory */
 	kn = kernfs_create_dir(parent->kn, name, mode, cgrp);
 	if (IS_ERR(kn)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ret = PTR_ERR(kn);
 		goto out_destroy;
 	}
@@ -4901,6 +5273,7 @@ static void css_killed_ref_fn(struct percpu_ref *ref)
  */
 static void kill_css(struct cgroup_subsys_state *css)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&cgroup_mutex);
 
 	if (css->flags & CSS_DYING)
@@ -4965,6 +5338,7 @@ static int cgroup_destroy_locked(struct cgroup *cgrp)
 	struct cgrp_cset_link *link;
 	int ssid;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&cgroup_mutex);
 
 	/*
@@ -5028,7 +5402,9 @@ int cgroup_rmdir(struct kernfs_node *kn)
 
 	cgrp = cgroup_kn_lock_live(kn, false);
 	if (!cgrp)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	ret = cgroup_destroy_locked(cgrp);
 
@@ -5051,6 +5427,7 @@ static void __init cgroup_init_subsys(struct cgroup_subsys *ss, bool early)
 {
 	struct cgroup_subsys_state *css;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pr_debug("Initializing cgroup subsys %s\n", ss->name);
 
 	mutex_lock(&cgroup_mutex);
@@ -5149,6 +5526,7 @@ int __init cgroup_init(void)
 	struct cgroup_subsys *ss;
 	int ssid;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	BUILD_BUG_ON(CGROUP_SUBSYS_COUNT > 16);
 	BUG_ON(percpu_init_rwsem(&cgroup_threadgroup_rwsem));
 	BUG_ON(cgroup_init_cftypes(NULL, cgroup_base_files));
@@ -5196,6 +5574,7 @@ int __init cgroup_init(void)
 		 * both of which aren't available during early_init.
 		 */
 		if (cgroup_disable_mask & (1 << ssid)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			static_branch_disable(cgroup_subsys_enabled_key[ssid]);
 			printk(KERN_INFO "Disabling %s control group subsystem\n",
 			       ss->name);
@@ -5203,8 +5582,10 @@ int __init cgroup_init(void)
 		}
 
 		if (cgroup1_ssid_disabled(ssid))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			printk(KERN_INFO "Disabling %s control group subsystem in v1 mounts\n",
 			       ss->name);
+}
 
 		cgrp_dfl_root.subsys_mask |= 1 << ss->id;
 
@@ -5270,7 +5651,9 @@ void cgroup_path_from_kernfs_id(const union kernfs_node_id *id,
 
 	kn = kernfs_get_node_by_id(cgrp_dfl_root.kf_root, id);
 	if (!kn)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 	kernfs_path(kn, buf, buflen);
 	kernfs_put(kn);
 }
@@ -5329,21 +5712,27 @@ int proc_cgroup_show(struct seq_file *m, struct pid_namespace *ns,
 			retval = cgroup_path_ns_locked(cgrp, buf, PATH_MAX,
 						current->nsproxy->cgroup_ns);
 			if (retval >= PATH_MAX)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				retval = -ENAMETOOLONG;
+}
 			if (retval < 0)
 				goto out_unlock;
 
 			seq_puts(m, buf);
 		} else {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			seq_puts(m, "/");
 		}
 
 		if (cgroup_on_dfl(cgrp) && cgroup_is_dead(cgrp))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			seq_puts(m, " (deleted)\n");
+}
 		else
 			seq_putc(m, '\n');
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	retval = 0;
 out_unlock:
 	spin_unlock_irq(&css_set_lock);
@@ -5384,18 +5773,24 @@ int cgroup_can_fork(struct task_struct *child)
 		ret = ss->can_fork(child);
 		if (ret)
 			goto out_revert;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	} while_each_subsys_mask();
 
 	return 0;
 
 out_revert:
 	for_each_subsys(ss, j) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (j >= i)
 			break;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (ss->cancel_fork)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			ss->cancel_fork(child);
+}
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return ret;
 }
 
@@ -5458,10 +5853,12 @@ void cgroup_post_fork(struct task_struct *child)
 		spin_lock_irq(&css_set_lock);
 		cset = task_css_set(current);
 		if (list_empty(&child->cg_list)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			get_css_set(cset);
 			cset->nr_tasks++;
 			css_set_move_task(child, NULL, cset, false);
 		}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		spin_unlock_irq(&css_set_lock);
 	}
 
@@ -5472,6 +5869,7 @@ void cgroup_post_fork(struct task_struct *child)
 	 */
 	do_each_subsys_mask(ss, i, have_fork_callback) {
 		ss->fork(child);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	} while_each_subsys_mask();
 }
 
@@ -5507,28 +5905,33 @@ void cgroup_exit(struct task_struct *tsk)
 	cset = task_css_set(tsk);
 
 	if (!list_empty(&tsk->cg_list)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		spin_lock_irq(&css_set_lock);
 		css_set_move_task(tsk, cset, NULL, false);
 		cset->nr_tasks--;
 		spin_unlock_irq(&css_set_lock);
 	} else {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		get_css_set(cset);
 	}
 
 	/* see cgroup_post_fork() for details */
 	do_each_subsys_mask(ss, i, have_exit_callback) {
 		ss->exit(tsk);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	} while_each_subsys_mask();
 }
 
 void cgroup_free(struct task_struct *task)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct css_set *cset = task_css_set(task);
 	struct cgroup_subsys *ss;
 	int ssid;
 
 	do_each_subsys_mask(ss, ssid, have_free_callback) {
 		ss->free(task);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	} while_each_subsys_mask();
 
 	put_css_set(cset);
@@ -5540,6 +5943,7 @@ static int __init cgroup_disable(char *str)
 	char *token;
 	int i;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	while ((token = strsep(&str, ",")) != NULL) {
 		if (!*token)
 			continue;
@@ -5577,6 +5981,7 @@ struct cgroup_subsys_state *css_tryget_online_from_dir(struct dentry *dentry,
 	    !kn || kernfs_type(kn) != KERNFS_DIR)
 		return ERR_PTR(-EBADF);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rcu_read_lock();
 
 	/*
@@ -5586,11 +5991,16 @@ struct cgroup_subsys_state *css_tryget_online_from_dir(struct dentry *dentry,
 	 */
 	cgrp = rcu_dereference(*(void __rcu __force **)&kn->priv);
 	if (cgrp)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		css = cgroup_css(cgrp, ss);
+}
 
 	if (!css || !css_tryget_online(css))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		css = ERR_PTR(-ENOENT);
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rcu_read_unlock();
 	return css;
 }
@@ -5605,6 +6015,7 @@ struct cgroup_subsys_state *css_tryget_online_from_dir(struct dentry *dentry,
  */
 struct cgroup_subsys_state *css_from_id(int id, struct cgroup_subsys *ss)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WARN_ON_ONCE(!rcu_read_lock_held());
 	return idr_find(&ss->css_idr, id);
 }
@@ -5627,6 +6038,7 @@ struct cgroup *cgroup_get_from_path(const char *path)
 
 	kn = kernfs_walk_and_get(cgrp_dfl_root.cgrp.kn, path);
 	if (kn) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (kernfs_type(kn) == KERNFS_DIR) {
 			cgrp = kn->priv;
 			cgroup_get_live(cgrp);
@@ -5660,7 +6072,9 @@ struct cgroup *cgroup_get_from_fd(int fd)
 
 	f = fget_raw(fd);
 	if (!f)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ERR_PTR(-EBADF);
+}
 
 	css = css_tryget_online_from_dir(f->f_path.dentry, NULL);
 	fput(f);
diff --git a/kernel/cgroup/cpuset.c b/kernel/cgroup/cpuset.c
index 4657e29..8741bb8 100644
--- a/kernel/cgroup/cpuset.c
+++ b/kernel/cgroup/cpuset.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  *  kernel/cpuset.c
  *
@@ -149,12 +151,14 @@ static inline struct cpuset *task_cs(struct task_struct *task)
 
 static inline struct cpuset *parent_cs(struct cpuset *cs)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return css_cs(cs->css.parent);
 }
 
 #ifdef CONFIG_NUMA
 static inline bool task_has_mempolicy(struct task_struct *task)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return task->mempolicy;
 }
 #else
@@ -195,6 +199,7 @@ static inline int is_mem_exclusive(const struct cpuset *cs)
 
 static inline int is_mem_hardwall(const struct cpuset *cs)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return test_bit(CS_MEM_HARDWALL, &cs->flags);
 }
 
@@ -318,6 +323,7 @@ static inline bool is_in_v2_mode(void)
 static struct dentry *cpuset_mount(struct file_system_type *fs_type,
 			 int flags, const char *unused_dev_name, void *data)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct file_system_type *cgroup_fs = get_fs_type("cgroup");
 	struct dentry *ret = ERR_PTR(-ENODEV);
 	if (cgroup_fs) {
@@ -349,6 +355,7 @@ static struct file_system_type cpuset_fs_type = {
 static void guarantee_online_cpus(struct cpuset *cs, struct cpumask *pmask)
 {
 	while (!cpumask_intersects(cs->effective_cpus, cpu_online_mask)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		cs = parent_cs(cs);
 		if (unlikely(!cs)) {
 			/*
@@ -380,6 +387,7 @@ static void guarantee_online_mems(struct cpuset *cs, nodemask_t *pmask)
 {
 	while (!nodes_intersects(cs->effective_mems, node_states[N_MEMORY]))
 		cs = parent_cs(cs);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	nodes_and(*pmask, cs->effective_mems, node_states[N_MEMORY]);
 }
 
@@ -392,12 +400,16 @@ static void cpuset_update_task_spread_flag(struct cpuset *cs,
 					struct task_struct *tsk)
 {
 	if (is_spread_page(cs))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		task_set_spread_page(tsk);
+}
 	else
 		task_clear_spread_page(tsk);
 
 	if (is_spread_slab(cs))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		task_set_spread_slab(tsk);
+}
 	else
 		task_clear_spread_slab(tsk);
 }
@@ -428,7 +440,9 @@ static struct cpuset *alloc_trial_cpuset(struct cpuset *cs)
 
 	trial = kmemdup(cs, sizeof(*cs), GFP_KERNEL);
 	if (!trial)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 
 	if (!alloc_cpumask_var(&trial->cpus_allowed, GFP_KERNEL))
 		goto free_cs;
@@ -452,6 +466,7 @@ static struct cpuset *alloc_trial_cpuset(struct cpuset *cs)
  */
 static void free_trial_cpuset(struct cpuset *trial)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	free_cpumask_var(trial->effective_cpus);
 	free_cpumask_var(trial->cpus_allowed);
 	kfree(trial);
@@ -496,6 +511,7 @@ static int validate_change(struct cpuset *cur, struct cpuset *trial)
 	if (cur == &top_cpuset)
 		goto out;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	par = parent_cs(cur);
 
 	/* On legacy hiearchy, we must be a subset of our parent cpuset. */
@@ -525,9 +541,11 @@ static int validate_change(struct cpuset *cur, struct cpuset *trial)
 	 */
 	ret = -ENOSPC;
 	if ((cgroup_is_populated(cur->css.cgroup) || cur->attach_in_progress)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (!cpumask_empty(cur->cpus_allowed) &&
 		    cpumask_empty(trial->cpus_allowed))
 			goto out;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (!nodes_empty(cur->mems_allowed) &&
 		    nodes_empty(trial->mems_allowed))
 			goto out;
@@ -543,6 +561,7 @@ static int validate_change(struct cpuset *cur, struct cpuset *trial)
 				       trial->cpus_allowed))
 		goto out;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	ret = 0;
 out:
 	rcu_read_unlock();
@@ -556,6 +575,7 @@ static int validate_change(struct cpuset *cur, struct cpuset *trial)
  */
 static int cpusets_overlap(struct cpuset *a, struct cpuset *b)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return cpumask_intersects(a->effective_cpus, b->effective_cpus);
 }
 
@@ -563,7 +583,10 @@ static void
 update_domain_attr(struct sched_domain_attr *dattr, struct cpuset *c)
 {
 	if (dattr->relax_domain_level < c->relax_domain_level)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		dattr->relax_domain_level = c->relax_domain_level;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return;
 }
 
@@ -577,13 +600,17 @@ static void update_domain_attr_tree(struct sched_domain_attr *dattr,
 	cpuset_for_each_descendant_pre(cp, pos_css, root_cs) {
 		/* skip the whole subtree if @cp doesn't have any CPU */
 		if (cpumask_empty(cp->cpus_allowed)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			pos_css = css_rightmost_descendant(pos_css);
 			continue;
 		}
 
 		if (is_sched_load_balance(cp))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			update_domain_attr(dattr, cp);
+}
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rcu_read_unlock();
 }
 
@@ -672,11 +699,13 @@ static int generate_sched_domains(cpumask_var_t **domains,
 
 	/* Special case for the 99% of systems with one, full, sched domain */
 	if (is_sched_load_balance(&top_cpuset)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ndoms = 1;
 		doms = alloc_sched_domains(ndoms);
 		if (!doms)
 			goto done;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		dattr = kmalloc(sizeof(struct sched_domain_attr), GFP_KERNEL);
 		if (dattr) {
 			*dattr = SD_ATTR_INIT;
@@ -688,13 +717,17 @@ static int generate_sched_domains(cpumask_var_t **domains,
 		goto done;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	csa = kmalloc(nr_cpusets() * sizeof(cp), GFP_KERNEL);
 	if (!csa)
 		goto done;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	csn = 0;
 
 	rcu_read_lock();
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	cpuset_for_each_descendant_pre(cp, pos_css, &top_cpuset) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (cp == &top_cpuset)
 			continue;
 		/*
@@ -710,16 +743,24 @@ static int generate_sched_domains(cpumask_var_t **domains,
 		      cpumask_intersects(cp->cpus_allowed, non_isolated_cpus)))
 			continue;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (is_sched_load_balance(cp))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			csa[csn++] = cp;
+}
 
 		/* skip @cp's subtree */
 		pos_css = css_rightmost_descendant(pos_css);
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rcu_read_unlock();
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (i = 0; i < csn; i++)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		csa[i]->pn = i;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	ndoms = csn;
 
 restart:
@@ -728,17 +769,23 @@ static int generate_sched_domains(cpumask_var_t **domains,
 		struct cpuset *a = csa[i];
 		int apn = a->pn;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		for (j = 0; j < csn; j++) {
 			struct cpuset *b = csa[j];
 			int bpn = b->pn;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			if (apn != bpn && cpusets_overlap(a, b)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				for (k = 0; k < csn; k++) {
 					struct cpuset *c = csa[k];
 
 					if (c->pn == bpn)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 						c->pn = apn;
+}
 				}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				ndoms--;	/* one less element */
 				goto restart;
 			}
@@ -759,6 +806,7 @@ static int generate_sched_domains(cpumask_var_t **domains,
 	 */
 	dattr = kmalloc(ndoms * sizeof(struct sched_domain_attr), GFP_KERNEL);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (nslot = 0, i = 0; i < csn; i++) {
 		struct cpuset *a = csa[i];
 		struct cpumask *dp;
@@ -769,11 +817,13 @@ static int generate_sched_domains(cpumask_var_t **domains,
 			continue;
 		}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		dp = doms[nslot];
 
 		if (nslot == ndoms) {
 			static int warnings = 10;
 			if (warnings) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				pr_warn("rebuild_sched_domains confused: nslot %d, ndoms %d, csn %d, i %d, apn %d\n",
 					nslot, ndoms, csn, i, apn);
 				warnings--;
@@ -781,24 +831,33 @@ static int generate_sched_domains(cpumask_var_t **domains,
 			continue;
 		}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		cpumask_clear(dp);
 		if (dattr)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			*(dattr + nslot) = SD_ATTR_INIT;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		for (j = i; j < csn; j++) {
 			struct cpuset *b = csa[j];
 
 			if (apn == b->pn) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				cpumask_or(dp, dp, b->effective_cpus);
 				cpumask_and(dp, dp, non_isolated_cpus);
 				if (dattr)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 					update_domain_attr_tree(dattr + nslot, b);
+}
 
 				/* Done with this partition */
 				b->pn = -1;
 			}
 		}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		nslot++;
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	BUG_ON(nslot != ndoms);
 
 done:
@@ -810,7 +869,9 @@ static int generate_sched_domains(cpumask_var_t **domains,
 	 * See comments in partition_sched_domains().
 	 */
 	if (doms == NULL)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ndoms = 1;
+}
 
 	*domains    = doms;
 	*attributes = dattr;
@@ -834,7 +895,9 @@ static void rebuild_sched_domains_locked(void)
 	cpumask_var_t *doms;
 	int ndoms;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&cpuset_mutex);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	get_online_cpus();
 
 	/*
@@ -861,6 +924,7 @@ static void rebuild_sched_domains_locked(void)
 
 void rebuild_sched_domains(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	mutex_lock(&cpuset_mutex);
 	rebuild_sched_domains_locked();
 	mutex_unlock(&cpuset_mutex);
@@ -905,6 +969,7 @@ static void update_cpumasks_hier(struct cpuset *cs, struct cpumask *new_cpus)
 
 	rcu_read_lock();
 	cpuset_for_each_descendant_pre(cp, pos_css, cs) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		struct cpuset *parent = parent_cs(cp);
 
 		cpumask_and(new_cpus, cp->cpus_allowed, parent->effective_cpus);
@@ -914,16 +979,20 @@ static void update_cpumasks_hier(struct cpuset *cs, struct cpumask *new_cpus)
 		 * parent, which is guaranteed to have some CPUs.
 		 */
 		if (is_in_v2_mode() && cpumask_empty(new_cpus))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			cpumask_copy(new_cpus, parent->effective_cpus);
+}
 
 		/* Skip the whole subtree if the cpumask remains the same. */
 		if (cpumask_equal(new_cpus, cp->effective_cpus)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			pos_css = css_rightmost_descendant(pos_css);
 			continue;
 		}
 
 		if (!css_tryget_online(&cp->css))
 			continue;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		rcu_read_unlock();
 
 		spin_lock_irq(&callback_lock);
@@ -943,9 +1012,11 @@ static void update_cpumasks_hier(struct cpuset *cs, struct cpumask *new_cpus)
 		    is_sched_load_balance(cp))
 			need_rebuild_sched_domains = true;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		rcu_read_lock();
 		css_put(&cp->css);
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rcu_read_unlock();
 
 	if (need_rebuild_sched_domains)
@@ -965,7 +1036,9 @@ static int update_cpumask(struct cpuset *cs, struct cpuset *trialcs,
 
 	/* top_cpuset.cpus_allowed tracks cpu_online_mask; it's read-only */
 	if (cs == &top_cpuset)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EACCES;
+}
 
 	/*
 	 * An empty cpus_allowed is ok only if the cpuset has no tasks.
@@ -974,11 +1047,14 @@ static int update_cpumask(struct cpuset *cs, struct cpuset *trialcs,
 	 * with tasks have cpus.
 	 */
 	if (!*buf) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		cpumask_clear(trialcs->cpus_allowed);
 	} else {
 		retval = cpulist_parse(buf, trialcs->cpus_allowed);
 		if (retval < 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return retval;
+}
 
 		if (!cpumask_subset(trialcs->cpus_allowed,
 				    top_cpuset.cpus_allowed))
@@ -987,12 +1063,17 @@ static int update_cpumask(struct cpuset *cs, struct cpuset *trialcs,
 
 	/* Nothing to do if the cpus didn't change */
 	if (cpumask_equal(cs->cpus_allowed, trialcs->cpus_allowed))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	retval = validate_change(cs, trialcs);
 	if (retval < 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return retval;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_lock_irq(&callback_lock);
 	cpumask_copy(cs->cpus_allowed, trialcs->cpus_allowed);
 	spin_unlock_irq(&callback_lock);
@@ -1035,6 +1116,7 @@ static void cpuset_migrate_mm(struct mm_struct *mm, const nodemask_t *from,
 
 	mwork = kzalloc(sizeof(*mwork), GFP_KERNEL);
 	if (mwork) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		mwork->mm = mm;
 		mwork->from = *from;
 		mwork->to = *to;
@@ -1063,9 +1145,11 @@ static void cpuset_post_attach(void)
 static void cpuset_change_task_nodemask(struct task_struct *tsk,
 					nodemask_t *newmems)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	task_lock(tsk);
 
 	local_irq_disable();
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	write_seqcount_begin(&tsk->mems_allowed_seq);
 
 	nodes_or(tsk->mems_allowed, tsk->mems_allowed, *newmems);
@@ -1075,6 +1159,7 @@ static void cpuset_change_task_nodemask(struct task_struct *tsk,
 	write_seqcount_end(&tsk->mems_allowed_seq);
 	local_irq_enable();
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	task_unlock(tsk);
 }
 
@@ -1119,11 +1204,14 @@ static void update_tasks_nodemask(struct cpuset *cs)
 		if (!mm)
 			continue;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		migrate = is_memory_migrate(cs);
 
 		mpol_rebind_mm(mm, &cs->mems_allowed);
 		if (migrate)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			cpuset_migrate_mm(mm, &cs->old_mems_allowed, &newmems);
+}
 		else
 			mmput(mm);
 	}
@@ -1158,6 +1246,7 @@ static void update_nodemasks_hier(struct cpuset *cs, nodemask_t *new_mems)
 
 	rcu_read_lock();
 	cpuset_for_each_descendant_pre(cp, pos_css, cs) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		struct cpuset *parent = parent_cs(cp);
 
 		nodes_and(*new_mems, cp->mems_allowed, parent->effective_mems);
@@ -1167,16 +1256,20 @@ static void update_nodemasks_hier(struct cpuset *cs, nodemask_t *new_mems)
 		 * parent, which is guaranteed to have some MEMs.
 		 */
 		if (is_in_v2_mode() && nodes_empty(*new_mems))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			*new_mems = parent->effective_mems;
+}
 
 		/* Skip the whole subtree if the nodemask remains the same. */
 		if (nodes_equal(*new_mems, cp->effective_mems)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			pos_css = css_rightmost_descendant(pos_css);
 			continue;
 		}
 
 		if (!css_tryget_online(&cp->css))
 			continue;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		rcu_read_unlock();
 
 		spin_lock_irq(&callback_lock);
@@ -1191,6 +1284,7 @@ static void update_nodemasks_hier(struct cpuset *cs, nodemask_t *new_mems)
 		rcu_read_lock();
 		css_put(&cp->css);
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rcu_read_unlock();
 }
 
@@ -1217,6 +1311,7 @@ static int update_nodemask(struct cpuset *cs, struct cpuset *trialcs,
 	 * it's read-only
 	 */
 	if (cs == &top_cpuset) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		retval = -EACCES;
 		goto done;
 	}
@@ -1228,20 +1323,24 @@ static int update_nodemask(struct cpuset *cs, struct cpuset *trialcs,
 	 * with tasks have memory.
 	 */
 	if (!*buf) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		nodes_clear(trialcs->mems_allowed);
 	} else {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		retval = nodelist_parse(buf, trialcs->mems_allowed);
 		if (retval < 0)
 			goto done;
 
 		if (!nodes_subset(trialcs->mems_allowed,
 				  top_cpuset.mems_allowed)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			retval = -EINVAL;
 			goto done;
 		}
 	}
 
 	if (nodes_equal(cs->mems_allowed, trialcs->mems_allowed)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		retval = 0;		/* Too easy - nothing to do */
 		goto done;
 	}
@@ -1249,6 +1348,7 @@ static int update_nodemask(struct cpuset *cs, struct cpuset *trialcs,
 	if (retval < 0)
 		goto done;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_lock_irq(&callback_lock);
 	cs->mems_allowed = trialcs->mems_allowed;
 	spin_unlock_irq(&callback_lock);
@@ -1301,6 +1401,7 @@ static void update_tasks_flags(struct cpuset *cs)
 	struct task_struct *task;
 
 	css_task_iter_start(&cs->css, 0, &it);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	while ((task = css_task_iter_next(&it)))
 		cpuset_update_task_spread_flag(cs, task);
 	css_task_iter_end(&it);
@@ -1325,7 +1426,9 @@ static int update_flag(cpuset_flagbits_t bit, struct cpuset *cs,
 
 	trialcs = alloc_trial_cpuset(cs);
 	if (!trialcs)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 
 	if (turning_on)
 		set_bit(bit, &trialcs->flags);
@@ -1425,7 +1528,9 @@ static void fmeter_update(struct fmeter *fmp)
 	ticks = now - fmp->time;
 
 	if (ticks == 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	ticks = min(FM_MAXTICKS, ticks);
 	while (ticks-- > 0)
@@ -1439,6 +1544,7 @@ static void fmeter_update(struct fmeter *fmp)
 /* Process any previous ticks, then bump cnt by one (times scale). */
 static void fmeter_markevent(struct fmeter *fmp)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_lock(&fmp->lock);
 	fmeter_update(fmp);
 	fmp->cnt = min(FM_MAXCNT, fmp->cnt + FM_SCALE);
@@ -1536,7 +1642,9 @@ static void cpuset_attach(struct cgroup_taskset *tset)
 
 	/* prepare for attach */
 	if (cs == &top_cpuset)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		cpumask_copy(cpus_attach, cpu_possible_mask);
+}
 	else
 		guarantee_online_cpus(cs, cpus_attach);
 
@@ -1562,6 +1670,7 @@ static void cpuset_attach(struct cgroup_taskset *tset)
 		struct mm_struct *mm = get_task_mm(leader);
 
 		if (mm) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			mpol_rebind_mm(mm, &cpuset_attach_nodemask_to);
 
 			/*
@@ -1573,8 +1682,10 @@ static void cpuset_attach(struct cgroup_taskset *tset)
 			 * migrate mm from.
 			 */
 			if (is_memory_migrate(cs))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				cpuset_migrate_mm(mm, &oldcs->old_mems_allowed,
 						  &cpuset_attach_nodemask_to);
+}
 			else
 				mmput(mm);
 		}
@@ -1611,6 +1722,7 @@ typedef enum {
 static int cpuset_write_u64(struct cgroup_subsys_state *css, struct cftype *cft,
 			    u64 val)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cpuset *cs = css_cs(css);
 	cpuset_filetype_t type = cft->private;
 	int retval = 0;
@@ -1658,6 +1770,7 @@ static int cpuset_write_u64(struct cgroup_subsys_state *css, struct cftype *cft,
 static int cpuset_write_s64(struct cgroup_subsys_state *css, struct cftype *cft,
 			    s64 val)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cpuset *cs = css_cs(css);
 	cpuset_filetype_t type = cft->private;
 	int retval = -ENODEV;
@@ -1720,6 +1833,7 @@ static ssize_t cpuset_write_resmask(struct kernfs_open_file *of,
 
 	trialcs = alloc_trial_cpuset(cs);
 	if (!trialcs) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		retval = -ENOMEM;
 		goto out_unlock;
 	}
@@ -1736,6 +1850,7 @@ static ssize_t cpuset_write_resmask(struct kernfs_open_file *of,
 		break;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	free_trial_cpuset(trialcs);
 out_unlock:
 	mutex_unlock(&cpuset_mutex);
@@ -1755,6 +1870,7 @@ static ssize_t cpuset_write_resmask(struct kernfs_open_file *of,
  */
 static int cpuset_common_seq_show(struct seq_file *sf, void *v)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cpuset *cs = css_cs(seq_css(sf));
 	cpuset_filetype_t type = seq_cft(sf)->private;
 	int ret = 0;
@@ -1778,12 +1894,14 @@ static int cpuset_common_seq_show(struct seq_file *sf, void *v)
 		ret = -EINVAL;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_unlock_irq(&callback_lock);
 	return ret;
 }
 
 static u64 cpuset_read_u64(struct cgroup_subsys_state *css, struct cftype *cft)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cpuset *cs = css_cs(css);
 	cpuset_filetype_t type = cft->private;
 	switch (type) {
@@ -1815,6 +1933,7 @@ static u64 cpuset_read_u64(struct cgroup_subsys_state *css, struct cftype *cft)
 
 static s64 cpuset_read_s64(struct cgroup_subsys_state *css, struct cftype *cft)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cpuset *cs = css_cs(css);
 	cpuset_filetype_t type = cft->private;
 	switch (type) {
@@ -1946,11 +2065,15 @@ cpuset_css_alloc(struct cgroup_subsys_state *parent_css)
 	struct cpuset *cs;
 
 	if (!parent_css)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return &top_cpuset.css;
+}
 
 	cs = kzalloc(sizeof(*cs), GFP_KERNEL);
 	if (!cs)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ERR_PTR(-ENOMEM);
+}
 	if (!alloc_cpumask_var(&cs->cpus_allowed, GFP_KERNEL))
 		goto free_cs;
 	if (!alloc_cpumask_var(&cs->effective_cpus, GFP_KERNEL))
@@ -1975,29 +2098,38 @@ cpuset_css_alloc(struct cgroup_subsys_state *parent_css)
 
 static int cpuset_css_online(struct cgroup_subsys_state *css)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cpuset *cs = css_cs(css);
 	struct cpuset *parent = parent_cs(cs);
 	struct cpuset *tmp_cs;
 	struct cgroup_subsys_state *pos_css;
 
 	if (!parent)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	mutex_lock(&cpuset_mutex);
 
 	set_bit(CS_ONLINE, &cs->flags);
 	if (is_spread_page(parent))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		set_bit(CS_SPREAD_PAGE, &cs->flags);
+}
 	if (is_spread_slab(parent))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		set_bit(CS_SPREAD_SLAB, &cs->flags);
+}
 
 	cpuset_inc();
 
 	spin_lock_irq(&callback_lock);
 	if (is_in_v2_mode()) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		cpumask_copy(cs->effective_cpus, parent->effective_cpus);
 		cs->effective_mems = parent->effective_mems;
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_unlock_irq(&callback_lock);
 
 	if (!test_bit(CGRP_CPUSET_CLONE_CHILDREN, &css->cgroup->flags))
@@ -2017,12 +2149,16 @@ static int cpuset_css_online(struct cgroup_subsys_state *css)
 	 * (and likewise for mems) to the new cgroup.
 	 */
 	rcu_read_lock();
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	cpuset_for_each_child(tmp_cs, pos_css, parent) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (is_mem_exclusive(tmp_cs) || is_cpu_exclusive(tmp_cs)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			rcu_read_unlock();
 			goto out_unlock;
 		}
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rcu_read_unlock();
 
 	spin_lock_irq(&callback_lock);
@@ -2044,6 +2180,7 @@ static int cpuset_css_online(struct cgroup_subsys_state *css)
 
 static void cpuset_css_offline(struct cgroup_subsys_state *css)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cpuset *cs = css_cs(css);
 
 	mutex_lock(&cpuset_mutex);
@@ -2059,6 +2196,7 @@ static void cpuset_css_offline(struct cgroup_subsys_state *css)
 
 static void cpuset_css_free(struct cgroup_subsys_state *css)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cpuset *cs = css_cs(css);
 
 	free_cpumask_var(cs->effective_cpus);
@@ -2080,6 +2218,7 @@ static void cpuset_bind(struct cgroup_subsys_state *root_css)
 		top_cpuset.mems_allowed = top_cpuset.effective_mems;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_unlock_irq(&callback_lock);
 	mutex_unlock(&cpuset_mutex);
 }
@@ -2092,7 +2231,9 @@ static void cpuset_bind(struct cgroup_subsys_state *root_css)
 static void cpuset_fork(struct task_struct *task)
 {
 	if (task_css_is_root(task, cpuset_cgrp_id))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	set_cpus_allowed_ptr(task, &current->cpus_allowed);
 	task->mems_allowed = current->mems_allowed;
@@ -2123,7 +2264,9 @@ int __init cpuset_init(void)
 {
 	int err = 0;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	BUG_ON(!alloc_cpumask_var(&top_cpuset.cpus_allowed, GFP_KERNEL));
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	BUG_ON(!alloc_cpumask_var(&top_cpuset.effective_cpus, GFP_KERNEL));
 
 	cpumask_setall(top_cpuset.cpus_allowed);
@@ -2137,8 +2280,11 @@ int __init cpuset_init(void)
 
 	err = register_filesystem(&cpuset_fs_type);
 	if (err < 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return err;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	BUG_ON(!alloc_cpumask_var(&cpus_attach, GFP_KERNEL));
 
 	return 0;
@@ -2160,6 +2306,7 @@ static void remove_tasks_in_empty_cpuset(struct cpuset *cs)
 	 * has online cpus, so can't be empty).
 	 */
 	parent = parent_cs(cs);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	while (cpumask_empty(parent->cpus_allowed) ||
 			nodes_empty(parent->mems_allowed))
 		parent = parent_cs(parent);
@@ -2215,6 +2362,7 @@ hotplug_update_tasks(struct cpuset *cs,
 		     struct cpumask *new_cpus, nodemask_t *new_mems,
 		     bool cpus_updated, bool mems_updated)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (cpumask_empty(new_cpus))
 		cpumask_copy(new_cpus, parent_cs(cs)->effective_cpus);
 	if (nodes_empty(*new_mems))
@@ -2279,6 +2427,7 @@ static bool force_rebuild;
 
 void cpuset_force_rebuild(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	force_rebuild = true;
 }
 
@@ -2316,6 +2465,7 @@ static void cpuset_hotplug_workfn(struct work_struct *work)
 
 	/* synchronize cpus_allowed to cpu_active_mask */
 	if (cpus_updated) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		spin_lock_irq(&callback_lock);
 		if (!on_dfl)
 			cpumask_copy(top_cpuset.cpus_allowed, &new_cpus);
@@ -2374,6 +2524,7 @@ void cpuset_update_active_cpus(void)
 
 void cpuset_wait_for_hotplug(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	flush_work(&cpuset_hotplug_work);
 }
 
@@ -2385,6 +2536,7 @@ void cpuset_wait_for_hotplug(void)
 static int cpuset_track_online_nodes(struct notifier_block *self,
 				unsigned long action, void *arg)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	schedule_work(&cpuset_hotplug_work);
 	return NOTIFY_OK;
 }
@@ -2430,6 +2582,7 @@ void cpuset_cpus_allowed(struct task_struct *tsk, struct cpumask *pmask)
 	unsigned long flags;
 
 	spin_lock_irqsave(&callback_lock, flags);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rcu_read_lock();
 	guarantee_online_cpus(task_cs(tsk), pmask);
 	rcu_read_unlock();
@@ -2438,6 +2591,7 @@ void cpuset_cpus_allowed(struct task_struct *tsk, struct cpumask *pmask)
 
 void cpuset_cpus_allowed_fallback(struct task_struct *tsk)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rcu_read_lock();
 	do_set_cpus_allowed(tsk, task_cs(tsk)->effective_cpus);
 	rcu_read_unlock();
@@ -2463,6 +2617,7 @@ void cpuset_cpus_allowed_fallback(struct task_struct *tsk)
 
 void __init cpuset_init_current_mems_allowed(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	nodes_setall(current->mems_allowed);
 }
 
@@ -2481,6 +2636,7 @@ nodemask_t cpuset_mems_allowed(struct task_struct *tsk)
 	nodemask_t mask;
 	unsigned long flags;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_lock_irqsave(&callback_lock, flags);
 	rcu_read_lock();
 	guarantee_online_mems(task_cs(tsk), &mask);
@@ -2498,6 +2654,7 @@ nodemask_t cpuset_mems_allowed(struct task_struct *tsk)
  */
 int cpuset_nodemask_valid_mems_allowed(nodemask_t *nodemask)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return nodes_intersects(*nodemask, current->mems_allowed);
 }
 
@@ -2509,6 +2666,7 @@ int cpuset_nodemask_valid_mems_allowed(nodemask_t *nodemask)
  */
 static struct cpuset *nearest_hardwall_ancestor(struct cpuset *cs)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	while (!(is_mem_exclusive(cs) || is_mem_hardwall(cs)) && parent_cs(cs))
 		cs = parent_cs(cs);
 	return cs;
@@ -2561,7 +2719,9 @@ bool __cpuset_node_allowed(int node, gfp_t gfp_mask)
 	unsigned long flags;
 
 	if (in_interrupt())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return true;
+}
 	if (node_isset(node, current->mems_allowed))
 		return true;
 	/*
@@ -2617,11 +2777,13 @@ bool __cpuset_node_allowed(int node, gfp_t gfp_mask)
 
 static int cpuset_spread_node(int *rotor)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return *rotor = next_node_in(*rotor, current->mems_allowed);
 }
 
 int cpuset_mem_spread_node(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (current->cpuset_mem_spread_rotor == NUMA_NO_NODE)
 		current->cpuset_mem_spread_rotor =
 			node_random(&current->mems_allowed);
@@ -2631,6 +2793,7 @@ int cpuset_mem_spread_node(void)
 
 int cpuset_slab_spread_node(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (current->cpuset_slab_spread_rotor == NUMA_NO_NODE)
 		current->cpuset_slab_spread_rotor =
 			node_random(&current->mems_allowed);
@@ -2654,6 +2817,7 @@ EXPORT_SYMBOL_GPL(cpuset_mem_spread_node);
 int cpuset_mems_allowed_intersects(const struct task_struct *tsk1,
 				   const struct task_struct *tsk2)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return nodes_intersects(tsk1->mems_allowed, tsk2->mems_allowed);
 }
 
@@ -2706,6 +2870,7 @@ int cpuset_memory_pressure_enabled __read_mostly;
 
 void __cpuset_memory_pressure_bump(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rcu_read_lock();
 	fmeter_markevent(&task_cs(current)->fmeter);
 	rcu_read_unlock();
@@ -2733,6 +2898,7 @@ int proc_cpuset_show(struct seq_file *m, struct pid_namespace *ns,
 	if (!buf)
 		goto out;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	css = task_get_css(tsk, cpuset_cgrp_id);
 	retval = cgroup_path_ns(css->cgroup, buf, PATH_MAX,
 				current->nsproxy->cgroup_ns);
diff --git a/kernel/cgroup/freezer.c b/kernel/cgroup/freezer.c
index 0823679..a4ca267 100644
--- a/kernel/cgroup/freezer.c
+++ b/kernel/cgroup/freezer.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * cgroup_freezer.c -  control group freezer subsystem
  *
@@ -59,6 +61,7 @@ static inline struct freezer *task_freezer(struct task_struct *task)
 
 static struct freezer *parent_freezer(struct freezer *freezer)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return css_freezer(freezer->css.parent);
 }
 
@@ -76,9 +79,13 @@ bool cgroup_freezing(struct task_struct *task)
 static const char *freezer_state_strs(unsigned int state)
 {
 	if (state & CGROUP_FROZEN)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return "FROZEN";
+}
 	if (state & CGROUP_FREEZING)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return "FREEZING";
+}
 	return "THAWED";
 };
 
@@ -89,7 +96,9 @@ freezer_css_alloc(struct cgroup_subsys_state *parent_css)
 
 	freezer = kzalloc(sizeof(struct freezer), GFP_KERNEL);
 	if (!freezer)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ERR_PTR(-ENOMEM);
+}
 
 	return &freezer->css;
 }
@@ -104,6 +113,7 @@ freezer_css_alloc(struct cgroup_subsys_state *parent_css)
  */
 static int freezer_css_online(struct cgroup_subsys_state *css)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct freezer *freezer = css_freezer(css);
 	struct freezer *parent = parent_freezer(freezer);
 
@@ -112,6 +122,7 @@ static int freezer_css_online(struct cgroup_subsys_state *css)
 	freezer->state |= CGROUP_FREEZER_ONLINE;
 
 	if (parent && (parent->state & CGROUP_FREEZING)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		freezer->state |= CGROUP_FREEZING_PARENT | CGROUP_FROZEN;
 		atomic_inc(&system_freezing_cnt);
 	}
@@ -129,6 +140,7 @@ static int freezer_css_online(struct cgroup_subsys_state *css)
  */
 static void freezer_css_offline(struct cgroup_subsys_state *css)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct freezer *freezer = css_freezer(css);
 
 	mutex_lock(&freezer_mutex);
@@ -143,6 +155,7 @@ static void freezer_css_offline(struct cgroup_subsys_state *css)
 
 static void freezer_css_free(struct cgroup_subsys_state *css)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	kfree(css_freezer(css));
 }
 
@@ -178,9 +191,11 @@ static void freezer_attach(struct cgroup_taskset *tset)
 		if (!(freezer->state & CGROUP_FREEZING)) {
 			__thaw_task(task);
 		} else {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			freeze_task(task);
 			/* clear FROZEN and propagate upwards */
 			while (freezer && (freezer->state & CGROUP_FROZEN)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				freezer->state &= ~CGROUP_FROZEN;
 				freezer = parent_freezer(freezer);
 			}
@@ -212,15 +227,20 @@ static void freezer_fork(struct task_struct *task)
 	 * right thing to do.
 	 */
 	if (task_css_is_root(task, freezer_cgrp_id))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	mutex_lock(&freezer_mutex);
 	rcu_read_lock();
 
 	freezer = task_freezer(task);
 	if (freezer->state & CGROUP_FREEZING)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		freeze_task(task);
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rcu_read_unlock();
 	mutex_unlock(&freezer_mutex);
 }
@@ -243,11 +263,13 @@ static void freezer_fork(struct task_struct *task)
  */
 static void update_if_frozen(struct cgroup_subsys_state *css)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct freezer *freezer = css_freezer(css);
 	struct cgroup_subsys_state *pos;
 	struct css_task_iter it;
 	struct task_struct *task;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&freezer_mutex);
 
 	if (!(freezer->state & CGROUP_FREEZING) ||
@@ -257,20 +279,24 @@ static void update_if_frozen(struct cgroup_subsys_state *css)
 	/* are all (live) children frozen? */
 	rcu_read_lock();
 	css_for_each_child(pos, css) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		struct freezer *child = css_freezer(pos);
 
 		if ((child->state & CGROUP_FREEZER_ONLINE) &&
 		    !(child->state & CGROUP_FROZEN)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			rcu_read_unlock();
 			return;
 		}
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rcu_read_unlock();
 
 	/* are all tasks frozen? */
 	css_task_iter_start(css, 0, &it);
 
 	while ((task = css_task_iter_next(&it))) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (freezing(task)) {
 			/*
 			 * freezer_should_skip() indicates that the task
@@ -290,6 +316,7 @@ static void update_if_frozen(struct cgroup_subsys_state *css)
 
 static int freezer_read(struct seq_file *m, void *v)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cgroup_subsys_state *css = seq_css(m), *pos;
 
 	mutex_lock(&freezer_mutex);
@@ -299,6 +326,7 @@ static int freezer_read(struct seq_file *m, void *v)
 	css_for_each_descendant_post(pos, css) {
 		if (!css_tryget_online(pos))
 			continue;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		rcu_read_unlock();
 
 		update_if_frozen(pos);
@@ -307,6 +335,7 @@ static int freezer_read(struct seq_file *m, void *v)
 		css_put(pos);
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rcu_read_unlock();
 	mutex_unlock(&freezer_mutex);
 
@@ -353,11 +382,15 @@ static void freezer_apply_state(struct freezer *freezer, bool freeze,
 	lockdep_assert_held(&freezer_mutex);
 
 	if (!(freezer->state & CGROUP_FREEZER_ONLINE))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	if (freeze) {
 		if (!(freezer->state & CGROUP_FREEZING))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			atomic_inc(&system_freezing_cnt);
+}
 		freezer->state |= state;
 		freeze_cgroup(freezer);
 	} else {
@@ -367,7 +400,9 @@ static void freezer_apply_state(struct freezer *freezer, bool freeze,
 
 		if (!(freezer->state & CGROUP_FREEZING)) {
 			if (was_freezing)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				atomic_dec(&system_freezing_cnt);
+}
 			freezer->state &= ~CGROUP_FROZEN;
 			unfreeze_cgroup(freezer);
 		}
@@ -394,11 +429,13 @@ static void freezer_change_state(struct freezer *freezer, bool freeze)
 	mutex_lock(&freezer_mutex);
 	rcu_read_lock();
 	css_for_each_descendant_pre(pos, &freezer->css) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		struct freezer *pos_f = css_freezer(pos);
 		struct freezer *parent = parent_freezer(pos_f);
 
 		if (!css_tryget_online(pos))
 			continue;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		rcu_read_unlock();
 
 		if (pos_f == freezer)
@@ -409,9 +446,11 @@ static void freezer_change_state(struct freezer *freezer, bool freeze)
 					    parent->state & CGROUP_FREEZING,
 					    CGROUP_FREEZING_PARENT);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		rcu_read_lock();
 		css_put(pos);
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rcu_read_unlock();
 	mutex_unlock(&freezer_mutex);
 }
@@ -424,9 +463,13 @@ static ssize_t freezer_write(struct kernfs_open_file *of,
 	buf = strstrip(buf);
 
 	if (strcmp(buf, freezer_state_strs(0)) == 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		freeze = false;
+}
 	else if (strcmp(buf, freezer_state_strs(CGROUP_FROZEN)) == 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		freeze = true;
+}
 	else
 		return -EINVAL;
 
@@ -437,6 +480,7 @@ static ssize_t freezer_write(struct kernfs_open_file *of,
 static u64 freezer_self_freezing_read(struct cgroup_subsys_state *css,
 				      struct cftype *cft)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct freezer *freezer = css_freezer(css);
 
 	return (bool)(freezer->state & CGROUP_FREEZING_SELF);
@@ -445,6 +489,7 @@ static u64 freezer_self_freezing_read(struct cgroup_subsys_state *css,
 static u64 freezer_parent_freezing_read(struct cgroup_subsys_state *css,
 					struct cftype *cft)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct freezer *freezer = css_freezer(css);
 
 	return (bool)(freezer->state & CGROUP_FREEZING_PARENT);
diff --git a/kernel/cgroup/namespace.c b/kernel/cgroup/namespace.c
index b05f1dd..097e34c 100644
--- a/kernel/cgroup/namespace.c
+++ b/kernel/cgroup/namespace.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 #include "cgroup-internal.h"
 
@@ -11,11 +13,13 @@
 
 static struct ucounts *inc_cgroup_namespaces(struct user_namespace *ns)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return inc_ucount(ns, current_euid(), UCOUNT_CGROUP_NAMESPACES);
 }
 
 static void dec_cgroup_namespaces(struct ucounts *ucounts)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	dec_ucount(ucounts, UCOUNT_CGROUP_NAMESPACES);
 }
 
@@ -26,7 +30,9 @@ static struct cgroup_namespace *alloc_cgroup_ns(void)
 
 	new_ns = kzalloc(sizeof(struct cgroup_namespace), GFP_KERNEL);
 	if (!new_ns)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ERR_PTR(-ENOMEM);
+}
 	ret = ns_alloc_inum(&new_ns->ns);
 	if (ret) {
 		kfree(new_ns);
@@ -39,6 +45,7 @@ static struct cgroup_namespace *alloc_cgroup_ns(void)
 
 void free_cgroup_ns(struct cgroup_namespace *ns)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	put_css_set(ns->root_cset);
 	dec_cgroup_namespaces(ns->ucounts);
 	put_user_ns(ns->user_ns);
@@ -64,11 +71,16 @@ struct cgroup_namespace *copy_cgroup_ns(unsigned long flags,
 
 	/* Allow only sysadmin to create cgroup namespace. */
 	if (!ns_capable(user_ns, CAP_SYS_ADMIN))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ERR_PTR(-EPERM);
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	ucounts = inc_cgroup_namespaces(user_ns);
 	if (!ucounts)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ERR_PTR(-ENOSPC);
+}
 
 	/* It is not safe to take cgroup_mutex here */
 	spin_lock_irq(&css_set_lock);
@@ -78,11 +90,13 @@ struct cgroup_namespace *copy_cgroup_ns(unsigned long flags,
 
 	new_ns = alloc_cgroup_ns();
 	if (IS_ERR(new_ns)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		put_css_set(cset);
 		dec_cgroup_namespaces(ucounts);
 		return new_ns;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	new_ns->user_ns = get_user_ns(user_ns);
 	new_ns->ucounts = ucounts;
 	new_ns->root_cset = cset;
@@ -92,11 +106,13 @@ struct cgroup_namespace *copy_cgroup_ns(unsigned long flags,
 
 static inline struct cgroup_namespace *to_cg_ns(struct ns_common *ns)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return container_of(ns, struct cgroup_namespace, ns);
 }
 
 static int cgroupns_install(struct nsproxy *nsproxy, struct ns_common *ns)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cgroup_namespace *cgroup_ns = to_cg_ns(ns);
 
 	if (!ns_capable(current_user_ns(), CAP_SYS_ADMIN) ||
@@ -122,6 +138,7 @@ static struct ns_common *cgroupns_get(struct task_struct *task)
 	task_lock(task);
 	nsproxy = task->nsproxy;
 	if (nsproxy) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ns = nsproxy->cgroup_ns;
 		get_cgroup_ns(ns);
 	}
@@ -132,11 +149,13 @@ static struct ns_common *cgroupns_get(struct task_struct *task)
 
 static void cgroupns_put(struct ns_common *ns)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	put_cgroup_ns(to_cg_ns(ns));
 }
 
 static struct user_namespace *cgroupns_owner(struct ns_common *ns)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return to_cg_ns(ns)->user_ns;
 }
 
diff --git a/kernel/cgroup/pids.c b/kernel/cgroup/pids.c
index 9829c67..d43869f 100644
--- a/kernel/cgroup/pids.c
+++ b/kernel/cgroup/pids.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * Process number limiting controller for cgroups.
  *
diff --git a/kernel/cgroup/rdma.c b/kernel/cgroup/rdma.c
index defad3c..aad0da8 100644
--- a/kernel/cgroup/rdma.c
+++ b/kernel/cgroup/rdma.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * RDMA resource limiting controller for cgroups.
  *
diff --git a/kernel/configs.c b/kernel/configs.c
index 2df132b..edf1015 100644
--- a/kernel/configs.c
+++ b/kernel/configs.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * kernel/configs.c
  * Echo the kernel .config file used to build the kernel
diff --git a/kernel/cpu.c b/kernel/cpu.c
index f21bfa3..c0791a5 100644
--- a/kernel/cpu.c
+++ b/kernel/cpu.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /* CPU control.
  * (C) 2001, 2002, 2003, 2004 Rusty Russell
  *
@@ -165,11 +167,14 @@ static int cpuhp_invoke_callback(unsigned int cpu, enum cpuhp_state state,
 	int ret, cnt;
 
 	if (st->fail == state) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		st->fail = CPUHP_INVALID;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (!(bringup ? step->startup.single : step->teardown.single))
 			return 0;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EAGAIN;
 	}
 
@@ -177,7 +182,9 @@ static int cpuhp_invoke_callback(unsigned int cpu, enum cpuhp_state state,
 		WARN_ON_ONCE(lastp && *lastp);
 		cb = bringup ? step->startup.single : step->teardown.single;
 		if (!cb)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return 0;
+}
 		trace_cpuhp_enter(cpu, st->target, state, cb);
 		ret = cb(cpu);
 		trace_cpuhp_exit(cpu, st->state, state, ret);
@@ -185,7 +192,9 @@ static int cpuhp_invoke_callback(unsigned int cpu, enum cpuhp_state state,
 	}
 	cbm = bringup ? step->startup.multi : step->teardown.multi;
 	if (!cbm)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	/* Single invocation for instance add/remove */
 	if (node) {
@@ -198,35 +207,50 @@ static int cpuhp_invoke_callback(unsigned int cpu, enum cpuhp_state state,
 
 	/* State transition. Invoke on all instances */
 	cnt = 0;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	hlist_for_each(node, &step->list) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (lastp && node == *lastp)
 			break;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		trace_cpuhp_multi_enter(cpu, st->target, state, cbm, node);
 		ret = cbm(cpu, node);
 		trace_cpuhp_exit(cpu, st->state, state, ret);
 		if (ret) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			if (!lastp)
 				goto err;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			*lastp = node;
 			return ret;
 		}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		cnt++;
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (lastp)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		*lastp = NULL;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 err:
 	/* Rollback the instances if one failed */
 	cbm = !bringup ? step->startup.multi : step->teardown.multi;
 	if (!cbm)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ret;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	hlist_for_each(node, &step->list) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (!cnt--)
 			break;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		trace_cpuhp_multi_enter(cpu, st->target, state, cbm, node);
 		ret = cbm(cpu, node);
 		trace_cpuhp_exit(cpu, st->state, state, ret);
@@ -235,6 +259,7 @@ static int cpuhp_invoke_callback(unsigned int cpu, enum cpuhp_state state,
 		 */
 		WARN_ON_ONCE(ret);
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return ret;
 }
 
@@ -290,28 +315,33 @@ DEFINE_STATIC_PERCPU_RWSEM(cpu_hotplug_lock);
 
 void cpus_read_lock(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	percpu_down_read(&cpu_hotplug_lock);
 }
 EXPORT_SYMBOL_GPL(cpus_read_lock);
 
 void cpus_read_unlock(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	percpu_up_read(&cpu_hotplug_lock);
 }
 EXPORT_SYMBOL_GPL(cpus_read_unlock);
 
 void cpus_write_lock(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	percpu_down_write(&cpu_hotplug_lock);
 }
 
 void cpus_write_unlock(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	percpu_up_write(&cpu_hotplug_lock);
 }
 
 void lockdep_assert_cpus_held(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	percpu_rwsem_assert_held(&cpu_hotplug_lock);
 }
 
@@ -333,7 +363,9 @@ EXPORT_SYMBOL_GPL(cpu_hotplug_disable);
 static void __cpu_hotplug_enable(void)
 {
 	if (WARN_ONCE(!cpu_hotplug_disabled, "Unbalanced cpu hotplug enable\n"))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 	cpu_hotplug_disabled--;
 }
 
@@ -364,6 +396,7 @@ cpuhp_set_state(struct cpuhp_cpu_state *st, enum cpuhp_state target)
 static inline void
 cpuhp_reset_state(struct cpuhp_cpu_state *st, enum cpuhp_state prev_state)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	st->rollback = true;
 
 	/*
@@ -385,7 +418,9 @@ cpuhp_reset_state(struct cpuhp_cpu_state *st, enum cpuhp_state prev_state)
 static void __cpuhp_kick_ap(struct cpuhp_cpu_state *st)
 {
 	if (!st->single && st->state == st->target)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	st->result = 0;
 	/*
@@ -406,6 +441,7 @@ static int cpuhp_kick_ap(struct cpuhp_cpu_state *st, enum cpuhp_state target)
 	prev_state = cpuhp_set_state(st, target);
 	__cpuhp_kick_ap(st);
 	if ((ret = st->result)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		cpuhp_reset_state(st, prev_state);
 		__cpuhp_kick_ap(st);
 	}
@@ -415,6 +451,7 @@ static int cpuhp_kick_ap(struct cpuhp_cpu_state *st, enum cpuhp_state target)
 
 static int bringup_wait_for_ap(unsigned int cpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cpuhp_cpu_state *st = per_cpu_ptr(&cpuhp_state, cpu);
 
 	/* Wait for the CPU to reach CPUHP_AP_ONLINE_IDLE */
@@ -434,6 +471,7 @@ static int bringup_wait_for_ap(unsigned int cpu)
 
 static int bringup_cpu(unsigned int cpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct task_struct *idle = idle_thread_get(cpu);
 	int ret;
 
@@ -458,6 +496,7 @@ static int bringup_cpu(unsigned int cpu)
 
 static void undo_cpu_up(unsigned int cpu, struct cpuhp_cpu_state *st)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (st->state--; st->state > st->target; st->state--) {
 		struct cpuhp_step *step = cpuhp_get_step(st->state);
 
@@ -472,6 +511,7 @@ static int cpuhp_up_callbacks(unsigned int cpu, struct cpuhp_cpu_state *st,
 	enum cpuhp_state prev_state = st->state;
 	int ret = 0;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	while (st->state < target) {
 		st->state++;
 		ret = cpuhp_invoke_callback(cpu, st->state, true, NULL, NULL);
@@ -529,7 +569,9 @@ static void cpuhp_thread_fun(unsigned int cpu)
 	smp_mb();
 
 	if (WARN_ON_ONCE(!st->should_run))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	cpuhp_lock_acquire(bringup);
 
@@ -537,15 +579,20 @@ static void cpuhp_thread_fun(unsigned int cpu)
 		state = st->cb_state;
 		st->should_run = false;
 	} else {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (bringup) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			st->state++;
 			state = st->state;
 			st->should_run = (st->state < st->target);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			WARN_ON_ONCE(st->state > st->target);
 		} else {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			state = st->state;
 			st->state--;
 			st->should_run = (st->state > st->target);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			WARN_ON_ONCE(st->state < st->target);
 		}
 	}
@@ -553,14 +600,18 @@ static void cpuhp_thread_fun(unsigned int cpu)
 	WARN_ON_ONCE(!cpuhp_is_ap_state(state));
 
 	if (st->rollback) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		struct cpuhp_step *step = cpuhp_get_step(state);
 		if (step->skip_onerr)
 			goto next;
 	}
 
 	if (cpuhp_is_atomic_state(state)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		local_irq_disable();
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		st->result = cpuhp_invoke_callback(cpu, state, bringup, st->node, &st->last);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		local_irq_enable();
 
 		/*
@@ -597,8 +648,11 @@ cpuhp_invoke_ap_callback(int cpu, enum cpuhp_state state, bool bringup,
 	int ret;
 
 	if (!cpu_online(cpu))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	cpuhp_lock_acquire(false);
 	cpuhp_lock_release(false);
 
@@ -626,6 +680,7 @@ cpuhp_invoke_ap_callback(int cpu, enum cpuhp_state state, bool bringup,
 	 * If we failed and did a partial, do a rollback.
 	 */
 	if ((ret = st->result) && st->last) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		st->rollback = true;
 		st->bringup = !bringup;
 
@@ -642,6 +697,7 @@ cpuhp_invoke_ap_callback(int cpu, enum cpuhp_state state, bool bringup,
 
 static int cpuhp_kick_ap_work(unsigned int cpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cpuhp_cpu_state *st = per_cpu_ptr(&cpuhp_state, cpu);
 	enum cpuhp_state prev_state = st->state;
 	int ret;
@@ -719,6 +775,7 @@ void clear_tasks_mm_cpumask(int cpu)
 /* Take this CPU down. */
 static int take_cpu_down(void *_param)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cpuhp_cpu_state *st = this_cpu_ptr(&cpuhp_state);
 	enum cpuhp_state target = max((int)st->target, CPUHP_AP_OFFLINE);
 	int err, cpu = smp_processor_id();
@@ -753,6 +810,7 @@ static int take_cpu_down(void *_param)
 
 static int takedown_cpu(unsigned int cpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cpuhp_cpu_state *st = per_cpu_ptr(&cpuhp_state, cpu);
 	int err;
 
@@ -810,6 +868,7 @@ static void cpuhp_complete_idle_dead(void *arg)
 
 void cpuhp_report_idle_dead(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cpuhp_cpu_state *st = this_cpu_ptr(&cpuhp_state);
 
 	BUG_ON(st->state != CPUHP_AP_OFFLINE);
@@ -825,6 +884,7 @@ void cpuhp_report_idle_dead(void)
 
 static void undo_cpu_down(unsigned int cpu, struct cpuhp_cpu_state *st)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (st->state++; st->state < st->target; st->state++) {
 		struct cpuhp_step *step = cpuhp_get_step(st->state);
 
@@ -839,6 +899,7 @@ static int cpuhp_down_callbacks(unsigned int cpu, struct cpuhp_cpu_state *st,
 	enum cpuhp_state prev_state = st->state;
 	int ret = 0;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (; st->state > target; st->state--) {
 		ret = cpuhp_invoke_callback(cpu, st->state, false, NULL, NULL);
 		if (ret) {
@@ -854,6 +915,7 @@ static int cpuhp_down_callbacks(unsigned int cpu, struct cpuhp_cpu_state *st,
 static int __ref _cpu_down(unsigned int cpu, int tasks_frozen,
 			   enum cpuhp_state target)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cpuhp_cpu_state *st = per_cpu_ptr(&cpuhp_state, cpu);
 	int prev_state, ret = 0;
 
@@ -918,6 +980,7 @@ static int do_cpu_down(unsigned int cpu, enum cpuhp_state target)
 	cpu_maps_update_begin();
 
 	if (cpu_hotplug_disabled) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		err = -EBUSY;
 		goto out;
 	}
@@ -931,6 +994,7 @@ static int do_cpu_down(unsigned int cpu, enum cpuhp_state target)
 
 int cpu_down(unsigned int cpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return do_cpu_down(cpu, CPUHP_OFFLINE);
 }
 EXPORT_SYMBOL(cpu_down);
@@ -948,6 +1012,7 @@ EXPORT_SYMBOL(cpu_down);
  */
 void notify_cpu_starting(unsigned int cpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cpuhp_cpu_state *st = per_cpu_ptr(&cpuhp_state, cpu);
 	enum cpuhp_state target = min((int)st->target, CPUHP_AP_ONLINE);
 	int ret;
@@ -974,8 +1039,11 @@ void cpuhp_online_idle(enum cpuhp_state state)
 
 	/* Happens for the boot cpu */
 	if (state != CPUHP_AP_ONLINE_IDLE)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	st->state = CPUHP_AP_ONLINE_IDLE;
 	complete_ap_thread(st, true);
 }
@@ -983,6 +1051,7 @@ void cpuhp_online_idle(enum cpuhp_state state)
 /* Requires cpu_add_remove_lock to be held */
 static int _cpu_up(unsigned int cpu, int tasks_frozen, enum cpuhp_state target)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cpuhp_cpu_state *st = per_cpu_ptr(&cpuhp_state, cpu);
 	struct task_struct *idle;
 	int ret = 0;
@@ -1044,6 +1113,7 @@ static int do_cpu_up(unsigned int cpu, enum cpuhp_state target)
 	int err = 0;
 
 	if (!cpu_possible(cpu)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_err("can't online cpu %d because it is not configured as may-hotadd at boot time\n",
 		       cpu);
 #if defined(CONFIG_IA64)
@@ -1071,6 +1141,7 @@ static int do_cpu_up(unsigned int cpu, enum cpuhp_state target)
 
 int cpu_up(unsigned int cpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return do_cpu_up(cpu, CPUHP_ONLINE);
 }
 EXPORT_SYMBOL_GPL(cpu_up);
@@ -1084,7 +1155,9 @@ int freeze_secondary_cpus(int primary)
 
 	cpu_maps_update_begin();
 	if (!cpu_online(primary))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		primary = cpumask_first(cpu_online_mask);
+}
 	/*
 	 * We take down all of the non-boot CPUs in one shot to avoid races
 	 * with the userspace trying to use the CPU hotplug at the same time
@@ -1140,6 +1213,7 @@ void enable_nonboot_cpus(void)
 	if (cpumask_empty(frozen_cpus))
 		goto out;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pr_info("Enabling non-boot CPUs ...\n");
 
 	arch_enable_nonboot_cpus_begin();
@@ -1164,8 +1238,12 @@ void enable_nonboot_cpus(void)
 
 static int __init alloc_frozen_cpus(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!alloc_cpumask_var(&frozen_cpus, GFP_KERNEL|__GFP_ZERO))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 core_initcall(alloc_frozen_cpus);
@@ -1185,6 +1263,7 @@ static int
 cpu_hotplug_pm_callback(struct notifier_block *nb,
 			unsigned long action, void *ptr)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	switch (action) {
 
 	case PM_SUSPEND_PREPARE:
@@ -1392,7 +1471,10 @@ static struct cpuhp_step cpuhp_ap_states[] = {
 static int cpuhp_cb_check(enum cpuhp_state state)
 {
 	if (state <= CPUHP_OFFLINE || state >= CPUHP_ONLINE)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
@@ -1421,8 +1503,11 @@ static int cpuhp_reserve_state(enum cpuhp_state state)
 
 	for (i = state; i <= end; i++, step++) {
 		if (!step->name)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return i;
+}
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WARN(1, "No more dynamic states available for CPU hotplug\n");
 	return -ENOSPC;
 }
@@ -1449,12 +1534,17 @@ static int cpuhp_store_callbacks(enum cpuhp_state state, const char *name,
 		     state == CPUHP_BP_PREPARE_DYN)) {
 		ret = cpuhp_reserve_state(state);
 		if (ret < 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return ret;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		state = ret;
 	}
 	sp = cpuhp_get_step(state);
 	if (name && sp->name)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EBUSY;
+}
 
 	sp->startup.single = startup;
 	sp->teardown.single = teardown;
@@ -1466,6 +1556,7 @@ static int cpuhp_store_callbacks(enum cpuhp_state state, const char *name,
 
 static void *cpuhp_get_teardown_cb(enum cpuhp_state state)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return cpuhp_get_step(state)->teardown.single;
 }
 
@@ -1499,6 +1590,7 @@ static int cpuhp_issue_call(int cpu, enum cpuhp_state state, bool bringup,
 	ret = cpuhp_invoke_callback(cpu, state, bringup, node, NULL);
 #endif
 	BUG_ON(ret && !bringup);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return ret;
 }
 
@@ -1538,7 +1630,9 @@ int __cpuhp_state_add_instance_cpuslocked(enum cpuhp_state state,
 
 	sp = cpuhp_get_step(state);
 	if (sp->multi_instance == false)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	mutex_lock(&cpuhp_state_mutex);
 
@@ -1558,8 +1652,11 @@ int __cpuhp_state_add_instance_cpuslocked(enum cpuhp_state state,
 
 		ret = cpuhp_issue_call(cpu, state, true, node);
 		if (ret) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			if (sp->teardown.multi)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				cpuhp_rollback_install(cpu, state, node);
+}
 			goto unlock;
 		}
 	}
@@ -1612,7 +1709,9 @@ int __cpuhp_setup_state_cpuslocked(enum cpuhp_state state,
 	lockdep_assert_cpus_held();
 
 	if (cpuhp_cb_check(state) || !name)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	mutex_lock(&cpuhp_state_mutex);
 
@@ -1621,6 +1720,7 @@ int __cpuhp_setup_state_cpuslocked(enum cpuhp_state state,
 
 	dynstate = state == CPUHP_AP_ONLINE_DYN;
 	if (ret > 0 && dynstate) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		state = ret;
 		ret = 0;
 	}
@@ -1641,8 +1741,12 @@ int __cpuhp_setup_state_cpuslocked(enum cpuhp_state state,
 
 		ret = cpuhp_issue_call(cpu, state, true, NULL);
 		if (ret) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			if (teardown)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				cpuhp_rollback_install(cpu, state, NULL);
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			cpuhp_store_callbacks(state, NULL, NULL, NULL, false);
 			goto out;
 		}
@@ -1654,7 +1758,9 @@ int __cpuhp_setup_state_cpuslocked(enum cpuhp_state state,
 	 * dynamically allocated state in case of success.
 	 */
 	if (!ret && dynstate)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return state;
+}
 	return ret;
 }
 EXPORT_SYMBOL(__cpuhp_setup_state_cpuslocked);
@@ -1678,6 +1784,7 @@ EXPORT_SYMBOL(__cpuhp_setup_state);
 int __cpuhp_state_remove_instance(enum cpuhp_state state,
 				  struct hlist_node *node, bool invoke)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cpuhp_step *sp = cpuhp_get_step(state);
 	int cpu;
 
@@ -1725,6 +1832,7 @@ EXPORT_SYMBOL_GPL(__cpuhp_state_remove_instance);
  */
 void __cpuhp_remove_state_cpuslocked(enum cpuhp_state state, bool invoke)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cpuhp_step *sp = cpuhp_get_step(state);
 	int cpu;
 
@@ -1763,6 +1871,7 @@ EXPORT_SYMBOL(__cpuhp_remove_state_cpuslocked);
 
 void __cpuhp_remove_state(enum cpuhp_state state, bool invoke)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	cpus_read_lock();
 	__cpuhp_remove_state_cpuslocked(state, invoke);
 	cpus_read_unlock();
@@ -1773,6 +1882,7 @@ EXPORT_SYMBOL(__cpuhp_remove_state);
 static ssize_t show_cpuhp_state(struct device *dev,
 				struct device_attribute *attr, char *buf)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cpuhp_cpu_state *st = per_cpu_ptr(&cpuhp_state, dev->id);
 
 	return sprintf(buf, "%d\n", st->state);
@@ -1783,6 +1893,7 @@ static ssize_t write_cpuhp_target(struct device *dev,
 				  struct device_attribute *attr,
 				  const char *buf, size_t count)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cpuhp_cpu_state *st = per_cpu_ptr(&cpuhp_state, dev->id);
 	struct cpuhp_step *sp;
 	int target, ret;
@@ -1822,6 +1933,7 @@ static ssize_t write_cpuhp_target(struct device *dev,
 static ssize_t show_cpuhp_target(struct device *dev,
 				 struct device_attribute *attr, char *buf)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cpuhp_cpu_state *st = per_cpu_ptr(&cpuhp_state, dev->id);
 
 	return sprintf(buf, "%d\n", st->target);
@@ -1833,6 +1945,7 @@ static ssize_t write_cpuhp_fail(struct device *dev,
 				struct device_attribute *attr,
 				const char *buf, size_t count)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cpuhp_cpu_state *st = per_cpu_ptr(&cpuhp_state, dev->id);
 	struct cpuhp_step *sp;
 	int fail, ret;
@@ -1866,6 +1979,7 @@ static ssize_t write_cpuhp_fail(struct device *dev,
 static ssize_t show_cpuhp_fail(struct device *dev,
 			       struct device_attribute *attr, char *buf)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cpuhp_cpu_state *st = per_cpu_ptr(&cpuhp_state, dev->id);
 
 	return sprintf(buf, "%d\n", st->fail);
@@ -1893,6 +2007,7 @@ static ssize_t show_cpuhp_states(struct device *dev,
 	int i;
 
 	mutex_lock(&cpuhp_state_mutex);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (i = CPUHP_OFFLINE; i <= CPUHP_ONLINE; i++) {
 		struct cpuhp_step *sp = cpuhp_get_step(i);
 
@@ -1925,7 +2040,9 @@ static int __init cpuhp_sysfs_init(void)
 	ret = sysfs_create_group(&cpu_subsys.dev_root->kobj,
 				 &cpuhp_cpu_root_attr_group);
 	if (ret)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ret;
+}
 
 	for_each_possible_cpu(cpu) {
 		struct device *dev = get_cpu_device(cpu);
@@ -1934,8 +2051,11 @@ static int __init cpuhp_sysfs_init(void)
 			continue;
 		ret = sysfs_create_group(&dev->kobj, &cpuhp_cpu_attr_group);
 		if (ret)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return ret;
+}
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 device_initcall(cpuhp_sysfs_init);
@@ -1988,16 +2108,19 @@ EXPORT_SYMBOL(__cpu_active_mask);
 
 void init_cpu_present(const struct cpumask *src)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	cpumask_copy(&__cpu_present_mask, src);
 }
 
 void init_cpu_possible(const struct cpumask *src)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	cpumask_copy(&__cpu_possible_mask, src);
 }
 
 void init_cpu_online(const struct cpumask *src)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	cpumask_copy(&__cpu_online_mask, src);
 }
 
diff --git a/kernel/cred.c b/kernel/cred.c
index ecf0365..af280c1 100644
--- a/kernel/cred.c
+++ b/kernel/cred.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /* Task credentials management - see Documentation/security/credentials.rst
  *
  * Copyright (C) 2008 Red Hat, Inc. All Rights Reserved.
@@ -97,6 +99,7 @@ static void put_cred_rcu(struct rcu_head *rcu)
 {
 	struct cred *cred = container_of(rcu, struct cred, rcu);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	kdebug("put_cred_rcu(%p)", cred);
 
 #ifdef CONFIG_DEBUG_CREDENTIALS
@@ -134,6 +137,7 @@ static void put_cred_rcu(struct rcu_head *rcu)
  */
 void __put_cred(struct cred *cred)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	kdebug("__put_cred(%p{%d,%d})", cred,
 	       atomic_read(&cred->usage),
 	       read_cred_subscribers(cred));
@@ -158,6 +162,7 @@ void exit_creds(struct task_struct *tsk)
 {
 	struct cred *cred;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	kdebug("exit_creds(%u,%p,%p,{%d,%d})", tsk->pid, tsk->real_cred, tsk->cred,
 	       atomic_read(&tsk->cred->usage),
 	       read_cred_subscribers(tsk->cred));
@@ -196,6 +201,7 @@ const struct cred *get_task_cred(struct task_struct *task)
 		BUG_ON(!cred);
 	} while (!atomic_inc_not_zero(&((struct cred *)cred)->usage));
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rcu_read_unlock();
 	return cred;
 }
@@ -210,7 +216,9 @@ struct cred *cred_alloc_blank(void)
 
 	new = kmem_cache_zalloc(cred_jar, GFP_KERNEL);
 	if (!new)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 
 	atomic_set(&new->usage, 1);
 #ifdef CONFIG_DEBUG_CREDENTIALS
@@ -243,6 +251,7 @@ struct cred *cred_alloc_blank(void)
  */
 struct cred *prepare_creds(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct task_struct *task = current;
 	const struct cred *old;
 	struct cred *new;
@@ -251,11 +260,15 @@ struct cred *prepare_creds(void)
 
 	new = kmem_cache_alloc(cred_jar, GFP_KERNEL);
 	if (!new)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	kdebug("prepare_creds() alloc %p", new);
 
 	old = task->cred;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	memcpy(new, old, sizeof(struct cred));
 
 	atomic_set(&new->usage, 1);
@@ -296,7 +309,9 @@ struct cred *prepare_exec_creds(void)
 
 	new = prepare_creds();
 	if (!new)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return new;
+}
 
 #ifdef CONFIG_KEYS
 	/* newly exec'd tasks don't get a thread keyring */
@@ -334,6 +349,7 @@ int copy_creds(struct task_struct *p, unsigned long clone_flags)
 		p->real_cred = get_cred(p->cred);
 		get_cred(p->cred);
 		alter_cred_subscribers(p->cred, 2);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		kdebug("share_creds(%p{%d,%d})",
 		       p->cred, atomic_read(&p->cred->usage),
 		       read_cred_subscribers(p->cred));
@@ -343,9 +359,12 @@ int copy_creds(struct task_struct *p, unsigned long clone_flags)
 
 	new = prepare_creds();
 	if (!new)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 
 	if (clone_flags & CLONE_NEWUSER) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ret = create_user_ns(new);
 		if (ret < 0)
 			goto error_put;
@@ -355,10 +374,13 @@ int copy_creds(struct task_struct *p, unsigned long clone_flags)
 	/* new threads get their own thread keyrings if their parent already
 	 * had one */
 	if (new->thread_keyring) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		key_put(new->thread_keyring);
 		new->thread_keyring = NULL;
 		if (clone_flags & CLONE_THREAD)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			install_thread_keyring_to_cred(new);
+}
 	}
 
 	/* The process keyring is only shared between the threads in a process;
@@ -398,11 +420,13 @@ static bool cred_cap_issubset(const struct cred *set, const struct cred *subset)
 	 * of subsets ancestors.
 	 */
 	for (;subset_ns != &init_user_ns; subset_ns = subset_ns->parent) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if ((set_ns == subset_ns->parent)  &&
 		    uid_eq(subset_ns->owner, set->euid))
 			return true;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return false;
 }
 
@@ -422,9 +446,11 @@ static bool cred_cap_issubset(const struct cred *set, const struct cred *subset)
  */
 int commit_creds(struct cred *new)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct task_struct *task = current;
 	const struct cred *old = task->real_cred;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	kdebug("commit_creds(%p{%d,%d})", new,
 	       atomic_read(&new->usage),
 	       read_cred_subscribers(new));
@@ -499,6 +525,7 @@ EXPORT_SYMBOL(commit_creds);
  */
 void abort_creds(struct cred *new)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	kdebug("abort_creds(%p{%d,%d})", new,
 	       atomic_read(&new->usage),
 	       read_cred_subscribers(new));
@@ -522,6 +549,7 @@ const struct cred *override_creds(const struct cred *new)
 {
 	const struct cred *old = current->cred;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	kdebug("override_creds(%p{%d,%d})", new,
 	       atomic_read(&new->usage),
 	       read_cred_subscribers(new));
@@ -533,6 +561,7 @@ const struct cred *override_creds(const struct cred *new)
 	rcu_assign_pointer(current->cred, new);
 	alter_cred_subscribers(old, -1);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	kdebug("override_creds() = %p{%d,%d}", old,
 	       atomic_read(&old->usage),
 	       read_cred_subscribers(old));
@@ -551,6 +580,7 @@ void revert_creds(const struct cred *old)
 {
 	const struct cred *override = current->cred;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	kdebug("revert_creds(%p{%d,%d})", old,
 	       atomic_read(&old->usage),
 	       read_cred_subscribers(old));
@@ -599,8 +629,11 @@ struct cred *prepare_kernel_cred(struct task_struct *daemon)
 
 	new = kmem_cache_alloc(cred_jar, GFP_KERNEL);
 	if (!new)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	kdebug("prepare_kernel_cred() alloc %p", new);
 
 	if (daemon)
@@ -652,6 +685,7 @@ EXPORT_SYMBOL(prepare_kernel_cred);
  */
 int set_security_override(struct cred *new, u32 secid)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return security_kernel_act_as(new, secid);
 }
 EXPORT_SYMBOL(set_security_override);
@@ -673,7 +707,9 @@ int set_security_override_from_ctx(struct cred *new, const char *secctx)
 
 	ret = security_secctx_to_secid(secctx, strlen(secctx), &secid);
 	if (ret < 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ret;
+}
 
 	return set_security_override(new, secid);
 }
@@ -690,6 +726,7 @@ EXPORT_SYMBOL(set_security_override_from_ctx);
  */
 int set_create_files_as(struct cred *new, struct inode *inode)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!uid_valid(inode->i_uid) || !gid_valid(inode->i_gid))
 		return -EINVAL;
 	new->fsuid = inode->i_uid;
diff --git a/kernel/delayacct.c b/kernel/delayacct.c
index e2764d7..75e7daf 100644
--- a/kernel/delayacct.c
+++ b/kernel/delayacct.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /* delayacct.c - per-task delay accounting
  *
  * Copyright (C) Shailabh Nagar, IBM Corp. 2006
@@ -29,6 +31,7 @@ struct kmem_cache *delayacct_cache;
 
 static int __init delayacct_setup_disable(char *str)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	delayacct_on = 0;
 	return 1;
 }
@@ -80,6 +83,7 @@ void __delayacct_blkio_end(struct task_struct *p)
 	u32 *count;
 
 	if (p->delays->flags & DELAYACCT_PF_SWAPIN) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		total = &delays->swapin_delay;
 		count = &delays->swapin_count;
 	} else {
@@ -156,6 +160,7 @@ __u64 __delayacct_blkio_ticks(struct task_struct *tsk)
 
 void __delayacct_freepages_start(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	current->delays->freepages_start = ktime_get_ns();
 }
 
diff --git a/kernel/dma.c b/kernel/dma.c
index 3506fc3..5ecf321 100644
--- a/kernel/dma.c
+++ b/kernel/dma.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 /*
  * linux/kernel/dma.c: A DMA channel allocator. Inspired by linux/kernel/irq.c.
@@ -69,6 +71,7 @@ static struct dma_chan dma_chan_busy[MAX_DMA_CHANNELS] = {
  */
 int request_dma(unsigned int dmanr, const char * device_id)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (dmanr >= MAX_DMA_CHANNELS)
 		return -EINVAL;
 
@@ -87,6 +90,7 @@ int request_dma(unsigned int dmanr, const char * device_id)
  */
 void free_dma(unsigned int dmanr)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (dmanr >= MAX_DMA_CHANNELS) {
 		printk(KERN_WARNING "Trying to free DMA%d\n", dmanr);
 		return;
@@ -119,6 +123,7 @@ static int proc_dma_show(struct seq_file *m, void *v)
 {
 	int i;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (i = 0 ; i < MAX_DMA_CHANNELS ; i++) {
 		if (dma_chan_busy[i].lock) {
 			seq_printf(m, "%2d: %s\n", i,
@@ -137,6 +142,7 @@ static int proc_dma_show(struct seq_file *m, void *v)
 
 static int proc_dma_open(struct inode *inode, struct file *file)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return single_open(file, proc_dma_show, NULL);
 }
 
diff --git a/kernel/events/core.c b/kernel/events/core.c
index f42f7c7..af0fb83 100644
--- a/kernel/events/core.c
+++ b/kernel/events/core.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * Performance events core code:
  *
@@ -72,7 +74,9 @@ static void remote_function(void *data)
 	if (p) {
 		/* -EAGAIN */
 		if (task_cpu(p) != smp_processor_id())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return;
+}
 
 		/*
 		 * Now that we're on right CPU with IRQs disabled, we can test
@@ -81,9 +85,12 @@ static void remote_function(void *data)
 
 		tfc->ret = -ESRCH; /* No such (running) process */
 		if (p != current)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return;
+}
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	tfc->ret = tfc->func(tfc->info);
 }
 
@@ -146,12 +153,14 @@ static int cpu_function_call(int cpu, remote_function_f func, void *info)
 static inline struct perf_cpu_context *
 __get_cpu_context(struct perf_event_context *ctx)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return this_cpu_ptr(ctx->pmu->pmu_cpu_context);
 }
 
 static void perf_ctx_lock(struct perf_cpu_context *cpuctx,
 			  struct perf_event_context *ctx)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	raw_spin_lock(&cpuctx->ctx.lock);
 	if (ctx)
 		raw_spin_lock(&ctx->lock);
@@ -160,6 +169,7 @@ static void perf_ctx_lock(struct perf_cpu_context *cpuctx,
 static void perf_ctx_unlock(struct perf_cpu_context *cpuctx,
 			    struct perf_event_context *ctx)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (ctx)
 		raw_spin_unlock(&ctx->lock);
 	raw_spin_unlock(&cpuctx->ctx.lock);
@@ -169,6 +179,7 @@ static void perf_ctx_unlock(struct perf_cpu_context *cpuctx,
 
 static bool is_kernel_event(struct perf_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return READ_ONCE(event->owner) == TASK_TOMBSTONE;
 }
 
@@ -209,6 +220,7 @@ static int event_function(void *info)
 	struct perf_event_context *task_ctx = cpuctx->task_ctx;
 	int ret = 0;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WARN_ON_ONCE(!irqs_disabled());
 
 	perf_ctx_lock(cpuctx, task_ctx);
@@ -249,6 +261,7 @@ static int event_function(void *info)
 static void event_function_call(struct perf_event *event, event_f func, void *data)
 {
 	struct perf_event_context *ctx = event->ctx;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct task_struct *task = READ_ONCE(ctx->task); /* verified in event_function */
 	struct event_function_struct efs = {
 		.event = event,
@@ -303,6 +316,7 @@ static void event_function_local(struct perf_event *event, event_f func, void *d
 {
 	struct perf_event_context *ctx = event->ctx;
 	struct perf_cpu_context *cpuctx = __get_cpu_context(ctx);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct task_struct *task = READ_ONCE(ctx->task);
 	struct perf_event_context *task_ctx = NULL;
 
@@ -425,7 +439,9 @@ static void update_perf_cpu_limits(void)
 	tmp *= sysctl_perf_cpu_time_max_percent;
 	tmp = div_u64(tmp, 100);
 	if (!tmp)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		tmp = 1;
+}
 
 	WRITE_ONCE(perf_sample_allowed_ns, tmp);
 }
@@ -436,6 +452,7 @@ int perf_proc_update_handler(struct ctl_table *table, int write,
 		void __user *buffer, size_t *lenp,
 		loff_t *ppos)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	int ret = proc_dointvec_minmax(table, write, buffer, lenp, ppos);
 
 	if (ret || !write)
@@ -461,6 +478,7 @@ int perf_cpu_time_max_percent_handler(struct ctl_table *table, int write,
 				void __user *buffer, size_t *lenp,
 				loff_t *ppos)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	int ret = proc_dointvec_minmax(table, write, buffer, lenp, ppos);
 
 	if (ret || !write)
@@ -492,6 +510,7 @@ static u64 __report_allowed;
 
 static void perf_duration_warn(struct irq_work *w)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	printk_ratelimited(KERN_INFO
 		"perf: interrupt took too long (%lld > %lld), lowering "
 		"kernel.perf_event_max_sample_rate to %d\n",
@@ -503,6 +522,7 @@ static DEFINE_IRQ_WORK(perf_duration_work, perf_duration_warn);
 
 void perf_sample_event_took(u64 sample_len_ns)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	u64 max_len = READ_ONCE(perf_sample_allowed_ns);
 	u64 running_len;
 	u64 avg_len;
@@ -569,16 +589,19 @@ void __weak perf_event_print_debug(void)	{ }
 
 extern __weak const char *perf_pmu_name(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return "pmu";
 }
 
 static inline u64 perf_clock(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return local_clock();
 }
 
 static inline u64 perf_event_clock(struct perf_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return event->clock();
 }
 
@@ -917,6 +940,7 @@ list_update_cgroup_event(struct perf_event *event,
 static inline bool
 perf_cgroup_match(struct perf_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return true;
 }
 
@@ -925,6 +949,7 @@ static inline void perf_detach_cgroup(struct perf_event *event)
 
 static inline int is_cgroup_event(struct perf_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
@@ -950,6 +975,7 @@ static inline int perf_cgroup_connect(pid_t pid, struct perf_event *event,
 				      struct perf_event_attr *attr,
 				      struct perf_event *group_leader)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return -EINVAL;
 }
 
@@ -971,6 +997,7 @@ perf_cgroup_set_shadow_time(struct perf_event *event, u64 now)
 
 static inline u64 perf_cgroup_event_time(struct perf_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
@@ -1006,6 +1033,7 @@ static enum hrtimer_restart perf_mux_hrtimer_handler(struct hrtimer *hr)
 	struct perf_cpu_context *cpuctx;
 	int rotations = 0;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WARN_ON(!irqs_disabled());
 
 	cpuctx = container_of(hr, struct perf_cpu_context, hrtimer);
@@ -1029,7 +1057,9 @@ static void __perf_mux_hrtimer_init(struct perf_cpu_context *cpuctx, int cpu)
 
 	/* no multiplexing needed for SW PMU */
 	if (pmu->task_ctx_nr == perf_sw_context)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	/*
 	 * check default is sane, if not set then force to
@@ -1037,11 +1067,16 @@ static void __perf_mux_hrtimer_init(struct perf_cpu_context *cpuctx, int cpu)
 	 */
 	interval = pmu->hrtimer_interval_ms;
 	if (interval < 1)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		interval = pmu->hrtimer_interval_ms = PERF_CPU_HRTIMER;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	cpuctx->hrtimer_interval = ns_to_ktime(NSEC_PER_MSEC * interval);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	raw_spin_lock_init(&cpuctx->hrtimer_lock);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	hrtimer_init(timer, CLOCK_MONOTONIC, HRTIMER_MODE_ABS_PINNED);
 	timer->function = perf_mux_hrtimer_handler;
 }
@@ -1054,7 +1089,9 @@ static int perf_mux_hrtimer_restart(struct perf_cpu_context *cpuctx)
 
 	/* not for SW PMU */
 	if (pmu->task_ctx_nr == perf_sw_context)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	raw_spin_lock_irqsave(&cpuctx->hrtimer_lock, flags);
 	if (!cpuctx->hrtimer_active) {
@@ -1069,6 +1106,7 @@ static int perf_mux_hrtimer_restart(struct perf_cpu_context *cpuctx)
 
 void perf_pmu_disable(struct pmu *pmu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	int *count = this_cpu_ptr(pmu->pmu_disable_count);
 	if (!(*count)++)
 		pmu->pmu_disable(pmu);
@@ -1076,6 +1114,7 @@ void perf_pmu_disable(struct pmu *pmu)
 
 void perf_pmu_enable(struct pmu *pmu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	int *count = this_cpu_ptr(pmu->pmu_disable_count);
 	if (!--(*count))
 		pmu->pmu_enable(pmu);
@@ -1091,6 +1130,7 @@ static DEFINE_PER_CPU(struct list_head, active_ctx_list);
  */
 static void perf_event_ctx_activate(struct perf_event_context *ctx)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct list_head *head = this_cpu_ptr(&active_ctx_list);
 
 	WARN_ON(!irqs_disabled());
@@ -1102,6 +1142,7 @@ static void perf_event_ctx_activate(struct perf_event_context *ctx)
 
 static void perf_event_ctx_deactivate(struct perf_event_context *ctx)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WARN_ON(!irqs_disabled());
 
 	WARN_ON(list_empty(&ctx->active_ctx_list));
@@ -1111,6 +1152,7 @@ static void perf_event_ctx_deactivate(struct perf_event_context *ctx)
 
 static void get_ctx(struct perf_event_context *ctx)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WARN_ON(!atomic_inc_not_zero(&ctx->refcount));
 }
 
@@ -1118,6 +1160,7 @@ static void free_ctx(struct rcu_head *head)
 {
 	struct perf_event_context *ctx;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	ctx = container_of(head, struct perf_event_context, rcu_head);
 	kfree(ctx->task_ctx_data);
 	kfree(ctx);
@@ -1125,6 +1168,7 @@ static void free_ctx(struct rcu_head *head)
 
 static void put_ctx(struct perf_event_context *ctx)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (atomic_dec_and_test(&ctx->refcount)) {
 		if (ctx->parent_ctx)
 			put_ctx(ctx->parent_ctx);
@@ -1222,12 +1266,14 @@ perf_event_ctx_lock_nested(struct perf_event *event, int nesting)
 static inline struct perf_event_context *
 perf_event_ctx_lock(struct perf_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return perf_event_ctx_lock_nested(event, 0);
 }
 
 static void perf_event_ctx_unlock(struct perf_event *event,
 				  struct perf_event_context *ctx)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	mutex_unlock(&ctx->mutex);
 	put_ctx(ctx);
 }
@@ -1242,6 +1288,7 @@ unclone_ctx(struct perf_event_context *ctx)
 {
 	struct perf_event_context *parent_ctx = ctx->parent_ctx;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&ctx->lock);
 
 	if (parent_ctx)
@@ -1259,7 +1306,9 @@ static u32 perf_event_pid_type(struct perf_event *event, struct task_struct *p,
 	 * only top level events have the pid namespace they were created in
 	 */
 	if (event->parent)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		event = event->parent;
+}
 
 	nr = __task_pid_nr_ns(p, type, event->ns);
 	/* avoid -1 if it is idle thread or runs in another ns */
@@ -1270,11 +1319,13 @@ static u32 perf_event_pid_type(struct perf_event *event, struct task_struct *p,
 
 static u32 perf_event_pid(struct perf_event *event, struct task_struct *p)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return perf_event_pid_type(event, p, __PIDTYPE_TGID);
 }
 
 static u32 perf_event_tid(struct perf_event *event, struct task_struct *p)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return perf_event_pid_type(event, p, PIDTYPE_PID);
 }
 
@@ -1287,7 +1338,9 @@ static u64 primary_event_id(struct perf_event *event)
 	u64 id = event->id;
 
 	if (event->parent)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		id = event->parent->id;
+}
 
 	return id;
 }
@@ -1314,6 +1367,7 @@ perf_lock_task_context(struct task_struct *task, int ctxn, unsigned long *flags)
 	 * side critical section has interrupts disabled.
 	 */
 	local_irq_save(*flags);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rcu_read_lock();
 	ctx = rcu_dereference(task->perf_event_ctxp[ctxn]);
 	if (ctx) {
@@ -1328,21 +1382,28 @@ perf_lock_task_context(struct task_struct *task, int ctxn, unsigned long *flags)
 		 * can't get swapped on us any more.
 		 */
 		raw_spin_lock(&ctx->lock);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (ctx != rcu_dereference(task->perf_event_ctxp[ctxn])) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			raw_spin_unlock(&ctx->lock);
 			rcu_read_unlock();
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			local_irq_restore(*flags);
 			goto retry;
 		}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (ctx->task == TASK_TOMBSTONE ||
 		    !atomic_inc_not_zero(&ctx->refcount)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			raw_spin_unlock(&ctx->lock);
 			ctx = NULL;
 		} else {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			WARN_ON_ONCE(ctx->task != task);
 		}
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rcu_read_unlock();
 	if (!ctx)
 		local_irq_restore(*flags);
@@ -1362,7 +1423,9 @@ perf_pin_task_context(struct task_struct *task, int ctxn)
 
 	ctx = perf_lock_task_context(task, ctxn, &flags);
 	if (ctx) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		++ctx->pin_count;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		raw_spin_unlock_irqrestore(&ctx->lock, flags);
 	}
 	return ctx;
@@ -1372,6 +1435,7 @@ static void perf_unpin_context(struct perf_event_context *ctx)
 {
 	unsigned long flags;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	raw_spin_lock_irqsave(&ctx->lock, flags);
 	--ctx->pin_count;
 	raw_spin_unlock_irqrestore(&ctx->lock, flags);
@@ -1382,6 +1446,7 @@ static void perf_unpin_context(struct perf_event_context *ctx)
  */
 static void update_context_time(struct perf_event_context *ctx)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	u64 now = perf_clock();
 
 	ctx->time += now - ctx->timestamp;
@@ -1393,7 +1458,9 @@ static u64 perf_event_time(struct perf_event *event)
 	struct perf_event_context *ctx = event->ctx;
 
 	if (is_cgroup_event(event))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return perf_cgroup_event_time(event);
+}
 
 	return ctx ? ctx->time : 0;
 }
@@ -1406,6 +1473,7 @@ static void update_event_times(struct perf_event *event)
 	struct perf_event_context *ctx = event->ctx;
 	u64 run_end;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&ctx->lock);
 
 	if (event->state < PERF_EVENT_STATE_INACTIVE ||
@@ -1448,6 +1516,7 @@ static void update_group_times(struct perf_event *leader)
 	struct perf_event *event;
 
 	update_event_times(leader);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry(event, &leader->sibling_list, group_entry)
 		update_event_times(event);
 }
@@ -1457,6 +1526,7 @@ static enum event_type_t get_event_type(struct perf_event *event)
 	struct perf_event_context *ctx = event->ctx;
 	enum event_type_t event_type;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&ctx->lock);
 
 	/*
@@ -1476,6 +1546,7 @@ static enum event_type_t get_event_type(struct perf_event *event)
 static struct list_head *
 ctx_group_list(struct perf_event *event, struct perf_event_context *ctx)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (event->attr.pinned)
 		return &ctx->pinned_groups;
 	else
@@ -1489,6 +1560,7 @@ ctx_group_list(struct perf_event *event, struct perf_event_context *ctx)
 static void
 list_add_event(struct perf_event *event, struct perf_event_context *ctx)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&ctx->lock);
 
 	WARN_ON_ONCE(event->attach_state & PERF_ATTACH_CONTEXT);
@@ -1534,7 +1606,9 @@ static void __perf_event_read_size(struct perf_event *event, int nr_siblings)
 	int nr = 1;
 
 	if (event->attr.read_format & PERF_FORMAT_TOTAL_TIME_ENABLED)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		size += sizeof(u64);
+}
 
 	if (event->attr.read_format & PERF_FORMAT_TOTAL_TIME_RUNNING)
 		size += sizeof(u64);
@@ -1557,7 +1631,9 @@ static void __perf_event_header_size(struct perf_event *event, u64 sample_type)
 	u16 size = 0;
 
 	if (sample_type & PERF_SAMPLE_IP)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		size += sizeof(data->ip);
+}
 
 	if (sample_type & PERF_SAMPLE_ADDR)
 		size += sizeof(data->addr);
@@ -1589,6 +1665,7 @@ static void __perf_event_header_size(struct perf_event *event, u64 sample_type)
  */
 static void perf_event__header_size(struct perf_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	__perf_event_read_size(event,
 			       event->group_leader->nr_siblings);
 	__perf_event_header_size(event, event->attr.sample_type);
@@ -1601,7 +1678,9 @@ static void perf_event__id_header_size(struct perf_event *event)
 	u16 size = 0;
 
 	if (sample_type & PERF_SAMPLE_TID)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		size += sizeof(data->tid_entry);
+}
 
 	if (sample_type & PERF_SAMPLE_TIME)
 		size += sizeof(data->time);
@@ -1646,6 +1725,7 @@ static void perf_group_attach(struct perf_event *event)
 {
 	struct perf_event *group_leader = event->group_leader, *pos;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&event->ctx->lock);
 
 	/*
@@ -1679,6 +1759,7 @@ static void perf_group_attach(struct perf_event *event)
 static void
 list_del_event(struct perf_event *event, struct perf_event_context *ctx)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WARN_ON_ONCE(event->ctx != ctx);
 	lockdep_assert_held(&ctx->lock);
 
@@ -1721,6 +1802,7 @@ static void perf_group_detach(struct perf_event *event)
 	struct perf_event *sibling, *tmp;
 	struct list_head *list = NULL;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&event->ctx->lock);
 
 	/*
@@ -1768,12 +1850,14 @@ static void perf_group_detach(struct perf_event *event)
 
 static bool is_orphaned_event(struct perf_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return event->state == PERF_EVENT_STATE_DEAD;
 }
 
 static inline int __pmu_filter_match(struct perf_event *event)
 {
 	struct pmu *pmu = event->pmu;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return pmu->filter_match ? pmu->filter_match(event) : 1;
 }
 
@@ -1788,7 +1872,9 @@ static inline int pmu_filter_match(struct perf_event *event)
 	struct perf_event *child;
 
 	if (!__pmu_filter_match(event))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	list_for_each_entry(child, &event->sibling_list, group_entry) {
 		if (!__pmu_filter_match(child))
@@ -1801,6 +1887,7 @@ static inline int pmu_filter_match(struct perf_event *event)
 static inline int
 event_filter_match(struct perf_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return (event->cpu == -1 || event->cpu == smp_processor_id()) &&
 	       perf_cgroup_match(event) && pmu_filter_match(event);
 }
@@ -1810,6 +1897,7 @@ event_sched_out(struct perf_event *event,
 		  struct perf_cpu_context *cpuctx,
 		  struct perf_event_context *ctx)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	u64 tstamp = perf_event_time(event);
 	u64 delta;
 
@@ -1897,7 +1985,9 @@ __perf_remove_from_context(struct perf_event *event,
 
 	event_sched_out(event, cpuctx, ctx);
 	if (flags & DETACH_GROUP)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		perf_group_detach(event);
+}
 	list_del_event(event, ctx);
 
 	if (!ctx->nr_events && ctx->is_active) {
@@ -1923,6 +2013,7 @@ static void perf_remove_from_context(struct perf_event *event, unsigned long fla
 {
 	struct perf_event_context *ctx = event->ctx;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&ctx->mutex);
 
 	event_function_call(event, __perf_remove_from_context, (void *)flags);
@@ -1954,6 +2045,7 @@ static void __perf_event_disable(struct perf_event *event,
 				 struct perf_event_context *ctx,
 				 void *info)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (event->state < PERF_EVENT_STATE_INACTIVE)
 		return;
 
@@ -1987,6 +2079,7 @@ static void _perf_event_disable(struct perf_event *event)
 
 	raw_spin_lock_irq(&ctx->lock);
 	if (event->state <= PERF_EVENT_STATE_OFF) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		raw_spin_unlock_irq(&ctx->lock);
 		return;
 	}
@@ -1997,6 +2090,7 @@ static void _perf_event_disable(struct perf_event *event)
 
 void perf_event_disable_local(struct perf_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	event_function_local(event, __perf_event_disable, NULL);
 }
 
@@ -2016,6 +2110,7 @@ EXPORT_SYMBOL_GPL(perf_event_disable);
 
 void perf_event_disable_inatomic(struct perf_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	event->pending_disable = 1;
 	irq_work_queue(&event->pending);
 }
@@ -2065,6 +2160,7 @@ event_sched_in(struct perf_event *event,
 		 struct perf_cpu_context *cpuctx,
 		 struct perf_event_context *ctx)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	u64 tstamp = perf_event_time(event);
 	int ret = 0;
 
@@ -2138,7 +2234,9 @@ group_sched_in(struct perf_event *group_event,
 	bool simulate = false;
 
 	if (group_event->state == PERF_EVENT_STATE_OFF)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	pmu->start_txn(pmu, PERF_PMU_TXN_ADD);
 
@@ -2247,6 +2345,7 @@ static int group_can_go_on(struct perf_event *event,
  */
 static void __perf_event_enable_time(struct perf_event *event, u64 now)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WARN_ON_ONCE(event->state != PERF_EVENT_STATE_INACTIVE);
 
 	event->tstamp_stopped = now;
@@ -2257,6 +2356,7 @@ static void __perf_event_enable_time(struct perf_event *event, u64 now)
 static void add_event_to_ctx(struct perf_event *event,
 			       struct perf_event_context *ctx)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	u64 tstamp = perf_event_time(event);
 
 	list_add_event(event, ctx);
@@ -2282,6 +2382,7 @@ static void task_ctx_sched_out(struct perf_cpu_context *cpuctx,
 			       struct perf_event_context *ctx,
 			       enum event_type_t event_type)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!cpuctx->task_ctx)
 		return;
 
@@ -2295,6 +2396,7 @@ static void perf_event_sched_in(struct perf_cpu_context *cpuctx,
 				struct perf_event_context *ctx,
 				struct task_struct *task)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	cpu_ctx_sched_in(cpuctx, EVENT_PINNED, task);
 	if (ctx)
 		ctx_sched_in(ctx, cpuctx, EVENT_PINNED, task);
@@ -2330,7 +2432,9 @@ static void ctx_resched(struct perf_cpu_context *cpuctx,
 	 * scheduled out.
 	 */
 	if (event_type & EVENT_PINNED)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		event_type |= EVENT_FLEXIBLE;
+}
 
 	perf_pmu_disable(cpuctx->ctx.pmu);
 	if (task_ctx)
@@ -2369,6 +2473,7 @@ static int  __perf_install_in_context(void *info)
 
 	raw_spin_lock(&cpuctx->ctx.lock);
 	if (ctx->task) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		raw_spin_lock(&ctx->lock);
 		task_ctx = ctx;
 
@@ -2415,6 +2520,7 @@ perf_install_in_context(struct perf_event_context *ctx,
 			struct perf_event *event,
 			int cpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct task_struct *task = READ_ONCE(ctx->task);
 
 	lockdep_assert_held(&ctx->mutex);
@@ -2512,6 +2618,7 @@ static void __perf_event_mark_enabled(struct perf_event *event)
 
 	event->state = PERF_EVENT_STATE_INACTIVE;
 	__perf_event_enable_time(event, tstamp);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry(sub, &event->sibling_list, group_entry) {
 		/* XXX should not be > INACTIVE if event isn't */
 		if (sub->state >= PERF_EVENT_STATE_INACTIVE)
@@ -2662,6 +2769,7 @@ static int perf_event_stop(struct perf_event *event, int restart)
 	int ret = 0;
 
 	do {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (READ_ONCE(event->state) != PERF_EVENT_STATE_ACTIVE)
 			return 0;
 
@@ -2704,6 +2812,7 @@ static int perf_event_stop(struct perf_event *event, int restart)
  */
 void perf_event_addr_filters_sync(struct perf_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct perf_addr_filters_head *ifh = perf_event_addr_filters(event);
 
 	if (!has_addr_filter(event))
@@ -2755,6 +2864,7 @@ static void ctx_sched_out(struct perf_event_context *ctx,
 	int is_active = ctx->is_active;
 	struct perf_event *event;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&ctx->lock);
 
 	if (likely(!ctx->nr_events)) {
@@ -2822,6 +2932,7 @@ static void ctx_sched_out(struct perf_event_context *ctx,
 static int context_equiv(struct perf_event_context *ctx1,
 			 struct perf_event_context *ctx2)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&ctx1->lock);
 	lockdep_assert_held(&ctx2->lock);
 
@@ -2855,7 +2966,9 @@ static void __perf_event_sync_stat(struct perf_event *event,
 	u64 value;
 
 	if (!event->attr.inherit_stat)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	/*
 	 * Update the event value, we cannot use perf_event_read()
@@ -2901,7 +3014,9 @@ static void perf_event_sync_stat(struct perf_event_context *ctx,
 	struct perf_event *event, *next_event;
 
 	if (!ctx->nr_stat)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	update_context_time(ctx);
 
@@ -2931,7 +3046,9 @@ static void perf_event_context_sched_out(struct task_struct *task, int ctxn,
 	int do_switch = 1;
 
 	if (likely(!ctx))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	cpuctx = __get_cpu_context(ctx);
 	if (!cpuctx->task_ctx)
@@ -2998,6 +3115,7 @@ static DEFINE_PER_CPU(struct list_head, sched_cb_list);
 
 void perf_sched_cb_dec(struct pmu *pmu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct perf_cpu_context *cpuctx = this_cpu_ptr(pmu->pmu_cpu_context);
 
 	this_cpu_dec(perf_sched_cb_usages);
@@ -3009,6 +3127,7 @@ void perf_sched_cb_dec(struct pmu *pmu)
 
 void perf_sched_cb_inc(struct pmu *pmu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct perf_cpu_context *cpuctx = this_cpu_ptr(pmu->pmu_cpu_context);
 
 	if (!cpuctx->sched_cb_usage++)
@@ -3033,7 +3152,9 @@ static void perf_pmu_sched_task(struct task_struct *prev,
 	struct pmu *pmu;
 
 	if (prev == next)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	list_for_each_entry(cpuctx, this_cpu_ptr(&sched_cb_list), sched_cb_entry) {
 		pmu = cpuctx->ctx.pmu; /* software PMUs will not have sched_task */
@@ -3073,6 +3194,7 @@ void __perf_event_task_sched_out(struct task_struct *task,
 {
 	int ctxn;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (__this_cpu_read(perf_sched_cb_usages))
 		perf_pmu_sched_task(task, next, false);
 
@@ -3097,6 +3219,7 @@ void __perf_event_task_sched_out(struct task_struct *task,
 static void cpu_ctx_sched_out(struct perf_cpu_context *cpuctx,
 			      enum event_type_t event_type)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	ctx_sched_out(&cpuctx->ctx, cpuctx, event_type);
 }
 
@@ -3106,6 +3229,7 @@ ctx_pinned_sched_in(struct perf_event_context *ctx,
 {
 	struct perf_event *event;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry(event, &ctx->pinned_groups, group_entry) {
 		if (event->state <= PERF_EVENT_STATE_OFF)
 			continue;
@@ -3137,6 +3261,7 @@ ctx_flexible_sched_in(struct perf_event_context *ctx,
 	struct perf_event *event;
 	int can_add_hw = 1;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry(event, &ctx->flexible_groups, group_entry) {
 		/* Ignore events in OFF or ERROR state */
 		if (event->state <= PERF_EVENT_STATE_OFF)
@@ -3168,6 +3293,7 @@ ctx_sched_in(struct perf_event_context *ctx,
 	int is_active = ctx->is_active;
 	u64 now;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&ctx->lock);
 
 	if (likely(!ctx->nr_events))
@@ -3218,7 +3344,9 @@ static void perf_event_context_sched_in(struct perf_event_context *ctx,
 
 	cpuctx = __get_cpu_context(ctx);
 	if (cpuctx->task_ctx == ctx)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	perf_ctx_lock(cpuctx, ctx);
 	/*
@@ -3378,7 +3506,9 @@ static void perf_adjust_period(struct perf_event *event, u64 nsec, u64 count, bo
 	sample_period = hwc->sample_period + delta;
 
 	if (!sample_period)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		sample_period = 1;
+}
 
 	hwc->sample_period = sample_period;
 
@@ -3484,6 +3614,7 @@ static int perf_rotate_context(struct perf_cpu_context *cpuctx)
 	int rotate = 0;
 
 	if (cpuctx->ctx.nr_events) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (cpuctx->ctx.nr_events != cpuctx->ctx.nr_active)
 			rotate = 1;
 	}
@@ -3536,6 +3667,7 @@ void perf_event_task_tick(void)
 static int event_enable_on_exec(struct perf_event *event,
 				struct perf_event_context *ctx)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!event->attr.enable_on_exec)
 		return 0;
 
@@ -3561,6 +3693,7 @@ static void perf_event_enable_on_exec(int ctxn)
 	unsigned long flags;
 	int enabled = 0;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	local_irq_save(flags);
 	ctx = current->perf_event_ctxp[ctxn];
 	if (!ctx || !ctx->nr_events)
@@ -3603,6 +3736,7 @@ static int __perf_event_read_cpu(struct perf_event *event, int event_cpu)
 	u16 local_pkg, event_pkg;
 
 	if (event->group_caps & PERF_EV_CAP_READ_ACTIVE_PKG) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		int local_cpu = smp_processor_id();
 
 		event_pkg = topology_physical_package_id(event_cpu);
@@ -3675,6 +3809,7 @@ static void __perf_event_read(void *info)
 
 static inline u64 perf_event_count(struct perf_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return local64_read(&event->count) + atomic64_read(&event->child_count);
 }
 
@@ -3750,6 +3885,7 @@ static int perf_event_read(struct perf_event *event, bool group)
 			.ret = 0,
 		};
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		event_cpu = READ_ONCE(event->oncpu);
 		if ((unsigned)event_cpu >= nr_cpu_ids)
 			return 0;
@@ -3815,7 +3951,9 @@ alloc_perf_context(struct pmu *pmu, struct task_struct *task)
 
 	ctx = kzalloc(sizeof(struct perf_event_context), GFP_KERNEL);
 	if (!ctx)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 
 	__perf_event_init_context(ctx);
 	if (task) {
@@ -3834,7 +3972,9 @@ find_lively_task_by_vpid(pid_t vpid)
 
 	rcu_read_lock();
 	if (!vpid)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		task = current;
+}
 	else
 		task = find_task_by_vpid(vpid);
 	if (task)
@@ -3953,6 +4093,7 @@ static void free_event_rcu(struct rcu_head *head)
 {
 	struct perf_event *event;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	event = container_of(head, struct perf_event, rcu_head);
 	if (event->ns)
 		put_pid_ns(event->ns);
@@ -3965,6 +4106,7 @@ static void ring_buffer_attach(struct perf_event *event,
 
 static void detach_sb_event(struct perf_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct pmu_event_list *pel = per_cpu_ptr(&pmu_sb_events, event->cpu);
 
 	raw_spin_lock(&pel->lock);
@@ -3977,7 +4119,9 @@ static bool is_sb_event(struct perf_event *event)
 	struct perf_event_attr *attr = &event->attr;
 
 	if (event->parent)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return false;
+}
 
 	if (event->attach_state & PERF_ATTACH_TASK)
 		return false;
@@ -3992,12 +4136,14 @@ static bool is_sb_event(struct perf_event *event)
 
 static void unaccount_pmu_sb_event(struct perf_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (is_sb_event(event))
 		detach_sb_event(event);
 }
 
 static void unaccount_event_cpu(struct perf_event *event, int cpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (event->parent)
 		return;
 
@@ -4021,6 +4167,7 @@ static void unaccount_freq_event_nohz(void)
 
 static void unaccount_freq_event(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (tick_nohz_full_enabled())
 		unaccount_freq_event_nohz();
 	else
@@ -4032,7 +4179,9 @@ static void unaccount_event(struct perf_event *event)
 	bool dec = false;
 
 	if (event->parent)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	if (event->attach_state & PERF_ATTACH_TASK)
 		dec = true;
@@ -4067,6 +4216,7 @@ static void unaccount_event(struct perf_event *event)
 
 static void perf_sched_delayed(struct work_struct *work)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	mutex_lock(&perf_sched_mutex);
 	if (atomic_dec_and_test(&perf_sched_count))
 		static_branch_disable(&perf_sched_events);
@@ -4090,7 +4240,9 @@ static int exclusive_event_init(struct perf_event *event)
 	struct pmu *pmu = event->pmu;
 
 	if (!(pmu->capabilities & PERF_PMU_CAP_EXCLUSIVE))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	/*
 	 * Prevent co-existence of per-task and cpu-wide events on the
@@ -4121,7 +4273,9 @@ static void exclusive_event_destroy(struct perf_event *event)
 	struct pmu *pmu = event->pmu;
 
 	if (!(pmu->capabilities & PERF_PMU_CAP_EXCLUSIVE))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	/* see comment in exclusive_event_init() */
 	if (event->attach_state & PERF_ATTACH_TASK)
@@ -4132,6 +4286,7 @@ static void exclusive_event_destroy(struct perf_event *event)
 
 static bool exclusive_event_match(struct perf_event *e1, struct perf_event *e2)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if ((e1->pmu == e2->pmu) &&
 	    (e1->cpu == e2->cpu ||
 	     e1->cpu == -1 ||
@@ -4148,7 +4303,9 @@ static bool exclusive_event_installable(struct perf_event *event,
 	struct pmu *pmu = event->pmu;
 
 	if (!(pmu->capabilities & PERF_PMU_CAP_EXCLUSIVE))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return true;
+}
 
 	list_for_each_entry(iter_event, &ctx->event_list, event_entry) {
 		if (exclusive_event_match(iter_event, event))
@@ -4163,6 +4320,7 @@ static void perf_addr_filters_splice(struct perf_event *event,
 
 static void _free_event(struct perf_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	irq_work_sync(&event->pending);
 
 	unaccount_event(event);
@@ -4209,6 +4367,7 @@ static void _free_event(struct perf_event *event)
  */
 static void free_event(struct perf_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (WARN(atomic_long_cmpxchg(&event->refcount, 1, 0) != 1,
 				"unexpected event refcount: %ld; ptr=%p\n",
 				atomic_long_read(&event->refcount), event)) {
@@ -4272,6 +4431,7 @@ static void perf_remove_from_owner(struct perf_event *event)
 
 static void put_event(struct perf_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!atomic_long_dec_and_test(&event->refcount))
 		return;
 
@@ -4293,6 +4453,7 @@ int perf_event_release_kernel(struct perf_event *event)
 	 * attached to a context yet.
 	 */
 	if (!ctx) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		WARN_ON_ONCE(event->attach_state &
 				(PERF_ATTACH_CONTEXT|PERF_ATTACH_GROUP));
 		goto no_ctx;
@@ -4386,6 +4547,7 @@ EXPORT_SYMBOL_GPL(perf_event_release_kernel);
  */
 static int perf_release(struct inode *inode, struct file *file)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	perf_event_release_kernel(file->private_data);
 	return 0;
 }
@@ -4408,6 +4570,7 @@ u64 perf_event_read_value(struct perf_event *event, u64 *enabled, u64 *running)
 	*running += event->total_time_running +
 			atomic64_read(&event->child_total_time_running);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry(child, &event->child_list, child_list) {
 		(void)perf_event_read(child, false);
 		total += perf_event_count(child);
@@ -4431,7 +4594,9 @@ static int __perf_read_group_add(struct perf_event *leader,
 
 	ret = perf_event_read(leader, true);
 	if (ret)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ret;
+}
 
 	raw_spin_lock_irqsave(&ctx->lock, flags);
 
@@ -4475,6 +4640,7 @@ static int perf_read_group(struct perf_event *event,
 	int ret;
 	u64 *values;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&ctx->mutex);
 
 	values = kzalloc(event->read_size, GFP_KERNEL);
@@ -4522,7 +4688,9 @@ static int perf_read_one(struct perf_event *event,
 
 	values[n++] = perf_event_read_value(event, &enabled, &running);
 	if (read_format & PERF_FORMAT_TOTAL_TIME_ENABLED)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		values[n++] = enabled;
+}
 	if (read_format & PERF_FORMAT_TOTAL_TIME_RUNNING)
 		values[n++] = running;
 	if (read_format & PERF_FORMAT_ID)
@@ -4539,7 +4707,9 @@ static bool is_event_hup(struct perf_event *event)
 	bool no_children;
 
 	if (event->state > PERF_EVENT_STATE_EXIT)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return false;
+}
 
 	mutex_lock(&event->child_mutex);
 	no_children = list_empty(&event->child_list);
@@ -4562,7 +4732,9 @@ __perf_read(struct perf_event *event, char __user *buf, size_t count)
 	 * scheduled on to the CPU at some point).
 	 */
 	if (event->state == PERF_EVENT_STATE_ERROR)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	if (count < event->read_size)
 		return -ENOSPC;
@@ -4599,7 +4771,9 @@ static unsigned int perf_poll(struct file *file, poll_table *wait)
 	poll_wait(file, &event->waitq, wait);
 
 	if (is_event_hup(event))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return events;
+}
 
 	/*
 	 * Pin the event->rb by taking event->mmap_mutex; otherwise
@@ -4615,6 +4789,7 @@ static unsigned int perf_poll(struct file *file, poll_table *wait)
 
 static void _perf_event_reset(struct perf_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	(void)perf_event_read(event, false);
 	local64_set(&event->count, 0);
 	perf_event_update_userpage(event);
@@ -4631,6 +4806,7 @@ static void perf_event_for_each_child(struct perf_event *event,
 {
 	struct perf_event *child;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WARN_ON_ONCE(event->ctx->parent_ctx);
 
 	mutex_lock(&event->child_mutex);
@@ -4646,6 +4822,7 @@ static void perf_event_for_each(struct perf_event *event,
 	struct perf_event_context *ctx = event->ctx;
 	struct perf_event *sibling;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&ctx->mutex);
 
 	event = event->group_leader;
@@ -4664,6 +4841,7 @@ static void __perf_event_period(struct perf_event *event,
 	bool active;
 
 	if (event->attr.freq) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		event->attr.sample_freq = value;
 	} else {
 		event->attr.sample_period = value;
@@ -4697,7 +4875,9 @@ static int perf_event_period(struct perf_event *event, u64 __user *arg)
 	u64 value;
 
 	if (!is_sampling_event(event))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	if (copy_from_user(&value, arg, sizeof(value)))
 		return -EFAULT;
@@ -4717,6 +4897,7 @@ static const struct file_operations perf_fops;
 
 static inline int perf_fget_light(int fd, struct fd *p)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct fd f = fdget(fd);
 	if (!f.file)
 		return -EBADF;
@@ -4831,6 +5012,7 @@ static long perf_ioctl(struct file *file, unsigned int cmd, unsigned long arg)
 static long perf_compat_ioctl(struct file *file, unsigned int cmd,
 				unsigned long arg)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	switch (_IOC_NR(cmd)) {
 	case _IOC_NR(PERF_EVENT_IOC_SET_FILTER):
 	case _IOC_NR(PERF_EVENT_IOC_ID):
@@ -4853,6 +5035,7 @@ int perf_event_task_enable(void)
 	struct perf_event *event;
 
 	mutex_lock(&current->perf_event_mutex);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry(event, &current->perf_event_list, owner_entry) {
 		ctx = perf_event_ctx_lock(event);
 		perf_event_for_each_child(event, _perf_event_enable);
@@ -4869,6 +5052,7 @@ int perf_event_task_disable(void)
 	struct perf_event *event;
 
 	mutex_lock(&current->perf_event_mutex);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry(event, &current->perf_event_list, owner_entry) {
 		ctx = perf_event_ctx_lock(event);
 		perf_event_for_each_child(event, _perf_event_disable);
@@ -4881,6 +5065,7 @@ int perf_event_task_disable(void)
 
 static int perf_event_index(struct perf_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (event->hw.state & PERF_HES_STOPPED)
 		return 0;
 
@@ -4909,6 +5094,7 @@ static void perf_event_init_userpage(struct perf_event *event)
 	struct ring_buffer *rb;
 
 	rcu_read_lock();
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rb = rcu_dereference(event->rb);
 	if (!rb)
 		goto unlock;
@@ -4942,6 +5128,7 @@ void perf_event_update_userpage(struct perf_event *event)
 	u64 enabled, running, now;
 
 	rcu_read_lock();
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rb = rcu_dereference(event->rb);
 	if (!rb)
 		goto unlock;
@@ -4992,6 +5179,7 @@ static int perf_mmap_fault(struct vm_fault *vmf)
 	int ret = VM_FAULT_SIGBUS;
 
 	if (vmf->flags & FAULT_FLAG_MKWRITE) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (vmf->pgoff == 0)
 			ret = 0;
 		return ret;
@@ -5084,6 +5272,7 @@ static void ring_buffer_wakeup(struct perf_event *event)
 	struct ring_buffer *rb;
 
 	rcu_read_lock();
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rb = rcu_dereference(event->rb);
 	if (rb) {
 		list_for_each_entry_rcu(event, &rb->event_list, rb_entry)
@@ -5097,6 +5286,7 @@ struct ring_buffer *ring_buffer_get(struct perf_event *event)
 	struct ring_buffer *rb;
 
 	rcu_read_lock();
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rb = rcu_dereference(event->rb);
 	if (rb) {
 		if (!atomic_inc_not_zero(&rb->refcount))
@@ -5109,6 +5299,7 @@ struct ring_buffer *ring_buffer_get(struct perf_event *event)
 
 void ring_buffer_put(struct ring_buffer *rb)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!atomic_dec_and_test(&rb->refcount))
 		return;
 
@@ -5125,7 +5316,9 @@ static void perf_mmap_open(struct vm_area_struct *vma)
 	atomic_inc(&event->rb->mmap_count);
 
 	if (vma->vm_pgoff)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		atomic_inc(&event->rb->aux_mmap_count);
+}
 
 	if (event->pmu->event_mapped)
 		event->pmu->event_mapped(event, vma->vm_mm);
@@ -5151,7 +5344,9 @@ static void perf_mmap_close(struct vm_area_struct *vma)
 	unsigned long size = perf_data_size(rb);
 
 	if (event->pmu->event_unmapped)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		event->pmu->event_unmapped(event, vma->vm_mm);
+}
 
 	/*
 	 * rb->aux_mmap_count will always drop before rb->mmap_count and
@@ -5261,6 +5456,7 @@ static int perf_mmap(struct file *file, struct vm_area_struct *vma)
 {
 	struct perf_event *event = file->private_data;
 	unsigned long user_locked, user_lock_limit;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct user_struct *user = current_user();
 	unsigned long locked, lock_limit;
 	struct ring_buffer *rb = NULL;
@@ -5456,6 +5652,7 @@ static int perf_mmap(struct file *file, struct vm_area_struct *vma)
 
 static int perf_fasync(int fd, struct file *filp, int on)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct inode *inode = file_inode(filp);
 	struct perf_event *event = filp->private_data;
 	int retval;
@@ -5498,6 +5695,7 @@ static inline struct fasync_struct **perf_event_fasync(struct perf_event *event)
 
 void perf_event_wakeup(struct perf_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	ring_buffer_wakeup(event);
 
 	if (event->pending_kill) {
@@ -5508,6 +5706,7 @@ void perf_event_wakeup(struct perf_event *event)
 
 static void perf_pending_event(struct irq_work *entry)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct perf_event *event = container_of(entry,
 			struct perf_event, pending);
 	int rctx;
@@ -5541,6 +5740,7 @@ struct perf_guest_info_callbacks *perf_guest_cbs;
 
 int perf_register_guest_info_callbacks(struct perf_guest_info_callbacks *cbs)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	perf_guest_cbs = cbs;
 	return 0;
 }
@@ -5548,6 +5748,7 @@ EXPORT_SYMBOL_GPL(perf_register_guest_info_callbacks);
 
 int perf_unregister_guest_info_callbacks(struct perf_guest_info_callbacks *cbs)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	perf_guest_cbs = NULL;
 	return 0;
 }
@@ -5561,6 +5762,7 @@ perf_output_sample_regs(struct perf_output_handle *handle,
 	DECLARE_BITMAP(_mask, 64);
 
 	bitmap_from_u64(_mask, mask);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for_each_set_bit(bit, _mask, sizeof(mask) * BITS_PER_BYTE) {
 		u64 val;
 
@@ -5573,6 +5775,7 @@ static void perf_sample_regs_user(struct perf_regs *regs_user,
 				  struct pt_regs *regs,
 				  struct pt_regs *regs_user_copy)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (user_mode(regs)) {
 		regs_user->abi = perf_reg_abi(current);
 		regs_user->regs = regs;
@@ -5587,6 +5790,7 @@ static void perf_sample_regs_user(struct perf_regs *regs_user,
 static void perf_sample_regs_intr(struct perf_regs *regs_intr,
 				  struct pt_regs *regs)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	regs_intr->regs = regs;
 	regs_intr->abi  = perf_reg_abi(current);
 }
@@ -5601,6 +5805,7 @@ static void perf_sample_regs_intr(struct perf_regs *regs_intr,
  */
 static u64 perf_ustack_task_size(struct pt_regs *regs)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	unsigned long addr = perf_user_stack_pointer(regs);
 
 	if (!addr || addr >= TASK_SIZE)
@@ -5617,7 +5822,9 @@ perf_sample_ustack_size(u16 stack_size, u16 header_size,
 
 	/* No regs, no stack pointer, no dump. */
 	if (!regs)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	/*
 	 * Check if we fit in with the requested stack size into the:
@@ -5721,6 +5928,7 @@ void perf_event_header__init_id(struct perf_event_header *header,
 				struct perf_sample_data *data,
 				struct perf_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (event->attr.sample_id_all)
 		__perf_event_header__init_id(header, data, event);
 }
@@ -5731,7 +5939,9 @@ static void __perf_event__output_id_sample(struct perf_output_handle *handle,
 	u64 sample_type = data->type;
 
 	if (sample_type & PERF_SAMPLE_TID)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		perf_output_put(handle, data->tid_entry);
+}
 
 	if (sample_type & PERF_SAMPLE_TIME)
 		perf_output_put(handle, data->time);
@@ -5753,6 +5963,7 @@ void perf_event__output_id_sample(struct perf_event *event,
 				  struct perf_output_handle *handle,
 				  struct perf_sample_data *sample)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (event->attr.sample_id_all)
 		__perf_event__output_id_sample(handle, sample);
 }
@@ -5792,7 +6003,9 @@ static void perf_output_read_group(struct perf_output_handle *handle,
 	values[n++] = 1 + leader->nr_siblings;
 
 	if (read_format & PERF_FORMAT_TOTAL_TIME_ENABLED)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		values[n++] = enabled;
+}
 
 	if (read_format & PERF_FORMAT_TOTAL_TIME_RUNNING)
 		values[n++] = running;
@@ -5847,7 +6060,9 @@ static void perf_output_read(struct perf_output_handle *handle,
 	 * NMI context
 	 */
 	if (read_format & PERF_FORMAT_TOTAL_TIMES)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		calc_timer_values(event, &now, &enabled, &running);
+}
 
 	if (event->attr.read_format & PERF_FORMAT_GROUP)
 		perf_output_read_group(handle, event, enabled, running);
@@ -5865,7 +6080,9 @@ void perf_output_sample(struct perf_output_handle *handle,
 	perf_output_put(handle, *header);
 
 	if (sample_type & PERF_SAMPLE_IDENTIFIER)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		perf_output_put(handle, data->id);
+}
 
 	if (sample_type & PERF_SAMPLE_IP)
 		perf_output_put(handle, data->ip);
@@ -6034,7 +6251,9 @@ static u64 perf_virt_to_phys(u64 virt)
 	struct page *p = NULL;
 
 	if (!virt)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	if (virt >= TASK_SIZE) {
 		/* If it's vmalloc()d memory, leave phys_addr as 0 */
@@ -6076,7 +6295,9 @@ void perf_prepare_sample(struct perf_event_header *header,
 	__perf_event_header__init_id(header, data, event);
 
 	if (sample_type & PERF_SAMPLE_IP)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		data->ip = perf_instruction_pointer(regs);
+}
 
 	if (sample_type & PERF_SAMPLE_CALLCHAIN) {
 		int size = 1;
@@ -6202,6 +6423,7 @@ __perf_event_output(struct perf_event *event,
 	if (output_begin(&handle, event, header.size))
 		goto exit;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	perf_output_sample(&handle, &header, data, event);
 
 	perf_output_end(&handle);
@@ -6215,6 +6437,7 @@ perf_event_output_forward(struct perf_event *event,
 			 struct perf_sample_data *data,
 			 struct pt_regs *regs)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	__perf_event_output(event, data, regs, perf_output_begin_forward);
 }
 
@@ -6223,6 +6446,7 @@ perf_event_output_backward(struct perf_event *event,
 			   struct perf_sample_data *data,
 			   struct pt_regs *regs)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	__perf_event_output(event, data, regs, perf_output_begin_backward);
 }
 
@@ -6231,6 +6455,7 @@ perf_event_output(struct perf_event *event,
 		  struct perf_sample_data *data,
 		  struct pt_regs *regs)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	__perf_event_output(event, data, regs, perf_output_begin);
 }
 
@@ -6265,7 +6490,9 @@ perf_event_read_event(struct perf_event *event,
 	perf_event_header__init_id(&read_event.header, &sample, event);
 	ret = perf_output_begin(&handle, event, read_event.header.size);
 	if (ret)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	perf_output_put(&handle, read_event);
 	perf_output_read(&handle, event);
@@ -6283,6 +6510,7 @@ perf_iterate_ctx(struct perf_event_context *ctx,
 {
 	struct perf_event *event;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry_rcu(event, &ctx->event_list, event_entry) {
 		if (!all) {
 			if (event->state < PERF_EVENT_STATE_INACTIVE)
@@ -6297,6 +6525,7 @@ perf_iterate_ctx(struct perf_event_context *ctx,
 
 static void perf_iterate_sb_cpu(perf_iterate_f output, void *data)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct pmu_event_list *pel = this_cpu_ptr(&pmu_sb_events);
 	struct perf_event *event;
 
@@ -6339,6 +6568,7 @@ perf_iterate_sb(perf_iterate_f output, void *data,
 	 * context.
 	 */
 	if (task_ctx) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		perf_iterate_ctx(task_ctx, output, data, false);
 		goto done;
 	}
@@ -6361,6 +6591,7 @@ perf_iterate_sb(perf_iterate_f output, void *data,
  */
 static void perf_event_addr_filters_exec(struct perf_event *event, void *data)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct perf_addr_filters_head *ifh = perf_event_addr_filters(event);
 	struct perf_addr_filter *filter;
 	unsigned int restart = 0, count = 0;
@@ -6398,11 +6629,13 @@ void perf_event_exec(void)
 		if (!ctx)
 			continue;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		perf_event_enable_on_exec(ctxn);
 
 		perf_iterate_ctx(ctx, perf_event_addr_filters_exec, NULL,
 				   true);
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rcu_read_unlock();
 }
 
@@ -6421,7 +6654,9 @@ static void __perf_event_output_stop(struct perf_event *event, void *data)
 	};
 
 	if (!has_aux(event))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	if (!parent)
 		parent = event;
@@ -6444,6 +6679,7 @@ static int __perf_pmu_output_stop(void *info)
 {
 	struct perf_event *event = info;
 	struct pmu *pmu = event->pmu;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct perf_cpu_context *cpuctx = this_cpu_ptr(pmu->pmu_cpu_context);
 	struct remote_output ro = {
 		.rb	= event->rb,
@@ -6512,6 +6748,7 @@ struct perf_task_event {
 
 static int perf_event_task_match(struct perf_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return event->attr.comm  || event->attr.mmap ||
 	       event->attr.mmap2 || event->attr.mmap_data ||
 	       event->attr.task;
@@ -6527,7 +6764,9 @@ static void perf_event_task_output(struct perf_event *event,
 	int ret, size = task_event->event_id.header.size;
 
 	if (!perf_event_task_match(event))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	perf_event_header__init_id(&task_event->event_id.header, &sample, event);
 
@@ -6611,6 +6850,7 @@ struct perf_comm_event {
 
 static int perf_event_comm_match(struct perf_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return event->attr.comm;
 }
 
@@ -6624,7 +6864,9 @@ static void perf_event_comm_output(struct perf_event *event,
 	int ret;
 
 	if (!perf_event_comm_match(event))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	perf_event_header__init_id(&comm_event->event_id.header, &sample, event);
 	ret = perf_output_begin(&handle, event,
@@ -6710,6 +6952,7 @@ struct perf_namespaces_event {
 
 static int perf_event_namespaces_match(struct perf_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return event->attr.namespaces;
 }
 
@@ -6723,7 +6966,9 @@ static void perf_event_namespaces_output(struct perf_event *event,
 	int ret;
 
 	if (!perf_event_namespaces_match(event))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	perf_event_header__init_id(&namespaces_event->event_id.header,
 				   &sample, event);
@@ -6756,6 +7001,7 @@ static void perf_fill_ns_link_info(struct perf_ns_link_info *ns_link_info,
 
 	error = ns_get_path(&ns_path, task, ns_ops);
 	if (!error) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ns_inode = ns_path.dentry->d_inode;
 		ns_link_info->dev = new_encode_dev(ns_inode->i_sb->s_dev);
 		ns_link_info->ino = ns_inode->i_ino;
@@ -6853,6 +7099,7 @@ static int perf_event_mmap_match(struct perf_event *event,
 	struct vm_area_struct *vma = mmap_event->vma;
 	int executable = vma->vm_flags & VM_EXEC;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return (!executable && event->attr.mmap_data) ||
 	       (executable && (event->attr.mmap || event->attr.mmap2));
 }
@@ -6867,7 +7114,9 @@ static void perf_event_mmap_output(struct perf_event *event,
 	int ret;
 
 	if (!perf_event_mmap_match(event, data))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	if (event->attr.mmap2) {
 		mmap_event->event_id.header.type = PERF_RECORD_MMAP2;
@@ -6922,7 +7171,9 @@ static void perf_event_mmap_event(struct perf_mmap_event *mmap_event)
 	char *name;
 
 	if (vma->vm_flags & VM_READ)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		prot |= PROT_READ;
+}
 	if (vma->vm_flags & VM_WRITE)
 		prot |= PROT_WRITE;
 	if (vma->vm_flags & VM_EXEC)
@@ -7036,6 +7287,7 @@ static bool perf_addr_filter_match(struct perf_addr_filter *filter,
 				     struct file *file, unsigned long offset,
 				     unsigned long size)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (filter->inode != file_inode(file))
 		return false;
 
@@ -7050,6 +7302,7 @@ static bool perf_addr_filter_match(struct perf_addr_filter *filter,
 
 static void __perf_addr_filters_adjust(struct perf_event *event, void *data)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct perf_addr_filters_head *ifh = perf_event_addr_filters(event);
 	struct vm_area_struct *vma = data;
 	unsigned long off = vma->vm_pgoff << PAGE_SHIFT, flags;
@@ -7095,7 +7348,9 @@ static void perf_addr_filters_adjust(struct vm_area_struct *vma)
 	 * to keep track of anything that isn't related to executable code:
 	 */
 	if (!(vma->vm_flags & VM_EXEC))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	rcu_read_lock();
 	for_each_task_context_nr(ctxn) {
@@ -7169,7 +7424,9 @@ void perf_event_aux_event(struct perf_event *event, unsigned long head,
 	ret = perf_output_begin(&handle, event, rec.header.size);
 
 	if (ret)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	perf_output_put(&handle, rec);
 	perf_event__output_id_sample(event, &handle, &sample);
@@ -7203,7 +7460,9 @@ void perf_log_lost_samples(struct perf_event *event, u64 lost)
 	ret = perf_output_begin(&handle, event,
 				lost_samples_event.header.size);
 	if (ret)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	perf_output_put(&handle, lost_samples_event);
 	perf_event__output_id_sample(event, &handle, &sample);
@@ -7227,6 +7486,7 @@ struct perf_switch_event {
 
 static int perf_event_switch_match(struct perf_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return event->attr.context_switch;
 }
 
@@ -7238,7 +7498,9 @@ static void perf_event_switch_output(struct perf_event *event, void *data)
 	int ret;
 
 	if (!perf_event_switch_match(event))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	/* Only CPU-wide events are allowed to see next/prev pid/tid */
 	if (event->ctx->task) {
@@ -7322,7 +7584,9 @@ static void perf_log_throttle(struct perf_event *event, int enable)
 	};
 
 	if (enable)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		throttle_event.header.type = PERF_RECORD_UNTHROTTLE;
+}
 
 	perf_event_header__init_id(&throttle_event.header, &sample, event);
 
@@ -7338,6 +7602,7 @@ static void perf_log_throttle(struct perf_event *event, int enable)
 
 void perf_event_itrace_started(struct perf_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	event->attach_state |= PERF_ATTACH_ITRACE;
 }
 
@@ -7521,7 +7786,9 @@ static void perf_swevent_overflow(struct perf_event *event, u64 overflow,
 	int throttle = 0;
 
 	if (!overflow)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		overflow = perf_swevent_set_period(event);
+}
 
 	if (hwc->interrupts == MAX_INTERRUPTS)
 		return;
@@ -7548,7 +7815,9 @@ static void perf_swevent_event(struct perf_event *event, u64 nr,
 	local64_add(nr, &event->count);
 
 	if (!regs)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	if (!is_sampling_event(event))
 		return;
@@ -7571,6 +7840,7 @@ static void perf_swevent_event(struct perf_event *event, u64 nr,
 static int perf_exclude_event(struct perf_event *event,
 			      struct pt_regs *regs)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (event->hw.state & PERF_HES_STOPPED)
 		return 1;
 
@@ -7591,6 +7861,7 @@ static int perf_swevent_match(struct perf_event *event,
 				struct perf_sample_data *data,
 				struct pt_regs *regs)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (event->attr.type != type)
 		return 0;
 
@@ -7613,6 +7884,7 @@ static inline u64 swevent_hash(u64 type, u32 event_id)
 static inline struct hlist_head *
 __find_swevent_head(struct swevent_hlist *hlist, u64 type, u32 event_id)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	u64 hash = swevent_hash(type, event_id);
 
 	return &hlist->heads[hash];
@@ -7624,6 +7896,7 @@ find_swevent_head_rcu(struct swevent_htable *swhash, u64 type, u32 event_id)
 {
 	struct swevent_hlist *hlist;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	hlist = rcu_dereference(swhash->swevent_hlist);
 	if (!hlist)
 		return NULL;
@@ -7657,6 +7930,7 @@ static void do_perf_sw_event(enum perf_type_id type, u32 event_id,
 				    struct perf_sample_data *data,
 				    struct pt_regs *regs)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct swevent_htable *swhash = this_cpu_ptr(&swevent_htable);
 	struct perf_event *event;
 	struct hlist_head *head;
@@ -7678,6 +7952,7 @@ DEFINE_PER_CPU(struct pt_regs, __perf_regs[4]);
 
 int perf_swevent_get_recursion_context(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct swevent_htable *swhash = this_cpu_ptr(&swevent_htable);
 
 	return get_recursion_context(swhash->recursion);
@@ -7686,6 +7961,7 @@ EXPORT_SYMBOL_GPL(perf_swevent_get_recursion_context);
 
 void perf_swevent_put_recursion_context(int rctx)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct swevent_htable *swhash = this_cpu_ptr(&swevent_htable);
 
 	put_recursion_context(swhash->recursion, rctx);
@@ -7695,6 +7971,7 @@ void ___perf_sw_event(u32 event_id, u64 nr, struct pt_regs *regs, u64 addr)
 {
 	struct perf_sample_data data;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (WARN_ON_ONCE(!regs))
 		return;
 
@@ -7711,6 +7988,7 @@ void __perf_sw_event(u32 event_id, u64 nr, struct pt_regs *regs, u64 addr)
 	if (unlikely(rctx < 0))
 		goto fail;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	___perf_sw_event(event_id, nr, regs, addr);
 
 	perf_swevent_put_recursion_context(rctx);
@@ -7724,6 +8002,7 @@ static void perf_swevent_read(struct perf_event *event)
 
 static int perf_swevent_add(struct perf_event *event, int flags)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct swevent_htable *swhash = this_cpu_ptr(&swevent_htable);
 	struct hw_perf_event *hwc = &event->hw;
 	struct hlist_head *head;
@@ -7747,16 +8026,19 @@ static int perf_swevent_add(struct perf_event *event, int flags)
 
 static void perf_swevent_del(struct perf_event *event, int flags)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	hlist_del_rcu(&event->hlist_entry);
 }
 
 static void perf_swevent_start(struct perf_event *event, int flags)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	event->hw.state = 0;
 }
 
 static void perf_swevent_stop(struct perf_event *event, int flags)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	event->hw.state = PERF_HES_STOPPED;
 }
 
@@ -7764,12 +8046,14 @@ static void perf_swevent_stop(struct perf_event *event, int flags)
 static inline struct swevent_hlist *
 swevent_hlist_deref(struct swevent_htable *swhash)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return rcu_dereference_protected(swhash->swevent_hlist,
 					 lockdep_is_held(&swhash->hlist_mutex));
 }
 
 static void swevent_hlist_release(struct swevent_htable *swhash)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct swevent_hlist *hlist = swevent_hlist_deref(swhash);
 
 	if (!hlist)
@@ -7781,6 +8065,7 @@ static void swevent_hlist_release(struct swevent_htable *swhash)
 
 static void swevent_hlist_put_cpu(int cpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct swevent_htable *swhash = &per_cpu(swevent_htable, cpu);
 
 	mutex_lock(&swhash->hlist_mutex);
@@ -7795,12 +8080,14 @@ static void swevent_hlist_put(void)
 {
 	int cpu;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for_each_possible_cpu(cpu)
 		swevent_hlist_put_cpu(cpu);
 }
 
 static int swevent_hlist_get_cpu(int cpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct swevent_htable *swhash = &per_cpu(swevent_htable, cpu);
 	int err = 0;
 
@@ -7828,6 +8115,7 @@ static int swevent_hlist_get(void)
 	int err, cpu, failed_cpu;
 
 	mutex_lock(&pmus_lock);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for_each_possible_cpu(cpu) {
 		err = swevent_hlist_get_cpu(cpu);
 		if (err) {
@@ -7853,6 +8141,7 @@ static void sw_perf_event_destroy(struct perf_event *event)
 {
 	u64 event_id = event->attr.config;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WARN_ON(event->parent);
 
 	static_key_slow_dec(&perf_swevent_enabled[event_id]);
@@ -7864,14 +8153,19 @@ static int perf_swevent_init(struct perf_event *event)
 	u64 event_id = event->attr.config;
 
 	if (event->attr.type != PERF_TYPE_SOFTWARE)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOENT;
+}
 
 	/*
 	 * no branch sampling for software events
 	 */
 	if (has_branch_stack(event))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EOPNOTSUPP;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	switch (event_id) {
 	case PERF_COUNT_SW_CPU_CLOCK:
 	case PERF_COUNT_SW_TASK_CLOCK:
@@ -7881,20 +8175,28 @@ static int perf_swevent_init(struct perf_event *event)
 		break;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (event_id >= PERF_COUNT_SW_MAX)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOENT;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!event->parent) {
 		int err;
 
 		err = swevent_hlist_get();
 		if (err)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return err;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		static_key_slow_inc(&perf_swevent_enabled[event_id]);
 		event->destroy = sw_perf_event_destroy;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
@@ -7920,7 +8222,9 @@ static int perf_tp_filter_match(struct perf_event *event,
 
 	/* only top level events have filters set */
 	if (event->parent)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		event = event->parent;
+}
 
 	if (likely(!event->filter) || filter_match_preds(event->filter, record))
 		return 1;
@@ -7931,6 +8235,7 @@ static int perf_tp_event_match(struct perf_event *event,
 				struct perf_sample_data *data,
 				struct pt_regs *regs)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (event->hw.state & PERF_HES_STOPPED)
 		return 0;
 	/*
@@ -7953,6 +8258,7 @@ void perf_trace_run_bpf_submit(void *raw_data, int size, int rctx,
 	struct bpf_prog *prog = call->prog;
 
 	if (prog) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		*(struct pt_regs **)raw_data = regs;
 		if (!trace_call_bpf(prog, raw_data) || hlist_empty(head)) {
 			perf_swevent_put_recursion_context(rctx);
@@ -7984,6 +8290,7 @@ void perf_tp_event(u16 event_type, u64 count, void *record, int entry_size,
 
 	/* Use the given event instead of the hlist */
 	if (event) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (perf_tp_event_match(event, &data, regs))
 			perf_swevent_event(event, count, &data, regs);
 	} else {
@@ -8024,6 +8331,7 @@ EXPORT_SYMBOL_GPL(perf_tp_event);
 
 static void tp_perf_event_destroy(struct perf_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	perf_trace_destroy(event);
 }
 
@@ -8032,18 +8340,26 @@ static int perf_tp_event_init(struct perf_event *event)
 	int err;
 
 	if (event->attr.type != PERF_TYPE_TRACEPOINT)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOENT;
+}
 
 	/*
 	 * no branch sampling for tracepoint events
 	 */
 	if (has_branch_stack(event))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EOPNOTSUPP;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	err = perf_trace_init(event);
 	if (err)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return err;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	event->destroy = tp_perf_event_destroy;
 
 	return 0;
@@ -8067,6 +8383,7 @@ static inline void perf_tp_register(void)
 
 static void perf_event_free_filter(struct perf_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	ftrace_profile_free_filter(event);
 }
 
@@ -8131,6 +8448,7 @@ static void perf_event_free_bpf_handler(struct perf_event *event)
 #else
 static int perf_event_set_bpf_handler(struct perf_event *event, u32 prog_fd)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return -EOPNOTSUPP;
 }
 static void perf_event_free_bpf_handler(struct perf_event *event)
@@ -8144,7 +8462,9 @@ static int perf_event_set_bpf_prog(struct perf_event *event, u32 prog_fd)
 	struct bpf_prog *prog;
 
 	if (event->attr.type != PERF_TYPE_TRACEPOINT)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return perf_event_set_bpf_handler(event, prog_fd);
+}
 
 	if (event->tp_event->prog)
 		return -EEXIST;
@@ -8189,7 +8509,9 @@ static void perf_event_free_bpf_prog(struct perf_event *event)
 	perf_event_free_bpf_handler(event);
 
 	if (!event->tp_event)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	prog = event->tp_event->prog;
 	if (prog && event->tp_event->bpf_prog_owner == event) {
@@ -8226,6 +8548,7 @@ void perf_bp_event(struct perf_event *bp, void *data)
 
 	perf_sample_data_init(&sample, bp->attr.bp_addr, 0);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!bp->hw.state && !perf_exclude_event(bp, regs))
 		perf_swevent_event(bp, 1, &sample, regs);
 }
@@ -8237,6 +8560,7 @@ void perf_bp_event(struct perf_event *bp, void *data)
 static struct perf_addr_filter *
 perf_addr_filter_new(struct perf_event *event, struct list_head *filters)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	int node = cpu_to_node(event->cpu == -1 ? 0 : event->cpu);
 	struct perf_addr_filter *filter;
 
@@ -8254,6 +8578,7 @@ static void free_filters_list(struct list_head *filters)
 {
 	struct perf_addr_filter *filter, *iter;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry_safe(filter, iter, filters, entry) {
 		if (filter->inode)
 			iput(filter->inode);
@@ -8272,7 +8597,9 @@ static void perf_addr_filters_splice(struct perf_event *event,
 	LIST_HEAD(list);
 
 	if (!has_addr_filter(event))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	/* don't bother with children, they don't have their own filters */
 	if (event->parent)
@@ -8299,6 +8626,7 @@ static unsigned long perf_addr_filter_apply(struct perf_addr_filter *filter,
 {
 	struct vm_area_struct *vma;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (vma = mm->mmap; vma; vma = vma->vm_next) {
 		struct file *file = vma->vm_file;
 		unsigned long off = vma->vm_pgoff << PAGE_SHIFT;
@@ -8322,6 +8650,7 @@ static unsigned long perf_addr_filter_apply(struct perf_addr_filter *filter,
  */
 static void perf_event_addr_filters_apply(struct perf_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct perf_addr_filters_head *ifh = perf_event_addr_filters(event);
 	struct task_struct *task = READ_ONCE(event->ctx->task);
 	struct perf_addr_filter *filter;
@@ -8434,7 +8763,9 @@ perf_event_parse_addr_filter(struct perf_event *event, char *fstr,
 
 	orig = fstr = kstrdup(fstr, GFP_KERNEL);
 	if (!fstr)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 
 	while ((start = strsep(&fstr, " ,\n")) != NULL) {
 		ret = -EINVAL;
@@ -8647,6 +8978,7 @@ static enum hrtimer_restart perf_swevent_hrtimer(struct hrtimer *hrtimer)
 	struct perf_event *event;
 	u64 period;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	event = container_of(hrtimer, struct perf_event, hw.hrtimer);
 
 	if (event->state != PERF_EVENT_STATE_ACTIVE)
@@ -8675,7 +9007,9 @@ static void perf_swevent_start_hrtimer(struct perf_event *event)
 	s64 period;
 
 	if (!is_sampling_event(event))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	period = local64_read(&hwc->period_left);
 	if (period) {
@@ -8695,6 +9029,7 @@ static void perf_swevent_cancel_hrtimer(struct perf_event *event)
 	struct hw_perf_event *hwc = &event->hw;
 
 	if (is_sampling_event(event)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ktime_t remaining = hrtimer_get_remaining(&hwc->hrtimer);
 		local64_set(&hwc->period_left, ktime_to_ns(remaining));
 
@@ -8707,7 +9042,9 @@ static void perf_swevent_init_hrtimer(struct perf_event *event)
 	struct hw_perf_event *hwc = &event->hw;
 
 	if (!is_sampling_event(event))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	hrtimer_init(&hwc->hrtimer, CLOCK_MONOTONIC, HRTIMER_MODE_REL);
 	hwc->hrtimer.function = perf_swevent_hrtimer;
@@ -8737,24 +9074,28 @@ static void cpu_clock_event_update(struct perf_event *event)
 	u64 now;
 
 	now = local_clock();
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	prev = local64_xchg(&event->hw.prev_count, now);
 	local64_add(now - prev, &event->count);
 }
 
 static void cpu_clock_event_start(struct perf_event *event, int flags)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	local64_set(&event->hw.prev_count, local_clock());
 	perf_swevent_start_hrtimer(event);
 }
 
 static void cpu_clock_event_stop(struct perf_event *event, int flags)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	perf_swevent_cancel_hrtimer(event);
 	cpu_clock_event_update(event);
 }
 
 static int cpu_clock_event_add(struct perf_event *event, int flags)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (flags & PERF_EF_START)
 		cpu_clock_event_start(event, flags);
 	perf_event_update_userpage(event);
@@ -8764,28 +9105,38 @@ static int cpu_clock_event_add(struct perf_event *event, int flags)
 
 static void cpu_clock_event_del(struct perf_event *event, int flags)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	cpu_clock_event_stop(event, flags);
 }
 
 static void cpu_clock_event_read(struct perf_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	cpu_clock_event_update(event);
 }
 
 static int cpu_clock_event_init(struct perf_event *event)
 {
 	if (event->attr.type != PERF_TYPE_SOFTWARE)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOENT;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (event->attr.config != PERF_COUNT_SW_CPU_CLOCK)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOENT;
+}
 
 	/*
 	 * no branch sampling for software events
 	 */
 	if (has_branch_stack(event))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EOPNOTSUPP;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	perf_swevent_init_hrtimer(event);
 
 	return 0;
@@ -8813,6 +9164,7 @@ static void task_clock_event_update(struct perf_event *event, u64 now)
 	u64 prev;
 	s64 delta;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	prev = local64_xchg(&event->hw.prev_count, now);
 	delta = now - prev;
 	local64_add(delta, &event->count);
@@ -8820,18 +9172,21 @@ static void task_clock_event_update(struct perf_event *event, u64 now)
 
 static void task_clock_event_start(struct perf_event *event, int flags)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	local64_set(&event->hw.prev_count, event->ctx->time);
 	perf_swevent_start_hrtimer(event);
 }
 
 static void task_clock_event_stop(struct perf_event *event, int flags)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	perf_swevent_cancel_hrtimer(event);
 	task_clock_event_update(event, event->ctx->time);
 }
 
 static int task_clock_event_add(struct perf_event *event, int flags)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (flags & PERF_EF_START)
 		task_clock_event_start(event, flags);
 	perf_event_update_userpage(event);
@@ -8841,11 +9196,13 @@ static int task_clock_event_add(struct perf_event *event, int flags)
 
 static void task_clock_event_del(struct perf_event *event, int flags)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	task_clock_event_stop(event, PERF_EF_UPDATE);
 }
 
 static void task_clock_event_read(struct perf_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	u64 now = perf_clock();
 	u64 delta = now - event->ctx->timestamp;
 	u64 time = event->ctx->time + delta;
@@ -8856,17 +9213,25 @@ static void task_clock_event_read(struct perf_event *event)
 static int task_clock_event_init(struct perf_event *event)
 {
 	if (event->attr.type != PERF_TYPE_SOFTWARE)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOENT;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (event->attr.config != PERF_COUNT_SW_TASK_CLOCK)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOENT;
+}
 
 	/*
 	 * no branch sampling for software events
 	 */
 	if (has_branch_stack(event))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EOPNOTSUPP;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	perf_swevent_init_hrtimer(event);
 
 	return 0;
@@ -8895,6 +9260,7 @@ static void perf_pmu_nop_txn(struct pmu *pmu, unsigned int flags)
 
 static int perf_pmu_nop_int(struct pmu *pmu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
@@ -8902,6 +9268,7 @@ static DEFINE_PER_CPU(unsigned int, nop_txn_flags);
 
 static void perf_pmu_start_txn(struct pmu *pmu, unsigned int flags)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	__this_cpu_write(nop_txn_flags, flags);
 
 	if (flags & ~PERF_PMU_TXN_ADD)
@@ -8912,6 +9279,7 @@ static void perf_pmu_start_txn(struct pmu *pmu, unsigned int flags)
 
 static int perf_pmu_commit_txn(struct pmu *pmu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	unsigned int flags = __this_cpu_read(nop_txn_flags);
 
 	__this_cpu_write(nop_txn_flags, 0);
@@ -8925,6 +9293,7 @@ static int perf_pmu_commit_txn(struct pmu *pmu)
 
 static void perf_pmu_cancel_txn(struct pmu *pmu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	unsigned int flags =  __this_cpu_read(nop_txn_flags);
 
 	__this_cpu_write(nop_txn_flags, 0);
@@ -8937,6 +9306,7 @@ static void perf_pmu_cancel_txn(struct pmu *pmu)
 
 static int perf_event_idx_default(struct perf_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
@@ -8949,13 +9319,16 @@ static struct perf_cpu_context __percpu *find_pmu_context(int ctxn)
 	struct pmu *pmu;
 
 	if (ctxn < 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 
 	list_for_each_entry(pmu, &pmus, entry) {
 		if (pmu->task_ctx_nr == ctxn)
 			return pmu->pmu_cpu_context;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return NULL;
 }
 
@@ -8981,6 +9354,7 @@ static ssize_t nr_addr_filters_show(struct device *dev,
 				    struct device_attribute *attr,
 				    char *page)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct pmu *pmu = dev_get_drvdata(dev);
 
 	return snprintf(page, PAGE_SIZE - 1, "%d\n", pmu->nr_addr_filters);
@@ -8992,6 +9366,7 @@ static struct idr pmu_idr;
 static ssize_t
 type_show(struct device *dev, struct device_attribute *attr, char *page)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct pmu *pmu = dev_get_drvdata(dev);
 
 	return snprintf(page, PAGE_SIZE-1, "%d\n", pmu->type);
@@ -9003,6 +9378,7 @@ perf_event_mux_interval_ms_show(struct device *dev,
 				struct device_attribute *attr,
 				char *page)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct pmu *pmu = dev_get_drvdata(dev);
 
 	return snprintf(page, PAGE_SIZE-1, "%d\n", pmu->hrtimer_interval_ms);
@@ -9015,6 +9391,7 @@ perf_event_mux_interval_ms_store(struct device *dev,
 				 struct device_attribute *attr,
 				 const char *buf, size_t count)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct pmu *pmu = dev_get_drvdata(dev);
 	int timer, cpu, ret;
 
@@ -9064,6 +9441,7 @@ static struct bus_type pmu_bus = {
 
 static void pmu_dev_release(struct device *dev)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	kfree(dev);
 }
 
@@ -9090,7 +9468,9 @@ static int pmu_dev_alloc(struct pmu *pmu)
 
 	/* For PMUs with address filters, throw in an extra attribute: */
 	if (pmu->nr_addr_filters)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ret = device_create_file(pmu->dev, &dev_attr_nr_addr_filters);
+}
 
 	if (ret)
 		goto del_dev;
@@ -9127,6 +9507,7 @@ int perf_pmu_register(struct pmu *pmu, const char *name, int type)
 	if (type < 0) {
 		type = idr_alloc(&pmu_idr, pmu, PERF_TYPE_MAX, 0, GFP_KERNEL);
 		if (type < 0) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			ret = type;
 			goto free_pdc;
 		}
@@ -9134,6 +9515,7 @@ int perf_pmu_register(struct pmu *pmu, const char *name, int type)
 	pmu->type = type;
 
 	if (pmu_bus_running) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ret = pmu_dev_alloc(pmu);
 		if (ret)
 			goto free_idr;
@@ -9152,6 +9534,7 @@ int perf_pmu_register(struct pmu *pmu, const char *name, int type)
 		    !(pmu->capabilities & PERF_PMU_CAP_HETEROGENEOUS_CPUS)))
 			pmu->task_ctx_nr = perf_invalid_context;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		hw_context_taken = 1;
 	}
 
@@ -9159,6 +9542,7 @@ int perf_pmu_register(struct pmu *pmu, const char *name, int type)
 	if (pmu->pmu_cpu_context)
 		goto got_cpu_context;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	ret = -ENOMEM;
 	pmu->pmu_cpu_context = alloc_percpu(struct perf_cpu_context);
 	if (!pmu->pmu_cpu_context)
@@ -9169,7 +9553,9 @@ int perf_pmu_register(struct pmu *pmu, const char *name, int type)
 
 		cpuctx = per_cpu_ptr(pmu->pmu_cpu_context, cpu);
 		__perf_event_init_context(&cpuctx->ctx);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		lockdep_set_class(&cpuctx->ctx.mutex, &cpuctx_mutex);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		lockdep_set_class(&cpuctx->ctx.lock, &cpuctx_lock);
 		cpuctx->ctx.pmu = pmu;
 		cpuctx->online = cpumask_test_cpu(cpu, perf_online_mask);
@@ -9217,7 +9603,9 @@ int perf_pmu_register(struct pmu *pmu, const char *name, int type)
 
 free_idr:
 	if (pmu->type >= PERF_TYPE_MAX)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		idr_remove(&pmu_idr, pmu->type);
+}
 
 free_pdc:
 	free_percpu(pmu->pmu_disable_count);
@@ -9243,7 +9631,9 @@ void perf_pmu_unregister(struct pmu *pmu)
 
 	free_percpu(pmu->pmu_disable_count);
 	if (pmu->type >= PERF_TYPE_MAX)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		idr_remove(&pmu_idr, pmu->type);
+}
 	if (remove_device) {
 		if (pmu->nr_addr_filters)
 			device_remove_file(pmu->dev, &dev_attr_nr_addr_filters);
@@ -9260,7 +9650,9 @@ static int perf_try_init_event(struct pmu *pmu, struct perf_event *event)
 	int ret;
 
 	if (!try_module_get(pmu->module))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENODEV;
+}
 
 	if (event->group_leader != event) {
 		/*
@@ -9269,6 +9661,7 @@ static int perf_try_init_event(struct pmu *pmu, struct perf_event *event)
 		 */
 		ctx = perf_event_ctx_lock_nested(event->group_leader,
 						 SINGLE_DEPTH_NESTING);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		BUG_ON(!ctx);
 	}
 
@@ -9276,11 +9669,14 @@ static int perf_try_init_event(struct pmu *pmu, struct perf_event *event)
 	ret = pmu->event_init(event);
 
 	if (ctx)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		perf_event_ctx_unlock(event->group_leader, ctx);
+}
 
 	if (ret)
 		module_put(pmu->module);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return ret;
 }
 
@@ -9294,19 +9690,24 @@ static struct pmu *perf_init_event(struct perf_event *event)
 
 	/* Try parent's PMU first: */
 	if (event->parent && event->parent->pmu) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pmu = event->parent->pmu;
 		ret = perf_try_init_event(pmu, event);
 		if (!ret)
 			goto unlock;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rcu_read_lock();
 	pmu = idr_find(&pmu_idr, event->attr.type);
 	rcu_read_unlock();
 	if (pmu) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ret = perf_try_init_event(pmu, event);
 		if (ret)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			pmu = ERR_PTR(ret);
+}
 		goto unlock;
 	}
 
@@ -9316,10 +9717,12 @@ static struct pmu *perf_init_event(struct perf_event *event)
 			goto unlock;
 
 		if (ret != -ENOENT) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			pmu = ERR_PTR(ret);
 			goto unlock;
 		}
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pmu = ERR_PTR(-ENOENT);
 unlock:
 	srcu_read_unlock(&pmus_srcu, idx);
@@ -9329,6 +9732,7 @@ static struct pmu *perf_init_event(struct perf_event *event)
 
 static void attach_sb_event(struct perf_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct pmu_event_list *pel = per_cpu_ptr(&pmu_sb_events, event->cpu);
 
 	raw_spin_lock(&pel->lock);
@@ -9345,12 +9749,14 @@ static void attach_sb_event(struct perf_event *event)
  */
 static void account_pmu_sb_event(struct perf_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (is_sb_event(event))
 		attach_sb_event(event);
 }
 
 static void account_event_cpu(struct perf_event *event, int cpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (event->parent)
 		return;
 
@@ -9372,6 +9778,7 @@ static void account_freq_event_nohz(void)
 
 static void account_freq_event(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (tick_nohz_full_enabled())
 		account_freq_event_nohz();
 	else
@@ -9384,7 +9791,9 @@ static void account_event(struct perf_event *event)
 	bool inc = false;
 
 	if (event->parent)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	if (event->attach_state & PERF_ATTACH_TASK)
 		inc = true;
@@ -9452,20 +9861,27 @@ perf_event_alloc(struct perf_event_attr *attr, int cpu,
 	long err = -EINVAL;
 
 	if ((unsigned)cpu >= nr_cpu_ids) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (!task || cpu != -1)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return ERR_PTR(-EINVAL);
+}
 	}
 
 	event = kzalloc(sizeof(*event), GFP_KERNEL);
 	if (!event)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ERR_PTR(-ENOMEM);
+}
 
 	/*
 	 * Single events are their own group leaders, with an
 	 * empty sibling list:
 	 */
 	if (!group_leader)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		group_leader = event;
+}
 
 	mutex_init(&event->child_mutex);
 	INIT_LIST_HEAD(&event->child_list);
@@ -9480,11 +9896,13 @@ perf_event_alloc(struct perf_event_attr *attr, int cpu,
 
 
 	init_waitqueue_head(&event->waitq);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	init_irq_work(&event->pending, perf_pending_event);
 
 	mutex_init(&event->mmap_mutex);
 	raw_spin_lock_init(&event->addr_filters.lock);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	atomic_long_set(&event->refcount, 1);
 	event->cpu		= cpu;
 	event->attr		= *attr;
@@ -9500,6 +9918,7 @@ perf_event_alloc(struct perf_event_attr *attr, int cpu,
 	event->state		= PERF_EVENT_STATE_INACTIVE;
 
 	if (task) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		event->attach_state = PERF_ATTACH_TASK;
 		/*
 		 * XXX pmu::event_init needs to know what task to account to
@@ -9511,9 +9930,12 @@ perf_event_alloc(struct perf_event_attr *attr, int cpu,
 
 	event->clock = &local_clock;
 	if (parent_event)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		event->clock = parent_event->clock;
+}
 
 	if (!overflow_handler && parent_event) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		overflow_handler = parent_event->overflow_handler;
 		context = parent_event->overflow_handler_context;
 #if defined(CONFIG_BPF_SYSCALL) && defined(CONFIG_EVENT_TRACING)
@@ -9535,9 +9957,11 @@ perf_event_alloc(struct perf_event_attr *attr, int cpu,
 		event->overflow_handler	= overflow_handler;
 		event->overflow_handler_context = context;
 	} else if (is_write_backward(event)){
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		event->overflow_handler = perf_event_output_backward;
 		event->overflow_handler_context = NULL;
 	} else {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		event->overflow_handler = perf_event_output_forward;
 		event->overflow_handler_context = NULL;
 	}
@@ -9549,7 +9973,9 @@ perf_event_alloc(struct perf_event_attr *attr, int cpu,
 	hwc = &event->hw;
 	hwc->sample_period = attr->sample_period;
 	if (attr->freq && attr->sample_freq)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		hwc->sample_period = 1;
+}
 	hwc->last_period = hwc->sample_period;
 
 	local64_set(&hwc->period_left, hwc->sample_period);
@@ -9565,6 +9991,7 @@ perf_event_alloc(struct perf_event_attr *attr, int cpu,
 		event->attr.branch_sample_type = 0;
 
 	if (cgroup_fd != -1) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		err = perf_cgroup_connect(cgroup_fd, event, attr, group_leader);
 		if (err)
 			goto err_ns;
@@ -9572,19 +9999,24 @@ perf_event_alloc(struct perf_event_attr *attr, int cpu,
 
 	pmu = perf_init_event(event);
 	if (IS_ERR(pmu)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		err = PTR_ERR(pmu);
 		goto err_ns;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	err = exclusive_event_init(event);
 	if (err)
 		goto err_pmu;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (has_addr_filter(event)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		event->addr_filters_offs = kcalloc(pmu->nr_addr_filters,
 						   sizeof(unsigned long),
 						   GFP_KERNEL);
 		if (!event->addr_filters_offs) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			err = -ENOMEM;
 			goto err_per_task;
 		}
@@ -9593,8 +10025,11 @@ perf_event_alloc(struct perf_event_attr *attr, int cpu,
 		event->addr_filters_gen = 1;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!event->parent) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (event->attr.sample_type & PERF_SAMPLE_CALLCHAIN) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			err = get_callchain_buffers(attr->sample_max_stack);
 			if (err)
 				goto err_addr_filters;
@@ -9614,11 +10049,16 @@ perf_event_alloc(struct perf_event_attr *attr, int cpu,
 
 err_pmu:
 	if (event->destroy)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		event->destroy(event);
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	module_put(pmu->module);
 err_ns:
 	if (is_cgroup_event(event))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		perf_detach_cgroup(event);
+}
 	if (event->ns)
 		put_pid_ns(event->ns);
 	kfree(event);
@@ -9633,7 +10073,9 @@ static int perf_copy_attr(struct perf_event_attr __user *uattr,
 	int ret;
 
 	if (!access_ok(VERIFY_WRITE, uattr, PERF_ATTR_SIZE_VER0))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EFAULT;
+}
 
 	/*
 	 * zero the full structure, so that a short copy will be nice.
@@ -9828,6 +10270,7 @@ perf_event_set_output(struct perf_event *event, struct perf_event *output_event)
 
 static void mutex_lock_double(struct mutex *a, struct mutex *b)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (b < a)
 		swap(a, b);
 
@@ -9931,7 +10374,9 @@ SYSCALL_DEFINE5(perf_event_open,
 
 	/* for future expandability... */
 	if (flags & ~PERF_FLAG_ALL)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	err = perf_copy_attr(attr_uptr, &attr);
 	if (err)
@@ -10374,17 +10819,21 @@ perf_event_create_kernel_counter(struct perf_event_attr *attr, int cpu,
 
 	ctx = find_get_context(event->pmu, task, event);
 	if (IS_ERR(ctx)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		err = PTR_ERR(ctx);
 		goto err_free;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WARN_ON_ONCE(ctx->parent_ctx);
 	mutex_lock(&ctx->mutex);
 	if (ctx->task == TASK_TOMBSTONE) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		err = -ESRCH;
 		goto err_unlock;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!task) {
 		/*
 		 * Check if the @cpu we're creating an event for is online.
@@ -10395,16 +10844,20 @@ perf_event_create_kernel_counter(struct perf_event_attr *attr, int cpu,
 		struct perf_cpu_context *cpuctx =
 			container_of(ctx, struct perf_cpu_context, ctx);
 		if (!cpuctx->online) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			err = -ENODEV;
 			goto err_unlock;
 		}
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!exclusive_event_installable(event, ctx)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		err = -EBUSY;
 		goto err_unlock;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	perf_install_in_context(ctx, event, cpu);
 	perf_unpin_context(ctx);
 	mutex_unlock(&ctx->mutex);
@@ -10429,6 +10882,7 @@ void perf_pmu_migrate_context(struct pmu *pmu, int src_cpu, int dst_cpu)
 	struct perf_event *event, *tmp;
 	LIST_HEAD(events);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	src_ctx = &per_cpu_ptr(pmu->pmu_cpu_context, src_cpu)->ctx;
 	dst_ctx = &per_cpu_ptr(pmu->pmu_cpu_context, dst_cpu)->ctx;
 
@@ -10494,7 +10948,9 @@ static void sync_child_event(struct perf_event *child_event,
 	u64 child_val;
 
 	if (child_event->attr.inherit_stat)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		perf_event_read_event(child_event, child);
+}
 
 	child_val = perf_event_count(child_event);
 
@@ -10528,6 +10984,7 @@ perf_event_exit_event(struct perf_event *child_event,
 	 * and being thorough is better.
 	 */
 	raw_spin_lock_irq(&child_ctx->lock);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WARN_ON_ONCE(child_ctx->is_active);
 
 	if (parent_event)
@@ -10574,7 +11031,9 @@ static void perf_event_exit_task_context(struct task_struct *child, int ctxn)
 
 	child_ctx = perf_pin_task_context(child, ctxn);
 	if (!child_ctx)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	/*
 	 * In order to reduce the amount of tricky in ctx tear-down, we hold
@@ -10601,6 +11060,7 @@ static void perf_event_exit_task_context(struct task_struct *child, int ctxn)
 	 * and mark the context dead.
 	 */
 	RCU_INIT_POINTER(child->perf_event_ctxp[ctxn], NULL);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	put_ctx(child_ctx); /* cannot be last */
 	WRITE_ONCE(child_ctx->task, TASK_TOMBSTONE);
 	put_task_struct(current); /* cannot be last */
@@ -10609,7 +11069,9 @@ static void perf_event_exit_task_context(struct task_struct *child, int ctxn)
 	raw_spin_unlock_irq(&child_ctx->lock);
 
 	if (clone_ctx)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		put_ctx(clone_ctx);
+}
 
 	/*
 	 * Report the task dead after unscheduling the events so that we
@@ -10618,9 +11080,11 @@ static void perf_event_exit_task_context(struct task_struct *child, int ctxn)
 	 */
 	perf_event_task(child, child_ctx, 0);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry_safe(child_event, next, &child_ctx->event_list, event_entry)
 		perf_event_exit_event(child_event, child_ctx, child);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	mutex_unlock(&child_ctx->mutex);
 
 	put_ctx(child_ctx);
@@ -10640,6 +11104,7 @@ void perf_event_exit_task(struct task_struct *child)
 	mutex_lock(&child->perf_event_mutex);
 	list_for_each_entry_safe(event, tmp, &child->perf_event_list,
 				 owner_entry) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		list_del_init(&event->owner_entry);
 
 		/*
@@ -10668,6 +11133,7 @@ static void perf_free_event(struct perf_event *event,
 {
 	struct perf_event *parent = event->parent;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (WARN_ON_ONCE(!parent))
 		return;
 
@@ -10702,6 +11168,7 @@ void perf_event_free_task(struct task_struct *task)
 		if (!ctx)
 			continue;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		mutex_lock(&ctx->mutex);
 		raw_spin_lock_irq(&ctx->lock);
 		/*
@@ -10715,9 +11182,11 @@ void perf_event_free_task(struct task_struct *task)
 		put_task_struct(task); /* cannot be last */
 		raw_spin_unlock_irq(&ctx->lock);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		list_for_each_entry_safe(event, tmp, &ctx->event_list, event_entry)
 			perf_free_event(event, ctx);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		mutex_unlock(&ctx->mutex);
 		put_ctx(ctx);
 	}
@@ -10737,7 +11206,9 @@ struct file *perf_event_get(unsigned int fd)
 
 	file = fget_raw(fd);
 	if (!file)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ERR_PTR(-EBADF);
+}
 
 	if (file->f_op != &perf_fops) {
 		fput(file);
@@ -10749,6 +11220,7 @@ struct file *perf_event_get(unsigned int fd)
 
 const struct perf_event_attr *perf_event_attrs(struct perf_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!event)
 		return ERR_PTR(-EINVAL);
 
@@ -10782,7 +11254,9 @@ inherit_event(struct perf_event *parent_event,
 	 * count:
 	 */
 	if (parent_event->parent)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		parent_event = parent_event->parent;
+}
 
 	child_event = perf_event_alloc(&parent_event->attr,
 					   parent_event->cpu,
@@ -10878,7 +11352,9 @@ static int inherit_group(struct perf_event *parent_event,
 	leader = inherit_event(parent_event, parent, parent_ctx,
 				 child, NULL, child_ctx);
 	if (IS_ERR(leader))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return PTR_ERR(leader);
+}
 	/*
 	 * @leader can be NULL here because of is_orphaned_event(). In this
 	 * case inherit_event() will create individual events, similar to what
@@ -10914,6 +11390,7 @@ inherit_task_group(struct perf_event *event, struct task_struct *parent,
 	struct perf_event_context *child_ctx;
 
 	if (!event->attr.inherit) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		*inherited_all = 0;
 		return 0;
 	}
@@ -10956,7 +11433,9 @@ static int perf_event_init_context(struct task_struct *child, int ctxn)
 	int ret = 0;
 
 	if (likely(!parent->perf_event_ctxp[ctxn]))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	/*
 	 * If the parent's context is a clone, pin it so it won't get
@@ -10964,7 +11443,9 @@ static int perf_event_init_context(struct task_struct *child, int ctxn)
 	 */
 	parent_ctx = perf_pin_task_context(parent, ctxn);
 	if (!parent_ctx)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	/*
 	 * No need to check if parent_ctx != NULL here; since we saw
@@ -10984,6 +11465,7 @@ static int perf_event_init_context(struct task_struct *child, int ctxn)
 	 * the list, not manipulating it:
 	 */
 	list_for_each_entry(event, &parent_ctx->pinned_groups, group_entry) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ret = inherit_task_group(event, parent, parent_ctx,
 					 child, ctxn, &inherited_all);
 		if (ret)
@@ -10996,21 +11478,28 @@ static int perf_event_init_context(struct task_struct *child, int ctxn)
 	 * rotate_ctx() will change the list from interrupt context.
 	 */
 	raw_spin_lock_irqsave(&parent_ctx->lock, flags);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	parent_ctx->rotate_disable = 1;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	raw_spin_unlock_irqrestore(&parent_ctx->lock, flags);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry(event, &parent_ctx->flexible_groups, group_entry) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ret = inherit_task_group(event, parent, parent_ctx,
 					 child, ctxn, &inherited_all);
 		if (ret)
 			goto out_unlock;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	raw_spin_lock_irqsave(&parent_ctx->lock, flags);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	parent_ctx->rotate_disable = 0;
 
 	child_ctx = child->perf_event_ctxp[ctxn];
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (child_ctx && inherited_all) {
 		/*
 		 * Mark the child context as a clone of the parent
@@ -11021,15 +11510,19 @@ static int perf_event_init_context(struct task_struct *child, int ctxn)
 		 */
 		cloned_ctx = parent_ctx->parent_ctx;
 		if (cloned_ctx) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			child_ctx->parent_ctx = cloned_ctx;
 			child_ctx->parent_gen = parent_ctx->parent_gen;
 		} else {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			child_ctx->parent_ctx = parent_ctx;
 			child_ctx->parent_gen = parent_ctx->generation;
 		}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		get_ctx(child_ctx->parent_ctx);
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	raw_spin_unlock_irqrestore(&parent_ctx->lock, flags);
 out_unlock:
 	mutex_unlock(&parent_ctx->mutex);
@@ -11054,11 +11547,13 @@ int perf_event_init_task(struct task_struct *child)
 	for_each_task_context_nr(ctxn) {
 		ret = perf_event_init_context(child, ctxn);
 		if (ret) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			perf_event_free_task(child);
 			return ret;
 		}
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
@@ -11093,7 +11588,9 @@ void perf_swevent_init_cpu(unsigned int cpu)
 		struct swevent_hlist *hlist;
 
 		hlist = kzalloc_node(sizeof(*hlist), GFP_KERNEL, cpu_to_node(cpu));
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		WARN_ON(!hlist);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		rcu_assign_pointer(swhash->swevent_hlist, hlist);
 	}
 	mutex_unlock(&swhash->hlist_mutex);
@@ -11107,6 +11604,7 @@ static void __perf_event_exit_context(void *__info)
 	struct perf_event *event;
 
 	raw_spin_lock(&ctx->lock);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry(event, &ctx->event_list, event_entry)
 		__perf_remove_from_context(event, cpuctx, ctx, (void *)DETACH_GROUP);
 	raw_spin_unlock(&ctx->lock);
@@ -11119,6 +11617,7 @@ static void perf_event_exit_cpu_context(int cpu)
 	struct pmu *pmu;
 
 	mutex_lock(&pmus_lock);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry(pmu, &pmus, entry) {
 		cpuctx = per_cpu_ptr(pmu->pmu_cpu_context, cpu);
 		ctx = &cpuctx->ctx;
@@ -11162,6 +11661,7 @@ int perf_event_init_cpu(unsigned int cpu)
 
 int perf_event_exit_cpu(unsigned int cpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	perf_event_exit_cpu_context(cpu);
 	return 0;
 }
@@ -11171,6 +11671,7 @@ perf_reboot(struct notifier_block *notifier, unsigned long val, void *v)
 {
 	int cpu;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for_each_online_cpu(cpu)
 		perf_event_exit_cpu(cpu);
 
diff --git a/kernel/events/hw_breakpoint.c b/kernel/events/hw_breakpoint.c
index 3f8cb1e..7210bfd 100644
--- a/kernel/events/hw_breakpoint.c
+++ b/kernel/events/hw_breakpoint.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * This program is free software; you can redistribute it and/or modify
  * it under the terms of the GNU General Public License as published by
@@ -82,11 +84,13 @@ static DEFINE_MUTEX(nr_bp_mutex);
 
 __weak int hw_breakpoint_weight(struct perf_event *bp)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 1;
 }
 
 static inline enum bp_type_idx find_slot_idx(struct perf_event *bp)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (bp->attr.bp_type & HW_BREAKPOINT_RW)
 		return TYPE_DATA;
 
@@ -99,6 +103,7 @@ static inline enum bp_type_idx find_slot_idx(struct perf_event *bp)
  */
 static unsigned int max_task_bp_pinned(int cpu, enum bp_type_idx type)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	unsigned int *tsk_pinned = get_bp_info(cpu, type)->tsk_pinned;
 	int i;
 
@@ -120,6 +125,7 @@ static int task_bp_pinned(int cpu, struct perf_event *bp, enum bp_type_idx type)
 	struct perf_event *iter;
 	int count = 0;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry(iter, &bp_task_head, hw.bp_list) {
 		if (iter->hw.target == tsk &&
 		    find_slot_idx(iter) == type &&
@@ -132,6 +138,7 @@ static int task_bp_pinned(int cpu, struct perf_event *bp, enum bp_type_idx type)
 
 static const struct cpumask *cpumask_of_bp(struct perf_event *bp)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (bp->cpu >= 0)
 		return cpumask_of(bp->cpu);
 	return cpu_possible_mask;
@@ -145,6 +152,7 @@ static void
 fetch_bp_busy_slots(struct bp_busy_slots *slots, struct perf_event *bp,
 		    enum bp_type_idx type)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	const struct cpumask *cpumask = cpumask_of_bp(bp);
 	int cpu;
 
@@ -175,6 +183,7 @@ fetch_bp_busy_slots(struct bp_busy_slots *slots, struct perf_event *bp,
 static void
 fetch_this_slot(struct bp_busy_slots *slots, int weight)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	slots->pinned += weight;
 }
 
@@ -184,6 +193,7 @@ fetch_this_slot(struct bp_busy_slots *slots, int weight)
 static void toggle_bp_task_slot(struct perf_event *bp, int cpu,
 				enum bp_type_idx type, int weight)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	unsigned int *tsk_pinned = get_bp_info(cpu, type)->tsk_pinned;
 	int old_idx, new_idx;
 
@@ -203,6 +213,7 @@ static void
 toggle_bp_slot(struct perf_event *bp, bool enable, enum bp_type_idx type,
 	       int weight)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	const struct cpumask *cpumask = cpumask_of_bp(bp);
 	int cpu;
 
@@ -285,7 +296,9 @@ static int __reserve_bp_slot(struct perf_event *bp)
 
 	/* We couldn't initialize breakpoint constraints on boot */
 	if (!constraints_initialized)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 
 	/* Basic checks */
 	if (bp->attr.bp_type == HW_BREAKPOINT_EMPTY ||
@@ -336,6 +349,7 @@ static void __release_bp_slot(struct perf_event *bp)
 
 void release_bp_slot(struct perf_event *bp)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	mutex_lock(&nr_bp_mutex);
 
 	arch_unregister_hw_breakpoint(bp);
@@ -351,6 +365,7 @@ void release_bp_slot(struct perf_event *bp)
  */
 int dbg_reserve_bp_slot(struct perf_event *bp)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (mutex_is_locked(&nr_bp_mutex))
 		return -1;
 
@@ -359,6 +374,7 @@ int dbg_reserve_bp_slot(struct perf_event *bp)
 
 int dbg_release_bp_slot(struct perf_event *bp)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (mutex_is_locked(&nr_bp_mutex))
 		return -1;
 
@@ -373,7 +389,9 @@ static int validate_hw_breakpoint(struct perf_event *bp)
 
 	ret = arch_validate_hwbkpt_settings(bp);
 	if (ret)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ret;
+}
 
 	if (arch_check_bp_in_kernelspace(bp)) {
 		if (bp->attr.exclude_kernel)
@@ -395,7 +413,9 @@ int register_perf_hw_breakpoint(struct perf_event *bp)
 
 	ret = reserve_bp_slot(bp);
 	if (ret)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ret;
+}
 
 	ret = validate_hw_breakpoint(bp);
 
@@ -418,6 +438,7 @@ register_user_hw_breakpoint(struct perf_event_attr *attr,
 			    void *context,
 			    struct task_struct *tsk)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return perf_event_create_kernel_counter(attr, -1, tsk, triggered,
 						context);
 }
@@ -483,7 +504,10 @@ EXPORT_SYMBOL_GPL(modify_user_hw_breakpoint);
 void unregister_hw_breakpoint(struct perf_event *bp)
 {
 	if (!bp)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	perf_event_release_kernel(bp);
 }
 EXPORT_SYMBOL_GPL(unregister_hw_breakpoint);
@@ -506,7 +530,9 @@ register_wide_hw_breakpoint(struct perf_event_attr *attr,
 
 	cpu_events = alloc_percpu(typeof(*cpu_events));
 	if (!cpu_events)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return (void __percpu __force *)ERR_PTR(-ENOMEM);
+}
 
 	get_online_cpus();
 	for_each_online_cpu(cpu) {
@@ -537,6 +563,7 @@ void unregister_wide_hw_breakpoint(struct perf_event * __percpu *cpu_events)
 {
 	int cpu;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for_each_possible_cpu(cpu)
 		unregister_hw_breakpoint(per_cpu(*cpu_events, cpu));
 
@@ -552,6 +579,7 @@ static struct notifier_block hw_breakpoint_exceptions_nb = {
 
 static void bp_perf_event_destroy(struct perf_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	release_bp_slot(event);
 }
 
@@ -560,18 +588,26 @@ static int hw_breakpoint_event_init(struct perf_event *bp)
 	int err;
 
 	if (bp->attr.type != PERF_TYPE_BREAKPOINT)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOENT;
+}
 
 	/*
 	 * no branch sampling for breakpoint events
 	 */
 	if (has_branch_stack(bp))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EOPNOTSUPP;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	err = register_perf_hw_breakpoint(bp);
 	if (err)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return err;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	bp->destroy = bp_perf_event_destroy;
 
 	return 0;
@@ -579,6 +615,7 @@ static int hw_breakpoint_event_init(struct perf_event *bp)
 
 static int hw_breakpoint_add(struct perf_event *bp, int flags)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!(flags & PERF_EF_START))
 		bp->hw.state = PERF_HES_STOPPED;
 
@@ -592,16 +629,19 @@ static int hw_breakpoint_add(struct perf_event *bp, int flags)
 
 static void hw_breakpoint_del(struct perf_event *bp, int flags)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	arch_uninstall_hw_breakpoint(bp);
 }
 
 static void hw_breakpoint_start(struct perf_event *bp, int flags)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	bp->hw.state = 0;
 }
 
 static void hw_breakpoint_stop(struct perf_event *bp, int flags)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	bp->hw.state = PERF_HES_STOPPED;
 }
 
@@ -643,12 +683,17 @@ int __init init_hw_breakpoint(void)
 
  err_alloc:
 	for_each_possible_cpu(err_cpu) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		for (i = 0; i < TYPE_MAX; i++)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			kfree(get_bp_info(err_cpu, i)->tsk_pinned);
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (err_cpu == cpu)
 			break;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return -ENOMEM;
 }
 
diff --git a/kernel/events/uprobes.c b/kernel/events/uprobes.c
index 267f6ef..fcad9d4 100644
--- a/kernel/events/uprobes.c
+++ b/kernel/events/uprobes.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * User-space Probes (UProbes)
  *
@@ -125,18 +127,22 @@ static bool valid_vma(struct vm_area_struct *vma, bool is_register)
 	vm_flags_t flags = VM_HUGETLB | VM_MAYEXEC | VM_MAYSHARE;
 
 	if (is_register)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		flags |= VM_WRITE;
+}
 
 	return vma->vm_file && (vma->vm_flags & flags) == VM_MAYEXEC;
 }
 
 static unsigned long offset_to_vaddr(struct vm_area_struct *vma, loff_t offset)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return vma->vm_start + offset - ((loff_t)vma->vm_pgoff << PAGE_SHIFT);
 }
 
 static loff_t vaddr_to_offset(struct vm_area_struct *vma, unsigned long vaddr)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return ((loff_t)vma->vm_pgoff << PAGE_SHIFT) + (vaddr - vma->vm_start);
 }
 
@@ -171,7 +177,9 @@ static int __replace_page(struct vm_area_struct *vma, unsigned long addr,
 	err = mem_cgroup_try_charge(new_page, vma->vm_mm, GFP_KERNEL, &memcg,
 			false);
 	if (err)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return err;
+}
 
 	/* For try_to_free_swap() and munlock_vma_page() below */
 	lock_page(old_page);
@@ -223,6 +231,7 @@ static int __replace_page(struct vm_area_struct *vma, unsigned long addr,
  */
 bool __weak is_swbp_insn(uprobe_opcode_t *insn)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return *insn == UPROBE_SWBP_INSN;
 }
 
@@ -237,11 +246,13 @@ bool __weak is_swbp_insn(uprobe_opcode_t *insn)
  */
 bool __weak is_trap_insn(uprobe_opcode_t *insn)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return is_swbp_insn(insn);
 }
 
 static void copy_from_page(struct page *page, unsigned long vaddr, void *dst, int len)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	void *kaddr = kmap_atomic(page);
 	memcpy(dst, kaddr + (vaddr & ~PAGE_MASK), len);
 	kunmap_atomic(kaddr);
@@ -249,6 +260,7 @@ static void copy_from_page(struct page *page, unsigned long vaddr, void *dst, in
 
 static void copy_to_page(struct page *page, unsigned long vaddr, const void *src, int len)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	void *kaddr = kmap_atomic(page);
 	memcpy(kaddr + (vaddr & ~PAGE_MASK), src, len);
 	kunmap_atomic(kaddr);
@@ -272,6 +284,7 @@ static int verify_opcode(struct page *page, unsigned long vaddr, uprobe_opcode_t
 	is_swbp = is_swbp_insn(&old_opcode);
 
 	if (is_swbp_insn(new_opcode)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (is_swbp)		/* register: already installed? */
 			return 0;
 	} else {
@@ -351,6 +364,7 @@ int uprobe_write_opcode(struct mm_struct *mm, unsigned long vaddr,
  */
 int __weak set_swbp(struct arch_uprobe *auprobe, struct mm_struct *mm, unsigned long vaddr)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return uprobe_write_opcode(mm, vaddr, UPROBE_SWBP_INSN);
 }
 
@@ -366,23 +380,27 @@ int __weak set_swbp(struct arch_uprobe *auprobe, struct mm_struct *mm, unsigned
 int __weak
 set_orig_insn(struct arch_uprobe *auprobe, struct mm_struct *mm, unsigned long vaddr)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return uprobe_write_opcode(mm, vaddr, *(uprobe_opcode_t *)&auprobe->insn);
 }
 
 static struct uprobe *get_uprobe(struct uprobe *uprobe)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	atomic_inc(&uprobe->ref);
 	return uprobe;
 }
 
 static void put_uprobe(struct uprobe *uprobe)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (atomic_dec_and_test(&uprobe->ref))
 		kfree(uprobe);
 }
 
 static int match_uprobe(struct uprobe *l, struct uprobe *r)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (l->inode < r->inode)
 		return -1;
 
@@ -405,6 +423,7 @@ static struct uprobe *__find_uprobe(struct inode *inode, loff_t offset)
 	struct uprobe *uprobe;
 	int match;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	while (n) {
 		uprobe = rb_entry(n, struct uprobe, rb_node);
 		match = match_uprobe(&u, uprobe);
@@ -441,6 +460,7 @@ static struct uprobe *__insert_uprobe(struct uprobe *uprobe)
 	struct uprobe *u;
 	int match;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	while (*p) {
 		parent = *p;
 		u = rb_entry(parent, struct uprobe, rb_node);
@@ -489,7 +509,9 @@ static struct uprobe *alloc_uprobe(struct inode *inode, loff_t offset)
 
 	uprobe = kzalloc(sizeof(struct uprobe), GFP_KERNEL);
 	if (!uprobe)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 
 	uprobe->inode = igrab(inode);
 	uprobe->offset = offset;
@@ -510,6 +532,7 @@ static struct uprobe *alloc_uprobe(struct inode *inode, loff_t offset)
 
 static void consumer_add(struct uprobe *uprobe, struct uprobe_consumer *uc)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	down_write(&uprobe->consumer_rwsem);
 	uc->next = uprobe->consumers;
 	uprobe->consumers = uc;
@@ -527,6 +550,7 @@ static bool consumer_del(struct uprobe *uprobe, struct uprobe_consumer *uc)
 	bool ret = false;
 
 	down_write(&uprobe->consumer_rwsem);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (con = &uprobe->consumers; *con; con = &(*con)->next) {
 		if (*con == uc) {
 			*con = uc->next;
@@ -549,7 +573,9 @@ static int __copy_insn(struct address_space *mapping, struct file *filp,
 	 * see uprobe_register().
 	 */
 	if (mapping->a_ops->readpage)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		page = read_mapping_page(mapping, offset >> PAGE_SHIFT, filp);
+}
 	else
 		page = shmem_read_mapping_page(mapping, offset >> PAGE_SHIFT);
 	if (IS_ERR(page))
@@ -571,6 +597,7 @@ static int copy_insn(struct uprobe *uprobe, struct file *filp)
 
 	/* Copy only available bytes, -EIO if nothing was read */
 	do {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (offs >= i_size_read(uprobe->inode))
 			break;
 
@@ -592,6 +619,7 @@ static int prepare_uprobe(struct uprobe *uprobe, struct file *file,
 {
 	int ret = 0;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (test_bit(UPROBE_COPY_INSN, &uprobe->flags))
 		return ret;
 
@@ -628,6 +656,7 @@ static int prepare_uprobe(struct uprobe *uprobe, struct file *file,
 static inline bool consumer_filter(struct uprobe_consumer *uc,
 				   enum uprobe_filter_ctx ctx, struct mm_struct *mm)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return !uc->filter || uc->filter(uc, ctx, mm);
 }
 
@@ -638,6 +667,7 @@ static bool filter_chain(struct uprobe *uprobe,
 	bool ret = false;
 
 	down_read(&uprobe->consumer_rwsem);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (uc = uprobe->consumers; uc; uc = uc->next) {
 		ret = consumer_filter(uc, ctx, mm);
 		if (ret)
@@ -657,7 +687,9 @@ install_breakpoint(struct uprobe *uprobe, struct mm_struct *mm,
 
 	ret = prepare_uprobe(uprobe, vma->vm_file, mm, vaddr);
 	if (ret)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ret;
+}
 
 	/*
 	 * set MMF_HAS_UPROBES in advance for uprobe_pre_sstep_notifier(),
@@ -679,12 +711,14 @@ install_breakpoint(struct uprobe *uprobe, struct mm_struct *mm,
 static int
 remove_breakpoint(struct uprobe *uprobe, struct mm_struct *mm, unsigned long vaddr)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	set_bit(MMF_RECALC_UPROBES, &mm->flags);
 	return set_orig_insn(&uprobe->arch, mm, vaddr);
 }
 
 static inline bool uprobe_is_active(struct uprobe *uprobe)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return !RB_EMPTY_NODE(&uprobe->rb_node);
 }
 /*
@@ -694,6 +728,7 @@ static inline bool uprobe_is_active(struct uprobe *uprobe)
  */
 static void delete_uprobe(struct uprobe *uprobe)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (WARN_ON(!uprobe_is_active(uprobe)))
 		return;
 
@@ -799,6 +834,7 @@ register_for_each_vma(struct uprobe *uprobe, struct uprobe_consumer *new)
 	info = build_map_info(uprobe->inode->i_mapping,
 					uprobe->offset, is_register);
 	if (IS_ERR(info)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		err = PTR_ERR(info);
 		goto out;
 	}
@@ -844,6 +880,7 @@ register_for_each_vma(struct uprobe *uprobe, struct uprobe_consumer *new)
 
 static int __uprobe_register(struct uprobe *uprobe, struct uprobe_consumer *uc)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	consumer_add(uprobe, uc);
 	return register_for_each_vma(uprobe, uc);
 }
@@ -852,6 +889,7 @@ static void __uprobe_unregister(struct uprobe *uprobe, struct uprobe_consumer *u
 {
 	int err;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (WARN_ON(!consumer_del(uprobe, uc)))
 		return;
 
@@ -933,6 +971,7 @@ int uprobe_apply(struct inode *inode, loff_t offset,
 	int ret = -ENOENT;
 
 	uprobe = find_uprobe(inode, offset);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (WARN_ON(!uprobe))
 		return ret;
 
@@ -958,6 +997,7 @@ void uprobe_unregister(struct inode *inode, loff_t offset, struct uprobe_consume
 	struct uprobe *uprobe;
 
 	uprobe = find_uprobe(inode, offset);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (WARN_ON(!uprobe))
 		return;
 
@@ -974,6 +1014,7 @@ static int unapply_uprobe(struct uprobe *uprobe, struct mm_struct *mm)
 	int err = 0;
 
 	down_read(&mm->mmap_sem);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (vma = mm->mmap; vma; vma = vma->vm_next) {
 		unsigned long vaddr;
 		loff_t offset;
@@ -1000,6 +1041,7 @@ find_node_in_range(struct inode *inode, loff_t min, loff_t max)
 {
 	struct rb_node *n = uprobes_tree.rb_node;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	while (n) {
 		struct uprobe *u = rb_entry(n, struct uprobe, rb_node);
 
@@ -1039,6 +1081,7 @@ static void build_probe_list(struct inode *inode,
 	spin_lock(&uprobes_treelock);
 	n = find_node_in_range(inode, min, max);
 	if (n) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		for (t = n; t; t = rb_prev(t)) {
 			u = rb_entry(t, struct uprobe, rb_node);
 			if (u->inode != inode || u->offset < min)
@@ -1070,12 +1113,18 @@ int uprobe_mmap(struct vm_area_struct *vma)
 	struct inode *inode;
 
 	if (no_uprobe_events() || !valid_vma(vma, true))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	inode = file_inode(vma->vm_file);
 	if (!inode)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	mutex_lock(uprobes_mmap_hash(inode));
 	build_probe_list(inode, vma, vma->vm_start, vma->vm_end, &tmp_list);
 	/*
@@ -1084,13 +1133,17 @@ int uprobe_mmap(struct vm_area_struct *vma)
 	 * consumers have gone away.
 	 */
 	list_for_each_entry_safe(uprobe, u, &tmp_list, pending_list) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (!fatal_signal_pending(current) &&
 		    filter_chain(uprobe, UPROBE_FILTER_MMAP, vma->vm_mm)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			unsigned long vaddr = offset_to_vaddr(vma, uprobe->offset);
 			install_breakpoint(uprobe, vma->vm_mm, vma, vaddr);
 		}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		put_uprobe(uprobe);
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	mutex_unlock(uprobes_mmap_hash(inode));
 
 	return 0;
@@ -1121,18 +1174,25 @@ vma_has_uprobes(struct vm_area_struct *vma, unsigned long start, unsigned long e
 void uprobe_munmap(struct vm_area_struct *vma, unsigned long start, unsigned long end)
 {
 	if (no_uprobe_events() || !valid_vma(vma, false))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!atomic_read(&vma->vm_mm->mm_users)) /* called by mmput() ? */
 		return;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!test_bit(MMF_HAS_UPROBES, &vma->vm_mm->flags) ||
 	     test_bit(MMF_RECALC_UPROBES, &vma->vm_mm->flags))
 		return;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (vma_has_uprobes(vma, start, end))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		set_bit(MMF_RECALC_UPROBES, &vma->vm_mm->flags);
 }
+}
 
 /* Slot allocation for XOL */
 static int xol_add_vma(struct mm_struct *mm, struct xol_area *area)
@@ -1141,7 +1201,9 @@ static int xol_add_vma(struct mm_struct *mm, struct xol_area *area)
 	int ret;
 
 	if (down_write_killable(&mm->mmap_sem))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINTR;
+}
 
 	if (mm->uprobes_state.xol_area) {
 		ret = -EALREADY;
@@ -1177,6 +1239,7 @@ static int xol_add_vma(struct mm_struct *mm, struct xol_area *area)
 
 static struct xol_area *__create_xol_area(unsigned long vaddr)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct mm_struct *mm = current->mm;
 	uprobe_opcode_t insn = UPROBE_SWBP_INSN;
 	struct xol_area *area;
@@ -1224,6 +1287,7 @@ static struct xol_area *__create_xol_area(unsigned long vaddr)
  */
 static struct xol_area *get_xol_area(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct mm_struct *mm = current->mm;
 	struct xol_area *area;
 
@@ -1243,8 +1307,11 @@ void uprobe_clear_state(struct mm_struct *mm)
 	struct xol_area *area = mm->uprobes_state.xol_area;
 
 	if (!area)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	put_page(area->pages[0]);
 	kfree(area->bitmap);
 	kfree(area);
@@ -1252,17 +1319,20 @@ void uprobe_clear_state(struct mm_struct *mm)
 
 void uprobe_start_dup_mmap(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	percpu_down_read(&dup_mmap_sem);
 }
 
 void uprobe_end_dup_mmap(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	percpu_up_read(&dup_mmap_sem);
 }
 
 void uprobe_dup_mmap(struct mm_struct *oldmm, struct mm_struct *newmm)
 {
 	if (test_bit(MMF_HAS_UPROBES, &oldmm->flags)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		set_bit(MMF_HAS_UPROBES, &newmm->flags);
 		/* unconditionally, dup_mmap() skips VM_DONTCOPY vmas */
 		set_bit(MMF_RECALC_UPROBES, &newmm->flags);
@@ -1278,6 +1348,7 @@ static unsigned long xol_take_insn_slot(struct xol_area *area)
 	int slot_nr;
 
 	do {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		slot_nr = find_first_zero_bit(area->bitmap, UINSNS_PER_PAGE);
 		if (slot_nr < UINSNS_PER_PAGE) {
 			if (!test_and_set_bit(slot_nr, area->bitmap))
@@ -1306,7 +1377,9 @@ static unsigned long xol_get_insn_slot(struct uprobe *uprobe)
 
 	area = get_xol_area();
 	if (!area)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	xol_vaddr = xol_take_insn_slot(area);
 	if (unlikely(!xol_vaddr))
@@ -1329,6 +1402,7 @@ static void xol_free_insn_slot(struct task_struct *tsk)
 	unsigned long vma_end;
 	unsigned long slot_addr;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!tsk->mm || !tsk->mm->uprobes_state.xol_area || !tsk->utask)
 		return;
 
@@ -1380,6 +1454,7 @@ void __weak arch_uprobe_copy_ixol(struct page *page, unsigned long vaddr,
  */
 unsigned long __weak uprobe_get_swbp_addr(struct pt_regs *regs)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return instruction_pointer(regs) - UPROBE_SWBP_INSN_SIZE;
 }
 
@@ -1388,7 +1463,9 @@ unsigned long uprobe_get_trap_addr(struct pt_regs *regs)
 	struct uprobe_task *utask = current->utask;
 
 	if (unlikely(utask && utask->active_uprobe))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return utask->vaddr;
+}
 
 	return instruction_pointer(regs);
 }
@@ -1411,15 +1488,23 @@ void uprobe_free_utask(struct task_struct *t)
 	struct return_instance *ri;
 
 	if (!utask)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (utask->active_uprobe)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		put_uprobe(utask->active_uprobe);
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	ri = utask->return_instances;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	while (ri)
 		ri = free_ret_instance(ri);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	xol_free_insn_slot(t);
 	kfree(utask);
 	t->utask = NULL;
@@ -1435,6 +1520,7 @@ void uprobe_free_utask(struct task_struct *t)
  */
 static struct uprobe_task *get_utask(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!current->utask)
 		current->utask = kzalloc(sizeof(struct uprobe_task), GFP_KERNEL);
 	return current->utask;
@@ -1447,7 +1533,9 @@ static int dup_utask(struct task_struct *t, struct uprobe_task *o_utask)
 
 	n_utask = kzalloc(sizeof(struct uprobe_task), GFP_KERNEL);
 	if (!n_utask)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 	t->utask = n_utask;
 
 	p = &n_utask->return_instances;
@@ -1470,12 +1558,14 @@ static int dup_utask(struct task_struct *t, struct uprobe_task *o_utask)
 
 static void uprobe_warn(struct task_struct *t, const char *msg)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pr_warn("uprobe: %s:%d failed to %s\n",
 			current->comm, current->pid, msg);
 }
 
 static void dup_xol_work(struct callback_head *work)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (current->flags & PF_EXITING)
 		return;
 
@@ -1496,22 +1586,36 @@ void uprobe_copy_process(struct task_struct *t, unsigned long flags)
 	t->utask = NULL;
 
 	if (!utask || !utask->return_instances)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (mm == t->mm && !(flags & CLONE_VFORK))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (dup_utask(t, utask))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return uprobe_warn(t, "dup ret instances");
+}
 
 	/* The task can fork() after dup_xol_work() fails */
 	area = mm->uprobes_state.xol_area;
 	if (!area)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return uprobe_warn(t, "dup xol area");
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (mm == t->mm)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	t->utask->dup_xol_addr = area->vaddr;
 	init_task_work(&t->utask->dup_xol_work, dup_xol_work);
 	task_work_add(t, &t->utask->dup_xol_work, true);
@@ -1529,6 +1633,7 @@ static unsigned long get_trampoline_vaddr(void)
 	unsigned long trampoline_vaddr = -1;
 
 	area = current->mm->uprobes_state.xol_area;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	smp_read_barrier_depends();
 	if (area)
 		trampoline_vaddr = area->vaddr;
@@ -1540,6 +1645,7 @@ static void cleanup_return_instances(struct uprobe_task *utask, bool chained,
 					struct pt_regs *regs)
 {
 	struct return_instance *ri = utask->return_instances;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	enum rp_check ctx = chained ? RP_CHECK_CHAIN_CALL : RP_CHECK_CALL;
 
 	while (ri && !arch_uretprobe_is_alive(ri, ctx, regs)) {
@@ -1557,7 +1663,9 @@ static void prepare_uretprobe(struct uprobe *uprobe, struct pt_regs *regs)
 	bool chained;
 
 	if (!get_xol_area())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	utask = get_utask();
 	if (!utask)
@@ -1625,7 +1733,9 @@ pre_ssout(struct uprobe *uprobe, struct pt_regs *regs, unsigned long bp_vaddr)
 
 	utask = get_utask();
 	if (!utask)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 
 	xol_vaddr = xol_get_insn_slot(uprobe);
 	if (!xol_vaddr)
@@ -1656,25 +1766,33 @@ pre_ssout(struct uprobe *uprobe, struct pt_regs *regs, unsigned long bp_vaddr)
  */
 bool uprobe_deny_signal(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct task_struct *t = current;
 	struct uprobe_task *utask = t->utask;
 
 	if (likely(!utask || !utask->active_uprobe))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return false;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WARN_ON_ONCE(utask->state != UTASK_SSTEP);
 
 	if (signal_pending(t)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		spin_lock_irq(&t->sighand->siglock);
 		clear_tsk_thread_flag(t, TIF_SIGPENDING);
 		spin_unlock_irq(&t->sighand->siglock);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (__fatal_signal_pending(t) || arch_uprobe_xol_was_trapped(t)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			utask->state = UTASK_SSTEP_TRAPPED;
 			set_tsk_thread_flag(t, TIF_UPROBE);
 		}
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return true;
 }
 
@@ -1682,6 +1800,7 @@ static void mmf_recalc_uprobes(struct mm_struct *mm)
 {
 	struct vm_area_struct *vma;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (vma = mm->mmap; vma; vma = vma->vm_next) {
 		if (!valid_vma(vma, false))
 			continue;
@@ -1705,6 +1824,7 @@ static int is_trap_at_addr(struct mm_struct *mm, unsigned long vaddr)
 	int result;
 
 	pagefault_disable();
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	result = __get_user(opcode, (uprobe_opcode_t __user *)vaddr);
 	pagefault_enable();
 
@@ -1731,6 +1851,7 @@ static int is_trap_at_addr(struct mm_struct *mm, unsigned long vaddr)
 
 static struct uprobe *find_active_uprobe(unsigned long bp_vaddr, int *is_swbp)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct mm_struct *mm = current->mm;
 	struct uprobe *uprobe = NULL;
 	struct vm_area_struct *vma;
@@ -1765,6 +1886,7 @@ static void handler_chain(struct uprobe *uprobe, struct pt_regs *regs)
 	bool need_prep = false; /* prepare return uprobe, when needed */
 
 	down_read(&uprobe->register_rwsem);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (uc = uprobe->consumers; uc; uc = uc->next) {
 		int rc = 0;
 
@@ -1797,6 +1919,7 @@ handle_uretprobe_chain(struct return_instance *ri, struct pt_regs *regs)
 	struct uprobe_consumer *uc;
 
 	down_read(&uprobe->register_rwsem);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (uc = uprobe->consumers; uc; uc = uc->next) {
 		if (uc->ret_handler)
 			uc->ret_handler(uc, ri->func, regs);
@@ -1809,6 +1932,7 @@ static struct return_instance *find_next_ret_chain(struct return_instance *ri)
 	bool chained;
 
 	do {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		chained = ri->chained;
 		ri = ri->next;	/* can't be NULL if chained */
 	} while (chained);
@@ -1826,6 +1950,7 @@ static void handle_trampoline(struct pt_regs *regs)
 	if (!utask)
 		goto sigill;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	ri = utask->return_instances;
 	if (!ri)
 		goto sigill;
@@ -1860,12 +1985,14 @@ static void handle_trampoline(struct pt_regs *regs)
 
 bool __weak arch_uprobe_ignore(struct arch_uprobe *aup, struct pt_regs *regs)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return false;
 }
 
 bool __weak arch_uretprobe_is_alive(struct return_instance *ret, enum rp_check ctx,
 					struct pt_regs *regs)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return true;
 }
 
@@ -1881,7 +2008,9 @@ static void handle_swbp(struct pt_regs *regs)
 
 	bp_vaddr = uprobe_get_swbp_addr(regs);
 	if (bp_vaddr == get_trampoline_vaddr())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return handle_trampoline(regs);
+}
 
 	uprobe = find_active_uprobe(bp_vaddr, &is_swbp);
 	if (!uprobe) {
@@ -1945,7 +2074,9 @@ static void handle_singlestep(struct uprobe_task *utask, struct pt_regs *regs)
 
 	uprobe = utask->active_uprobe;
 	if (utask->state == UTASK_SSTEP_ACK)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		err = arch_uprobe_post_xol(&uprobe->arch, regs);
+}
 	else if (utask->state == UTASK_SSTEP_TRAPPED)
 		arch_uprobe_abort_xol(&uprobe->arch, regs);
 	else
@@ -1984,6 +2115,7 @@ void uprobe_notify_resume(struct pt_regs *regs)
 	clear_thread_flag(TIF_UPROBE);
 
 	utask = current->utask;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (utask && utask->active_uprobe)
 		handle_singlestep(utask, regs);
 	else
@@ -1996,6 +2128,7 @@ void uprobe_notify_resume(struct pt_regs *regs)
  */
 int uprobe_pre_sstep_notifier(struct pt_regs *regs)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!current->mm)
 		return 0;
 
@@ -2013,6 +2146,7 @@ int uprobe_pre_sstep_notifier(struct pt_regs *regs)
  */
 int uprobe_post_sstep_notifier(struct pt_regs *regs)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct uprobe_task *utask = current->utask;
 
 	if (!current->mm || !utask || !utask->active_uprobe)
@@ -2037,7 +2171,9 @@ static int __init init_uprobes(void)
 		mutex_init(&uprobes_mmap_mutex[i]);
 
 	if (percpu_init_rwsem(&dup_mmap_sem))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 
 	return register_die_notifier(&uprobe_exception_nb);
 }
diff --git a/kernel/exec_domain.c b/kernel/exec_domain.c
index 0975b02..324fef4 100644
--- a/kernel/exec_domain.c
+++ b/kernel/exec_domain.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 /*
  * Handling of different ABIs (personalities).
@@ -24,12 +26,14 @@
 #ifdef CONFIG_PROC_FS
 static int execdomains_proc_show(struct seq_file *m, void *v)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	seq_puts(m, "0-0\tLinux           \t[kernel]\n");
 	return 0;
 }
 
 static int execdomains_proc_open(struct inode *inode, struct file *file)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return single_open(file, execdomains_proc_show, NULL);
 }
 
@@ -49,7 +53,8 @@ module_init(proc_execdomains_init);
 #endif
 
 SYSCALL_DEFINE1(personality, unsigned int, personality)
-{
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	unsigned int old = current->personality;
 
 	if (personality != 0xffffffff)
diff --git a/kernel/exit.c b/kernel/exit.c
index e3a0876..13b9362 100644
--- a/kernel/exit.c
+++ b/kernel/exit.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  *  linux/kernel/exit.c
  *
@@ -214,9 +216,12 @@ void release_task(struct task_struct *p)
 		 */
 		zap_leader = do_notify_parent(leader, leader->exit_signal);
 		if (zap_leader)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			leader->exit_state = EXIT_DEAD;
+}
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	write_unlock_irq(&tasklist_lock);
 	release_thread(p);
 	call_rcu(&p->rcu, delayed_put_task_struct);
@@ -315,6 +320,7 @@ void rcuwait_wake_up(struct rcuwait *w)
 	task = rcu_dereference(w->task);
 	if (task)
 		wake_up_process(task);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rcu_read_unlock();
 }
 
@@ -340,8 +346,10 @@ static int will_become_orphaned_pgrp(struct pid *pgrp,
 		if (task_pgrp(p->real_parent) != pgrp &&
 		    task_session(p->real_parent) == task_session(p))
 			return 0;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	} while_each_pid_task(pgrp, PIDTYPE_PGID, p);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 1;
 }
 
@@ -362,9 +370,13 @@ static bool has_stopped_jobs(struct pid *pgrp)
 
 	do_each_pid_task(pgrp, PIDTYPE_PGID, p) {
 		if (p->signal->flags & SIGNAL_STOP_STOPPED)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return true;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	} while_each_pid_task(pgrp, PIDTYPE_PGID, p);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return false;
 }
 
@@ -376,6 +388,7 @@ static bool has_stopped_jobs(struct pid *pgrp)
 static void
 kill_orphaned_pgrp(struct task_struct *tsk, struct task_struct *parent)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct pid *pgrp = task_pgrp(tsk);
 	struct task_struct *ignored_task = tsk;
 
@@ -394,6 +407,7 @@ kill_orphaned_pgrp(struct task_struct *tsk, struct task_struct *parent)
 	    task_session(parent) == task_session(tsk) &&
 	    will_become_orphaned_pgrp(pgrp, ignored_task) &&
 	    has_stopped_jobs(pgrp)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		__kill_pgrp_info(SIGHUP, SEND_SIG_PRIV, pgrp);
 		__kill_pgrp_info(SIGCONT, SEND_SIG_PRIV, pgrp);
 	}
@@ -498,7 +512,9 @@ static void exit_mm(void)
 
 	mm_release(current, mm);
 	if (!mm)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 	sync_mm_rss(mm);
 	/*
 	 * Serialize with any possible pending coredump.
@@ -515,21 +531,29 @@ static void exit_mm(void)
 		up_read(&mm->mmap_sem);
 
 		self.task = current;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		self.next = xchg(&core_state->dumper.next, &self);
 		/*
 		 * Implies mb(), the result of xchg() must be visible
 		 * to core_state->dumper.
 		 */
 		if (atomic_dec_and_test(&core_state->nr_threads))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			complete(&core_state->startup);
+}
 
 		for (;;) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			set_current_state(TASK_UNINTERRUPTIBLE);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			if (!self.task) /* see coredump_finish() */
 				break;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			freezable_schedule();
 		}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		__set_current_state(TASK_RUNNING);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		down_read(&mm->mmap_sem);
 	}
 	mmgrab(mm);
@@ -543,8 +567,10 @@ static void exit_mm(void)
 	mm_update_next_owner(mm);
 	mmput(mm);
 	if (test_thread_flag(TIF_MEMDIE))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		exit_oom_victim();
 }
+}
 
 static struct task_struct *find_alive_thread(struct task_struct *p)
 {
@@ -552,8 +578,11 @@ static struct task_struct *find_alive_thread(struct task_struct *p)
 
 	for_each_thread(p, t) {
 		if (!(t->flags & PF_EXITING))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return t;
+}
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return NULL;
 }
 
@@ -565,7 +594,9 @@ static struct task_struct *find_child_reaper(struct task_struct *father)
 	struct task_struct *reaper = pid_ns->child_reaper;
 
 	if (likely(reaper != father))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return reaper;
+}
 
 	reaper = find_alive_thread(father);
 	if (reaper) {
@@ -573,6 +604,7 @@ static struct task_struct *find_child_reaper(struct task_struct *father)
 		return reaper;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	write_unlock_irq(&tasklist_lock);
 	if (unlikely(pid_ns == &init_pid_ns)) {
 		panic("Attempted to kill init! exitcode=0x%08x\n",
@@ -598,7 +630,9 @@ static struct task_struct *find_new_reaper(struct task_struct *father,
 
 	thread = find_alive_thread(father);
 	if (thread)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return thread;
+}
 
 	if (father->signal->has_child_subreaper) {
 		unsigned int ns_level = task_pid(father)->level;
@@ -619,10 +653,13 @@ static struct task_struct *find_new_reaper(struct task_struct *father,
 				continue;
 			thread = find_alive_thread(reaper);
 			if (thread)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				return thread;
+}
 		}
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return child_reaper;
 }
 
@@ -633,7 +670,9 @@ static void reparent_leader(struct task_struct *father, struct task_struct *p,
 				struct list_head *dead)
 {
 	if (unlikely(p->exit_state == EXIT_DEAD))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	/* We don't want people slaying init. */
 	p->exit_signal = SIGCHLD;
@@ -642,6 +681,7 @@ static void reparent_leader(struct task_struct *father, struct task_struct *p,
 	if (!p->ptrace &&
 	    p->exit_state == EXIT_ZOMBIE && thread_group_empty(p)) {
 		if (do_notify_parent(p, p->exit_signal)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			p->exit_state = EXIT_DEAD;
 			list_add(&p->ptrace_entry, dead);
 		}
@@ -664,12 +704,16 @@ static void forget_original_parent(struct task_struct *father,
 	struct task_struct *p, *t, *reaper;
 
 	if (unlikely(!list_empty(&father->ptraced)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		exit_ptrace(father, dead);
+}
 
 	/* Can drop and reacquire tasklist_lock */
 	reaper = find_child_reaper(father);
 	if (list_empty(&father->children))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	reaper = find_new_reaper(father, reaper);
 	list_for_each_entry(p, &father->children, sibling) {
@@ -679,8 +723,10 @@ static void forget_original_parent(struct task_struct *father,
 			if (likely(!t->ptrace))
 				t->parent = t->real_parent;
 			if (t->pdeath_signal)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				group_send_sig_info(t->pdeath_signal,
 						    SEND_SIG_NOINFO, t);
+}
 		}
 		/*
 		 * If this is a threaded reparent there is no need to
@@ -709,6 +755,7 @@ static void exit_notify(struct task_struct *tsk, int group_dead)
 		kill_orphaned_pgrp(tsk->group_leader, NULL);
 
 	if (unlikely(tsk->ptrace)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		int sig = thread_group_leader(tsk) &&
 				thread_group_empty(tsk) &&
 				!ptrace_reparented(tsk) ?
@@ -718,6 +765,7 @@ static void exit_notify(struct task_struct *tsk, int group_dead)
 		autoreap = thread_group_empty(tsk) &&
 			do_notify_parent(tsk, tsk->exit_signal);
 	} else {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		autoreap = true;
 	}
 
@@ -727,7 +775,10 @@ static void exit_notify(struct task_struct *tsk, int group_dead)
 
 	/* mt-exec, de_thread() is waiting for group leader */
 	if (unlikely(tsk->signal->notify_count < 0))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		wake_up_process(tsk->signal->group_exit_task);
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	write_unlock_irq(&tasklist_lock);
 
 	list_for_each_entry_safe(p, n, &dead, ptrace_entry) {
@@ -746,7 +797,9 @@ static void check_stack_usage(void)
 	free = stack_not_used(current);
 
 	if (free >= lowest_to_date)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	spin_lock(&low_water_lock);
 	if (free < lowest_to_date) {
@@ -762,6 +815,7 @@ static inline void check_stack_usage(void) {}
 
 void __noreturn do_exit(long code)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct task_struct *tsk = current;
 	int group_dead;
 
@@ -771,9 +825,13 @@ void __noreturn do_exit(long code)
 	WARN_ON(blk_needs_flush_plug(tsk));
 
 	if (unlikely(in_interrupt()))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		panic("Aiee, killing interrupt handler!");
+}
 	if (unlikely(!tsk->pid))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		panic("Attempted to kill the idle task!");
+}
 
 	/*
 	 * If do_exit is called because this processes oopsed, it's possible
@@ -793,6 +851,7 @@ void __noreturn do_exit(long code)
 	 * leave this task alone and wait for reboot.
 	 */
 	if (unlikely(tsk->flags & PF_EXITING)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_alert("Fixing recursive fault but reboot is needed!\n");
 		/*
 		 * We can do this unlocked here. The futex code uses
@@ -804,7 +863,9 @@ void __noreturn do_exit(long code)
 		 * task into the wait for ever nirwana as well.
 		 */
 		tsk->flags |= PF_EXITPIDONE;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		set_current_state(TASK_UNINTERRUPTIBLE);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		schedule();
 	}
 
@@ -822,6 +883,7 @@ void __noreturn do_exit(long code)
 	raw_spin_unlock_irq(&tsk->pi_lock);
 
 	if (unlikely(in_atomic())) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_info("note: %s[%d] exited with preempt_count %d\n",
 			current->comm, task_pid_nr(current),
 			preempt_count());
@@ -887,7 +949,9 @@ void __noreturn do_exit(long code)
 	mpol_put_task_policy(tsk);
 #ifdef CONFIG_FUTEX
 	if (unlikely(current->pi_state_cache))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		kfree(current->pi_state_cache);
+}
 #endif
 	/*
 	 * Make sure we are holding no locks:
@@ -914,7 +978,9 @@ void __noreturn do_exit(long code)
 	check_stack_usage();
 	preempt_disable();
 	if (tsk->nr_dirtied)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		__this_cpu_add(dirty_throttle_leaks, tsk->nr_dirtied);
+}
 	exit_rcu();
 	exit_tasks_rcu_finish();
 
@@ -925,6 +991,7 @@ EXPORT_SYMBOL_GPL(do_exit);
 
 void complete_and_exit(struct completion *comp, long code)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (comp)
 		complete(comp);
 
@@ -962,6 +1029,7 @@ do_group_exit(int exit_code)
 			sig->flags = SIGNAL_GROUP_EXIT;
 			zap_other_threads(current);
 		}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		spin_unlock_irq(&sighand->siglock);
 	}
 
@@ -1005,7 +1073,9 @@ static inline
 struct pid *task_pid_type(struct task_struct *task, enum pid_type type)
 {
 	if (type != PIDTYPE_PID)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		task = task->group_leader;
+}
 	return task->pids[type].pid;
 }
 
@@ -1019,14 +1089,18 @@ static int
 eligible_child(struct wait_opts *wo, bool ptrace, struct task_struct *p)
 {
 	if (!eligible_pid(wo, p))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	/*
 	 * Wait for all children (clone and not) if __WALL is set or
 	 * if it is traced by us.
 	 */
 	if (ptrace || (wo->wo_flags & __WALL))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 1;
+}
 
 	/*
 	 * Otherwise, wait for clone children *only* if __WCLONE is set;
@@ -1037,7 +1111,9 @@ eligible_child(struct wait_opts *wo, bool ptrace, struct task_struct *p)
 	 * we can only see if it is traced by us.
 	 */
 	if ((p->exit_signal != SIGCHLD) ^ !!(wo->wo_flags & __WCLONE))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	return 1;
 }
@@ -1056,15 +1132,21 @@ static int wait_task_zombie(struct wait_opts *wo, struct task_struct *p)
 	struct waitid_info *infop;
 
 	if (!likely(wo->wo_flags & WEXITED))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	if (unlikely(wo->wo_flags & WNOWAIT)) {
 		status = p->exit_code;
 		get_task_struct(p);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		read_unlock(&tasklist_lock);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		sched_annotate_sleep();
 		if (wo->wo_rusage)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			getrusage(p, RUSAGE_BOTH, wo->wo_rusage);
+}
 		put_task_struct(p);
 		goto out_info;
 	}
@@ -1074,11 +1156,14 @@ static int wait_task_zombie(struct wait_opts *wo, struct task_struct *p)
 	state = (ptrace_reparented(p) && thread_group_leader(p)) ?
 		EXIT_TRACE : EXIT_DEAD;
 	if (cmpxchg(&p->exit_state, EXIT_ZOMBIE, state) != EXIT_ZOMBIE)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 	/*
 	 * We own this thread, nobody else can reap it.
 	 */
 	read_unlock(&tasklist_lock);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	sched_annotate_sleep();
 
 	/*
@@ -1146,6 +1231,7 @@ static int wait_task_zombie(struct wait_opts *wo, struct task_struct *p)
 	wo->wo_stat = status;
 
 	if (state == EXIT_TRACE) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		write_lock_irq(&tasklist_lock);
 		/* We dropped tasklist, ptracer could die and untrace */
 		ptrace_unlink(p);
@@ -1153,7 +1239,10 @@ static int wait_task_zombie(struct wait_opts *wo, struct task_struct *p)
 		/* If parent wants a zombie, don't release it now */
 		state = EXIT_ZOMBIE;
 		if (do_notify_parent(p, p->exit_signal))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			state = EXIT_DEAD;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		p->exit_state = state;
 		write_unlock_irq(&tasklist_lock);
 	}
@@ -1174,6 +1263,7 @@ static int wait_task_zombie(struct wait_opts *wo, struct task_struct *p)
 		infop->uid = uid;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return pid;
 }
 
@@ -1186,6 +1276,7 @@ static int *task_stopped_code(struct task_struct *p, bool ptrace)
 		if (p->signal->flags & SIGNAL_STOP_STOPPED)
 			return &p->signal->group_exit_code;
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return NULL;
 }
 
@@ -1219,11 +1310,16 @@ static int wait_task_stopped(struct wait_opts *wo,
 	 * Traditionally we see ptrace'd stopped tasks regardless of options.
 	 */
 	if (!ptrace && !(wo->wo_flags & WUNTRACED))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	if (!task_stopped_code(p, ptrace))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	exit_code = 0;
 	spin_lock_irq(&p->sighand->siglock);
 
@@ -1242,7 +1338,9 @@ static int wait_task_stopped(struct wait_opts *wo,
 unlock_sig:
 	spin_unlock_irq(&p->sighand->siglock);
 	if (!exit_code)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	/*
 	 * Now we are pretty sure this task is interesting.
@@ -1255,9 +1353,12 @@ static int wait_task_stopped(struct wait_opts *wo,
 	pid = task_pid_vnr(p);
 	why = ptrace ? CLD_TRAPPED : CLD_STOPPED;
 	read_unlock(&tasklist_lock);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	sched_annotate_sleep();
 	if (wo->wo_rusage)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		getrusage(p, RUSAGE_BOTH, wo->wo_rusage);
+}
 	put_task_struct(p);
 
 	if (likely(!(wo->wo_flags & WNOWAIT)))
@@ -1270,6 +1371,7 @@ static int wait_task_stopped(struct wait_opts *wo,
 		infop->pid = pid;
 		infop->uid = uid;
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return pid;
 }
 
@@ -1286,14 +1388,19 @@ static int wait_task_continued(struct wait_opts *wo, struct task_struct *p)
 	uid_t uid;
 
 	if (!unlikely(wo->wo_flags & WCONTINUED))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	if (!(p->signal->flags & SIGNAL_STOP_CONTINUED))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	spin_lock_irq(&p->sighand->siglock);
 	/* Re-check with the lock held.  */
 	if (!(p->signal->flags & SIGNAL_STOP_CONTINUED)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		spin_unlock_irq(&p->sighand->siglock);
 		return 0;
 	}
@@ -1304,14 +1411,19 @@ static int wait_task_continued(struct wait_opts *wo, struct task_struct *p)
 
 	pid = task_pid_vnr(p);
 	get_task_struct(p);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	read_unlock(&tasklist_lock);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	sched_annotate_sleep();
 	if (wo->wo_rusage)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		getrusage(p, RUSAGE_BOTH, wo->wo_rusage);
+}
 	put_task_struct(p);
 
 	infop = wo->wo_info;
 	if (!infop) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		wo->wo_stat = 0xffff;
 	} else {
 		infop->cause = CLD_CONTINUED;
@@ -1319,6 +1431,7 @@ static int wait_task_continued(struct wait_opts *wo, struct task_struct *p)
 		infop->uid = uid;
 		infop->status = SIGCONT;
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return pid;
 }
 
@@ -1343,11 +1456,15 @@ static int wait_consider_task(struct wait_opts *wo, int ptrace,
 	int ret;
 
 	if (unlikely(exit_state == EXIT_DEAD))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	ret = eligible_child(wo, ptrace, p);
 	if (!ret)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ret;
+}
 
 	if (unlikely(exit_state == EXIT_TRACE)) {
 		/*
@@ -1355,7 +1472,10 @@ static int wait_consider_task(struct wait_opts *wo, int ptrace,
 		 * we should clear notask_error, debugger will notify us.
 		 */
 		if (likely(!ptrace))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			wo->notask_error = 0;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
 	}
 
@@ -1372,7 +1492,9 @@ static int wait_consider_task(struct wait_opts *wo, int ptrace,
 		 * the role of real parent.
 		 */
 		if (!ptrace_reparented(p))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			ptrace = 1;
+}
 	}
 
 	/* slay zombie? */
@@ -1424,7 +1546,9 @@ static int wait_consider_task(struct wait_opts *wo, int ptrace,
 	 */
 	ret = wait_task_stopped(wo, ptrace, p);
 	if (ret)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ret;
+}
 
 	/*
 	 * Wait for continued.  There's only one continued state and the
@@ -1451,9 +1575,12 @@ static int do_wait_thread(struct wait_opts *wo, struct task_struct *tsk)
 		int ret = wait_consider_task(wo, 0, p);
 
 		if (ret)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return ret;
+}
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
@@ -1465,9 +1592,12 @@ static int ptrace_do_wait(struct wait_opts *wo, struct task_struct *tsk)
 		int ret = wait_consider_task(wo, 1, p);
 
 		if (ret)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return ret;
+}
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
@@ -1479,10 +1609,14 @@ static int child_wait_callback(wait_queue_entry_t *wait, unsigned mode,
 	struct task_struct *p = key;
 
 	if (!eligible_pid(wo, p))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	if ((wo->wo_flags & __WNOTHREAD) && wait->private != p->parent)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	return default_wake_function(wait, mode, sync, key);
 }
@@ -1530,11 +1664,13 @@ static long do_wait(struct wait_opts *wo)
 		if (wo->wo_flags & __WNOTHREAD)
 			break;
 	} while_each_thread(current, tsk);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	read_unlock(&tasklist_lock);
 
 notask:
 	retval = wo->notask_error;
 	if (!retval && !(wo->wo_flags & WNOHANG)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		retval = -ERESTARTSYS;
 		if (!signal_pending(current)) {
 			schedule();
@@ -1559,7 +1695,9 @@ static long kernel_waitid(int which, pid_t upid, struct waitid_info *infop,
 			__WNOTHREAD|__WCLONE|__WALL))
 		return -EINVAL;
 	if (!(options & (WEXITED|WSTOPPED|WCONTINUED)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	switch (which) {
 	case P_ALL:
@@ -1568,12 +1706,16 @@ static long kernel_waitid(int which, pid_t upid, struct waitid_info *infop,
 	case P_PID:
 		type = PIDTYPE_PID;
 		if (upid <= 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -EINVAL;
+}
 		break;
 	case P_PGID:
 		type = PIDTYPE_PGID;
 		if (upid <= 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -EINVAL;
+}
 		break;
 	default:
 		return -EINVAL;
@@ -1602,16 +1744,23 @@ SYSCALL_DEFINE5(waitid, int, which, pid_t, upid, struct siginfo __user *,
 	int signo = 0;
 
 	if (err > 0) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		signo = SIGCHLD;
 		err = 0;
 		if (ru && copy_to_user(ru, &r, sizeof(struct rusage)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -EFAULT;
+}
 	}
 	if (!infop)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return err;
+}
 
 	if (!access_ok(VERIFY_WRITE, infop, sizeof(*infop)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EFAULT;
+}
 
 	user_access_begin();
 	unsafe_put_user(signo, &infop->si_signo, Efault);
@@ -1641,17 +1790,24 @@ long kernel_wait4(pid_t upid, int __user *stat_addr, int options,
 
 	/* -INT_MIN is not defined */
 	if (upid == INT_MIN)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ESRCH;
+}
 
 	if (upid == -1)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		type = PIDTYPE_MAX;
+}
 	else if (upid < 0) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		type = PIDTYPE_PGID;
 		pid = find_get_pid(-upid);
 	} else if (upid == 0) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		type = PIDTYPE_PGID;
 		pid = get_task_pid(current, PIDTYPE_PGID);
 	} else /* upid > 0 */ {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		type = PIDTYPE_PID;
 		pid = find_get_pid(upid);
 	}
@@ -1665,8 +1821,11 @@ long kernel_wait4(pid_t upid, int __user *stat_addr, int options,
 	ret = do_wait(&wo);
 	put_pid(pid);
 	if (ret > 0 && stat_addr && put_user(wo.wo_stat, stat_addr))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ret = -EFAULT;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return ret;
 }
 
@@ -1678,8 +1837,11 @@ SYSCALL_DEFINE4(wait4, pid_t, upid, int __user *, stat_addr,
 
 	if (err > 0) {
 		if (ru && copy_to_user(ru, &r, sizeof(struct rusage)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -EFAULT;
+}
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return err;
 }
 
@@ -1691,6 +1853,7 @@ SYSCALL_DEFINE4(wait4, pid_t, upid, int __user *, stat_addr,
  */
 SYSCALL_DEFINE3(waitpid, pid_t, pid, int __user *, stat_addr, int, options)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return sys_wait4(pid, stat_addr, options, NULL);
 }
 
@@ -1704,6 +1867,7 @@ COMPAT_SYSCALL_DEFINE4(wait4,
 	struct compat_rusage __user *, ru)
 {
 	struct rusage r;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	long err = kernel_wait4(pid, stat_addr, options, ru ? &r : NULL);
 	if (err > 0) {
 		if (ru && put_compat_rusage(&r, ru))
@@ -1719,6 +1883,7 @@ COMPAT_SYSCALL_DEFINE5(waitid,
 {
 	struct rusage ru;
 	struct waitid_info info = {.status = 0};
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	long err = kernel_waitid(which, pid, &info, options, uru ? &ru : NULL);
 	int signo = 0;
 	if (err > 0) {
diff --git a/kernel/extable.c b/kernel/extable.c
index 9aa1cc4..0896f71 100644
--- a/kernel/extable.c
+++ b/kernel/extable.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /* Rewritten by Rusty Russell, on the backs of many others...
    Copyright (C) 2001 Rusty Russell, 2002 Rusty Russell IBM.
 
@@ -45,6 +47,7 @@ u32 __initdata __visible main_extable_sort_needed = 1;
 void __init sort_main_extable(void)
 {
 	if (main_extable_sort_needed && __stop___ex_table > __start___ex_table) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_notice("Sorting __ex_table...\n");
 		sort_extable(__start___ex_table, __stop___ex_table);
 	}
@@ -58,12 +61,15 @@ const struct exception_table_entry *search_exception_tables(unsigned long addr)
 	e = search_extable(__start___ex_table,
 			   __stop___ex_table - __start___ex_table, addr);
 	if (!e)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		e = search_module_extables(addr);
+}
 	return e;
 }
 
 static inline int init_kernel_text(unsigned long addr)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (addr >= (unsigned long)_sinittext &&
 	    addr < (unsigned long)_einittext)
 		return 1;
@@ -76,9 +82,11 @@ int notrace core_kernel_text(unsigned long addr)
 	    addr < (unsigned long)_etext)
 		return 1;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (system_state < SYSTEM_RUNNING &&
 	    init_kernel_text(addr))
 		return 1;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
@@ -94,6 +102,7 @@ int notrace core_kernel_text(unsigned long addr)
  */
 int core_kernel_data(unsigned long addr)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (addr >= (unsigned long)_sdata &&
 	    addr < (unsigned long)_edata)
 		return 1;
@@ -102,6 +111,7 @@ int core_kernel_data(unsigned long addr)
 
 int __kernel_text_address(unsigned long addr)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (kernel_text_address(addr))
 		return 1;
 	/*
@@ -123,7 +133,9 @@ int kernel_text_address(unsigned long addr)
 	int ret = 1;
 
 	if (core_kernel_text(addr))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 1;
+}
 
 	/*
 	 * If a stack dump happens while RCU is not watching, then
@@ -139,21 +151,31 @@ int kernel_text_address(unsigned long addr)
 
 	/* Treat this like an NMI as it can happen anywhere */
 	if (no_rcu)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		rcu_nmi_enter();
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (is_module_text_address(addr))
 		goto out;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (is_ftrace_trampoline(addr))
 		goto out;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (is_kprobe_optinsn_slot(addr) || is_kprobe_insn_slot(addr))
 		goto out;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (is_bpf_text_address(addr))
 		goto out;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	ret = 0;
 out:
 	if (no_rcu)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		rcu_nmi_exit();
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return ret;
 }
 
@@ -169,6 +191,9 @@ int func_ptr_is_kernel_text(void *ptr)
 	unsigned long addr;
 	addr = (unsigned long) dereference_function_descriptor(ptr);
 	if (core_kernel_text(addr))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 1;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return is_module_text_address(addr);
 }
diff --git a/kernel/fork.c b/kernel/fork.c
index 98c91bd..c245e96 100644
--- a/kernel/fork.c
+++ b/kernel/fork.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  *  linux/kernel/fork.c
  *
@@ -184,6 +186,7 @@ static DEFINE_PER_CPU(struct vm_struct *, cached_stacks[NR_CACHED_STACKS]);
 
 static int free_vm_stack_cache(unsigned int cpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct vm_struct **cached_vm_stacks = per_cpu_ptr(cached_stacks, cpu);
 	int i;
 
@@ -236,6 +239,7 @@ static unsigned long *alloc_thread_stack_node(struct task_struct *tsk, int node)
 	 */
 	if (stack)
 		tsk->stack_vm_area = find_vm_area(stack);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return stack;
 #else
 	struct page *page = alloc_pages_node(node, THREADINFO_GFP,
@@ -256,6 +260,7 @@ static inline void free_thread_stack(struct task_struct *tsk)
 					NULL, tsk->stack_vm_area) != NULL)
 				continue;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return;
 		}
 
@@ -264,6 +269,7 @@ static inline void free_thread_stack(struct task_struct *tsk)
 	}
 #endif
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	__free_pages(virt_to_page(tsk->stack), THREAD_SIZE_ORDER);
 }
 # else
@@ -309,9 +315,11 @@ static struct kmem_cache *mm_cachep;
 
 static void account_kernel_stack(struct task_struct *tsk, int account)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	void *stack = task_stack_page(tsk);
 	struct vm_struct *vm = task_stack_vm_area(tsk);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	BUILD_BUG_ON(IS_ENABLED(CONFIG_VMAP_STACK) && PAGE_SIZE % 1024 != 0);
 
 	if (vm) {
@@ -346,7 +354,9 @@ static void account_kernel_stack(struct task_struct *tsk, int account)
 static void release_task_stack(struct task_struct *tsk)
 {
 	if (WARN_ON(tsk->state != TASK_DEAD))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;  /* Better to leak the stack than to free prematurely */
+}
 
 	account_kernel_stack(tsk, -1);
 	arch_release_thread_stack(tsk->stack);
@@ -399,7 +409,9 @@ static inline void free_signal_struct(struct signal_struct *sig)
 	 * pgd_dtor so postpone it to the async context
 	 */
 	if (sig->oom_mm)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		mmdrop_async(sig->oom_mm);
+}
 	kmem_cache_free(signal_cachep, sig);
 }
 
@@ -441,13 +453,17 @@ static void set_max_threads(unsigned int max_threads_suggested)
 	 * structures may only consume a small part of the available memory.
 	 */
 	if (fls64(totalram_pages) + fls64(PAGE_SIZE) > 64)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		threads = MAX_THREADS;
+}
 	else
 		threads = div64_u64((u64) totalram_pages * (u64) PAGE_SIZE,
 				    (u64) THREAD_SIZE * 8UL);
 
 	if (threads > max_threads_suggested)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		threads = max_threads_suggested;
+}
 
 	max_threads = clamp_t(u64, threads, MIN_THREADS, MAX_THREADS);
 }
@@ -497,6 +513,7 @@ void __init fork_init(void)
 int __weak arch_dup_task_struct(struct task_struct *dst,
 					       struct task_struct *src)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	*dst = *src;
 	return 0;
 }
@@ -520,12 +537,15 @@ static struct task_struct *dup_task_struct(struct task_struct *orig, int node)
 		node = tsk_fork_get_node(orig);
 	tsk = alloc_task_struct_node(node);
 	if (!tsk)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 
 	stack = alloc_thread_stack_node(tsk, node);
 	if (!stack)
 		goto free_tsk;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	stack_vm_area = task_stack_vm_area(tsk);
 
 	err = arch_dup_task_struct(tsk, orig);
@@ -556,6 +576,7 @@ static struct task_struct *dup_task_struct(struct task_struct *orig, int node)
 	tsk->seccomp.filter = NULL;
 #endif
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	setup_thread_stack(tsk, orig);
 	clear_user_return_notifier(tsk);
 	clear_tsk_need_resched(tsk);
@@ -606,9 +627,11 @@ static __latent_entropy int dup_mmap(struct mm_struct *mm,
 
 	uprobe_start_dup_mmap();
 	if (down_write_killable(&oldmm->mmap_sem)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		retval = -EINTR;
 		goto fail_uprobe_end;
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	flush_cache_dup_mm(oldmm);
 	uprobe_dup_mmap(oldmm, mm);
 	/*
@@ -634,20 +657,25 @@ static __latent_entropy int dup_mmap(struct mm_struct *mm,
 	if (retval)
 		goto out;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	prev = NULL;
 	for (mpnt = oldmm->mmap; mpnt; mpnt = mpnt->vm_next) {
 		struct file *file;
 
 		if (mpnt->vm_flags & VM_DONTCOPY) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			vm_stat_account(mm, mpnt->vm_flags, -vma_pages(mpnt));
 			continue;
 		}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		charge = 0;
 		if (mpnt->vm_flags & VM_ACCOUNT) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			unsigned long len = vma_pages(mpnt);
 
 			if (security_vm_enough_memory_mm(oldmm, len)) /* sic */
 				goto fail_nomem;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			charge = len;
 		}
 		tmp = kmem_cache_alloc(vm_area_cachep, GFP_KERNEL);
@@ -673,20 +701,25 @@ static __latent_entropy int dup_mmap(struct mm_struct *mm,
 		tmp->vm_next = tmp->vm_prev = NULL;
 		file = tmp->vm_file;
 		if (file) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			struct inode *inode = file_inode(file);
 			struct address_space *mapping = file->f_mapping;
 
 			get_file(file);
 			if (tmp->vm_flags & VM_DENYWRITE)
 				atomic_dec(&inode->i_writecount);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			i_mmap_lock_write(mapping);
 			if (tmp->vm_flags & VM_SHARED)
 				atomic_inc(&mapping->i_mmap_writable);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			flush_dcache_mmap_lock(mapping);
 			/* insert tmp into the share list, just after mpnt */
 			vma_interval_tree_insert_after(tmp, mpnt,
 					&mapping->i_mmap);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			flush_dcache_mmap_unlock(mapping);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			i_mmap_unlock_write(mapping);
 		}
 
@@ -696,7 +729,9 @@ static __latent_entropy int dup_mmap(struct mm_struct *mm,
 		 * are not guaranteed to succeed, even if read-only
 		 */
 		if (is_vm_hugetlb_page(tmp))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			reset_vma_resv_huge_pages(tmp);
+}
 
 		/*
 		 * Link in the new vma and copy the page table entries.
@@ -715,7 +750,9 @@ static __latent_entropy int dup_mmap(struct mm_struct *mm,
 			retval = copy_page_range(mm, oldmm, mpnt);
 
 		if (tmp->vm_ops && tmp->vm_ops->open)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			tmp->vm_ops->open(tmp);
+}
 
 		if (retval)
 			goto out;
@@ -744,7 +781,9 @@ static inline int mm_alloc_pgd(struct mm_struct *mm)
 {
 	mm->pgd = pgd_alloc(mm);
 	if (unlikely(!mm->pgd))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 	return 0;
 }
 
@@ -823,10 +862,13 @@ static struct mm_struct *mm_init(struct mm_struct *mm, struct task_struct *p,
 	mm->pinned_vm = 0;
 	memset(&mm->rss_stat, 0, sizeof(mm->rss_stat));
 	spin_lock_init(&mm->page_table_lock);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	mm_init_cpumask(mm);
 	mm_init_aio(mm);
 	mm_init_owner(mm, p);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	RCU_INIT_POINTER(mm->exe_file, NULL);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	mmu_notifier_mm_init(mm);
 	hmm_mm_init(mm);
 	init_tlb_flush_pending(mm);
@@ -867,16 +909,22 @@ static void check_mm(struct mm_struct *mm)
 		long x = atomic_long_read(&mm->rss_stat.count[i]);
 
 		if (unlikely(x))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			printk(KERN_ALERT "BUG: Bad rss-counter state "
 					  "mm:%p idx:%d val:%ld\n", mm, i, x);
+}
 	}
 
 	if (atomic_long_read(&mm->nr_ptes))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_alert("BUG: non-zero nr_ptes on freeing mm: %ld\n",
 				atomic_long_read(&mm->nr_ptes));
+}
 	if (mm_nr_pmds(mm))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_alert("BUG: non-zero nr_pmds on freeing mm: %ld\n",
 				mm_nr_pmds(mm));
+}
 
 #if defined(CONFIG_TRANSPARENT_HUGEPAGE) && !USE_SPLIT_PMD_PTLOCKS
 	VM_BUG_ON_MM(mm->pmd_huge_pte, mm);
@@ -892,8 +940,11 @@ struct mm_struct *mm_alloc(void)
 
 	mm = allocate_mm();
 	if (!mm)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	memset(mm, 0, sizeof(*mm));
 	return mm_init(mm, current, current_user_ns());
 }
@@ -918,6 +969,7 @@ EXPORT_SYMBOL_GPL(__mmdrop);
 
 static inline void __mmput(struct mm_struct *mm)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	VM_BUG_ON(atomic_read(&mm->mm_users));
 
 	uprobe_clear_state(mm);
@@ -928,6 +980,7 @@ static inline void __mmput(struct mm_struct *mm)
 	mm_put_huge_zero_page(mm);
 	set_mm_exe_file(mm, NULL);
 	if (!list_empty(&mm->mmlist)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		spin_lock(&mmlist_lock);
 		list_del(&mm->mmlist);
 		spin_unlock(&mmlist_lock);
@@ -952,6 +1005,7 @@ EXPORT_SYMBOL_GPL(mmput);
 #ifdef CONFIG_MMU
 static void mmput_async_fn(struct work_struct *work)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct mm_struct *mm = container_of(work, struct mm_struct,
 					    async_put_work);
 
@@ -960,6 +1014,7 @@ static void mmput_async_fn(struct work_struct *work)
 
 void mmput_async(struct mm_struct *mm)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (atomic_dec_and_test(&mm->mm_users)) {
 		INIT_WORK(&mm->async_put_work, mmput_async_fn);
 		schedule_work(&mm->async_put_work);
@@ -1009,7 +1064,10 @@ struct file *get_mm_exe_file(struct mm_struct *mm)
 	rcu_read_lock();
 	exe_file = rcu_dereference(mm->exe_file);
 	if (exe_file && !get_file_rcu(exe_file))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		exe_file = NULL;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rcu_read_unlock();
 	return exe_file;
 }
@@ -1033,6 +1091,7 @@ struct file *get_task_exe_file(struct task_struct *task)
 		if (!(task->flags & PF_KTHREAD))
 			exe_file = get_mm_exe_file(mm);
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	task_unlock(task);
 	return exe_file;
 }
@@ -1055,10 +1114,13 @@ struct mm_struct *get_task_mm(struct task_struct *task)
 	mm = task->mm;
 	if (mm) {
 		if (task->flags & PF_KTHREAD)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			mm = NULL;
+}
 		else
 			mmget(mm);
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	task_unlock(task);
 	return mm;
 }
@@ -1071,11 +1133,14 @@ struct mm_struct *mm_access(struct task_struct *task, unsigned int mode)
 
 	err =  mutex_lock_killable(&task->signal->cred_guard_mutex);
 	if (err)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ERR_PTR(err);
+}
 
 	mm = get_task_mm(task);
 	if (mm && mm != current->mm &&
 			!ptrace_may_access(task, mode)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		mmput(mm);
 		mm = ERR_PTR(-EACCES);
 	}
@@ -1094,6 +1159,7 @@ static void complete_vfork_done(struct task_struct *tsk)
 		tsk->vfork_done = NULL;
 		complete(vfork);
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	task_unlock(tsk);
 }
 
@@ -1107,6 +1173,7 @@ static int wait_for_vfork_done(struct task_struct *child,
 	freezer_count();
 
 	if (killed) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		task_lock(child);
 		child->vfork_done = NULL;
 		task_unlock(child);
@@ -1139,12 +1206,15 @@ void mm_release(struct task_struct *tsk, struct mm_struct *mm)
 	}
 #ifdef CONFIG_COMPAT
 	if (unlikely(tsk->compat_robust_list)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		compat_exit_robust_list(tsk);
 		tsk->compat_robust_list = NULL;
 	}
 #endif
 	if (unlikely(!list_empty(&tsk->pi_state_list)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		exit_pi_state_list(tsk);
+}
 #endif
 
 	uprobe_free_utask(tsk);
@@ -1192,6 +1262,7 @@ static struct mm_struct *dup_mm(struct task_struct *tsk)
 	if (!mm)
 		goto fail_nomem;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	memcpy(mm, oldmm, sizeof(*mm));
 
 	if (!mm_init(mm, tsk, mm->user_ns))
@@ -1207,6 +1278,7 @@ static struct mm_struct *dup_mm(struct task_struct *tsk)
 	if (mm->binfmt && !try_module_get(mm->binfmt->module))
 		goto free_pt;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return mm;
 
 free_pt:
@@ -1239,7 +1311,9 @@ static int copy_mm(unsigned long clone_flags, struct task_struct *tsk)
 	 */
 	oldmm = current->mm;
 	if (!oldmm)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	/* initialize the new vmacache entries */
 	vmacache_flush(tsk);
@@ -1250,6 +1324,7 @@ static int copy_mm(unsigned long clone_flags, struct task_struct *tsk)
 		goto good_mm;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	retval = -ENOMEM;
 	mm = dup_mm(tsk);
 	if (!mm)
@@ -1271,6 +1346,7 @@ static int copy_fs(unsigned long clone_flags, struct task_struct *tsk)
 		/* tsk->fs is already what we want */
 		spin_lock(&fs->lock);
 		if (fs->in_exec) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			spin_unlock(&fs->lock);
 			return -EAGAIN;
 		}
@@ -1280,7 +1356,9 @@ static int copy_fs(unsigned long clone_flags, struct task_struct *tsk)
 	}
 	tsk->fs = copy_fs_struct(fs);
 	if (!tsk->fs)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 	return 0;
 }
 
@@ -1318,18 +1396,25 @@ static int copy_io(unsigned long clone_flags, struct task_struct *tsk)
 	struct io_context *new_ioc;
 
 	if (!ioc)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 	/*
 	 * Share io context with parent, if CLONE_IO is set
 	 */
 	if (clone_flags & CLONE_IO) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ioc_task_link(ioc);
 		tsk->io_context = ioc;
 	} else if (ioprio_valid(ioc->ioprio)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		new_ioc = get_task_io_context(tsk, GFP_KERNEL, NUMA_NO_NODE);
 		if (unlikely(!new_ioc))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -ENOMEM;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		new_ioc->ioprio = ioc->ioprio;
 		put_io_context(new_ioc);
 	}
@@ -1348,8 +1433,11 @@ static int copy_sighand(unsigned long clone_flags, struct task_struct *tsk)
 	sig = kmem_cache_alloc(sighand_cachep, GFP_KERNEL);
 	rcu_assign_pointer(tsk->sighand, sig);
 	if (!sig)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	atomic_set(&sig->count, 1);
 	memcpy(sig->action, current->sighand->action, sizeof(sig->action));
 	return 0;
@@ -1375,8 +1463,10 @@ static void posix_cpu_timers_init_group(struct signal_struct *sig)
 {
 	unsigned long cpu_limit;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	cpu_limit = READ_ONCE(sig->rlim[RLIMIT_CPU].rlim_cur);
 	if (cpu_limit != RLIM_INFINITY) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		sig->cputime_expires.prof_exp = cpu_limit * NSEC_PER_SEC;
 		sig->cputimer.running = true;
 	}
diff --git a/kernel/freezer.c b/kernel/freezer.c
index 6f56a9e..1959a86 100644
--- a/kernel/freezer.c
+++ b/kernel/freezer.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * kernel/freezer.c - Function to freeze a process
  *
@@ -40,16 +42,24 @@ static DEFINE_SPINLOCK(freezer_lock);
 bool freezing_slow_path(struct task_struct *p)
 {
 	if (p->flags & (PF_NOFREEZE | PF_SUSPEND_TASK))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return false;
+}
 
 	if (test_tsk_thread_flag(p, TIF_MEMDIE))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return false;
+}
 
 	if (pm_nosig_freezing || cgroup_freezing(p))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return true;
+}
 
 	if (pm_freezing && !(p->flags & PF_KTHREAD))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return true;
+}
 
 	return false;
 }
@@ -63,6 +73,7 @@ bool __refrigerator(bool check_kthr_stop)
 	bool was_frozen = false;
 	long save = current->state;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pr_debug("%s entered refrigerator\n", current->comm);
 
 	for (;;) {
@@ -99,6 +110,7 @@ static void fake_signal_wake_up(struct task_struct *p)
 	unsigned long flags;
 
 	if (lock_task_sighand(p, &flags)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		signal_wake_up(p, 0);
 		unlock_task_sighand(p, &flags);
 	}
@@ -129,7 +141,9 @@ bool freeze_task(struct task_struct *p)
 	 * normally.
 	 */
 	if (freezer_should_skip(p))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return false;
+}
 
 	spin_lock_irqsave(&freezer_lock, flags);
 	if (!freezing(p) || frozen(p)) {
@@ -152,7 +166,10 @@ void __thaw_task(struct task_struct *p)
 
 	spin_lock_irqsave(&freezer_lock, flags);
 	if (frozen(p))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		wake_up_process(p);
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_unlock_irqrestore(&freezer_lock, flags);
 }
 
diff --git a/kernel/futex.c b/kernel/futex.c
index 046cd78..f2fbefd 100644
--- a/kernel/futex.c
+++ b/kernel/futex.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  *  Fast Userspace Mutexes (which I call "Futexes!").
  *  (C) Rusty Russell, IBM 2002
@@ -334,6 +336,7 @@ late_initcall(fail_futex_debugfs);
 #else
 static inline bool should_fail_futex(bool fshared)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return false;
 }
 #endif /* CONFIG_FAIL_FUTEX */
@@ -422,7 +425,9 @@ static inline int match_futex(union futex_key *key1, union futex_key *key2)
 static void get_futex_key_refs(union futex_key *key)
 {
 	if (!key->both.ptr)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	/*
 	 * On MMU less systems futexes are always "private" as there is no per
@@ -430,6 +435,7 @@ static void get_futex_key_refs(union futex_key *key)
 	 * arch/blackfin has MMU less SMP ...
 	 */
 	if (!IS_ENABLED(CONFIG_MMU)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		smp_mb(); /* explicit smp_mb(); (B) */
 		return;
 	}
@@ -465,8 +471,11 @@ static void drop_futex_key_refs(union futex_key *key)
 		return;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!IS_ENABLED(CONFIG_MMU))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	switch (key->both.offset & (FUT_OFF_INODE|FUT_OFF_MMSHARED)) {
 	case FUT_OFF_INODE:
@@ -510,14 +519,21 @@ get_futex_key(u32 __user *uaddr, int fshared, union futex_key *key, int rw)
 	 */
 	key->both.offset = address % PAGE_SIZE;
 	if (unlikely((address % sizeof(u32)) != 0))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 	address -= key->both.offset;
 
 	if (unlikely(!access_ok(rw, uaddr, sizeof(u32))))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EFAULT;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (unlikely(should_fail_futex(fshared)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EFAULT;
+}
 
 	/*
 	 * PROCESS_PRIVATE futexes are fast.
@@ -536,7 +552,9 @@ get_futex_key(u32 __user *uaddr, int fshared, union futex_key *key, int rw)
 again:
 	/* Ignore any VERIFY_READ mapping (futex common case) */
 	if (unlikely(should_fail_futex(fshared)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EFAULT;
+}
 
 	err = get_user_pages_fast(address, 1, 1, &page);
 	/*
@@ -544,11 +562,14 @@ get_futex_key(u32 __user *uaddr, int fshared, union futex_key *key, int rw)
 	 * and get read-only access.
 	 */
 	if (err == -EFAULT && rw == VERIFY_READ) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		err = get_user_pages_fast(address, 1, 0, &page);
 		ro = 1;
 	}
 	if (err < 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return err;
+}
 	else
 		err = 0;
 
@@ -598,6 +619,7 @@ get_futex_key(u32 __user *uaddr, int fshared, union futex_key *key, int rw)
 		 * will prevent unexpected transitions.
 		 */
 		lock_page(page);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		shmem_swizzled = PageSwapCache(page) || page->mapping;
 		unlock_page(page);
 		put_page(page);
@@ -605,6 +627,7 @@ get_futex_key(u32 __user *uaddr, int fshared, union futex_key *key, int rw)
 		if (shmem_swizzled)
 			goto again;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EFAULT;
 	}
 
@@ -624,6 +647,7 @@ get_futex_key(u32 __user *uaddr, int fshared, union futex_key *key, int rw)
 		 * sense for futex operations.
 		 */
 		if (unlikely(should_fail_futex(fshared)) || ro) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			err = -EFAULT;
 			goto out;
 		}
@@ -650,15 +674,19 @@ get_futex_key(u32 __user *uaddr, int fshared, union futex_key *key, int rw)
 		 */
 		rcu_read_lock();
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (READ_ONCE(page->mapping) != mapping) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			rcu_read_unlock();
 			put_page(page);
 
 			goto again;
 		}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		inode = READ_ONCE(mapping->host);
 		if (!inode) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			rcu_read_unlock();
 			put_page(page);
 
@@ -678,6 +706,7 @@ get_futex_key(u32 __user *uaddr, int fshared, union futex_key *key, int rw)
 		 * guarantee that get_futex_key() will still imply smp_mb(); (B).
 		 */
 		if (!atomic_inc_not_zero(&inode->i_count)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			rcu_read_unlock();
 			put_page(page);
 
@@ -686,6 +715,7 @@ get_futex_key(u32 __user *uaddr, int fshared, union futex_key *key, int rw)
 
 		/* Should be impossible but lets be paranoid for now */
 		if (WARN_ON_ONCE(inode->i_mapping != mapping)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			err = -EFAULT;
 			rcu_read_unlock();
 			iput(inode);
@@ -693,6 +723,7 @@ get_futex_key(u32 __user *uaddr, int fshared, union futex_key *key, int rw)
 			goto out;
 		}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		key->both.offset |= FUT_OFF_INODE; /* inode-based key */
 		key->shared.inode = inode;
 		key->shared.pgoff = basepage_index(tail);
@@ -723,6 +754,7 @@ static inline void put_futex_key(union futex_key *key)
  */
 static int fault_in_user_writeable(u32 __user *uaddr)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct mm_struct *mm = current->mm;
 	int ret;
 
@@ -746,6 +778,7 @@ static struct futex_q *futex_top_waiter(struct futex_hash_bucket *hb,
 {
 	struct futex_q *this;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	plist_for_each_entry(this, &hb->chain, list) {
 		if (match_futex(&this->key, key))
 			return this;
@@ -785,7 +818,9 @@ static int refill_pi_state_cache(void)
 	struct futex_pi_state *pi_state;
 
 	if (likely(current->pi_state_cache))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	pi_state = kzalloc(sizeof(*pi_state), GFP_KERNEL);
 
@@ -805,6 +840,7 @@ static int refill_pi_state_cache(void)
 
 static struct futex_pi_state *alloc_pi_state(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct futex_pi_state *pi_state = current->pi_state_cache;
 
 	WARN_ON(!pi_state);
@@ -815,6 +851,7 @@ static struct futex_pi_state *alloc_pi_state(void)
 
 static void get_pi_state(struct futex_pi_state *pi_state)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WARN_ON_ONCE(!atomic_inc_not_zero(&pi_state->refcount));
 }
 
@@ -825,10 +862,15 @@ static void get_pi_state(struct futex_pi_state *pi_state)
 static void put_pi_state(struct futex_pi_state *pi_state)
 {
 	if (!pi_state)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!atomic_dec_and_test(&pi_state->refcount))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	/*
 	 * If pi_state->owner is NULL, the owner is most probably dying
@@ -840,15 +882,19 @@ static void put_pi_state(struct futex_pi_state *pi_state)
 		raw_spin_lock_irq(&pi_state->pi_mutex.wait_lock);
 		owner = pi_state->owner;
 		if (owner) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			raw_spin_lock(&owner->pi_lock);
 			list_del_init(&pi_state->list);
 			raw_spin_unlock(&owner->pi_lock);
 		}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		rt_mutex_proxy_unlock(&pi_state->pi_mutex, owner);
 		raw_spin_unlock_irq(&pi_state->pi_mutex.wait_lock);
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (current->pi_state_cache) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		kfree(pi_state);
 	} else {
 		/*
@@ -873,7 +919,9 @@ static struct task_struct *futex_find_get_task(pid_t pid)
 	rcu_read_lock();
 	p = find_task_by_vpid(pid);
 	if (p)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		get_task_struct(p);
+}
 
 	rcu_read_unlock();
 
@@ -895,7 +943,9 @@ void exit_pi_state_list(struct task_struct *curr)
 	union futex_key key = FUTEX_KEY_INIT;
 
 	if (!futex_cmpxchg_enabled)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 	/*
 	 * We are a ZOMBIE and nobody can enqueue itself on
 	 * pi_state_list anymore, but we have to be careful
@@ -1060,7 +1110,9 @@ static int attach_to_pi_state(u32 __user *uaddr, u32 uval,
 	 * Userspace might have messed up non-PI and PI futexes [3]
 	 */
 	if (unlikely(!pi_state))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	/*
 	 * We get here with hb->lock held, and having found a
@@ -1182,7 +1234,9 @@ static int attach_to_pi_owner(u32 uval, union futex_key *key,
 	 * the new pi_state to it, but bail out when TID = 0 [1]
 	 */
 	if (!pid)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ESRCH;
+}
 	p = futex_find_get_task(pid);
 	if (!p)
 		return -ESRCH;
@@ -1249,6 +1303,7 @@ static int lookup_pi_state(u32 __user *uaddr, u32 uval,
 			   struct futex_hash_bucket *hb,
 			   union futex_key *key, struct futex_pi_state **ps)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct futex_q *top_waiter = futex_top_waiter(hb, key);
 
 	/*
@@ -1270,7 +1325,9 @@ static int lock_pi_update_atomic(u32 __user *uaddr, u32 uval, u32 newval)
 	u32 uninitialized_var(curval);
 
 	if (unlikely(should_fail_futex(true)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EFAULT;
+}
 
 	if (unlikely(cmpxchg_futex_value_locked(&curval, uaddr, uval, newval)))
 		return -EFAULT;
@@ -1311,7 +1368,9 @@ static int futex_lock_pi_atomic(u32 __user *uaddr, struct futex_hash_bucket *hb,
 	 * things before proceeding further.
 	 */
 	if (get_futex_value_locked(&uval, uaddr))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EFAULT;
+}
 
 	if (unlikely(should_fail_futex(true)))
 		return -EFAULT;
@@ -1403,7 +1462,9 @@ static void mark_wake_futex(struct wake_q_head *wake_q, struct futex_q *q)
 	struct task_struct *p = q->task;
 
 	if (WARN(q->pi_state || q->rt_waiter, "refusing to wake PI futex\n"))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	/*
 	 * Queue the task for later wakeup for after we've released
@@ -1433,6 +1494,7 @@ static int wake_futex_pi(u32 __user *uaddr, u32 uval, struct futex_pi_state *pi_
 	int ret = 0;
 
 	new_owner = rt_mutex_next_owner(&pi_state->pi_mutex);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (WARN_ON_ONCE(!new_owner)) {
 		/*
 		 * As per the comment in futex_unlock_pi() this should not happen.
@@ -1509,10 +1571,12 @@ static inline void
 double_lock_hb(struct futex_hash_bucket *hb1, struct futex_hash_bucket *hb2)
 {
 	if (hb1 <= hb2) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		spin_lock(&hb1->lock);
 		if (hb1 < hb2)
 			spin_lock_nested(&hb2->lock, SINGLE_DEPTH_NESTING);
 	} else { /* hb1 > hb2 */
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		spin_lock(&hb2->lock);
 		spin_lock_nested(&hb1->lock, SINGLE_DEPTH_NESTING);
 	}
@@ -1521,10 +1585,13 @@ double_lock_hb(struct futex_hash_bucket *hb1, struct futex_hash_bucket *hb2)
 static inline void
 double_unlock_hb(struct futex_hash_bucket *hb1, struct futex_hash_bucket *hb2)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_unlock(&hb1->lock);
 	if (hb1 != hb2)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		spin_unlock(&hb2->lock);
 }
+}
 
 /*
  * Wake up waiters matching bitset queued on this futex (uaddr).
@@ -1539,7 +1606,9 @@ futex_wake(u32 __user *uaddr, unsigned int flags, int nr_wake, u32 bitset)
 	DEFINE_WAKE_Q(wake_q);
 
 	if (!bitset)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	ret = get_futex_key(uaddr, flags & FLAGS_SHARED, &key, VERIFY_READ);
 	if (unlikely(ret != 0))
@@ -1551,11 +1620,13 @@ futex_wake(u32 __user *uaddr, unsigned int flags, int nr_wake, u32 bitset)
 	if (!hb_waiters_pending(hb))
 		goto out_put_key;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_lock(&hb->lock);
 
 	plist_for_each_entry_safe(this, next, &hb->chain, list) {
 		if (match_futex (&this->key, &key)) {
 			if (this->pi_state || this->rt_waiter) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				ret = -EINVAL;
 				break;
 			}
@@ -1570,6 +1641,7 @@ futex_wake(u32 __user *uaddr, unsigned int flags, int nr_wake, u32 bitset)
 		}
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_unlock(&hb->lock);
 	wake_up_q(&wake_q);
 out_put_key:
@@ -1587,6 +1659,7 @@ static int futex_atomic_op_inuser(unsigned int encoded_op, u32 __user *uaddr)
 	int oldval, ret;
 
 	if (encoded_op & (FUTEX_OP_OPARG_SHIFT << 28)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (oparg < 0 || oparg > 31) {
 			char comm[sizeof(current->comm)];
 			/*
@@ -1597,15 +1670,20 @@ static int futex_atomic_op_inuser(unsigned int encoded_op, u32 __user *uaddr)
 					get_task_comm(comm, current), oparg);
 			oparg &= 31;
 		}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		oparg = 1 << oparg;
 	}
 
 	if (!access_ok(VERIFY_WRITE, uaddr, sizeof(u32)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EFAULT;
+}
 
 	ret = arch_futex_atomic_op_inuser(op, oparg, &oldval, uaddr);
 	if (ret)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ret;
+}
 
 	switch (cmp) {
 	case FUTEX_OP_CMP_EQ:
@@ -1655,6 +1733,7 @@ futex_wake_op(u32 __user *uaddr1, unsigned int flags, u32 __user *uaddr2,
 	op_ret = futex_atomic_op_inuser(op, uaddr2);
 	if (unlikely(op_ret < 0)) {
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		double_unlock_hb(hb1, hb2);
 
 #ifndef CONFIG_MMU
@@ -1667,17 +1746,21 @@ futex_wake_op(u32 __user *uaddr1, unsigned int flags, u32 __user *uaddr2,
 #endif
 
 		if (unlikely(op_ret != -EFAULT)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			ret = op_ret;
 			goto out_put_keys;
 		}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ret = fault_in_user_writeable(uaddr2);
 		if (ret)
 			goto out_put_keys;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (!(flags & FLAGS_SHARED))
 			goto retry_private;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		put_futex_key(&key2);
 		put_futex_key(&key1);
 		goto retry;
@@ -1686,6 +1769,7 @@ futex_wake_op(u32 __user *uaddr1, unsigned int flags, u32 __user *uaddr2,
 	plist_for_each_entry_safe(this, next, &hb1->chain, list) {
 		if (match_futex (&this->key, &key1)) {
 			if (this->pi_state || this->rt_waiter) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				ret = -EINVAL;
 				goto out_unlock;
 			}
@@ -1696,13 +1780,17 @@ futex_wake_op(u32 __user *uaddr1, unsigned int flags, u32 __user *uaddr2,
 	}
 
 	if (op_ret > 0) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		op_ret = 0;
 		plist_for_each_entry_safe(this, next, &hb2->chain, list) {
 			if (match_futex (&this->key, &key2)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				if (this->pi_state || this->rt_waiter) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 					ret = -EINVAL;
 					goto out_unlock;
 				}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				mark_wake_futex(&wake_q, this);
 				if (++op_ret >= nr_wake2)
 					break;
@@ -1767,6 +1855,7 @@ static inline
 void requeue_pi_wake_futex(struct futex_q *q, union futex_key *key,
 			   struct futex_hash_bucket *hb)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	get_futex_key_refs(key);
 	q->key = *key;
 
@@ -1811,7 +1900,9 @@ static int futex_proxy_trylock_atomic(u32 __user *pifutex,
 	int ret, vpid;
 
 	if (get_futex_value_locked(&curval, pifutex))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EFAULT;
+}
 
 	if (unlikely(should_fail_futex(true)))
 		return -EFAULT;
@@ -1879,7 +1970,9 @@ static int futex_requeue(u32 __user *uaddr1, unsigned int flags,
 	DEFINE_WAKE_Q(wake_q);
 
 	if (nr_wake < 0 || nr_requeue < 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	/*
 	 * When PI not supported: return -ENOSYS if requeue_pi is true,
@@ -1888,7 +1981,9 @@ static int futex_requeue(u32 __user *uaddr1, unsigned int flags,
 	 * further down.
 	 */
 	if (!IS_ENABLED(CONFIG_FUTEX_PI) && requeue_pi)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOSYS;
+}
 
 	if (requeue_pi) {
 		/*
@@ -1896,14 +1991,18 @@ static int futex_requeue(u32 __user *uaddr1, unsigned int flags,
 		 * check is only valid for private futexes. See below.
 		 */
 		if (uaddr1 == uaddr2)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -EINVAL;
+}
 
 		/*
 		 * requeue_pi requires a pi_state, try to allocate it now
 		 * without any locks in case it fails.
 		 */
 		if (refill_pi_state_cache())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -ENOMEM;
+}
 		/*
 		 * requeue_pi must wake as many tasks as it can, up to nr_wake
 		 * + nr_requeue, since it acquires the rt_mutex prior to
@@ -1915,7 +2014,9 @@ static int futex_requeue(u32 __user *uaddr1, unsigned int flags,
 		 * use nr_wake=1.
 		 */
 		if (nr_wake != 1)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -EINVAL;
+}
 	}
 
 retry:
@@ -1932,6 +2033,7 @@ static int futex_requeue(u32 __user *uaddr1, unsigned int flags,
 	 * shared futexes. We need to compare the keys:
 	 */
 	if (requeue_pi && match_futex(&key1, &key2)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ret = -EINVAL;
 		goto out_put_keys;
 	}
@@ -1949,6 +2051,7 @@ static int futex_requeue(u32 __user *uaddr1, unsigned int flags,
 		ret = get_futex_value_locked(&curval, uaddr1);
 
 		if (unlikely(ret)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			double_unlock_hb(hb1, hb2);
 			hb_waiters_dec(hb2);
 
@@ -1956,14 +2059,17 @@ static int futex_requeue(u32 __user *uaddr1, unsigned int flags,
 			if (ret)
 				goto out_put_keys;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			if (!(flags & FLAGS_SHARED))
 				goto retry_private;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			put_futex_key(&key2);
 			put_futex_key(&key1);
 			goto retry;
 		}
 		if (curval != *cmpval) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			ret = -EAGAIN;
 			goto out_unlock;
 		}
@@ -1989,6 +2095,7 @@ static int futex_requeue(u32 __user *uaddr1, unsigned int flags,
 		 * refcount on it. In case of an error we have nothing.
 		 */
 		if (ret > 0) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			WARN_ON(pi_state);
 			drop_count++;
 			task_count++;
@@ -2007,6 +2114,7 @@ static int futex_requeue(u32 __user *uaddr1, unsigned int flags,
 			ret = lookup_pi_state(uaddr2, ret, hb2, &key2, &pi_state);
 		}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		switch (ret) {
 		case 0:
 			/* We hold a reference on the pi state. */
@@ -2057,6 +2165,7 @@ static int futex_requeue(u32 __user *uaddr1, unsigned int flags,
 		if ((requeue_pi && !this->rt_waiter) ||
 		    (!requeue_pi && this->rt_waiter) ||
 		    this->pi_state) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			ret = -EINVAL;
 			break;
 		}
@@ -2073,6 +2182,7 @@ static int futex_requeue(u32 __user *uaddr1, unsigned int flags,
 
 		/* Ensure we requeue to the expected futex for requeue_pi. */
 		if (requeue_pi && !match_futex(this->requeue_pi_key, &key2)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			ret = -EINVAL;
 			break;
 		}
@@ -2183,6 +2293,7 @@ static inline void
 queue_unlock(struct futex_hash_bucket *hb)
 	__releases(&hb->lock)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_unlock(&hb->lock);
 	hb_waiters_dec(hb);
 }
@@ -2250,6 +2361,7 @@ static int unqueue_me(struct futex_q *q)
 	 */
 	lock_ptr = READ_ONCE(q->lock_ptr);
 	if (lock_ptr != NULL) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		spin_lock(lock_ptr);
 		/*
 		 * q->lock_ptr can change between reading it and
@@ -2265,6 +2377,7 @@ static int unqueue_me(struct futex_q *q)
 		 * we can detect whether we acquired the correct lock.
 		 */
 		if (unlikely(lock_ptr != q->lock_ptr)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			spin_unlock(lock_ptr);
 			goto retry;
 		}
@@ -2272,6 +2385,7 @@ static int unqueue_me(struct futex_q *q)
 
 		BUG_ON(q->pi_state);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		spin_unlock(lock_ptr);
 		ret = 1;
 	}
@@ -2288,6 +2402,7 @@ static int unqueue_me(struct futex_q *q)
 static void unqueue_me_pi(struct futex_q *q)
 	__releases(q->lock_ptr)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	__unqueue_futex(q);
 
 	BUG_ON(!q->pi_state);
@@ -2306,6 +2421,7 @@ static int fixup_pi_state_owner(u32 __user *uaddr, struct futex_q *q,
 	u32 newtid;
 	int ret;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(q->lock_ptr);
 
 	raw_spin_lock_irq(&pi_state->pi_mutex.wait_lock);
@@ -2594,7 +2710,9 @@ static int futex_wait_setup(u32 __user *uaddr, u32 val, unsigned int flags,
 retry:
 	ret = get_futex_key(uaddr, flags & FLAGS_SHARED, &q->key, VERIFY_READ);
 	if (unlikely(ret != 0))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ret;
+}
 
 retry_private:
 	*hb = queue_lock(q);
@@ -2602,15 +2720,18 @@ static int futex_wait_setup(u32 __user *uaddr, u32 val, unsigned int flags,
 	ret = get_futex_value_locked(&uval, uaddr);
 
 	if (ret) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		queue_unlock(*hb);
 
 		ret = get_user(uval, uaddr);
 		if (ret)
 			goto out;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (!(flags & FLAGS_SHARED))
 			goto retry_private;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		put_futex_key(&q->key);
 		goto retry;
 	}
@@ -2622,7 +2743,10 @@ static int futex_wait_setup(u32 __user *uaddr, u32 val, unsigned int flags,
 
 out:
 	if (ret)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		put_futex_key(&q->key);
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return ret;
 }
 
@@ -2636,10 +2760,13 @@ static int futex_wait(u32 __user *uaddr, unsigned int flags, u32 val,
 	int ret;
 
 	if (!bitset)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 	q.bitset = bitset;
 
 	if (abs_time) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		to = &timeout;
 
 		hrtimer_init_on_stack(&to->timer, (flags & FLAGS_CLOCKRT) ?
@@ -2667,6 +2794,7 @@ static int futex_wait(u32 __user *uaddr, unsigned int flags, u32 val,
 	/* unqueue_me() drops q.key ref */
 	if (!unqueue_me(&q))
 		goto out;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	ret = -ETIMEDOUT;
 	if (to && !to->task)
 		goto out;
@@ -2678,10 +2806,12 @@ static int futex_wait(u32 __user *uaddr, unsigned int flags, u32 val,
 	if (!signal_pending(current))
 		goto retry;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	ret = -ERESTARTSYS;
 	if (!abs_time)
 		goto out;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	restart = &current->restart_block;
 	restart->fn = futex_wait_restart;
 	restart->futex.uaddr = uaddr;
@@ -2697,6 +2827,7 @@ static int futex_wait(u32 __user *uaddr, unsigned int flags, u32 val,
 		hrtimer_cancel(&to->timer);
 		destroy_hrtimer_on_stack(&to->timer);
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return ret;
 }
 
@@ -2707,6 +2838,7 @@ static long futex_wait_restart(struct restart_block *restart)
 	ktime_t t, *tp = NULL;
 
 	if (restart->futex.flags & FLAGS_HAS_TIMEOUT) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		t = restart->futex.time;
 		tp = &t;
 	}
@@ -2737,7 +2869,9 @@ static int futex_lock_pi(u32 __user *uaddr, unsigned int flags,
 	int res, ret;
 
 	if (!IS_ENABLED(CONFIG_FUTEX_PI))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOSYS;
+}
 
 	if (refill_pi_state_cache())
 		return -ENOMEM;
@@ -2919,7 +3053,9 @@ static int futex_unlock_pi(u32 __user *uaddr, unsigned int flags)
 	int ret;
 
 	if (!IS_ENABLED(CONFIG_FUTEX_PI))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOSYS;
+}
 
 retry:
 	if (get_user(uval, uaddr))
@@ -3062,6 +3198,7 @@ int handle_early_requeue_pi_wakeup(struct futex_hash_bucket *hb,
 	 * support a PI aware source futex for requeue.
 	 */
 	if (!match_futex(&q->key, key2)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		WARN_ON(q->lock_ptr && (&hb->lock != q->lock_ptr));
 		/*
 		 * We were woken prior to requeue by a timeout or a signal.
@@ -3133,7 +3270,9 @@ static int futex_wait_requeue_pi(u32 __user *uaddr, unsigned int flags,
 	int res, ret;
 
 	if (!IS_ENABLED(CONFIG_FUTEX_PI))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOSYS;
+}
 
 	if (uaddr == uaddr2)
 		return -EINVAL;
@@ -3317,12 +3456,16 @@ SYSCALL_DEFINE2(set_robust_list, struct robust_list_head __user *, head,
 		size_t, len)
 {
 	if (!futex_cmpxchg_enabled)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOSYS;
+}
 	/*
 	 * The kernel knows only one size for now:
 	 */
 	if (unlikely(len != sizeof(*head)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	current->robust_list = head;
 
@@ -3344,7 +3487,9 @@ SYSCALL_DEFINE3(get_robust_list, int, pid,
 	struct task_struct *p;
 
 	if (!futex_cmpxchg_enabled)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOSYS;
+}
 
 	rcu_read_lock();
 
@@ -3384,7 +3529,9 @@ int handle_futex_death(u32 __user *uaddr, struct task_struct *curr, int pi)
 
 retry:
 	if (get_user(uval, uaddr))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -1;
+}
 
 	if ((uval & FUTEX_TID_MASK) == task_pid_vnr(curr)) {
 		/*
@@ -3435,7 +3582,9 @@ static inline int fetch_robust_entry(struct robust_list __user **entry,
 	unsigned long uentry;
 
 	if (get_user(uentry, (unsigned long __user *)head))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EFAULT;
+}
 
 	*entry = (void __user *)(uentry & ~1UL);
 	*pi = uentry & 1;
@@ -3459,25 +3608,33 @@ void exit_robust_list(struct task_struct *curr)
 	int rc;
 
 	if (!futex_cmpxchg_enabled)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	/*
 	 * Fetch the list head (which was registered earlier, via
 	 * sys_set_robust_list()):
 	 */
 	if (fetch_robust_entry(&entry, &head->list.next, &pi))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 	/*
 	 * Fetch the relative futex offset:
 	 */
 	if (get_user(futex_offset, &head->futex_offset))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 	/*
 	 * Fetch any possibly pending lock-add first, and handle it
 	 * if it exists:
 	 */
 	if (fetch_robust_entry(&pending, &head->list_op_pending, &pip))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	next_entry = NULL;	/* avoid warning with gcc */
 	while (entry != &head->list) {
@@ -3491,11 +3648,16 @@ void exit_robust_list(struct task_struct *curr)
 		 * don't process it twice:
 		 */
 		if (entry != pending)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			if (handle_futex_death((void __user *)entry + futex_offset,
 						curr, pi))
 				return;
+}
 		if (rc)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		entry = next_entry;
 		pi = next_pi;
 		/*
@@ -3504,13 +3666,16 @@ void exit_robust_list(struct task_struct *curr)
 		if (!--limit)
 			break;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		cond_resched();
 	}
 
 	if (pending)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		handle_futex_death((void __user *)pending + futex_offset,
 				   curr, pip);
 }
+}
 
 long do_futex(u32 __user *uaddr, int op, u32 val, ktime_t *timeout,
 		u32 __user *uaddr2, u32 val2, u32 val3)
@@ -3519,7 +3684,9 @@ long do_futex(u32 __user *uaddr, int op, u32 val, ktime_t *timeout,
 	unsigned int flags = 0;
 
 	if (!(op & FUTEX_PRIVATE_FLAG))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		flags |= FLAGS_SHARED;
+}
 
 	if (op & FUTEX_CLOCK_REALTIME) {
 		flags |= FLAGS_CLOCKRT;
@@ -3528,6 +3695,7 @@ long do_futex(u32 __user *uaddr, int op, u32 val, ktime_t *timeout,
 			return -ENOSYS;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	switch (cmd) {
 	case FUTEX_LOCK_PI:
 	case FUTEX_UNLOCK_PI:
@@ -3535,7 +3703,9 @@ long do_futex(u32 __user *uaddr, int op, u32 val, ktime_t *timeout,
 	case FUTEX_WAIT_REQUEUE_PI:
 	case FUTEX_CMP_REQUEUE_PI:
 		if (!futex_cmpxchg_enabled)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -ENOSYS;
+}
 	}
 
 	switch (cmd) {
@@ -3566,6 +3736,7 @@ long do_futex(u32 __user *uaddr, int op, u32 val, ktime_t *timeout,
 	case FUTEX_CMP_REQUEUE_PI:
 		return futex_requeue(uaddr, flags, uaddr2, val, val2, &val3, 1);
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return -ENOSYS;
 }
 
@@ -3583,15 +3754,22 @@ SYSCALL_DEFINE6(futex, u32 __user *, uaddr, int, op, u32, val,
 		      cmd == FUTEX_WAIT_BITSET ||
 		      cmd == FUTEX_WAIT_REQUEUE_PI)) {
 		if (unlikely(should_fail_futex(!(op & FUTEX_PRIVATE_FLAG))))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -EFAULT;
+}
 		if (copy_from_user(&ts, utime, sizeof(ts)) != 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -EFAULT;
+}
 		if (!timespec_valid(&ts))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -EINVAL;
+}
 
 		t = timespec_to_ktime(ts);
 		if (cmd == FUTEX_WAIT)
 			t = ktime_add_safe(ktime_get(), t);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		tp = &t;
 	}
 	/*
diff --git a/kernel/gcov/base.c b/kernel/gcov/base.c
index 9c7c8d5..403ba76 100644
--- a/kernel/gcov/base.c
+++ b/kernel/gcov/base.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 /*
  *  This code maintains a list of active profiling data structures.
diff --git a/kernel/gcov/fs.c b/kernel/gcov/fs.c
index 6e40ff6b..2ff10bd 100644
--- a/kernel/gcov/fs.c
+++ b/kernel/gcov/fs.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 /*
  *  This code exports profiling data as debugfs files to userspace.
diff --git a/kernel/gcov/gcc_4_7.c b/kernel/gcov/gcc_4_7.c
index ca5e5c0..9ace6bd 100644
--- a/kernel/gcov/gcc_4_7.c
+++ b/kernel/gcov/gcc_4_7.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 /*
  *  This code provides functions to handle gcc's profiling data format
diff --git a/kernel/groups.c b/kernel/groups.c
index daae2f2..415bd75 100644
--- a/kernel/groups.c
+++ b/kernel/groups.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 /*
  * Supplementary group IDs
@@ -20,10 +22,15 @@ struct group_info *groups_alloc(int gidsetsize)
 	len = sizeof(struct group_info) + sizeof(kgid_t) * gidsetsize;
 	gi = kmalloc(len, GFP_KERNEL_ACCOUNT|__GFP_NOWARN|__GFP_NORETRY);
 	if (!gi)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		gi = __vmalloc(len, GFP_KERNEL_ACCOUNT, PAGE_KERNEL);
+}
 	if (!gi)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	atomic_set(&gi->usage, 1);
 	gi->ngroups = gidsetsize;
 	return gi;
@@ -50,8 +57,11 @@ static int groups_to_user(gid_t __user *grouplist,
 		gid_t gid;
 		gid = from_kgid_munged(user_ns, group_info->gid[i]);
 		if (put_user(gid, grouplist+i))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -EFAULT;
+}
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
@@ -67,14 +77,19 @@ static int groups_from_user(struct group_info *group_info,
 		gid_t gid;
 		kgid_t kgid;
 		if (get_user(gid, grouplist+i))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -EFAULT;
+}
 
 		kgid = make_kgid(user_ns, gid);
 		if (!gid_valid(kgid))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -EINVAL;
+}
 
 		group_info->gid[i] = kgid;
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
@@ -99,8 +114,11 @@ int groups_search(const struct group_info *group_info, kgid_t grp)
 	unsigned int left, right;
 
 	if (!group_info)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	left = 0;
 	right = group_info->ngroups;
 	while (left < right) {
@@ -108,10 +126,13 @@ int groups_search(const struct group_info *group_info, kgid_t grp)
 		if (gid_gt(grp, group_info->gid[mid]))
 			left = mid + 1;
 		else if (gid_lt(grp, group_info->gid[mid]))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			right = mid;
+}
 		else
 			return 1;
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
@@ -142,7 +163,9 @@ int set_current_groups(struct group_info *group_info)
 
 	new = prepare_creds();
 	if (!new)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 
 	set_groups(new, group_info);
 	return commit_creds(new);
@@ -156,16 +179,20 @@ SYSCALL_DEFINE2(getgroups, int, gidsetsize, gid_t __user *, grouplist)
 	int i;
 
 	if (gidsetsize < 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	/* no need to grab task_lock here; it cannot change */
 	i = cred->group_info->ngroups;
 	if (gidsetsize) {
 		if (i > gidsetsize) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			i = -EINVAL;
 			goto out;
 		}
 		if (groups_to_user(grouplist, cred->group_info)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			i = -EFAULT;
 			goto out;
 		}
@@ -193,16 +220,24 @@ SYSCALL_DEFINE2(setgroups, int, gidsetsize, gid_t __user *, grouplist)
 	int retval;
 
 	if (!may_setgroups())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EPERM;
+}
 	if ((unsigned)gidsetsize > NGROUPS_MAX)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	group_info = groups_alloc(gidsetsize);
 	if (!group_info)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 	retval = groups_from_user(group_info, grouplist);
 	if (retval) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		put_group_info(group_info);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return retval;
 	}
 
diff --git a/kernel/hung_task.c b/kernel/hung_task.c
index 751593e..bed82b4 100644
--- a/kernel/hung_task.c
+++ b/kernel/hung_task.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * Detect Hung Task
  *
diff --git a/kernel/irq/chip.c b/kernel/irq/chip.c
index 5a2ef92c..48b4a15 100644
--- a/kernel/irq/chip.c
+++ b/kernel/irq/chip.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * linux/kernel/irq/chip.c
  *
@@ -23,6 +25,7 @@
 
 static irqreturn_t bad_chained_irq(int irq, void *dev_id)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WARN_ONCE(1, "Chained irq %d should not call an action\n", irq);
 	return IRQ_NONE;
 }
@@ -46,10 +49,14 @@ int irq_set_chip(unsigned int irq, struct irq_chip *chip)
 	struct irq_desc *desc = irq_get_desc_lock(irq, &flags, 0);
 
 	if (!desc)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	if (!chip)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		chip = &no_irq_chip;
+}
 
 	desc->irq_data.chip = chip;
 	irq_put_desc_unlock(desc, flags);
@@ -74,7 +81,9 @@ int irq_set_irq_type(unsigned int irq, unsigned int type)
 	int ret = 0;
 
 	if (!desc)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	ret = __irq_set_trigger(desc, type);
 	irq_put_desc_busunlock(desc, flags);
@@ -95,7 +104,9 @@ int irq_set_handler_data(unsigned int irq, void *data)
 	struct irq_desc *desc = irq_get_desc_lock(irq, &flags, 0);
 
 	if (!desc)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 	desc->irq_common_data.handler_data = data;
 	irq_put_desc_unlock(desc, flags);
 	return 0;
@@ -117,7 +128,9 @@ int irq_set_msi_desc_off(unsigned int irq_base, unsigned int irq_offset,
 	struct irq_desc *desc = irq_get_desc_lock(irq_base + irq_offset, &flags, IRQ_GET_DESC_CHECK_GLOBAL);
 
 	if (!desc)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 	desc->irq_common_data.msi_desc = entry;
 	if (entry && !irq_offset)
 		entry->irq = irq_base;
@@ -134,6 +147,7 @@ int irq_set_msi_desc_off(unsigned int irq_base, unsigned int irq_offset,
  */
 int irq_set_msi_desc(unsigned int irq, struct msi_desc *entry)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return irq_set_msi_desc_off(irq, 0, entry);
 }
 
@@ -150,7 +164,9 @@ int irq_set_chip_data(unsigned int irq, void *data)
 	struct irq_desc *desc = irq_get_desc_lock(irq, &flags, 0);
 
 	if (!desc)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 	desc->irq_data.chip_data = data;
 	irq_put_desc_unlock(desc, flags);
 	return 0;
@@ -167,21 +183,25 @@ EXPORT_SYMBOL_GPL(irq_get_irq_data);
 
 static void irq_state_clr_disabled(struct irq_desc *desc)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	irqd_clear(&desc->irq_data, IRQD_IRQ_DISABLED);
 }
 
 static void irq_state_clr_masked(struct irq_desc *desc)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	irqd_clear(&desc->irq_data, IRQD_IRQ_MASKED);
 }
 
 static void irq_state_clr_started(struct irq_desc *desc)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	irqd_clear(&desc->irq_data, IRQD_IRQ_STARTED);
 }
 
 static void irq_state_set_started(struct irq_desc *desc)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	irqd_set(&desc->irq_data, IRQD_IRQ_STARTED);
 }
 
@@ -195,11 +215,15 @@ enum {
 static int
 __irq_startup_managed(struct irq_desc *desc, struct cpumask *aff, bool force)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct irq_data *d = irq_desc_get_irq_data(desc);
 
 	if (!irqd_affinity_is_managed(d))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return IRQ_STARTUP_NORMAL;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	irqd_clr_managed_shutdown(d);
 
 	if (cpumask_any_and(aff, cpu_online_mask) >= nr_cpu_ids) {
@@ -211,7 +235,9 @@ __irq_startup_managed(struct irq_desc *desc, struct cpumask *aff, bool force)
 		 * and start it up as a normal interrupt.
 		 */
 		if (WARN_ON_ONCE(force))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return IRQ_STARTUP_NORMAL;
+}
 		/*
 		 * The interrupt was requested, but there is no online CPU
 		 * in it's affinity mask. Put it into managed shutdown
@@ -221,6 +247,7 @@ __irq_startup_managed(struct irq_desc *desc, struct cpumask *aff, bool force)
 		irqd_set_managed_shutdown(d);
 		return IRQ_STARTUP_ABORT;
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return IRQ_STARTUP_MANAGED;
 }
 #else
@@ -233,6 +260,7 @@ __irq_startup_managed(struct irq_desc *desc, struct cpumask *aff, bool force)
 
 static int __irq_startup(struct irq_desc *desc)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct irq_data *d = irq_desc_get_irq_data(desc);
 	int ret = 0;
 
@@ -250,6 +278,7 @@ static int __irq_startup(struct irq_desc *desc)
 
 int irq_startup(struct irq_desc *desc, bool resend, bool force)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct irq_data *d = irq_desc_get_irq_data(desc);
 	struct cpumask *aff = irq_data_get_affinity_mask(d);
 	int ret = 0;
@@ -257,6 +286,7 @@ int irq_startup(struct irq_desc *desc, bool resend, bool force)
 	desc->depth = 0;
 
 	if (irqd_is_started(d)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		irq_enable(desc);
 	} else {
 		switch (__irq_startup_managed(desc, aff, force)) {
@@ -275,6 +305,7 @@ int irq_startup(struct irq_desc *desc, bool resend, bool force)
 	if (resend)
 		check_irq_resend(desc);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return ret;
 }
 
@@ -285,6 +316,7 @@ void irq_shutdown(struct irq_desc *desc)
 	if (irqd_is_started(&desc->irq_data)) {
 		desc->depth = 1;
 		if (desc->irq_data.chip->irq_shutdown) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			desc->irq_data.chip->irq_shutdown(&desc->irq_data);
 			irq_state_set_disabled(desc);
 			irq_state_set_masked(desc);
@@ -305,10 +337,12 @@ void irq_shutdown(struct irq_desc *desc)
 void irq_enable(struct irq_desc *desc)
 {
 	if (!irqd_irq_disabled(&desc->irq_data)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		unmask_irq(desc);
 	} else {
 		irq_state_clr_disabled(desc);
 		if (desc->irq_data.chip->irq_enable) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			desc->irq_data.chip->irq_enable(&desc->irq_data);
 			irq_state_clr_masked(desc);
 		} else {
@@ -320,11 +354,15 @@ void irq_enable(struct irq_desc *desc)
 static void __irq_disable(struct irq_desc *desc, bool mask)
 {
 	if (irqd_irq_disabled(&desc->irq_data)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (mask)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			mask_irq(desc);
+}
 	} else {
 		irq_state_set_disabled(desc);
 		if (desc->irq_data.chip->irq_disable) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			desc->irq_data.chip->irq_disable(&desc->irq_data);
 			irq_state_set_masked(desc);
 		} else if (mask) {
@@ -355,11 +393,13 @@ static void __irq_disable(struct irq_desc *desc, bool mask)
  */
 void irq_disable(struct irq_desc *desc)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	__irq_disable(desc, irq_settings_disable_unlazy(desc));
 }
 
 void irq_percpu_enable(struct irq_desc *desc, unsigned int cpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (desc->irq_data.chip->irq_enable)
 		desc->irq_data.chip->irq_enable(&desc->irq_data);
 	else
@@ -369,6 +409,7 @@ void irq_percpu_enable(struct irq_desc *desc, unsigned int cpu)
 
 void irq_percpu_disable(struct irq_desc *desc, unsigned int cpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (desc->irq_data.chip->irq_disable)
 		desc->irq_data.chip->irq_disable(&desc->irq_data);
 	else
@@ -391,7 +432,9 @@ static inline void mask_ack_irq(struct irq_desc *desc)
 void mask_irq(struct irq_desc *desc)
 {
 	if (irqd_irq_masked(&desc->irq_data))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	if (desc->irq_data.chip->irq_mask) {
 		desc->irq_data.chip->irq_mask(&desc->irq_data);
@@ -402,7 +445,9 @@ void mask_irq(struct irq_desc *desc)
 void unmask_irq(struct irq_desc *desc)
 {
 	if (!irqd_irq_masked(&desc->irq_data))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	if (desc->irq_data.chip->irq_unmask) {
 		desc->irq_data.chip->irq_unmask(&desc->irq_data);
@@ -415,7 +460,9 @@ void unmask_threaded_irq(struct irq_desc *desc)
 	struct irq_chip *chip = desc->irq_data.chip;
 
 	if (chip->flags & IRQCHIP_EOI_THREADED)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		chip->irq_eoi(&desc->irq_data);
+}
 
 	unmask_irq(desc);
 }
@@ -430,6 +477,7 @@ void unmask_threaded_irq(struct irq_desc *desc)
  */
 void handle_nested_irq(unsigned int irq)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct irq_desc *desc = irq_to_desc(irq);
 	struct irqaction *action;
 	irqreturn_t action_ret;
@@ -467,6 +515,7 @@ EXPORT_SYMBOL_GPL(handle_nested_irq);
 
 static bool irq_check_poll(struct irq_desc *desc)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!(desc->istate & IRQS_POLL_INPROGRESS))
 		return false;
 	return irq_wait_for_poll(desc);
@@ -481,7 +530,9 @@ static bool irq_may_run(struct irq_desc *desc)
 	 * wakeup interrupt, proceed.
 	 */
 	if (!irqd_has_set(&desc->irq_data, mask))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return true;
+}
 
 	/*
 	 * If the interrupt is an armed wakeup source, mark it pending
@@ -489,7 +540,9 @@ static bool irq_may_run(struct irq_desc *desc)
 	 * event.
 	 */
 	if (irq_pm_check_wakeup(desc))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return false;
+}
 
 	/*
 	 * Handle a potential concurrent poll on a different core.
@@ -510,6 +563,7 @@ static bool irq_may_run(struct irq_desc *desc)
  */
 void handle_simple_irq(struct irq_desc *desc)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	raw_spin_lock(&desc->lock);
 
 	if (!irq_may_run(desc))
@@ -552,6 +606,7 @@ void handle_untracked_irq(struct irq_desc *desc)
 	if (!irq_may_run(desc))
 		goto out_unlock;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	desc->istate &= ~(IRQS_REPLAY | IRQS_WAITING);
 
 	if (unlikely(!desc->action || irqd_irq_disabled(&desc->irq_data))) {
@@ -615,10 +670,12 @@ void handle_level_irq(struct irq_desc *desc)
 	 * keep it masked and get out of here
 	 */
 	if (unlikely(!desc->action || irqd_irq_disabled(&desc->irq_data))) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		desc->istate |= IRQS_PENDING;
 		goto out_unlock;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	kstat_incr_irqs_this_cpu(desc);
 	handle_irq_event(desc);
 
diff --git a/kernel/irq/devres.c b/kernel/irq/devres.c
index 194c506..1903b4b 100644
--- a/kernel/irq/devres.c
+++ b/kernel/irq/devres.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 #include <linux/module.h>
 #include <linux/interrupt.h>
 #include <linux/device.h>
@@ -25,6 +27,7 @@ static int devm_irq_match(struct device *dev, void *res, void *data)
 {
 	struct irq_devres *this = res, *match = data;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return this->irq == match->irq && this->dev_id == match->dev_id;
 }
 
@@ -58,14 +61,19 @@ int devm_request_threaded_irq(struct device *dev, unsigned int irq,
 	dr = devres_alloc(devm_irq_release, sizeof(struct irq_devres),
 			  GFP_KERNEL);
 	if (!dr)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 
 	if (!devname)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		devname = dev_name(dev);
+}
 
 	rc = request_threaded_irq(irq, handler, thread_fn, irqflags, devname,
 				  dev_id);
 	if (rc) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		devres_free(dr);
 		return rc;
 	}
@@ -107,7 +115,9 @@ int devm_request_any_context_irq(struct device *dev, unsigned int irq,
 	dr = devres_alloc(devm_irq_release, sizeof(struct irq_devres),
 			  GFP_KERNEL);
 	if (!dr)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 
 	if (!devname)
 		devname = dev_name(dev);
@@ -141,6 +151,7 @@ void devm_free_irq(struct device *dev, unsigned int irq, void *dev_id)
 {
 	struct irq_devres match_data = { irq, dev_id };
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WARN_ON(devres_destroy(dev, devm_irq_release, devm_irq_match,
 			       &match_data));
 	free_irq(irq, dev_id);
@@ -185,7 +196,9 @@ int __devm_irq_alloc_descs(struct device *dev, int irq, unsigned int from,
 
 	dr = devres_alloc(devm_irq_desc_release, sizeof(*dr), GFP_KERNEL);
 	if (!dr)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 
 	base = __irq_alloc_descs(irq, from, cnt, node, owner, affinity);
 	if (base < 0) {
diff --git a/kernel/irq/handle.c b/kernel/irq/handle.c
index 79f987b..3abde27 100644
--- a/kernel/irq/handle.c
+++ b/kernel/irq/handle.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * linux/kernel/irq/handle.c
  *
@@ -28,6 +30,7 @@
  */
 void handle_bad_irq(struct irq_desc *desc)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	unsigned int irq = irq_desc_get_irq(desc);
 
 	print_irq_desc(irq, desc);
@@ -41,12 +44,14 @@ EXPORT_SYMBOL_GPL(handle_bad_irq);
  */
 irqreturn_t no_action(int cpl, void *dev_id)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return IRQ_NONE;
 }
 EXPORT_SYMBOL_GPL(no_action);
 
 static void warn_no_thread(unsigned int irq, struct irqaction *action)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (test_and_set_bit(IRQTF_WARNED, &action->thread_flags))
 		return;
 
@@ -158,10 +163,12 @@ irqreturn_t __handle_irq_event_percpu(struct irq_desc *desc, unsigned int *flags
 			 * did not set up a thread function
 			 */
 			if (unlikely(!action->thread_fn)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				warn_no_thread(irq, action);
 				break;
 			}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			__irq_wake_thread(desc, action);
 
 			/* Fall through to add to randomness */
diff --git a/kernel/irq/internals.h b/kernel/irq/internals.h
index 44ed5f8..d5951a7 100644
--- a/kernel/irq/internals.h
+++ b/kernel/irq/internals.h
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /* SPDX-License-Identifier: GPL-2.0 */
 /*
  * IRQ subsystem internal functions and variables:
diff --git a/kernel/irq/irqdesc.c b/kernel/irq/irqdesc.c
index 82afb7e..8fc62b5 100644
--- a/kernel/irq/irqdesc.c
+++ b/kernel/irq/irqdesc.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * Copyright (C) 1992, 1998-2006 Linus Torvalds, Ingo Molnar
  * Copyright (C) 2005-2006, Thomas Gleixner, Russell King
@@ -27,6 +29,7 @@ static struct lock_class_key irq_desc_lock_class;
 #if defined(CONFIG_SMP)
 static int __init irq_affinity_setup(char *str)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	zalloc_cpumask_var(&irq_default_affinity, GFP_NOWAIT);
 	cpulist_parse(str, irq_default_affinity);
 	/*
@@ -63,6 +66,7 @@ static int alloc_masks(struct irq_desc *desc, int node)
 #ifdef CONFIG_GENERIC_IRQ_EFFECTIVE_AFF_MASK
 	if (!zalloc_cpumask_var_node(&desc->irq_common_data.effective_affinity,
 				     GFP_KERNEL, node)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		free_cpumask_var(desc->irq_common_data.affinity);
 		return -ENOMEM;
 	}
@@ -84,7 +88,9 @@ static void desc_smp_init(struct irq_desc *desc, int node,
 			  const struct cpumask *affinity)
 {
 	if (!affinity)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		affinity = irq_default_affinity;
+}
 	cpumask_copy(desc->irq_common_data.affinity, affinity);
 
 #ifdef CONFIG_GENERIC_PENDING_IRQ
@@ -274,7 +280,9 @@ static void irq_sysfs_add(int irq, struct irq_desc *desc)
 		 * crucial.
 		 */
 		if (kobject_add(&desc->kobj, irq_kobj_base, "%d", irq))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			pr_warn("Failed to add kobject for irq %d\n", irq);
+}
 	}
 }
 
@@ -288,6 +296,7 @@ static int __init irq_sysfs_init(void)
 
 	irq_kobj_base = kobject_create_and_add("irq", kernel_kobj);
 	if (!irq_kobj_base) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		irq_unlock_sparse();
 		return -ENOMEM;
 	}
@@ -600,6 +609,7 @@ void irq_init_desc(unsigned int irq)
  */
 int generic_handle_irq(unsigned int irq)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct irq_desc *desc = irq_to_desc(irq);
 
 	if (!desc)
@@ -661,6 +671,7 @@ void irq_free_descs(unsigned int from, unsigned int cnt)
 {
 	int i;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (from >= nr_irqs || (from + cnt) > nr_irqs)
 		return;
 
@@ -693,11 +704,16 @@ __irq_alloc_descs(int irq, unsigned int from, unsigned int cnt, int node,
 	int start, ret;
 
 	if (!cnt)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	if (irq >= 0) {
 		if (from > irq)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -EINVAL;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		from = irq;
 	} else {
 		/*
@@ -717,6 +733,7 @@ __irq_alloc_descs(int irq, unsigned int from, unsigned int cnt, int node,
 		goto unlock;
 
 	if (start + cnt > nr_irqs) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ret = irq_expand_nr_irqs(start + cnt);
 		if (ret)
 			goto unlock;
@@ -811,6 +828,7 @@ __irq_get_desc_lock(unsigned int irq, unsigned long *flags, bool bus,
 			chip_bus_lock(desc);
 		raw_spin_lock_irqsave(&desc->lock, *flags);
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return desc;
 }
 
@@ -824,6 +842,7 @@ void __irq_put_desc_unlock(struct irq_desc *desc, unsigned long flags, bool bus)
 int irq_set_percpu_devid_partition(unsigned int irq,
 				   const struct cpumask *affinity)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct irq_desc *desc = irq_to_desc(irq);
 
 	if (!desc)
@@ -848,11 +867,13 @@ int irq_set_percpu_devid_partition(unsigned int irq,
 
 int irq_set_percpu_devid(unsigned int irq)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return irq_set_percpu_devid_partition(irq, NULL);
 }
 
 int irq_get_percpu_devid_partition(unsigned int irq, struct cpumask *affinity)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct irq_desc *desc = irq_to_desc(irq);
 
 	if (!desc || !desc->percpu_enabled)
@@ -866,6 +887,7 @@ int irq_get_percpu_devid_partition(unsigned int irq, struct cpumask *affinity)
 
 void kstat_incr_irq_this_cpu(unsigned int irq)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	kstat_incr_irqs_this_cpu(irq_to_desc(irq));
 }
 
@@ -880,6 +902,7 @@ void kstat_incr_irq_this_cpu(unsigned int irq)
  */
 unsigned int kstat_irqs_cpu(unsigned int irq, int cpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct irq_desc *desc = irq_to_desc(irq);
 
 	return desc && desc->kstat_irqs ?
@@ -901,9 +924,12 @@ unsigned int kstat_irqs(unsigned int irq)
 	unsigned int sum = 0;
 
 	if (!desc || !desc->kstat_irqs)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 	for_each_possible_cpu(cpu)
 		sum += *per_cpu_ptr(desc->kstat_irqs, cpu);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return sum;
 }
 
diff --git a/kernel/irq/irqdomain.c b/kernel/irq/irqdomain.c
index ac4644e..431c556 100644
--- a/kernel/irq/irqdomain.c
+++ b/kernel/irq/irqdomain.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 #define pr_fmt(fmt)  "irq: " fmt
 
 #include <linux/acpi.h>
@@ -166,12 +168,15 @@ struct irq_domain *__irq_domain_add(struct fwnode_handle *fwnode, int size,
 		};
 		acpi_handle handle;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		handle = acpi_device_handle(to_acpi_device_node(fwnode));
 		if (acpi_get_name(handle, ACPI_FULL_PATHNAME, &buf) == AE_OK) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			domain->name = buf.pointer;
 			domain->flags |= IRQ_DOMAIN_NAME_ALLOCATED;
 		}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		domain->fwnode = fwnode;
 #endif
 	} else if (of_node) {
@@ -184,10 +189,12 @@ struct irq_domain *__irq_domain_add(struct fwnode_handle *fwnode, int size,
 		 */
 		name = kstrdup(of_node_full_name(of_node), GFP_KERNEL);
 		if (!name) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			kfree(domain);
 			return NULL;
 		}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		strreplace(name, '/', ':');
 
 		domain->name = name;
@@ -196,17 +203,23 @@ struct irq_domain *__irq_domain_add(struct fwnode_handle *fwnode, int size,
 	}
 
 	if (!domain->name) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (fwnode)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			pr_err("Invalid fwnode type for irqdomain\n");
+}
 		domain->name = kasprintf(GFP_KERNEL, "unknown-%d",
 					 atomic_inc_return(&unknown_domains));
 		if (!domain->name) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			kfree(domain);
 			return NULL;
 		}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		domain->flags |= IRQ_DOMAIN_NAME_ALLOCATED;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	of_node_get(of_node);
 
 	/* Fill structure */
@@ -223,6 +236,7 @@ struct irq_domain *__irq_domain_add(struct fwnode_handle *fwnode, int size,
 	list_add(&domain->link, &irq_domain_list);
 	mutex_unlock(&irq_domain_mutex);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pr_debug("Added domain %s\n", domain->name);
 	return domain;
 }
@@ -238,6 +252,7 @@ EXPORT_SYMBOL_GPL(__irq_domain_add);
  */
 void irq_domain_remove(struct irq_domain *domain)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	mutex_lock(&irq_domain_mutex);
 	debugfs_remove_domain_dir(domain);
 
@@ -268,7 +283,9 @@ void irq_domain_update_bus_token(struct irq_domain *domain,
 	char *name;
 
 	if (domain->bus_token == bus_token)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	mutex_lock(&irq_domain_mutex);
 
@@ -276,10 +293,12 @@ void irq_domain_update_bus_token(struct irq_domain *domain,
 
 	name = kasprintf(GFP_KERNEL, "%s-%d", domain->name, bus_token);
 	if (!name) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		mutex_unlock(&irq_domain_mutex);
 		return;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	debugfs_remove_domain_dir(domain);
 
 	if (domain->flags & IRQ_DOMAIN_NAME_ALLOCATED)
@@ -321,7 +340,9 @@ struct irq_domain *irq_domain_add_simple(struct device_node *of_node,
 
 	domain = __irq_domain_add(of_node_to_fwnode(of_node), size, size, 0, ops, host_data);
 	if (!domain)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 
 	if (first_irq > 0) {
 		if (IS_ENABLED(CONFIG_SPARSE_IRQ)) {
@@ -366,7 +387,9 @@ struct irq_domain *irq_domain_add_legacy(struct device_node *of_node,
 	domain = __irq_domain_add(of_node_to_fwnode(of_node), first_hwirq + size,
 				  first_hwirq + size, 0, ops, host_data);
 	if (domain)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		irq_domain_associate_many(domain, first_irq, first_hwirq, size);
+}
 
 	return domain;
 }
@@ -394,6 +417,7 @@ struct irq_domain *irq_find_matching_fwspec(struct irq_fwspec *fwspec,
 	 * selected.
 	 */
 	mutex_lock(&irq_domain_mutex);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry(h, &irq_domain_list, link) {
 		if (h->ops->select && fwspec->param_count)
 			rc = h->ops->select(h, fwspec, bus_token);
@@ -427,6 +451,7 @@ bool irq_domain_check_msi_remap(void)
 	bool ret = true;
 
 	mutex_lock(&irq_domain_mutex);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry(h, &irq_domain_list, link) {
 		if (irq_domain_is_msi(h) &&
 		    !irq_domain_hierarchical_is_msi_remap(h)) {
@@ -450,6 +475,7 @@ EXPORT_SYMBOL_GPL(irq_domain_check_msi_remap);
  */
 void irq_set_default_host(struct irq_domain *domain)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pr_debug("Default domain set to @0x%p\n", domain);
 
 	irq_default_domain = domain;
@@ -459,6 +485,7 @@ EXPORT_SYMBOL_GPL(irq_set_default_host);
 static void irq_domain_clear_mapping(struct irq_domain *domain,
 				     irq_hw_number_t hwirq)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (hwirq < domain->revmap_size) {
 		domain->linear_revmap[hwirq] = 0;
 	} else {
@@ -483,6 +510,7 @@ static void irq_domain_set_mapping(struct irq_domain *domain,
 
 void irq_domain_disassociate(struct irq_domain *domain, unsigned int irq)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct irq_data *irq_data = irq_get_irq_data(irq);
 	irq_hw_number_t hwirq;
 
@@ -515,6 +543,7 @@ void irq_domain_disassociate(struct irq_domain *domain, unsigned int irq)
 int irq_domain_associate(struct irq_domain *domain, unsigned int virq,
 			 irq_hw_number_t hwirq)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct irq_data *irq_data = irq_get_irq_data(virq);
 	int ret;
 
@@ -569,6 +598,7 @@ void irq_domain_associate_many(struct irq_domain *domain, unsigned int irq_base,
 	int i;
 
 	of_node = irq_domain_get_of_node(domain);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pr_debug("%s(%s, irqbase=%i, hwbase=%i, count=%i)\n", __func__,
 		of_node_full_name(of_node), irq_base, (int)hwirq_base, count);
 
@@ -594,7 +624,9 @@ unsigned int irq_create_direct_mapping(struct irq_domain *domain)
 	unsigned int virq;
 
 	if (domain == NULL)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		domain = irq_default_domain;
+}
 
 	of_node = irq_domain_get_of_node(domain);
 	virq = irq_alloc_desc_from(1, of_node_to_nid(of_node));
@@ -635,6 +667,7 @@ unsigned int irq_create_mapping(struct irq_domain *domain,
 	struct device_node *of_node;
 	int virq;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pr_debug("irq_create_mapping(0x%p, 0x%lx)\n", domain, hwirq);
 
 	/* Look for default domain if nececssary */
@@ -702,7 +735,9 @@ int irq_create_strict_mappings(struct irq_domain *domain, unsigned int irq_base,
 	ret = irq_alloc_descs(irq_base, irq_base, count,
 			      of_node_to_nid(of_node));
 	if (unlikely(ret < 0))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ret;
+}
 
 	irq_domain_associate_many(domain, irq_base, hwirq_base, count);
 	return 0;
@@ -732,6 +767,7 @@ static void of_phandle_args_to_fwspec(struct of_phandle_args *irq_data,
 {
 	int i;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	fwspec->fwnode = irq_data->np ? &irq_data->np->fwnode : NULL;
 	fwspec->param_count = irq_data->args_count;
 
@@ -748,6 +784,7 @@ unsigned int irq_create_fwspec_mapping(struct irq_fwspec *fwspec)
 	int virq;
 
 	if (fwspec->fwnode) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		domain = irq_find_matching_fwspec(fwspec, DOMAIN_BUS_WIRED);
 		if (!domain)
 			domain = irq_find_matching_fwspec(fwspec, DOMAIN_BUS_ANY);
@@ -845,6 +882,7 @@ EXPORT_SYMBOL_GPL(irq_create_of_mapping);
  */
 void irq_dispose_mapping(unsigned int virq)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct irq_data *irq_data = irq_get_irq_data(virq);
 	struct irq_domain *domain;
 
@@ -876,20 +914,29 @@ unsigned int irq_find_mapping(struct irq_domain *domain,
 
 	/* Look for default domain if nececssary */
 	if (domain == NULL)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		domain = irq_default_domain;
+}
 	if (domain == NULL)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	if (hwirq < domain->revmap_direct_max_irq) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		data = irq_domain_get_irq_data(domain, hwirq);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (data && data->hwirq == hwirq)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return hwirq;
+}
 	}
 
 	/* Check if the hwirq is in the linear revmap. */
 	if (hwirq < domain->revmap_size)
 		return domain->linear_revmap[hwirq];
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rcu_read_lock();
 	data = radix_tree_lookup(&domain->revmap_tree, hwirq);
 	rcu_read_unlock();
@@ -1026,6 +1073,7 @@ int irq_domain_xlate_onecell(struct irq_domain *d, struct device_node *ctrlr,
 			     const u32 *intspec, unsigned int intsize,
 			     unsigned long *out_hwirq, unsigned int *out_type)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (WARN_ON(intsize < 1))
 		return -EINVAL;
 	*out_hwirq = intspec[0];
@@ -1045,6 +1093,7 @@ int irq_domain_xlate_twocell(struct irq_domain *d, struct device_node *ctrlr,
 			const u32 *intspec, unsigned int intsize,
 			irq_hw_number_t *out_hwirq, unsigned int *out_type)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (WARN_ON(intsize < 2))
 		return -EINVAL;
 	*out_hwirq = intspec[0];
@@ -1069,6 +1118,7 @@ int irq_domain_xlate_onetwocell(struct irq_domain *d,
 				const u32 *intspec, unsigned int intsize,
 				unsigned long *out_hwirq, unsigned int *out_type)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (WARN_ON(intsize < 1))
 		return -EINVAL;
 	*out_hwirq = intspec[0];
@@ -1100,6 +1150,7 @@ int irq_domain_alloc_descs(int virq, unsigned int cnt, irq_hw_number_t hwirq,
 		virq = __irq_alloc_descs(-1, hint, cnt, node, THIS_MODULE,
 					 affinity);
 		if (virq <= 0 && hint > 1) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			virq = __irq_alloc_descs(-1, 1, cnt, node, THIS_MODULE,
 						 affinity);
 		}
@@ -1134,7 +1185,9 @@ struct irq_domain *irq_domain_create_hierarchy(struct irq_domain *parent,
 	struct irq_domain *domain;
 
 	if (size)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		domain = irq_domain_create_linear(fwnode, size, ops, host_data);
+}
 	else
 		domain = irq_domain_create_tree(fwnode, ops, host_data);
 	if (domain) {
@@ -1158,7 +1211,9 @@ static void irq_domain_insert_irq(int virq)
 
 		/* If not already assigned, give the domain the chip's name */
 		if (!domain->name && data->chip)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			domain->name = data->chip->name;
+}
 	}
 
 	irq_clear_status_flags(virq, IRQ_NOREQUEST);
@@ -1173,6 +1228,7 @@ static void irq_domain_remove_irq(int virq)
 	synchronize_irq(virq);
 	smp_mb();
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (data = irq_get_irq_data(virq); data; data = data->parent_data) {
 		struct irq_domain *domain = data->domain;
 		irq_hw_number_t hwirq = data->hwirq;
@@ -1204,6 +1260,7 @@ static void irq_domain_free_irq_data(unsigned int virq, unsigned int nr_irqs)
 	struct irq_data *irq_data, *tmp;
 	int i;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (i = 0; i < nr_irqs; i++) {
 		irq_data = irq_get_irq_data(virq + i);
 		tmp = irq_data->parent_data;
@@ -1233,12 +1290,14 @@ static int irq_domain_alloc_irq_data(struct irq_domain *domain,
 		for (parent = domain->parent; parent; parent = parent->parent) {
 			irq_data = irq_domain_insert_irq_data(parent, irq_data);
 			if (!irq_data) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				irq_domain_free_irq_data(virq, i + 1);
 				return -ENOMEM;
 			}
 		}
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
@@ -1255,8 +1314,11 @@ struct irq_data *irq_domain_get_irq_data(struct irq_domain *domain,
 	for (irq_data = irq_get_irq_data(virq); irq_data;
 	     irq_data = irq_data->parent_data)
 		if (irq_data->domain == domain)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return irq_data;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return NULL;
 }
 EXPORT_SYMBOL_GPL(irq_domain_get_irq_data);
@@ -1276,7 +1338,9 @@ int irq_domain_set_hwirq_and_chip(struct irq_domain *domain, unsigned int virq,
 	struct irq_data *irq_data = irq_domain_get_irq_data(domain, virq);
 
 	if (!irq_data)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOENT;
+}
 
 	irq_data->hwirq = hwirq;
 	irq_data->chip = chip ? chip : &no_irq_chip;
@@ -1302,6 +1366,7 @@ void irq_domain_set_info(struct irq_domain *domain, unsigned int virq,
 			 void *chip_data, irq_flow_handler_t handler,
 			 void *handler_data, const char *handler_name)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	irq_domain_set_hwirq_and_chip(domain, virq, hwirq, chip, chip_data);
 	__irq_set_handler(virq, handler, 0, handler_name);
 	irq_set_handler_data(virq, handler_data);
@@ -1314,6 +1379,7 @@ EXPORT_SYMBOL(irq_domain_set_info);
  */
 void irq_domain_reset_irq_data(struct irq_data *irq_data)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	irq_data->hwirq = 0;
 	irq_data->chip = &no_irq_chip;
 	irq_data->chip_data = NULL;
@@ -1332,6 +1398,7 @@ void irq_domain_free_irqs_common(struct irq_domain *domain, unsigned int virq,
 	struct irq_data *irq_data;
 	int i;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (i = 0; i < nr_irqs; i++) {
 		irq_data = irq_domain_get_irq_data(domain, virq + i);
 		if (irq_data)
@@ -1352,6 +1419,7 @@ void irq_domain_free_irqs_top(struct irq_domain *domain, unsigned int virq,
 {
 	int i;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (i = 0; i < nr_irqs; i++) {
 		irq_set_handler_data(virq + i, NULL);
 		irq_set_handler(virq + i, NULL);
@@ -1363,6 +1431,7 @@ static void irq_domain_free_irqs_hierarchy(struct irq_domain *domain,
 					   unsigned int irq_base,
 					   unsigned int nr_irqs)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (domain->ops->free)
 		domain->ops->free(domain, irq_base, nr_irqs);
 }
@@ -1403,22 +1472,29 @@ int __irq_domain_alloc_irqs(struct irq_domain *domain, int irq_base,
 	int i, ret, virq;
 
 	if (domain == NULL) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		domain = irq_default_domain;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (WARN(!domain, "domain is NULL; cannot allocate IRQ\n"))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -EINVAL;
+}
 	}
 
 	if (!domain->ops->alloc) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_debug("domain->ops->alloc() is NULL\n");
 		return -ENOSYS;
 	}
 
 	if (realloc && irq_base >= 0) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		virq = irq_base;
 	} else {
 		virq = irq_domain_alloc_descs(irq_base, nr_irqs, 0, node,
 					      affinity);
 		if (virq < 0) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			pr_debug("cannot allocate IRQ(base %d, count %d)\n",
 				 irq_base, nr_irqs);
 			return virq;
@@ -1426,6 +1502,7 @@ int __irq_domain_alloc_irqs(struct irq_domain *domain, int irq_base,
 	}
 
 	if (irq_domain_alloc_irq_data(domain, virq, nr_irqs)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_debug("cannot allocate memory for IRQ%d\n", virq);
 		ret = -ENOMEM;
 		goto out_free_desc;
@@ -1434,6 +1511,7 @@ int __irq_domain_alloc_irqs(struct irq_domain *domain, int irq_base,
 	mutex_lock(&irq_domain_mutex);
 	ret = irq_domain_alloc_irqs_hierarchy(domain, virq, nr_irqs, arg);
 	if (ret < 0) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		mutex_unlock(&irq_domain_mutex);
 		goto out_free_irq_data;
 	}
@@ -1456,7 +1534,9 @@ static void irq_domain_fix_revmap(struct irq_data *d)
 	void __rcu **slot;
 
 	if (d->hwirq < d->domain->revmap_size)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return; /* Not using radix tree. */
+}
 
 	/* Fix up the revmap. */
 	mutex_lock(&revmap_trees_mutex);
@@ -1495,7 +1575,9 @@ int irq_domain_push_irq(struct irq_domain *domain, int virq, void *arg)
 	 */
 	desc = irq_to_desc(virq);
 	if (!desc)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 	if (WARN_ON(desc->action))
 		return -EBUSY;
 
@@ -1560,6 +1642,7 @@ EXPORT_SYMBOL_GPL(irq_domain_push_irq);
  */
 int irq_domain_pop_irq(struct irq_domain *domain, int virq)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct irq_data *root_irq_data = irq_get_irq_data(virq);
 	struct irq_data *child_irq_data;
 	struct irq_data *tmp_irq_data;
@@ -1626,6 +1709,7 @@ EXPORT_SYMBOL_GPL(irq_domain_pop_irq);
  */
 void irq_domain_free_irqs(unsigned int virq, unsigned int nr_irqs)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct irq_data *data = irq_get_irq_data(virq);
 	int i;
 
@@ -1657,7 +1741,9 @@ int irq_domain_alloc_irqs_parent(struct irq_domain *domain,
 				 void *arg)
 {
 	if (!domain->parent)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOSYS;
+}
 
 	return irq_domain_alloc_irqs_hierarchy(domain->parent, irq_base,
 					       nr_irqs, arg);
@@ -1675,6 +1761,7 @@ EXPORT_SYMBOL_GPL(irq_domain_alloc_irqs_parent);
 void irq_domain_free_irqs_parent(struct irq_domain *domain,
 				 unsigned int irq_base, unsigned int nr_irqs)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!domain->parent)
 		return;
 
@@ -1702,7 +1789,9 @@ static void __irq_domain_deactivate_irq(struct irq_data *irq_data)
 		if (domain->ops->deactivate)
 			domain->ops->deactivate(domain, irq_data);
 		if (irq_data->parent_data)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			__irq_domain_deactivate_irq(irq_data->parent_data);
+}
 	}
 }
 
@@ -1752,6 +1841,7 @@ static void irq_domain_check_hierarchy(struct irq_domain *domain)
  */
 bool irq_domain_hierarchical_is_msi_remap(struct irq_domain *domain)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (; domain; domain = domain->parent) {
 		if (irq_domain_is_msi_remap(domain))
 			return true;
diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index b02caa4..284c3d2 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * linux/kernel/irq/manage.c
  *
@@ -28,6 +30,7 @@ __read_mostly bool force_irqthreads;
 
 static int __init setup_forced_irqthreads(char *arg)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	force_irqthreads = true;
 	return 0;
 }
@@ -50,6 +53,7 @@ static void __synchronize_hardirq(struct irq_desc *desc)
 
 		/* Ok, that indicated we're done: double-check carefully. */
 		raw_spin_lock_irqsave(&desc->lock, flags);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		inprogress = irqd_irq_inprogress(&desc->irq_data);
 		raw_spin_unlock_irqrestore(&desc->lock, flags);
 
@@ -76,6 +80,7 @@ static void __synchronize_hardirq(struct irq_desc *desc)
  */
 bool synchronize_hardirq(unsigned int irq)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct irq_desc *desc = irq_to_desc(irq);
 
 	if (desc) {
@@ -122,6 +127,7 @@ static bool __irq_can_set_affinity(struct irq_desc *desc)
 	if (!desc || !irqd_can_balance(&desc->irq_data) ||
 	    !desc->irq_data.chip || !desc->irq_data.chip->irq_set_affinity)
 		return false;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return true;
 }
 
@@ -132,6 +138,7 @@ static bool __irq_can_set_affinity(struct irq_desc *desc)
  */
 int irq_can_set_affinity(unsigned int irq)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return __irq_can_set_affinity(irq_to_desc(irq));
 }
 
@@ -144,6 +151,7 @@ int irq_can_set_affinity(unsigned int irq)
  */
 bool irq_can_set_affinity_usr(unsigned int irq)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct irq_desc *desc = irq_to_desc(irq);
 
 	return __irq_can_set_affinity(desc) &&
@@ -165,8 +173,10 @@ void irq_set_thread_affinity(struct irq_desc *desc)
 
 	for_each_action_of_desc(desc, action)
 		if (action->thread)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			set_bit(IRQTF_AFFINITY, &action->thread_flags);
 }
+}
 
 static void irq_validate_effective_affinity(struct irq_data *data)
 {
@@ -175,7 +185,10 @@ static void irq_validate_effective_affinity(struct irq_data *data)
 	struct irq_chip *chip = irq_data_get_irq_chip(data);
 
 	if (!cpumask_empty(m))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pr_warn_once("irq_chip %s did not update eff. affinity mask of irq %u\n",
 		     chip->name, data->irq);
 #endif
@@ -184,12 +197,15 @@ static void irq_validate_effective_affinity(struct irq_data *data)
 int irq_do_set_affinity(struct irq_data *data, const struct cpumask *mask,
 			bool force)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct irq_desc *desc = irq_data_to_desc(data);
 	struct irq_chip *chip = irq_data_get_irq_chip(data);
 	int ret;
 
 	if (!chip || !chip->irq_set_affinity)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	ret = chip->irq_set_affinity(data, mask, force);
 	switch (ret) {
@@ -202,12 +218,14 @@ int irq_do_set_affinity(struct irq_data *data, const struct cpumask *mask,
 		ret = 0;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return ret;
 }
 
 int irq_set_affinity_locked(struct irq_data *data, const struct cpumask *mask,
 			    bool force)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct irq_chip *chip = irq_data_get_irq_chip(data);
 	struct irq_desc *desc = irq_data_to_desc(data);
 	int ret = 0;
@@ -233,6 +251,7 @@ int irq_set_affinity_locked(struct irq_data *data, const struct cpumask *mask,
 
 int __irq_set_affinity(unsigned int irq, const struct cpumask *mask, bool force)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct irq_desc *desc = irq_to_desc(irq);
 	unsigned long flags;
 	int ret;
@@ -252,7 +271,9 @@ int irq_set_affinity_hint(unsigned int irq, const struct cpumask *m)
 	struct irq_desc *desc = irq_get_desc_lock(irq, &flags, IRQ_GET_DESC_CHECK_GLOBAL);
 
 	if (!desc)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 	desc->affinity_hint = m;
 	irq_put_desc_unlock(desc, flags);
 	/* set the initial affinity to prevent every interrupt being on CPU0 */
@@ -301,6 +322,7 @@ static void irq_affinity_notify(struct work_struct *work)
 int
 irq_set_affinity_notifier(unsigned int irq, struct irq_affinity_notify *notify)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct irq_desc *desc = irq_to_desc(irq);
 	struct irq_affinity_notify *old_notify;
 	unsigned long flags;
@@ -343,7 +365,9 @@ int irq_setup_affinity(struct irq_desc *desc)
 
 	/* Excludes PER_CPU and NO_BALANCE interrupts */
 	if (!__irq_can_set_affinity(desc))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	raw_spin_lock(&mask_lock);
 	/*
@@ -352,6 +376,7 @@ int irq_setup_affinity(struct irq_desc *desc)
 	 */
 	if (irqd_affinity_is_managed(&desc->irq_data) ||
 	    irqd_has_set(&desc->irq_data, IRQD_AFFINITY_SET)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (cpumask_intersects(desc->irq_common_data.affinity,
 				       cpu_online_mask))
 			set = desc->irq_common_data.affinity;
@@ -361,6 +386,7 @@ int irq_setup_affinity(struct irq_desc *desc)
 
 	cpumask_and(&mask, cpu_online_mask, set);
 	if (node != NUMA_NO_NODE) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		const struct cpumask *nodemask = cpumask_of_node(node);
 
 		/* make sure at least one of the cpus in nodemask is online */
@@ -384,6 +410,7 @@ int irq_setup_affinity(struct irq_desc *desc)
  */
 int irq_select_affinity_usr(unsigned int irq)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct irq_desc *desc = irq_to_desc(irq);
 	unsigned long flags;
 	int ret;
@@ -414,7 +441,9 @@ int irq_set_vcpu_affinity(unsigned int irq, void *vcpu_info)
 	int ret = -ENOSYS;
 
 	if (!desc)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	data = irq_desc_get_irq_data(desc);
 	do {
@@ -438,6 +467,7 @@ EXPORT_SYMBOL_GPL(irq_set_vcpu_affinity);
 
 void __disable_irq(struct irq_desc *desc)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!desc->depth++)
 		irq_disable(desc);
 }
@@ -448,7 +478,9 @@ static int __disable_irq_nosync(unsigned int irq)
 	struct irq_desc *desc = irq_get_desc_buslock(irq, &flags, IRQ_GET_DESC_CHECK_GLOBAL);
 
 	if (!desc)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 	__disable_irq(desc);
 	irq_put_desc_busunlock(desc, flags);
 	return 0;
@@ -467,6 +499,7 @@ static int __disable_irq_nosync(unsigned int irq)
  */
 void disable_irq_nosync(unsigned int irq)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	__disable_irq_nosync(irq);
 }
 EXPORT_SYMBOL(disable_irq_nosync);
@@ -485,6 +518,7 @@ EXPORT_SYMBOL(disable_irq_nosync);
  */
 void disable_irq(unsigned int irq)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!__disable_irq_nosync(irq))
 		synchronize_irq(irq);
 }
@@ -509,6 +543,7 @@ EXPORT_SYMBOL(disable_irq);
  */
 bool disable_hardirq(unsigned int irq)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!__disable_irq_nosync(irq))
 		return synchronize_hardirq(irq);
 
@@ -518,6 +553,7 @@ EXPORT_SYMBOL_GPL(disable_hardirq);
 
 void __enable_irq(struct irq_desc *desc)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	switch (desc->depth) {
 	case 0:
  err_out:
@@ -561,7 +597,9 @@ void enable_irq(unsigned int irq)
 	struct irq_desc *desc = irq_get_desc_buslock(irq, &flags, IRQ_GET_DESC_CHECK_GLOBAL);
 
 	if (!desc)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 	if (WARN(!desc->irq_data.chip,
 		 KERN_ERR "enable_irq before setup/request_irq: irq %u\n", irq))
 		goto out;
@@ -574,6 +612,7 @@ EXPORT_SYMBOL(enable_irq);
 
 static int set_irq_wake_real(unsigned int irq, unsigned int on)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct irq_desc *desc = irq_to_desc(irq);
 	int ret = -ENXIO;
 
@@ -605,7 +644,9 @@ int irq_set_irq_wake(unsigned int irq, unsigned int on)
 	int ret = 0;
 
 	if (!desc)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	/* wakeup-capable irqs can be shared between drivers that
 	 * don't need to have the same sleep mode behaviors.
@@ -646,7 +687,9 @@ int can_request_irq(unsigned int irq, unsigned long irqflags)
 	int canrequest = 0;
 
 	if (!desc)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	if (irq_settings_can_request(desc)) {
 		if (!desc->action ||
@@ -662,6 +705,7 @@ int __irq_set_trigger(struct irq_desc *desc, unsigned long flags)
 	struct irq_chip *chip = desc->irq_data.chip;
 	int ret, unmask = 0;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!chip || !chip->irq_set_type) {
 		/*
 		 * IRQF_TRIGGER_* but the PIC does not support multiple
@@ -735,6 +779,7 @@ EXPORT_SYMBOL_GPL(irq_set_parent);
  */
 static irqreturn_t irq_default_primary_handler(int irq, void *dev_id)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return IRQ_WAKE_THREAD;
 }
 
@@ -744,18 +789,21 @@ static irqreturn_t irq_default_primary_handler(int irq, void *dev_id)
  */
 static irqreturn_t irq_nested_primary_handler(int irq, void *dev_id)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WARN(1, "Primary handler called for nested irq %d\n", irq);
 	return IRQ_NONE;
 }
 
 static irqreturn_t irq_forced_secondary_handler(int irq, void *dev_id)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WARN(1, "Secondary action handler called for irq %d\n", irq);
 	return IRQ_NONE;
 }
 
 static int irq_wait_for_interrupt(struct irqaction *action)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	set_current_state(TASK_INTERRUPTIBLE);
 
 	while (!kthread_should_stop()) {
@@ -780,6 +828,7 @@ static int irq_wait_for_interrupt(struct irqaction *action)
 static void irq_finalize_oneshot(struct irq_desc *desc,
 				 struct irqaction *action)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!(desc->istate & IRQS_ONESHOT) ||
 	    action->handler == irq_forced_secondary_handler)
 		return;
@@ -838,7 +887,9 @@ irq_thread_check_affinity(struct irq_desc *desc, struct irqaction *action)
 	bool valid = true;
 
 	if (!test_and_clear_bit(IRQTF_AFFINITY, &action->thread_flags))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	/*
 	 * In case we are out of memory we set IRQTF_AFFINITY again and
@@ -1081,6 +1132,7 @@ setup_irq_thread(struct irqaction *new, unsigned int irq, bool secondary)
 	};
 
 	if (!secondary) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		t = kthread_create(irq_thread, new, "irq/%d-%s", irq,
 				   new->name);
 	} else {
@@ -1136,12 +1188,18 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 	int ret, nested, shared = 0;
 
 	if (!desc)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	if (desc->irq_data.chip == &no_irq_chip)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOSYS;
+}
 	if (!try_module_get(desc->owner))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENODEV;
+}
 
 	new->irq = irq;
 
@@ -1158,7 +1216,9 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 	 */
 	nested = irq_settings_is_nested_thread(desc);
 	if (nested) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (!new->thread_fn) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			ret = -EINVAL;
 			goto out_mput;
 		}
@@ -1182,10 +1242,13 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 	 * thread.
 	 */
 	if (new->thread_fn && !nested) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ret = setup_irq_thread(new, irq, false);
 		if (ret)
 			goto out_mput;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (new->secondary) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			ret = setup_irq_thread(new->secondary, irq, true);
 			if (ret)
 				goto out_thread;
@@ -1202,7 +1265,9 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 	 * the threaded handler for those.
 	 */
 	if (desc->irq_data.chip->flags & IRQCHIP_ONESHOT_SAFE)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		new->flags &= ~IRQF_ONESHOT;
+}
 
 	/*
 	 * Protects against a concurrent __free_irq() call which might wait
@@ -1222,6 +1287,7 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 	if (!desc->action) {
 		ret = irq_request_resources(desc);
 		if (ret) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			pr_err("Failed to request resources for %s (irq %d) on irqchip %s\n",
 			       new->name, irq, desc->irq_data.chip->name);
 			goto out_bus_unlock;
@@ -1252,12 +1318,15 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 		 * the one provided by the requester.
 		 */
 		if (irqd_trigger_type_was_set(&desc->irq_data)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			oldtype = irqd_get_trigger_type(&desc->irq_data);
 		} else {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			oldtype = new->flags & IRQF_TRIGGER_MASK;
 			irqd_set_trigger_type(&desc->irq_data, oldtype);
 		}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (!((old->flags & new->flags) & IRQF_SHARED) ||
 		    (oldtype != (new->flags & IRQF_TRIGGER_MASK)) ||
 		    ((old->flags ^ new->flags) & IRQF_ONESHOT))
@@ -1278,7 +1347,9 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 			thread_mask |= old->thread_mask;
 			old_ptr = &old->next;
 			old = *old_ptr;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		} while (old);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		shared = 1;
 	}
 
@@ -1293,6 +1364,7 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 		 * but who knows.
 		 */
 		if (thread_mask == ~0UL) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			ret = -EBUSY;
 			goto out_unlock;
 		}
@@ -1346,6 +1418,7 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 
 		/* Setup the type (level, edge polarity) if configured: */
 		if (new->flags & IRQF_TRIGGER_MASK) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			ret = __irq_set_trigger(desc,
 						new->flags & IRQF_TRIGGER_MASK);
 
@@ -1358,15 +1431,19 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 		irqd_clear(&desc->irq_data, IRQD_IRQ_INPROGRESS);
 
 		if (new->flags & IRQF_PERCPU) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			irqd_set(&desc->irq_data, IRQD_PER_CPU);
 			irq_settings_set_per_cpu(desc);
 		}
 
 		if (new->flags & IRQF_ONESHOT)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			desc->istate |= IRQS_ONESHOT;
+}
 
 		/* Exclude IRQ from balancing if requested */
 		if (new->flags & IRQF_NOBALANCING) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			irq_settings_set_no_balancing(desc);
 			irqd_set(&desc->irq_data, IRQD_NO_BALANCING);
 		}
@@ -1408,6 +1485,7 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 	 * before. Reenable it and give it another chance.
 	 */
 	if (shared && (desc->istate & IRQS_SPURIOUS_DISABLED)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		desc->istate &= ~IRQS_SPURIOUS_DISABLED;
 		__enable_irq(desc);
 	}
@@ -1423,9 +1501,13 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 	 * when no hard interrupt wakes the thread up.
 	 */
 	if (new->thread)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		wake_up_process(new->thread);
+}
 	if (new->secondary)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		wake_up_process(new->secondary->thread);
+}
 
 	register_irq_proc(irq, desc);
 	irq_add_debugfs_entry(irq, desc);
@@ -1435,19 +1517,24 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 
 mismatch:
 	if (!(new->flags & IRQF_PROBE_SHARED)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_err("Flags mismatch irq %d. %08x (%s) vs. %08x (%s)\n",
 		       irq, new->flags, new->name, old->flags, old->name);
 #ifdef CONFIG_DEBUG_SHIRQ
 		dump_stack();
 #endif
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	ret = -EBUSY;
 
 out_unlock:
 	raw_spin_unlock_irqrestore(&desc->lock, flags);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!desc->action)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		irq_release_resources(desc);
+}
 out_bus_unlock:
 	chip_bus_sync_unlock(desc);
 	mutex_unlock(&desc->request_mutex);
@@ -1460,6 +1547,7 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 		kthread_stop(t);
 		put_task_struct(t);
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (new->secondary && new->secondary->thread) {
 		struct task_struct *t = new->secondary->thread;
 
@@ -1485,17 +1573,24 @@ int setup_irq(unsigned int irq, struct irqaction *act)
 	struct irq_desc *desc = irq_to_desc(irq);
 
 	if (!desc || WARN_ON(irq_settings_is_per_cpu_devid(desc)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	retval = irq_chip_pm_get(&desc->irq_data);
 	if (retval < 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return retval;
+}
 
 	retval = __setup_irq(irq, desc, act);
 
 	if (retval)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		irq_chip_pm_put(&desc->irq_data);
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return retval;
 }
 EXPORT_SYMBOL_GPL(setup_irq);
@@ -1513,7 +1608,9 @@ static struct irqaction *__free_irq(unsigned int irq, void *dev_id)
 	WARN(in_interrupt(), "Trying to free IRQ %d from IRQ context!\n", irq);
 
 	if (!desc)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 
 	mutex_lock(&desc->request_mutex);
 	chip_bus_lock(desc);
@@ -1528,8 +1625,11 @@ static struct irqaction *__free_irq(unsigned int irq, void *dev_id)
 		action = *action_ptr;
 
 		if (!action) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			WARN(1, "Trying to free already-free IRQ %d\n", irq);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			raw_spin_unlock_irqrestore(&desc->lock, flags);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			chip_bus_sync_unlock(desc);
 			mutex_unlock(&desc->request_mutex);
 			return NULL;
@@ -1537,6 +1637,7 @@ static struct irqaction *__free_irq(unsigned int irq, void *dev_id)
 
 		if (action->dev_id == dev_id)
 			break;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		action_ptr = &action->next;
 	}
 
@@ -1547,6 +1648,7 @@ static struct irqaction *__free_irq(unsigned int irq, void *dev_id)
 
 	/* If this was the last handler, shut down the IRQ line: */
 	if (!desc->action) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		irq_settings_clr_disable_unlazy(desc);
 		irq_shutdown(desc);
 	}
@@ -1554,7 +1656,9 @@ static struct irqaction *__free_irq(unsigned int irq, void *dev_id)
 #ifdef CONFIG_SMP
 	/* make sure affinity_hint is cleaned up */
 	if (WARN_ON_ONCE(desc->affinity_hint))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		desc->affinity_hint = NULL;
+}
 #endif
 
 	raw_spin_unlock_irqrestore(&desc->lock, flags);
@@ -1596,9 +1700,12 @@ static struct irqaction *__free_irq(unsigned int irq, void *dev_id)
 #endif
 
 	if (action->thread) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		kthread_stop(action->thread);
 		put_task_struct(action->thread);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (action->secondary && action->secondary->thread) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			kthread_stop(action->secondary->thread);
 			put_task_struct(action->secondary->thread);
 		}
@@ -1633,6 +1740,7 @@ static struct irqaction *__free_irq(unsigned int irq, void *dev_id)
  */
 void remove_irq(unsigned int irq, struct irqaction *act)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct irq_desc *desc = irq_to_desc(irq);
 
 	if (desc && !WARN_ON(irq_settings_is_per_cpu_devid(desc)))
@@ -1663,17 +1771,23 @@ const void *free_irq(unsigned int irq, void *dev_id)
 	const char *devname;
 
 	if (!desc || WARN_ON(irq_settings_is_per_cpu_devid(desc)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 
 #ifdef CONFIG_SMP
 	if (WARN_ON(desc->affinity_notify))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		desc->affinity_notify = NULL;
+}
 #endif
 
 	action = __free_irq(irq, dev_id);
 
 	if (!action)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 
 	devname = action->name;
 	kfree(action);
@@ -1732,7 +1846,9 @@ int request_threaded_irq(unsigned int irq, irq_handler_t handler,
 	int retval;
 
 	if (irq == IRQ_NOTCONNECTED)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOTCONN;
+}
 
 	/*
 	 * Sanity-check: shared interrupts must pass in a real dev-ID,
@@ -1750,21 +1866,29 @@ int request_threaded_irq(unsigned int irq, irq_handler_t handler,
 
 	desc = irq_to_desc(irq);
 	if (!desc)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	if (!irq_settings_can_request(desc) ||
 	    WARN_ON(irq_settings_is_per_cpu_devid(desc)))
 		return -EINVAL;
 
 	if (!handler) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (!thread_fn)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -EINVAL;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		handler = irq_default_primary_handler;
 	}
 
 	action = kzalloc(sizeof(struct irqaction), GFP_KERNEL);
 	if (!action)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 
 	action->handler = handler;
 	action->thread_fn = thread_fn;
@@ -1774,6 +1898,7 @@ int request_threaded_irq(unsigned int irq, irq_handler_t handler,
 
 	retval = irq_chip_pm_get(&desc->irq_data);
 	if (retval < 0) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		kfree(action);
 		return retval;
 	}
@@ -1781,6 +1906,7 @@ int request_threaded_irq(unsigned int irq, irq_handler_t handler,
 	retval = __setup_irq(irq, desc, action);
 
 	if (retval) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		irq_chip_pm_put(&desc->irq_data);
 		kfree(action->secondary);
 		kfree(action);
@@ -1833,7 +1959,9 @@ int request_any_context_irq(unsigned int irq, irq_handler_t handler,
 	int ret;
 
 	if (irq == IRQ_NOTCONNECTED)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOTCONN;
+}
 
 	desc = irq_to_desc(irq);
 	if (!desc)
@@ -1852,6 +1980,7 @@ EXPORT_SYMBOL_GPL(request_any_context_irq);
 
 void enable_percpu_irq(unsigned int irq, unsigned int type)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	unsigned int cpu = smp_processor_id();
 	unsigned long flags;
 	struct irq_desc *desc = irq_get_desc_lock(irq, &flags, IRQ_GET_DESC_CHECK_PERCPU);
@@ -1893,6 +2022,7 @@ EXPORT_SYMBOL_GPL(enable_percpu_irq);
  */
 bool irq_percpu_is_enabled(unsigned int irq)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	unsigned int cpu = smp_processor_id();
 	struct irq_desc *desc;
 	unsigned long flags;
@@ -1911,6 +2041,7 @@ EXPORT_SYMBOL_GPL(irq_percpu_is_enabled);
 
 void disable_percpu_irq(unsigned int irq)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	unsigned int cpu = smp_processor_id();
 	unsigned long flags;
 	struct irq_desc *desc = irq_get_desc_lock(irq, &flags, IRQ_GET_DESC_CHECK_PERCPU);
@@ -1928,6 +2059,7 @@ EXPORT_SYMBOL_GPL(disable_percpu_irq);
  */
 static struct irqaction *__free_percpu_irq(unsigned int irq, void __percpu *dev_id)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct irq_desc *desc = irq_to_desc(irq);
 	struct irqaction *action;
 	unsigned long flags;
@@ -1976,6 +2108,7 @@ static struct irqaction *__free_percpu_irq(unsigned int irq, void __percpu *dev_
  */
 void remove_percpu_irq(unsigned int irq, struct irqaction *act)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct irq_desc *desc = irq_to_desc(irq);
 
 	if (desc && irq_settings_is_per_cpu_devid(desc))
@@ -1996,6 +2129,7 @@ void remove_percpu_irq(unsigned int irq, struct irqaction *act)
  */
 void free_percpu_irq(unsigned int irq, void __percpu *dev_id)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct irq_desc *desc = irq_to_desc(irq);
 
 	if (!desc || !irq_settings_is_per_cpu_devid(desc))
@@ -2016,6 +2150,7 @@ EXPORT_SYMBOL_GPL(free_percpu_irq);
  */
 int setup_percpu_irq(unsigned int irq, struct irqaction *act)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct irq_desc *desc = irq_to_desc(irq);
 	int retval;
 
@@ -2060,7 +2195,9 @@ int __request_percpu_irq(unsigned int irq, irq_handler_t handler,
 	int retval;
 
 	if (!dev_id)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	desc = irq_to_desc(irq);
 	if (!desc || !irq_settings_can_request(desc) ||
@@ -2120,7 +2257,9 @@ int irq_get_irqchip_state(unsigned int irq, enum irqchip_irq_state which,
 
 	desc = irq_get_desc_buslock(irq, &flags, 0);
 	if (!desc)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return err;
+}
 
 	data = irq_desc_get_irq_data(desc);
 
@@ -2166,7 +2305,9 @@ int irq_set_irqchip_state(unsigned int irq, enum irqchip_irq_state which,
 
 	desc = irq_get_desc_buslock(irq, &flags, 0);
 	if (!desc)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return err;
+}
 
 	data = irq_desc_get_irq_data(desc);
 
diff --git a/kernel/irq/migration.c b/kernel/irq/migration.c
index 86ae0eb8..de9efe6 100644
--- a/kernel/irq/migration.c
+++ b/kernel/irq/migration.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 
 #include <linux/irq.h>
@@ -17,6 +19,7 @@
  */
 bool irq_fixup_move_pending(struct irq_desc *desc, bool force_clear)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct irq_data *data = irq_desc_get_irq_data(desc);
 
 	if (!irqd_is_setaffinity_pending(data))
@@ -37,6 +40,7 @@ bool irq_fixup_move_pending(struct irq_desc *desc, bool force_clear)
 
 void irq_move_masked_irq(struct irq_data *idata)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct irq_desc *desc = irq_data_to_desc(idata);
 	struct irq_chip *chip = desc->irq_data.chip;
 
@@ -91,10 +95,15 @@ void irq_move_irq(struct irq_data *idata)
 	idata = irq_desc_get_irq_data(irq_data_to_desc(idata));
 
 	if (likely(!irqd_is_setaffinity_pending(idata)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (unlikely(irqd_irq_disabled(idata)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	/*
 	 * Be careful vs. already masked interrupts. If this is a
@@ -103,8 +112,13 @@ void irq_move_irq(struct irq_data *idata)
 	 */
 	masked = irqd_irq_masked(idata);
 	if (!masked)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		idata->chip->irq_mask(idata);
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	irq_move_masked_irq(idata);
 	if (!masked)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		idata->chip->irq_unmask(idata);
 }
+}
diff --git a/kernel/irq/msi.c b/kernel/irq/msi.c
index 3fa4bd5..e53377a 100644
--- a/kernel/irq/msi.c
+++ b/kernel/irq/msi.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * linux/kernel/irq/msi.c
  *
@@ -32,36 +34,44 @@ alloc_msi_entry(struct device *dev, int nvec, const struct cpumask *affinity)
 
 	desc = kzalloc(sizeof(*desc), GFP_KERNEL);
 	if (!desc)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 
 	INIT_LIST_HEAD(&desc->list);
 	desc->dev = dev;
 	desc->nvec_used = nvec;
 	if (affinity) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		desc->affinity = kmemdup(affinity,
 			nvec * sizeof(*desc->affinity), GFP_KERNEL);
 		if (!desc->affinity) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			kfree(desc);
 			return NULL;
 		}
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return desc;
 }
 
 void free_msi_entry(struct msi_desc *entry)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	kfree(entry->affinity);
 	kfree(entry);
 }
 
 void __get_cached_msi_msg(struct msi_desc *entry, struct msi_msg *msg)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	*msg = entry->msg;
 }
 
 void get_cached_msi_msg(unsigned int irq, struct msi_msg *msg)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct msi_desc *entry = irq_get_msi_desc(irq);
 
 	__get_cached_msi_msg(entry, msg);
@@ -127,26 +137,36 @@ static int msi_domain_alloc(struct irq_domain *domain, unsigned int virq,
 	int i, ret;
 
 	if (irq_find_mapping(domain, hwirq) > 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EEXIST;
+}
 
 	if (domain->parent) {
 		ret = irq_domain_alloc_irqs_parent(domain, virq, nr_irqs, arg);
 		if (ret < 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return ret;
+}
 	}
 
 	for (i = 0; i < nr_irqs; i++) {
 		ret = ops->msi_init(domain, info, virq + i, hwirq + i, arg);
 		if (ret < 0) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			if (ops->msi_free) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				for (i--; i > 0; i--)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 					ops->msi_free(domain, info, virq + i);
+}
 			}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			irq_domain_free_irqs_top(domain, virq, nr_irqs);
 			return ret;
 		}
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
@@ -157,6 +177,7 @@ static void msi_domain_free(struct irq_domain *domain, unsigned int virq,
 	int i;
 
 	if (info->ops->msi_free) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		for (i = 0; i < nr_irqs; i++)
 			info->ops->msi_free(domain, info, virq + i);
 	}
@@ -205,7 +226,9 @@ static int msi_domain_ops_init(struct irq_domain *domain,
 	if (info->handler && info->handler_name) {
 		__irq_set_handler(virq, info->handler, 0, info->handler_name);
 		if (info->handler_data)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			irq_set_handler_data(virq, info->handler_data);
+}
 	}
 	return 0;
 }
@@ -214,6 +237,7 @@ static int msi_domain_ops_check(struct irq_domain *domain,
 				struct msi_domain_info *info,
 				struct device *dev)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
@@ -230,21 +254,30 @@ static void msi_domain_update_dom_ops(struct msi_domain_info *info)
 	struct msi_domain_ops *ops = info->ops;
 
 	if (ops == NULL) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		info->ops = &msi_domain_ops_default;
 		return;
 	}
 
 	if (ops->get_hwirq == NULL)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ops->get_hwirq = msi_domain_ops_default.get_hwirq;
+}
 	if (ops->msi_init == NULL)
 		ops->msi_init = msi_domain_ops_default.msi_init;
 	if (ops->msi_check == NULL)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ops->msi_check = msi_domain_ops_default.msi_check;
+}
 	if (ops->msi_prepare == NULL)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ops->msi_prepare = msi_domain_ops_default.msi_prepare;
+}
 	if (ops->set_desc == NULL)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ops->set_desc = msi_domain_ops_default.set_desc;
 }
+}
 
 static void msi_domain_update_chip_ops(struct msi_domain_info *info)
 {
@@ -276,7 +309,9 @@ struct irq_domain *msi_create_irq_domain(struct fwnode_handle *fwnode,
 					     fwnode, &msi_domain_ops, info);
 
 	if (domain && !domain->name && info->chip)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		domain->name = info->chip->name;
+}
 
 	return domain;
 }
@@ -303,6 +338,7 @@ int msi_domain_populate_irqs(struct irq_domain *domain, struct device *dev,
 	struct msi_desc *desc;
 	int ret = 0;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for_each_msi_entry(desc, dev) {
 		/* Don't even try the multi-MSI brain damage. */
 		if (WARN_ON(!desc->irq || desc->nvec_used != 1)) {
@@ -356,7 +392,9 @@ int msi_domain_alloc_irqs(struct irq_domain *domain, struct device *dev,
 
 	ret = msi_domain_prepare_irqs(domain, dev, nvec, &arg);
 	if (ret)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ret;
+}
 
 	for_each_msi_entry(desc, dev) {
 		ops->set_desc(&arg, desc);
@@ -365,11 +403,18 @@ int msi_domain_alloc_irqs(struct irq_domain *domain, struct device *dev,
 					       dev_to_node(dev), &arg, false,
 					       desc->affinity);
 		if (virq < 0) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			ret = -ENOSPC;
 			if (ops->handle_error)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				ret = ops->handle_error(domain, desc, ret);
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			if (ops->msi_finish)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				ops->msi_finish(&arg, ret);
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return ret;
 		}
 
@@ -378,12 +423,16 @@ int msi_domain_alloc_irqs(struct irq_domain *domain, struct device *dev,
 	}
 
 	if (ops->msi_finish)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ops->msi_finish(&arg, 0);
+}
 
 	for_each_msi_entry(desc, dev) {
 		virq = desc->irq;
 		if (desc->nvec_used == 1)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			dev_dbg(dev, "irq %d for MSI\n", virq);
+}
 		else
 			dev_dbg(dev, "irq [%d-%d] for MSI\n",
 				virq, virq + desc->nvec_used - 1);
@@ -400,6 +449,7 @@ int msi_domain_alloc_irqs(struct irq_domain *domain, struct device *dev,
 		}
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
@@ -413,6 +463,7 @@ void msi_domain_free_irqs(struct irq_domain *domain, struct device *dev)
 {
 	struct msi_desc *desc;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for_each_msi_entry(desc, dev) {
 		/*
 		 * We might have failed to allocate an MSI early
@@ -435,6 +486,7 @@ void msi_domain_free_irqs(struct irq_domain *domain, struct device *dev)
  */
 struct msi_domain_info *msi_get_domain_info(struct irq_domain *domain)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return (struct msi_domain_info *)domain->host_data;
 }
 
diff --git a/kernel/irq/pm.c b/kernel/irq/pm.c
index 6bd9b58..19def5b 100644
--- a/kernel/irq/pm.c
+++ b/kernel/irq/pm.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * linux/kernel/irq/pm.c
  *
@@ -16,6 +18,7 @@
 
 bool irq_pm_check_wakeup(struct irq_desc *desc)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (irqd_is_wakeup_armed(&desc->irq_data)) {
 		irqd_clear(&desc->irq_data, IRQD_WAKEUP_ARMED);
 		desc->istate |= IRQS_SUSPENDED | IRQS_PENDING;
@@ -36,7 +39,9 @@ void irq_pm_install_action(struct irq_desc *desc, struct irqaction *action)
 	desc->nr_actions++;
 
 	if (action->flags & IRQF_FORCE_RESUME)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		desc->force_resume_depth++;
+}
 
 	WARN_ON_ONCE(desc->force_resume_depth &&
 		     desc->force_resume_depth != desc->nr_actions);
@@ -44,7 +49,9 @@ void irq_pm_install_action(struct irq_desc *desc, struct irqaction *action)
 	if (action->flags & IRQF_NO_SUSPEND)
 		desc->no_suspend_depth++;
 	else if (action->flags & IRQF_COND_SUSPEND)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		desc->cond_suspend_depth++;
+}
 
 	WARN_ON_ONCE(desc->no_suspend_depth &&
 		     (desc->no_suspend_depth +
@@ -60,16 +67,23 @@ void irq_pm_remove_action(struct irq_desc *desc, struct irqaction *action)
 	desc->nr_actions--;
 
 	if (action->flags & IRQF_FORCE_RESUME)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		desc->force_resume_depth--;
+}
 
 	if (action->flags & IRQF_NO_SUSPEND)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		desc->no_suspend_depth--;
+}
 	else if (action->flags & IRQF_COND_SUSPEND)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		desc->cond_suspend_depth--;
 }
+}
 
 static bool suspend_device_irq(struct irq_desc *desc)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!desc->action || irq_desc_is_chained(desc) ||
 	    desc->no_suspend_depth)
 		return false;
@@ -120,6 +134,7 @@ void suspend_device_irqs(void)
 	struct irq_desc *desc;
 	int irq;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for_each_irq_desc(irq, desc) {
 		unsigned long flags;
 		bool sync;
@@ -138,6 +153,7 @@ EXPORT_SYMBOL_GPL(suspend_device_irqs);
 
 static void resume_irq(struct irq_desc *desc)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	irqd_clear(&desc->irq_data, IRQD_WAKEUP_ARMED);
 
 	if (desc->istate & IRQS_SUSPENDED)
@@ -161,6 +177,7 @@ static void resume_irqs(bool want_early)
 	struct irq_desc *desc;
 	int irq;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for_each_irq_desc(irq, desc) {
 		unsigned long flags;
 		bool is_early = desc->action &&
@@ -184,6 +201,7 @@ static void resume_irqs(bool want_early)
  */
 static void irq_pm_syscore_resume(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	resume_irqs(true);
 }
 
@@ -208,6 +226,7 @@ device_initcall(irq_pm_init_ops);
  */
 void resume_device_irqs(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	resume_irqs(false);
 }
 EXPORT_SYMBOL_GPL(resume_device_irqs);
diff --git a/kernel/irq/proc.c b/kernel/irq/proc.c
index c010cc0..c17a85a 100644
--- a/kernel/irq/proc.c
+++ b/kernel/irq/proc.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 /*
  * linux/kernel/irq/proc.c
@@ -47,6 +49,7 @@ enum {
 
 static int show_irq_affinity(int type, struct seq_file *m)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct irq_desc *desc = irq_to_desc((long)m->private);
 	const struct cpumask *mask;
 
@@ -84,6 +87,7 @@ static int show_irq_affinity(int type, struct seq_file *m)
 
 static int irq_affinity_hint_proc_show(struct seq_file *m, void *v)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct irq_desc *desc = irq_to_desc((long)m->private);
 	unsigned long flags;
 	cpumask_var_t mask;
@@ -109,11 +113,13 @@ static int irq_affinity_hint_proc_show(struct seq_file *m, void *v)
 int no_irq_affinity;
 static int irq_affinity_proc_show(struct seq_file *m, void *v)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return show_irq_affinity(AFFINITY, m);
 }
 
 static int irq_affinity_list_proc_show(struct seq_file *m, void *v)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return show_irq_affinity(AFFINITY_LIST, m);
 }
 
@@ -121,6 +127,7 @@ static int irq_affinity_list_proc_show(struct seq_file *m, void *v)
 static ssize_t write_irq_affinity(int type, struct file *file,
 		const char __user *buffer, size_t count, loff_t *pos)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	unsigned int irq = (int)(long)PDE_DATA(file_inode(file));
 	cpumask_var_t new_value;
 	int err;
@@ -167,27 +174,32 @@ static ssize_t write_irq_affinity(int type, struct file *file,
 static ssize_t irq_affinity_proc_write(struct file *file,
 		const char __user *buffer, size_t count, loff_t *pos)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return write_irq_affinity(0, file, buffer, count, pos);
 }
 
 static ssize_t irq_affinity_list_proc_write(struct file *file,
 		const char __user *buffer, size_t count, loff_t *pos)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return write_irq_affinity(1, file, buffer, count, pos);
 }
 
 static int irq_affinity_proc_open(struct inode *inode, struct file *file)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return single_open(file, irq_affinity_proc_show, PDE_DATA(inode));
 }
 
 static int irq_affinity_list_proc_open(struct inode *inode, struct file *file)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return single_open(file, irq_affinity_list_proc_show, PDE_DATA(inode));
 }
 
 static int irq_affinity_hint_proc_open(struct inode *inode, struct file *file)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return single_open(file, irq_affinity_hint_proc_show, PDE_DATA(inode));
 }
 
@@ -217,16 +229,19 @@ static const struct file_operations irq_affinity_list_proc_fops = {
 #ifdef CONFIG_GENERIC_IRQ_EFFECTIVE_AFF_MASK
 static int irq_effective_aff_proc_show(struct seq_file *m, void *v)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return show_irq_affinity(EFFECTIVE, m);
 }
 
 static int irq_effective_aff_list_proc_show(struct seq_file *m, void *v)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return show_irq_affinity(EFFECTIVE_LIST, m);
 }
 
 static int irq_effective_aff_proc_open(struct inode *inode, struct file *file)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return single_open(file, irq_effective_aff_proc_show, PDE_DATA(inode));
 }
 
@@ -254,6 +269,7 @@ static const struct file_operations irq_effective_aff_list_proc_fops = {
 
 static int default_affinity_show(struct seq_file *m, void *v)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	seq_printf(m, "%*pb\n", cpumask_pr_args(irq_default_affinity));
 	return 0;
 }
@@ -265,7 +281,9 @@ static ssize_t default_affinity_write(struct file *file,
 	int err;
 
 	if (!alloc_cpumask_var(&new_value, GFP_KERNEL))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 
 	err = cpumask_parse_user(buffer, count, new_value);
 	if (err)
@@ -296,6 +314,7 @@ static ssize_t default_affinity_write(struct file *file,
 
 static int default_affinity_open(struct inode *inode, struct file *file)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return single_open(file, default_affinity_show, PDE_DATA(inode));
 }
 
@@ -309,6 +328,7 @@ static const struct file_operations default_affinity_proc_fops = {
 
 static int irq_node_proc_show(struct seq_file *m, void *v)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct irq_desc *desc = irq_to_desc((long) m->private);
 
 	seq_printf(m, "%d\n", irq_desc_get_node(desc));
@@ -317,6 +337,7 @@ static int irq_node_proc_show(struct seq_file *m, void *v)
 
 static int irq_node_proc_open(struct inode *inode, struct file *file)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return single_open(file, irq_node_proc_show, PDE_DATA(inode));
 }
 
@@ -330,6 +351,7 @@ static const struct file_operations irq_node_proc_fops = {
 
 static int irq_spurious_proc_show(struct seq_file *m, void *v)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct irq_desc *desc = irq_to_desc((long) m->private);
 
 	seq_printf(m, "count %u\n" "unhandled %u\n" "last_unhandled %u ms\n",
@@ -340,6 +362,7 @@ static int irq_spurious_proc_show(struct seq_file *m, void *v)
 
 static int irq_spurious_proc_open(struct inode *inode, struct file *file)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return single_open(file, irq_spurious_proc_show, PDE_DATA(inode));
 }
 
@@ -363,6 +386,7 @@ static int name_unique(unsigned int irq, struct irqaction *new_action)
 	for_each_action_of_desc(desc, action) {
 		if ((action != new_action) && action->name &&
 				!strcmp(new_action->name, action->name)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			ret = 0;
 			break;
 		}
@@ -449,6 +473,7 @@ void unregister_irq_proc(unsigned int irq, struct irq_desc *desc)
 {
 	char name [MAX_NAMELEN];
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!root_irq_dir || !desc->dir)
 		return;
 #ifdef CONFIG_SMP
@@ -490,7 +515,9 @@ void init_irq_proc(void)
 	/* create /proc/irq */
 	root_irq_dir = proc_mkdir("irq", NULL);
 	if (!root_irq_dir)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	register_default_affinity_proc();
 
@@ -505,6 +532,7 @@ void init_irq_proc(void)
 
 int __weak arch_show_interrupts(struct seq_file *p, int prec)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
@@ -522,7 +550,9 @@ int show_interrupts(struct seq_file *p, void *v)
 	struct irq_desc *desc;
 
 	if (i > ACTUAL_NR_IRQS)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	if (i == ACTUAL_NR_IRQS)
 		return arch_show_interrupts(p, prec);
diff --git a/kernel/irq/resend.c b/kernel/irq/resend.c
index 1d08f451..ef3c0e1 100644
--- a/kernel/irq/resend.c
+++ b/kernel/irq/resend.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 /*
  * linux/kernel/irq/resend.c
@@ -67,7 +69,9 @@ void check_irq_resend(struct irq_desc *desc)
 		return;
 	}
 	if (desc->istate & IRQS_REPLAY)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 	if (desc->istate & IRQS_PENDING) {
 		desc->istate &= ~IRQS_PENDING;
 		desc->istate |= IRQS_REPLAY;
diff --git a/kernel/irq/settings.h b/kernel/irq/settings.h
index e43795c..d8f24f9 100644
--- a/kernel/irq/settings.h
+++ b/kernel/irq/settings.h
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /* SPDX-License-Identifier: GPL-2.0 */
 /*
  * Internal header to deal with irq_desc->status which will be renamed
diff --git a/kernel/irq/spurious.c b/kernel/irq/spurious.c
index 987d7bc..55a3b1d 100644
--- a/kernel/irq/spurious.c
+++ b/kernel/irq/spurious.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 /*
  * linux/kernel/irq/spurious.c
@@ -38,6 +40,7 @@ static atomic_t irq_poll_active;
  */
 bool irq_wait_for_poll(struct irq_desc *desc)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (WARN_ONCE(irq_poll_cpu == smp_processor_id(),
 		      "irq poll in progress on cpu %d for irq %d\n",
 		      smp_processor_id(), desc->irq_data.irq))
@@ -125,6 +128,7 @@ static int misrouted_irq(int irq)
 	if (atomic_inc_return(&irq_poll_active) != 1)
 		goto out;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	irq_poll_cpu = smp_processor_id();
 
 	for_each_irq_desc(i, desc) {
@@ -150,6 +154,7 @@ static void poll_spurious_irqs(unsigned long dummy)
 
 	if (atomic_inc_return(&irq_poll_active) != 1)
 		goto out;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	irq_poll_cpu = smp_processor_id();
 
 	for_each_irq_desc(i, desc) {
@@ -179,7 +184,10 @@ static inline int bad_action_ret(irqreturn_t action_ret)
 	unsigned int r = action_ret;
 
 	if (likely(r <= (IRQ_HANDLED | IRQ_WAKE_THREAD)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 1;
 }
 
@@ -193,6 +201,7 @@ static inline int bad_action_ret(irqreturn_t action_ret)
  */
 static void __report_bad_irq(struct irq_desc *desc, irqreturn_t action_ret)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	unsigned int irq = irq_desc_get_irq(desc);
 	struct irqaction *action;
 	unsigned long flags;
@@ -229,6 +238,7 @@ static void report_bad_irq(struct irq_desc *desc, irqreturn_t action_ret)
 	static int count = 100;
 
 	if (count > 0) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		count--;
 		__report_bad_irq(desc, action_ret);
 	}
@@ -241,11 +251,15 @@ try_misrouted_irq(unsigned int irq, struct irq_desc *desc,
 	struct irqaction *action;
 
 	if (!irqfixup)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	/* We didn't actually handle the IRQ - see if it was misrouted? */
 	if (action_ret == IRQ_NONE)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 1;
+}
 
 	/*
 	 * But for 'irqfixup == 2' we also do it for handled interrupts if
@@ -253,10 +267,15 @@ try_misrouted_irq(unsigned int irq, struct irq_desc *desc,
 	 * traditional PC timer interrupt.. Legacy)
 	 */
 	if (irqfixup < 2)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!irq)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 1;
+}
 
 	/*
 	 * Since we don't get the descriptor lock, "action" can
@@ -266,6 +285,7 @@ try_misrouted_irq(unsigned int irq, struct irq_desc *desc,
 	 */
 	action = desc->action;
 	barrier();
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return action && (action->flags & IRQF_IRQPOLL);
 }
 
@@ -280,6 +300,7 @@ void note_interrupt(struct irq_desc *desc, irqreturn_t action_ret)
 		return;
 
 	if (bad_action_ret(action_ret)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		report_bad_irq(desc, action_ret);
 		return;
 	}
@@ -322,6 +343,7 @@ void note_interrupt(struct irq_desc *desc, irqreturn_t action_ret)
 			 * interrupts are not reentrant.
 			 */
 			if (!(desc->threads_handled_last & SPURIOUS_DEFERRED)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				desc->threads_handled_last |= SPURIOUS_DEFERRED;
 				return;
 			}
@@ -340,6 +362,7 @@ void note_interrupt(struct irq_desc *desc, irqreturn_t action_ret)
 			handled = atomic_read(&desc->threads_handled);
 			handled |= SPURIOUS_DEFERRED;
 			if (handled != desc->threads_handled_last) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				action_ret = IRQ_HANDLED;
 				/*
 				 * Note: We keep the SPURIOUS_DEFERRED
@@ -398,17 +421,24 @@ void note_interrupt(struct irq_desc *desc, irqreturn_t action_ret)
 		desc->last_unhandled = jiffies;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	irq = irq_desc_get_irq(desc);
 	if (unlikely(try_misrouted_irq(irq, desc, action_ret))) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		int ok = misrouted_irq(irq);
 		if (action_ret == IRQ_NONE)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			desc->irqs_unhandled -= ok;
+}
 	}
 
 	desc->irq_count++;
 	if (likely(desc->irq_count < 100000))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	desc->irq_count = 0;
 	if (unlikely(desc->irqs_unhandled > 99900)) {
 		/*
@@ -426,6 +456,7 @@ void note_interrupt(struct irq_desc *desc, irqreturn_t action_ret)
 		mod_timer(&poll_spurious_irq_timer,
 			  jiffies + POLL_SPURIOUS_IRQ_INTERVAL);
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	desc->irqs_unhandled = 0;
 }
 
@@ -433,6 +464,7 @@ bool noirqdebug __read_mostly;
 
 int noirqdebug_setup(char *str)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	noirqdebug = 1;
 	printk(KERN_INFO "IRQ lockup detection disabled\n");
 
@@ -445,6 +477,7 @@ MODULE_PARM_DESC(noirqdebug, "Disable irq lockup detection when true");
 
 static int __init irqfixup_setup(char *str)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	irqfixup = 1;
 	printk(KERN_WARNING "Misrouted IRQ fixup support enabled.\n");
 	printk(KERN_WARNING "This may impact system performance.\n");
@@ -457,6 +490,7 @@ module_param(irqfixup, int, 0644);
 
 static int __init irqpoll_setup(char *str)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	irqfixup = 2;
 	printk(KERN_WARNING "Misrouted IRQ fixup and polling support "
 				"enabled\n");
diff --git a/kernel/irq_work.c b/kernel/irq_work.c
index bcf107c..fb13276 100644
--- a/kernel/irq_work.c
+++ b/kernel/irq_work.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * Copyright (C) 2010 Red Hat, Inc., Peter Zijlstra
  *
@@ -36,6 +38,7 @@ static bool irq_work_claim(struct irq_work *work)
 	 */
 	flags = work->flags & ~IRQ_WORK_PENDING;
 	for (;;) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		nflags = flags | IRQ_WORK_FLAGS;
 		oflags = cmpxchg(&work->flags, flags, nflags);
 		if (oflags == flags)
@@ -118,7 +121,9 @@ bool irq_work_needs_cpu(void)
 
 	if (llist_empty(raised) || arch_irq_work_has_interrupt())
 		if (llist_empty(lazy))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return false;
+}
 
 	/* All work should have been flushed before going offline */
 	WARN_ON_ONCE(cpu_is_offline(smp_processor_id()));
@@ -135,10 +140,15 @@ static void irq_work_run_list(struct llist_head *list)
 	BUG_ON(!irqs_disabled());
 
 	if (llist_empty(list))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	llnode = llist_del_all(list);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	while (llnode != NULL) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		work = llist_entry(llnode, struct irq_work, llnode);
 
 		llnode = llist_next(llnode);
@@ -151,6 +161,7 @@ static void irq_work_run_list(struct llist_head *list)
 		 * while we are in the middle of the func.
 		 */
 		flags = work->flags & ~IRQ_WORK_PENDING;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		xchg(&work->flags, flags);
 
 		work->func(work);
@@ -168,6 +179,7 @@ static void irq_work_run_list(struct llist_head *list)
  */
 void irq_work_run(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	irq_work_run_list(this_cpu_ptr(&raised_list));
 	irq_work_run_list(this_cpu_ptr(&lazy_list));
 }
@@ -178,7 +190,9 @@ void irq_work_tick(void)
 	struct llist_head *raised = this_cpu_ptr(&raised_list);
 
 	if (!llist_empty(raised) && !arch_irq_work_has_interrupt())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		irq_work_run_list(raised);
+}
 	irq_work_run_list(this_cpu_ptr(&lazy_list));
 }
 
@@ -188,6 +202,7 @@ void irq_work_tick(void)
  */
 void irq_work_sync(struct irq_work *work)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WARN_ON_ONCE(irqs_disabled());
 
 	while (work->flags & IRQ_WORK_BUSY)
diff --git a/kernel/jump_label.c b/kernel/jump_label.c
index 7c3774a..a046d00 100644
--- a/kernel/jump_label.c
+++ b/kernel/jump_label.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * jump label support
  *
diff --git a/kernel/kallsyms.c b/kernel/kallsyms.c
index 127e7cf..cdff874 100644
--- a/kernel/kallsyms.c
+++ b/kernel/kallsyms.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * kallsyms.c: in-kernel printing of symbolic oopses and stack traces.
  *
@@ -53,6 +55,7 @@ extern const unsigned long kallsyms_markers[] __weak;
 
 static inline int is_kernel_inittext(unsigned long addr)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (addr >= (unsigned long)_sinittext
 	    && addr <= (unsigned long)_einittext)
 		return 1;
@@ -64,11 +67,13 @@ static inline int is_kernel_text(unsigned long addr)
 	if ((addr >= (unsigned long)_stext && addr <= (unsigned long)_etext) ||
 	    arch_is_kernel_text(addr))
 		return 1;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return in_gate_area_no_mm(addr);
 }
 
 static inline int is_kernel(unsigned long addr)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (addr >= (unsigned long)_stext && addr <= (unsigned long)_end)
 		return 1;
 	return in_gate_area_no_mm(addr);
@@ -76,8 +81,11 @@ static inline int is_kernel(unsigned long addr)
 
 static int is_ksym_addr(unsigned long addr)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (IS_ENABLED(CONFIG_KALLSYMS_ALL))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return is_kernel(addr);
+}
 
 	return is_kernel_text(addr) || is_kernel_inittext(addr);
 }
@@ -121,7 +129,9 @@ static unsigned int kallsyms_expand_symbol(unsigned int off,
 				result++;
 				maxlen--;
 			} else
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				skipped_first = 1;
+}
 			tptr++;
 		}
 	}
@@ -177,16 +187,23 @@ static unsigned int get_symbol_offset(unsigned long pos)
 
 static unsigned long kallsyms_sym_address(int idx)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!IS_ENABLED(CONFIG_KALLSYMS_BASE_RELATIVE))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return kallsyms_addresses[idx];
+}
 
 	/* values are unsigned offsets if --absolute-percpu is not in effect */
 	if (!IS_ENABLED(CONFIG_KALLSYMS_ABSOLUTE_PERCPU))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return kallsyms_relative_base + (u32)kallsyms_offsets[idx];
+}
 
 	/* ...otherwise, positive offsets are absolute values */
 	if (kallsyms_offsets[idx] >= 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return kallsyms_offsets[idx];
+}
 
 	/* ...and negative offsets are relative to kallsyms_relative_base - 1 */
 	return kallsyms_relative_base - 1 - kallsyms_offsets[idx];
@@ -205,6 +222,7 @@ unsigned long kallsyms_lookup_name(const char *name)
 		if (strcmp(namebuf, name) == 0)
 			return kallsyms_sym_address(i);
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return module_kallsyms_lookup_name(name);
 }
 EXPORT_SYMBOL_GPL(kallsyms_lookup_name);
@@ -218,6 +236,7 @@ int kallsyms_on_each_symbol(int (*fn)(void *, const char *, struct module *,
 	unsigned int off;
 	int ret;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (i = 0, off = 0; i < kallsyms_num_syms; i++) {
 		off = kallsyms_expand_symbol(off, namebuf, ARRAY_SIZE(namebuf));
 		ret = fn(data, namebuf, NULL, kallsyms_sym_address(i));
@@ -237,7 +256,9 @@ static unsigned long get_symbol_pos(unsigned long addr,
 
 	/* This kernel should never had been booted. */
 	if (!IS_ENABLED(CONFIG_KALLSYMS_BASE_RELATIVE))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		BUG_ON(!kallsyms_addresses);
+}
 	else
 		BUG_ON(!kallsyms_offsets);
 
@@ -248,7 +269,9 @@ static unsigned long get_symbol_pos(unsigned long addr,
 	while (high - low > 1) {
 		mid = low + (high - low) / 2;
 		if (kallsyms_sym_address(mid) <= addr)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			low = mid;
+}
 		else
 			high = mid;
 	}
@@ -265,6 +288,7 @@ static unsigned long get_symbol_pos(unsigned long addr,
 	/* Search for next non-aliased symbol. */
 	for (i = low + 1; i < kallsyms_num_syms; i++) {
 		if (kallsyms_sym_address(i) > symbol_start) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			symbol_end = kallsyms_sym_address(i);
 			break;
 		}
@@ -272,10 +296,16 @@ static unsigned long get_symbol_pos(unsigned long addr,
 
 	/* If we found no next symbol, we use the end of the section. */
 	if (!symbol_end) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (is_kernel_inittext(addr))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			symbol_end = (unsigned long)_einittext;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		else if (IS_ENABLED(CONFIG_KALLSYMS_ALL))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			symbol_end = (unsigned long)_end;
+}
 		else
 			symbol_end = (unsigned long)_etext;
 	}
@@ -298,6 +328,7 @@ int kallsyms_lookup_size_offset(unsigned long addr, unsigned long *symbolsize,
 
 	if (is_ksym_addr(addr))
 		return !!get_symbol_pos(addr, symbolsize, offset);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return !!module_address_lookup(addr, symbolsize, offset, NULL, namebuf) ||
 	       !!__bpf_address_lookup(addr, symbolsize, offset, namebuf);
 }
@@ -327,7 +358,10 @@ const char *kallsyms_lookup(unsigned long addr,
 		kallsyms_expand_symbol(get_symbol_offset(pos),
 				       namebuf, KSYM_NAME_LEN);
 		if (modname)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			*modname = NULL;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return namebuf;
 	}
 
@@ -335,13 +369,16 @@ const char *kallsyms_lookup(unsigned long addr,
 	ret = module_address_lookup(addr, symbolsize, offset,
 				    modname, namebuf);
 	if (!ret)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ret = bpf_address_lookup(addr, symbolsize,
 					 offset, modname, namebuf);
+}
 	return ret;
 }
 
 int lookup_symbol_name(unsigned long addr, char *symname)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	symname[0] = '\0';
 	symname[KSYM_NAME_LEN - 1] = '\0';
 
@@ -361,6 +398,7 @@ int lookup_symbol_name(unsigned long addr, char *symname)
 int lookup_symbol_attrs(unsigned long addr, unsigned long *size,
 			unsigned long *offset, char *modname, char *name)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	name[0] = '\0';
 	name[KSYM_NAME_LEN - 1] = '\0';
 
@@ -390,7 +428,9 @@ static int __sprint_symbol(char *buffer, unsigned long address,
 	address += symbol_offset;
 	name = kallsyms_lookup(address, &size, &offset, &modname, buffer);
 	if (!name)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return sprintf(buffer, "0x%lx", address - symbol_offset);
+}
 
 	if (name != buffer)
 		strcpy(buffer, name);
@@ -419,6 +459,7 @@ static int __sprint_symbol(char *buffer, unsigned long address,
  */
 int sprint_symbol(char *buffer, unsigned long address)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return __sprint_symbol(buffer, address, 0, 1);
 }
 EXPORT_SYMBOL_GPL(sprint_symbol);
@@ -436,6 +477,7 @@ EXPORT_SYMBOL_GPL(sprint_symbol);
  */
 int sprint_symbol_no_offset(char *buffer, unsigned long address)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return __sprint_symbol(buffer, address, 0, 0);
 }
 EXPORT_SYMBOL_GPL(sprint_symbol_no_offset);
@@ -456,6 +498,7 @@ EXPORT_SYMBOL_GPL(sprint_symbol_no_offset);
  */
 int sprint_backtrace(char *buffer, unsigned long address)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return __sprint_symbol(buffer, address, -1, 1);
 }
 
@@ -484,6 +527,7 @@ struct kallsym_iter {
 
 static int get_ksymbol_mod(struct kallsym_iter *iter)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	int ret = module_get_kallsym(iter->pos - kallsyms_num_syms,
 				     &iter->value, &iter->type,
 				     iter->name, iter->module_name,
@@ -498,6 +542,7 @@ static int get_ksymbol_mod(struct kallsym_iter *iter)
 
 static int get_ksymbol_bpf(struct kallsym_iter *iter)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	iter->module_name[0] = '\0';
 	iter->exported = 0;
 	return bpf_get_kallsym(iter->pos - iter->pos_mod_end,
@@ -522,6 +567,7 @@ static unsigned long get_ksymbol_core(struct kallsym_iter *iter)
 
 static void reset_iter(struct kallsym_iter *iter, loff_t new_pos)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	iter->name[0] = '\0';
 	iter->nameoff = get_symbol_offset(new_pos);
 	iter->pos = new_pos;
@@ -531,6 +577,7 @@ static void reset_iter(struct kallsym_iter *iter, loff_t new_pos)
 
 static int update_iter_mod(struct kallsym_iter *iter, loff_t pos)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	iter->pos = pos;
 
 	if (iter->pos_mod_end > 0 &&
@@ -562,6 +609,7 @@ static int update_iter(struct kallsym_iter *iter, loff_t pos)
 
 static void *s_next(struct seq_file *m, void *p, loff_t *pos)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	(*pos)++;
 
 	if (!update_iter(m->private, *pos))
@@ -571,6 +619,7 @@ static void *s_next(struct seq_file *m, void *p, loff_t *pos)
 
 static void *s_start(struct seq_file *m, loff_t *pos)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!update_iter(m->private, *pos))
 		return NULL;
 	return m->private;
@@ -586,7 +635,9 @@ static int s_show(struct seq_file *m, void *p)
 
 	/* Some debugging symbols have no name.  Ignore them. */
 	if (!iter->name[0])
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	if (iter->module_name[0]) {
 		char type;
@@ -622,7 +673,9 @@ static int kallsyms_open(struct inode *inode, struct file *file)
 	struct kallsym_iter *iter;
 	iter = __seq_open_private(file, &kallsyms_op, sizeof(*iter));
 	if (!iter)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 	reset_iter(iter, 0);
 
 	return 0;
diff --git a/kernel/kcmp.c b/kernel/kcmp.c
index a0e3d7a..3ebfaac 100644
--- a/kernel/kcmp.c
+++ b/kernel/kcmp.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 #include <linux/kernel.h>
 #include <linux/syscalls.h>
diff --git a/kernel/kmod.c b/kernel/kmod.c
index bc6addd..fdb75c0 100644
--- a/kernel/kmod.c
+++ b/kernel/kmod.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * kmod - the kernel module loader
  */
@@ -137,30 +139,40 @@ int __request_module(bool wait, const char *fmt, ...)
 	WARN_ON_ONCE(wait && current_is_async());
 
 	if (!modprobe_path[0])
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	va_start(args, fmt);
 	ret = vsnprintf(module_name, MODULE_NAME_LEN, fmt, args);
 	va_end(args);
 	if (ret >= MODULE_NAME_LEN)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENAMETOOLONG;
+}
 
 	ret = security_kernel_module_request(module_name);
 	if (ret)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ret;
+}
 
 	if (atomic_dec_if_positive(&kmod_concurrent_max) < 0) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_warn_ratelimited("request_module: kmod_concurrent_max (%u) close to 0 (max_modprobes: %u), for module %s, throttling...",
 				    atomic_read(&kmod_concurrent_max),
 				    MAX_KMOD_CONCURRENT, module_name);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ret = wait_event_killable_timeout(kmod_wq,
 						  atomic_dec_if_positive(&kmod_concurrent_max) >= 0,
 						  MAX_KMOD_ALL_BUSY_TIMEOUT * HZ);
 		if (!ret) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			pr_warn_ratelimited("request_module: modprobe %s cannot be processed, kmod busy with %d threads for more than %d seconds now",
 					    module_name, MAX_KMOD_CONCURRENT, MAX_KMOD_ALL_BUSY_TIMEOUT);
 			return -ETIME;
 		} else if (ret == -ERESTARTSYS) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			pr_warn_ratelimited("request_module: sigkill sent for modprobe %s, giving up", module_name);
 			return ret;
 		}
diff --git a/kernel/kprobes.c b/kernel/kprobes.c
index a66e838..da1a996 100644
--- a/kernel/kprobes.c
+++ b/kernel/kprobes.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  *  Kernel Probes (KProbes)
  *  kernel/kprobes.c
@@ -108,6 +110,7 @@ struct kprobe_insn_page {
 
 static int slots_per_page(struct kprobe_insn_cache *c)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return PAGE_SIZE/(c->insn_size * sizeof(kprobe_opcode_t));
 }
 
@@ -119,11 +122,13 @@ enum kprobe_slot_state {
 
 static void *alloc_insn_page(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return module_alloc(PAGE_SIZE);
 }
 
 void __weak free_insn_page(void *page)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	module_memfree(page);
 }
 
@@ -204,6 +209,7 @@ kprobe_opcode_t *__get_insn_slot(struct kprobe_insn_cache *c)
 /* Return 1 if all garbages are collected, otherwise 0. */
 static int collect_one_slot(struct kprobe_insn_page *kip, int idx)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	kip->slot_used[idx] = SLOT_CLEAN;
 	kip->nused--;
 	if (kip->nused == 0) {
@@ -231,6 +237,7 @@ static int collect_garbage_slots(struct kprobe_insn_cache *c)
 	/* Ensure no-one is interrupted on the garbages */
 	synchronize_sched();
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry_safe(kip, next, &c->pages, list) {
 		int i;
 		if (kip->ngarbage == 0)
@@ -253,6 +260,7 @@ void __free_insn_slot(struct kprobe_insn_cache *c,
 
 	mutex_lock(&c->mutex);
 	rcu_read_lock();
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry_rcu(kip, &c->pages, list) {
 		idx = ((long)slot - (long)kip->insns) /
 			(c->insn_size * sizeof(kprobe_opcode_t));
@@ -291,6 +299,7 @@ bool __is_insn_slot_addr(struct kprobe_insn_cache *c, unsigned long addr)
 	bool ret = false;
 
 	rcu_read_lock();
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry_rcu(kip, &c->pages, list) {
 		if (addr >= (unsigned long)kip->insns &&
 		    addr < (unsigned long)kip->insns + PAGE_SIZE) {
@@ -319,11 +328,13 @@ struct kprobe_insn_cache kprobe_optinsn_slots = {
 /* We have preemption disabled.. so it is safe to use __ versions */
 static inline void set_kprobe_instance(struct kprobe *kp)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	__this_cpu_write(kprobe_instance, kp);
 }
 
 static inline void reset_kprobe_instance(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	__this_cpu_write(kprobe_instance, NULL);
 }
 
@@ -339,6 +350,7 @@ struct kprobe *get_kprobe(void *addr)
 	struct kprobe *p;
 
 	head = &kprobe_table[hash_ptr(addr, KPROBE_HASH_BITS)];
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	hlist_for_each_entry_rcu(p, head, hlist) {
 		if (p->addr == addr)
 			return p;
@@ -353,12 +365,14 @@ static int aggr_pre_handler(struct kprobe *p, struct pt_regs *regs);
 /* Return true if the kprobe is an aggregator */
 static inline int kprobe_aggrprobe(struct kprobe *p)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return p->pre_handler == aggr_pre_handler;
 }
 
 /* Return true(!0) if the kprobe is unused */
 static inline int kprobe_unused(struct kprobe *p)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return kprobe_aggrprobe(p) && kprobe_disabled(p) &&
 	       list_empty(&p->list);
 }
@@ -368,6 +382,7 @@ static inline int kprobe_unused(struct kprobe *p)
  */
 static inline void copy_kprobe(struct kprobe *ap, struct kprobe *p)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	memcpy(&p->opcode, &ap->opcode, sizeof(kprobe_opcode_t));
 	memcpy(&p->ainsn, &ap->ainsn, sizeof(struct arch_specific_insn));
 }
@@ -384,6 +399,7 @@ void opt_pre_handler(struct kprobe *p, struct pt_regs *regs)
 {
 	struct kprobe *kp;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry_rcu(kp, &p->list, list) {
 		if (kp->pre_handler && likely(!kprobe_disabled(kp))) {
 			set_kprobe_instance(kp);
@@ -399,6 +415,7 @@ static void free_aggr_kprobe(struct kprobe *p)
 {
 	struct optimized_kprobe *op;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	op = container_of(p, struct optimized_kprobe, kp);
 	arch_remove_optimized_kprobe(op);
 	arch_remove_kprobe(p);
@@ -411,6 +428,7 @@ static inline int kprobe_optready(struct kprobe *p)
 	struct optimized_kprobe *op;
 
 	if (kprobe_aggrprobe(p)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		op = container_of(p, struct optimized_kprobe, kp);
 		return arch_prepared_optinsn(&op->optinsn);
 	}
@@ -425,7 +443,9 @@ static inline int kprobe_disarmed(struct kprobe *p)
 
 	/* If kprobe is not aggr/opt probe, just return kprobe is disabled */
 	if (!kprobe_aggrprobe(p))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return kprobe_disabled(p);
+}
 
 	op = container_of(p, struct optimized_kprobe, kp);
 
@@ -438,6 +458,7 @@ static int kprobe_queued(struct kprobe *p)
 	struct optimized_kprobe *op;
 
 	if (kprobe_aggrprobe(p)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		op = container_of(p, struct optimized_kprobe, kp);
 		if (!list_empty(&op->list))
 			return 1;
@@ -518,7 +539,9 @@ static void do_unoptimize_kprobes(void)
 
 	/* Unoptimization must be done anytime */
 	if (list_empty(&unoptimizing_list))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	mutex_lock(&text_mutex);
 	arch_unoptimize_kprobes(&unoptimizing_list, &freeing_list);
@@ -545,6 +568,7 @@ static void do_free_cleaned_kprobes(void)
 {
 	struct optimized_kprobe *op, *tmp;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry_safe(op, tmp, &freeing_list, list) {
 		BUG_ON(!kprobe_unused(&op->kp));
 		list_del_init(&op->list);
@@ -555,12 +579,14 @@ static void do_free_cleaned_kprobes(void)
 /* Start optimizer after OPTIMIZE_DELAY passed */
 static void kick_kprobe_optimizer(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	schedule_delayed_work(&optimizing_work, OPTIMIZE_DELAY);
 }
 
 /* Kprobe jump optimizer */
 static void kprobe_optimizer(struct work_struct *work)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	mutex_lock(&kprobe_mutex);
 	cpus_read_lock();
 	/* Lock modules while optimizing kprobes */
@@ -601,6 +627,7 @@ static void kprobe_optimizer(struct work_struct *work)
 /* Wait for completing optimization and unoptimization */
 void wait_for_kprobe_optimizer(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	mutex_lock(&kprobe_mutex);
 
 	while (!list_empty(&optimizing_list) || !list_empty(&unoptimizing_list)) {
@@ -654,6 +681,7 @@ static void optimize_kprobe(struct kprobe *p)
 /* Short cut to direct unoptimizing */
 static void force_unoptimize_kprobe(struct optimized_kprobe *op)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_cpus_held();
 	arch_unoptimize_kprobe(op);
 	if (kprobe_disabled(&op->kp))
@@ -665,6 +693,7 @@ static void unoptimize_kprobe(struct kprobe *p, bool force)
 {
 	struct optimized_kprobe *op;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!kprobe_aggrprobe(p) || kprobe_disarmed(p))
 		return; /* This is not an optprobe nor optimized */
 
@@ -704,6 +733,7 @@ static void reuse_unused_kprobe(struct kprobe *ap)
 {
 	struct optimized_kprobe *op;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	BUG_ON(!kprobe_unused(ap));
 	/*
 	 * Unused kprobe MUST be on the way of delayed unoptimizing (means
@@ -725,6 +755,7 @@ static void kill_optimized_kprobe(struct kprobe *p)
 {
 	struct optimized_kprobe *op;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	op = container_of(p, struct optimized_kprobe, kp);
 	if (!list_empty(&op->list))
 		/* Dequeue from the (un)optimization queue */
@@ -749,6 +780,7 @@ static void kill_optimized_kprobe(struct kprobe *p)
 static inline
 void __prepare_optimized_kprobe(struct optimized_kprobe *op, struct kprobe *p)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!kprobe_ftrace(p))
 		arch_prepare_optimized_kprobe(op, p);
 }
@@ -758,6 +790,7 @@ static void prepare_optimized_kprobe(struct kprobe *p)
 {
 	struct optimized_kprobe *op;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	op = container_of(p, struct optimized_kprobe, kp);
 	__prepare_optimized_kprobe(op, p);
 }
@@ -769,7 +802,9 @@ static struct kprobe *alloc_aggr_kprobe(struct kprobe *p)
 
 	op = kzalloc(sizeof(struct optimized_kprobe), GFP_KERNEL);
 	if (!op)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 
 	INIT_LIST_HEAD(&op->list);
 	op->kp.addr = p->addr;
@@ -791,7 +826,9 @@ static void try_to_optimize_kprobe(struct kprobe *p)
 
 	/* Impossible to optimize ftrace-based kprobe */
 	if (kprobe_ftrace(p))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	/* For preparing optimization, jump_label_text_reserved() is called */
 	cpus_read_lock();
@@ -831,6 +868,7 @@ static void optimize_all_kprobes(void)
 	if (kprobes_allow_optimization)
 		goto out;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	cpus_read_lock();
 	kprobes_allow_optimization = true;
 	for (i = 0; i < KPROBE_TABLE_SIZE; i++) {
@@ -854,6 +892,7 @@ static void unoptimize_all_kprobes(void)
 	mutex_lock(&kprobe_mutex);
 	/* If optimization is already prohibited, just return */
 	if (!kprobes_allow_optimization) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		mutex_unlock(&kprobe_mutex);
 		return;
 	}
@@ -884,6 +923,7 @@ int proc_kprobes_optimization_handler(struct ctl_table *table, int write,
 	int ret;
 
 	mutex_lock(&kprobe_sysctl_mutex);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	sysctl_kprobes_optimization = kprobes_allow_optimization ? 1 : 0;
 	ret = proc_dointvec_minmax(table, write, buffer, length, ppos);
 
@@ -921,6 +961,7 @@ static void __disarm_kprobe(struct kprobe *p, bool reopt)
 	unoptimize_kprobe(p, kprobes_all_disarmed);
 
 	if (!kprobe_queued(p)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		arch_disarm_kprobe(p);
 		/* If another kprobe was blocked, optimize it. */
 		_p = get_optimized_kprobe((unsigned long)p->addr);
@@ -1015,6 +1056,7 @@ static void disarm_kprobe_ftrace(struct kprobe *p)
 /* Arm a kprobe with text_mutex */
 static void arm_kprobe(struct kprobe *kp)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (unlikely(kprobe_ftrace(kp))) {
 		arm_kprobe_ftrace(kp);
 		return;
@@ -1029,6 +1071,7 @@ static void arm_kprobe(struct kprobe *kp)
 /* Disarm a kprobe with text_mutex */
 static void disarm_kprobe(struct kprobe *kp, bool reopt)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (unlikely(kprobe_ftrace(kp))) {
 		disarm_kprobe_ftrace(kp);
 		return;
@@ -1049,6 +1092,7 @@ static int aggr_pre_handler(struct kprobe *p, struct pt_regs *regs)
 {
 	struct kprobe *kp;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry_rcu(kp, &p->list, list) {
 		if (kp->pre_handler && likely(!kprobe_disabled(kp))) {
 			set_kprobe_instance(kp);
@@ -1066,6 +1110,7 @@ static void aggr_post_handler(struct kprobe *p, struct pt_regs *regs,
 {
 	struct kprobe *kp;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry_rcu(kp, &p->list, list) {
 		if (kp->post_handler && likely(!kprobe_disabled(kp))) {
 			set_kprobe_instance(kp);
@@ -1079,6 +1124,7 @@ NOKPROBE_SYMBOL(aggr_post_handler);
 static int aggr_fault_handler(struct kprobe *p, struct pt_regs *regs,
 			      int trapnr)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct kprobe *cur = __this_cpu_read(kprobe_instance);
 
 	/*
@@ -1095,6 +1141,7 @@ NOKPROBE_SYMBOL(aggr_fault_handler);
 
 static int aggr_break_handler(struct kprobe *p, struct pt_regs *regs)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct kprobe *cur = __this_cpu_read(kprobe_instance);
 	int ret = 0;
 
@@ -1112,6 +1159,7 @@ void kprobes_inc_nmissed_count(struct kprobe *p)
 {
 	struct kprobe *kp;
 	if (!kprobe_aggrprobe(p)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		p->nmissed++;
 	} else {
 		list_for_each_entry_rcu(kp, &p->list, list)
@@ -1130,6 +1178,7 @@ void recycle_rp_inst(struct kretprobe_instance *ri,
 	hlist_del(&ri->hlist);
 	INIT_HLIST_NODE(&ri->hlist);
 	if (likely(rp)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		raw_spin_lock(&rp->lock);
 		hlist_add_head(&ri->hlist, &rp->free_instances);
 		raw_spin_unlock(&rp->lock);
@@ -1143,6 +1192,7 @@ void kretprobe_hash_lock(struct task_struct *tsk,
 			 struct hlist_head **head, unsigned long *flags)
 __acquires(hlist_lock)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	unsigned long hash = hash_ptr(tsk, KPROBE_HASH_BITS);
 	raw_spinlock_t *hlist_lock;
 
@@ -1156,6 +1206,7 @@ static void kretprobe_table_lock(unsigned long hash,
 				 unsigned long *flags)
 __acquires(hlist_lock)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	raw_spinlock_t *hlist_lock = kretprobe_table_lock_ptr(hash);
 	raw_spin_lock_irqsave(hlist_lock, *flags);
 }
@@ -1165,6 +1216,7 @@ void kretprobe_hash_unlock(struct task_struct *tsk,
 			   unsigned long *flags)
 __releases(hlist_lock)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	unsigned long hash = hash_ptr(tsk, KPROBE_HASH_BITS);
 	raw_spinlock_t *hlist_lock;
 
@@ -1177,6 +1229,7 @@ static void kretprobe_table_unlock(unsigned long hash,
 				   unsigned long *flags)
 __releases(hlist_lock)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	raw_spinlock_t *hlist_lock = kretprobe_table_lock_ptr(hash);
 	raw_spin_unlock_irqrestore(hlist_lock, *flags);
 }
@@ -1199,16 +1252,21 @@ void kprobe_flush_task(struct task_struct *tk)
 		/* Early boot.  kretprobe_table_locks not yet initialized. */
 		return;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	INIT_HLIST_HEAD(&empty_rp);
 	hash = hash_ptr(tk, KPROBE_HASH_BITS);
 	head = &kretprobe_inst_table[hash];
 	kretprobe_table_lock(hash, &flags);
 	hlist_for_each_entry_safe(ri, tmp, head, hlist) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (ri->task == tk)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			recycle_rp_inst(ri, &empty_rp);
+}
 	}
 	kretprobe_table_unlock(hash, &flags);
 	hlist_for_each_entry_safe(ri, tmp, &empty_rp, hlist) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		hlist_del(&ri->hlist);
 		kfree(ri);
 	}
@@ -1220,6 +1278,7 @@ static inline void free_rp_inst(struct kretprobe *rp)
 	struct kretprobe_instance *ri;
 	struct hlist_node *next;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	hlist_for_each_entry_safe(ri, next, &rp->free_instances, hlist) {
 		hlist_del(&ri->hlist);
 		kfree(ri);
@@ -1253,6 +1312,7 @@ NOKPROBE_SYMBOL(cleanup_rp_inst);
 */
 static int add_new_kprobe(struct kprobe *ap, struct kprobe *p)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	BUG_ON(kprobe_gone(ap) || kprobe_gone(p));
 
 	if (p->break_handler || p->post_handler)
@@ -1381,7 +1441,9 @@ bool within_kprobe_blacklist(unsigned long addr)
 	struct kprobe_blacklist_entry *ent;
 
 	if (arch_within_kprobe_blacklist(addr))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return true;
+}
 	/*
 	 * If there exists a kprobe_blacklist, verify and
 	 * fail any probe registration in the prohibited area
@@ -1403,6 +1465,7 @@ bool within_kprobe_blacklist(unsigned long addr)
 static kprobe_opcode_t *_kprobe_addr(kprobe_opcode_t *addr,
 			const char *symbol_name, unsigned int offset)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if ((symbol_name && addr) || (!symbol_name && !addr))
 		goto invalid;
 
@@ -1422,6 +1485,7 @@ static kprobe_opcode_t *_kprobe_addr(kprobe_opcode_t *addr,
 
 static kprobe_opcode_t *kprobe_addr(struct kprobe *p)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return _kprobe_addr(p->addr, p->symbol_name, p->offset);
 }
 
@@ -1432,7 +1496,9 @@ static struct kprobe *__get_valid_kprobe(struct kprobe *p)
 
 	ap = get_kprobe(p->addr);
 	if (unlikely(!ap))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 
 	if (p != ap) {
 		list_for_each_entry_rcu(list_p, &ap->list, list)
@@ -1452,7 +1518,9 @@ static inline int check_kprobe_rereg(struct kprobe *p)
 
 	mutex_lock(&kprobe_mutex);
 	if (__get_valid_kprobe(p))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ret = -EINVAL;
+}
 	mutex_unlock(&kprobe_mutex);
 
 	return ret;
@@ -1483,7 +1551,9 @@ static int check_kprobe_address_safe(struct kprobe *p,
 
 	ret = arch_check_ftrace_location(p);
 	if (ret)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ret;
+}
 	jump_label_lock();
 	preempt_disable();
 
@@ -1535,7 +1605,9 @@ int register_kprobe(struct kprobe *p)
 	/* Adjust probe address from symbol */
 	addr = kprobe_addr(p);
 	if (IS_ERR(addr))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return PTR_ERR(addr);
+}
 	p->addr = addr;
 
 	ret = check_kprobe_rereg(p);
@@ -1593,6 +1665,7 @@ static int aggr_kprobe_disabled(struct kprobe *ap)
 {
 	struct kprobe *kp;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry_rcu(kp, &ap->list, list)
 		if (!kprobe_disabled(kp))
 			/*
@@ -1612,7 +1685,9 @@ static struct kprobe *__disable_kprobe(struct kprobe *p)
 	/* Get an original kprobe for return */
 	orig_p = __get_valid_kprobe(p);
 	if (unlikely(orig_p == NULL))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 
 	if (!kprobe_disabled(p)) {
 		/* Disable probe if it is a child probe */
@@ -1645,7 +1720,9 @@ static int __unregister_kprobe_top(struct kprobe *p)
 	/* Disable kprobe. This will disarm it if needed. */
 	ap = __disable_kprobe(p);
 	if (ap == NULL)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	if (ap == p)
 		/*
@@ -1716,7 +1793,9 @@ int register_kprobes(struct kprobe **kps, int num)
 	int i, ret = 0;
 
 	if (num <= 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 	for (i = 0; i < num; i++) {
 		ret = register_kprobe(kps[i]);
 		if (ret < 0) {
@@ -1731,6 +1810,7 @@ EXPORT_SYMBOL_GPL(register_kprobes);
 
 void unregister_kprobe(struct kprobe *p)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	unregister_kprobes(&p, 1);
 }
 EXPORT_SYMBOL_GPL(unregister_kprobe);
@@ -1740,7 +1820,9 @@ void unregister_kprobes(struct kprobe **kps, int num)
 	int i;
 
 	if (num <= 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 	mutex_lock(&kprobe_mutex);
 	for (i = 0; i < num; i++)
 		if (__unregister_kprobe_top(kps[i]) < 0)
@@ -1757,6 +1839,7 @@ EXPORT_SYMBOL_GPL(unregister_kprobes);
 int __weak kprobe_exceptions_notify(struct notifier_block *self,
 					unsigned long val, void *data)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return NOTIFY_DONE;
 }
 NOKPROBE_SYMBOL(kprobe_exceptions_notify);
@@ -1776,7 +1859,9 @@ int register_jprobes(struct jprobe **jps, int num)
 	int ret = 0, i;
 
 	if (num <= 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	for (i = 0; i < num; i++) {
 		ret = register_jprobe(jps[i]);
@@ -1803,6 +1888,7 @@ int register_jprobe(struct jprobe *jp)
 	 */
 	addr = arch_deref_entry_point(jp->entry);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (kallsyms_lookup_size_offset(addr, NULL, &offset) && offset == 0 &&
 	    kprobe_on_func_entry(kp->addr, kp->symbol_name, kp->offset)) {
 		kp->pre_handler = setjmp_pre_handler;
@@ -1816,6 +1902,7 @@ EXPORT_SYMBOL_GPL(register_jprobe);
 
 void unregister_jprobe(struct jprobe *jp)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	unregister_jprobes(&jp, 1);
 }
 EXPORT_SYMBOL_GPL(unregister_jprobe);
@@ -1825,7 +1912,9 @@ void unregister_jprobes(struct jprobe **jps, int num)
 	int i;
 
 	if (num <= 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 	mutex_lock(&kprobe_mutex);
 	for (i = 0; i < num; i++)
 		if (__unregister_kprobe_top(&jps[i]->kp) < 0)
@@ -1847,6 +1936,7 @@ EXPORT_SYMBOL_GPL(unregister_jprobes);
  */
 static int pre_handler_kretprobe(struct kprobe *p, struct pt_regs *regs)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct kretprobe *rp = container_of(p, struct kretprobe, kp);
 	unsigned long hash, flags = 0;
 	struct kretprobe_instance *ri;
@@ -1898,11 +1988,13 @@ NOKPROBE_SYMBOL(pre_handler_kretprobe);
 
 bool __weak arch_kprobe_on_func_entry(unsigned long offset)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return !offset;
 }
 
 bool kprobe_on_func_entry(kprobe_opcode_t *addr, const char *sym, unsigned long offset)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	kprobe_opcode_t *kp_addr = _kprobe_addr(addr, sym, offset);
 
 	if (IS_ERR(kp_addr))
@@ -1923,7 +2015,9 @@ int register_kretprobe(struct kretprobe *rp)
 	void *addr;
 
 	if (!kprobe_on_func_entry(rp->kp.addr, rp->kp.symbol_name, rp->kp.offset))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	if (kretprobe_blacklist_size) {
 		addr = kprobe_addr(&rp->kp);
@@ -1976,7 +2070,9 @@ int register_kretprobes(struct kretprobe **rps, int num)
 	int ret = 0, i;
 
 	if (num <= 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 	for (i = 0; i < num; i++) {
 		ret = register_kretprobe(rps[i]);
 		if (ret < 0) {
@@ -1991,6 +2087,7 @@ EXPORT_SYMBOL_GPL(register_kretprobes);
 
 void unregister_kretprobe(struct kretprobe *rp)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	unregister_kretprobes(&rp, 1);
 }
 EXPORT_SYMBOL_GPL(unregister_kretprobe);
@@ -2000,7 +2097,9 @@ void unregister_kretprobes(struct kretprobe **rps, int num)
 	int i;
 
 	if (num <= 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 	mutex_lock(&kprobe_mutex);
 	for (i = 0; i < num; i++)
 		if (__unregister_kprobe_top(&rps[i]->kp) < 0)
@@ -2081,7 +2180,9 @@ int disable_kprobe(struct kprobe *kp)
 
 	/* Disable this kprobe */
 	if (__disable_kprobe(kp) == NULL)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ret = -EINVAL;
+}
 
 	mutex_unlock(&kprobe_mutex);
 	return ret;
@@ -2099,6 +2200,7 @@ int enable_kprobe(struct kprobe *kp)
 	/* Check whether specified probe is valid. */
 	p = __get_valid_kprobe(kp);
 	if (unlikely(p == NULL)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ret = -EINVAL;
 		goto out;
 	}
@@ -2124,6 +2226,7 @@ EXPORT_SYMBOL_GPL(enable_kprobe);
 
 void dump_kprobe(struct kprobe *kp)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	printk(KERN_WARNING "Dumping kprobe:\n");
 	printk(KERN_WARNING "Name: %s\nAddress: %p\nOffset: %x\n",
 	       kp->symbol_name, kp->addr, kp->offset);
@@ -2150,19 +2253,24 @@ static int __init populate_kprobe_blacklist(unsigned long *start,
 
 		if (!kernel_text_address(entry) ||
 		    !kallsyms_lookup_size_offset(entry, &size, &offset)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			pr_err("Failed to find blacklist at %p\n",
 				(void *)entry);
 			continue;
 		}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ent = kmalloc(sizeof(*ent), GFP_KERNEL);
 		if (!ent)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -ENOMEM;
+}
 		ent->start_addr = entry;
 		ent->end_addr = entry + size;
 		INIT_LIST_HEAD(&ent->list);
 		list_add_tail(&ent->list, &kprobe_blacklist);
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
@@ -2176,6 +2284,7 @@ static int kprobes_module_callback(struct notifier_block *nb,
 	unsigned int i;
 	int checkcore = (val == MODULE_STATE_GOING);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (val != MODULE_STATE_GOING && val != MODULE_STATE_LIVE)
 		return NOTIFY_DONE;
 
@@ -2234,6 +2343,7 @@ static int __init init_kprobes(void)
 	err = populate_kprobe_blacklist(__start_kprobe_blacklist,
 					__stop_kprobe_blacklist);
 	if (err) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_err("kprobes: failed to populate blacklist: %d\n", err);
 		pr_err("Please take care of using kprobes.\n");
 	}
@@ -2244,8 +2354,10 @@ static int __init init_kprobes(void)
 			kretprobe_blacklist[i].addr =
 				kprobe_lookup_name(kretprobe_blacklist[i].name, 0);
 			if (!kretprobe_blacklist[i].addr)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				printk("kretprobe: lookup failed: %s\n",
 				       kretprobe_blacklist[i].name);
+}
 		}
 	}
 
@@ -2270,7 +2382,9 @@ static int __init init_kprobes(void)
 	kprobes_initialized = (err == 0);
 
 	if (!err)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		init_test_probes();
+}
 	return err;
 }
 
@@ -2281,7 +2395,9 @@ static void report_probe(struct seq_file *pi, struct kprobe *p,
 	char *kprobe_type;
 
 	if (p->pre_handler == pre_handler_kretprobe)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		kprobe_type = "r";
+}
 	else if (p->pre_handler == setjmp_pre_handler)
 		kprobe_type = "j";
 	else
@@ -2306,11 +2422,13 @@ static void report_probe(struct seq_file *pi, struct kprobe *p,
 
 static void *kprobe_seq_start(struct seq_file *f, loff_t *pos)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return (*pos < KPROBE_TABLE_SIZE) ? pos : NULL;
 }
 
 static void *kprobe_seq_next(struct seq_file *f, void *v, loff_t *pos)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	(*pos)++;
 	if (*pos >= KPROBE_TABLE_SIZE)
 		return NULL;
@@ -2333,6 +2451,7 @@ static int show_kprobe_addr(struct seq_file *pi, void *v)
 
 	head = &kprobe_table[i];
 	preempt_disable();
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	hlist_for_each_entry_rcu(p, head, hlist) {
 		sym = kallsyms_lookup((unsigned long)p->addr, NULL,
 					&offset, &modname, namebuf);
@@ -2355,6 +2474,7 @@ static const struct seq_operations kprobes_seq_ops = {
 
 static int kprobes_open(struct inode *inode, struct file *filp)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return seq_open(filp, &kprobes_seq_ops);
 }
 
@@ -2368,11 +2488,13 @@ static const struct file_operations debugfs_kprobes_operations = {
 /* kprobes/blacklist -- shows which functions can not be probed */
 static void *kprobe_blacklist_seq_start(struct seq_file *m, loff_t *pos)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return seq_list_start(&kprobe_blacklist, *pos);
 }
 
 static void *kprobe_blacklist_seq_next(struct seq_file *m, void *v, loff_t *pos)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return seq_list_next(v, &kprobe_blacklist, pos);
 }
 
@@ -2395,6 +2517,7 @@ static const struct seq_operations kprobe_blacklist_seq_ops = {
 
 static int kprobe_blacklist_open(struct inode *inode, struct file *filp)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return seq_open(filp, &kprobe_blacklist_seq_ops);
 }
 
@@ -2448,6 +2571,7 @@ static void disarm_all_kprobes(void)
 
 	/* If kprobes are already disarmed, just return */
 	if (kprobes_all_disarmed) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		mutex_unlock(&kprobe_mutex);
 		return;
 	}
@@ -2479,7 +2603,9 @@ static ssize_t read_enabled_file_bool(struct file *file,
 	char buf[3];
 
 	if (!kprobes_all_disarmed)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		buf[0] = '1';
+}
 	else
 		buf[0] = '0';
 	buf[1] = '\n';
@@ -2493,6 +2619,7 @@ static ssize_t write_enabled_file_bool(struct file *file,
 	char buf[32];
 	size_t buf_size;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	buf_size = min(count, (sizeof(buf)-1));
 	if (copy_from_user(buf, user_buf, buf_size))
 		return -EFAULT;
@@ -2529,7 +2656,9 @@ static int __init debugfs_kprobe_init(void)
 
 	dir = debugfs_create_dir("kprobes", NULL);
 	if (!dir)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 
 	file = debugfs_create_file("list", 0444, dir, NULL,
 				&debugfs_kprobes_operations);
@@ -2546,6 +2675,7 @@ static int __init debugfs_kprobe_init(void)
 	if (!file)
 		goto error;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 
 error:
diff --git a/kernel/ksysfs.c b/kernel/ksysfs.c
index 46ba853..204fb81 100644
--- a/kernel/ksysfs.c
+++ b/kernel/ksysfs.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * kernel/ksysfs.c - sysfs attributes in /sys/kernel, which
  * 		     are not related to any other subsystem
@@ -33,6 +35,7 @@ static struct kobj_attribute _name##_attr = \
 static ssize_t uevent_seqnum_show(struct kobject *kobj,
 				  struct kobj_attribute *attr, char *buf)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return sprintf(buf, "%llu\n", (unsigned long long)uevent_seqnum);
 }
 KERNEL_ATTR_RO(uevent_seqnum);
@@ -42,12 +45,14 @@ KERNEL_ATTR_RO(uevent_seqnum);
 static ssize_t uevent_helper_show(struct kobject *kobj,
 				  struct kobj_attribute *attr, char *buf)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return sprintf(buf, "%s\n", uevent_helper);
 }
 static ssize_t uevent_helper_store(struct kobject *kobj,
 				   struct kobj_attribute *attr,
 				   const char *buf, size_t count)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (count+1 > UEVENT_HELPER_PATH_LEN)
 		return -ENOENT;
 	memcpy(uevent_helper, buf, count);
@@ -63,6 +68,7 @@ KERNEL_ATTR_RW(uevent_helper);
 static ssize_t profiling_show(struct kobject *kobj,
 				  struct kobj_attribute *attr, char *buf)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return sprintf(buf, "%d\n", prof_on);
 }
 static ssize_t profiling_store(struct kobject *kobj,
@@ -72,7 +78,9 @@ static ssize_t profiling_store(struct kobject *kobj,
 	int ret;
 
 	if (prof_on)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EEXIST;
+}
 	/*
 	 * This eventually calls into get_option() which
 	 * has a ton of callers and is not const.  It is
@@ -94,6 +102,7 @@ KERNEL_ATTR_RW(profiling);
 static ssize_t kexec_loaded_show(struct kobject *kobj,
 				 struct kobj_attribute *attr, char *buf)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return sprintf(buf, "%d\n", !!kexec_image);
 }
 KERNEL_ATTR_RO(kexec_loaded);
@@ -101,6 +110,7 @@ KERNEL_ATTR_RO(kexec_loaded);
 static ssize_t kexec_crash_loaded_show(struct kobject *kobj,
 				       struct kobj_attribute *attr, char *buf)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return sprintf(buf, "%d\n", kexec_crash_loaded());
 }
 KERNEL_ATTR_RO(kexec_crash_loaded);
@@ -108,6 +118,7 @@ KERNEL_ATTR_RO(kexec_crash_loaded);
 static ssize_t kexec_crash_size_show(struct kobject *kobj,
 				       struct kobj_attribute *attr, char *buf)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return sprintf(buf, "%zu\n", crash_get_memory_size());
 }
 static ssize_t kexec_crash_size_store(struct kobject *kobj,
@@ -118,7 +129,9 @@ static ssize_t kexec_crash_size_store(struct kobject *kobj,
 	int ret;
 
 	if (kstrtoul(buf, 0, &cnt))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	ret = crash_shrink_memory(cnt);
 	return ret < 0 ? ret : count;
@@ -132,6 +145,7 @@ KERNEL_ATTR_RW(kexec_crash_size);
 static ssize_t vmcoreinfo_show(struct kobject *kobj,
 			       struct kobj_attribute *attr, char *buf)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	phys_addr_t vmcore_base = paddr_vmcoreinfo_note();
 	return sprintf(buf, "%pa %x\n", &vmcore_base,
 			(unsigned int)VMCOREINFO_NOTE_SIZE);
@@ -144,6 +158,7 @@ KERNEL_ATTR_RO(vmcoreinfo);
 static ssize_t fscaps_show(struct kobject *kobj,
 				  struct kobj_attribute *attr, char *buf)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return sprintf(buf, "%d\n", file_caps_enabled);
 }
 KERNEL_ATTR_RO(fscaps);
@@ -153,12 +168,14 @@ int rcu_expedited;
 static ssize_t rcu_expedited_show(struct kobject *kobj,
 				  struct kobj_attribute *attr, char *buf)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return sprintf(buf, "%d\n", READ_ONCE(rcu_expedited));
 }
 static ssize_t rcu_expedited_store(struct kobject *kobj,
 				   struct kobj_attribute *attr,
 				   const char *buf, size_t count)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (kstrtoint(buf, 0, &rcu_expedited))
 		return -EINVAL;
 
@@ -170,12 +187,14 @@ int rcu_normal;
 static ssize_t rcu_normal_show(struct kobject *kobj,
 			       struct kobj_attribute *attr, char *buf)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return sprintf(buf, "%d\n", READ_ONCE(rcu_normal));
 }
 static ssize_t rcu_normal_store(struct kobject *kobj,
 				struct kobj_attribute *attr,
 				const char *buf, size_t count)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (kstrtoint(buf, 0, &rcu_normal))
 		return -EINVAL;
 
@@ -195,6 +214,7 @@ static ssize_t notes_read(struct file *filp, struct kobject *kobj,
 			  struct bin_attribute *bin_attr,
 			  char *buf, loff_t off, size_t count)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	memcpy(buf, &__start_notes + off, count);
 	return count;
 }
@@ -244,6 +264,7 @@ static int __init ksysfs_init(void)
 
 	kernel_kobj = kobject_create_and_add("kernel", NULL);
 	if (!kernel_kobj) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		error = -ENOMEM;
 		goto exit;
 	}
@@ -258,6 +279,7 @@ static int __init ksysfs_init(void)
 			goto group_exit;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 
 group_exit:
diff --git a/kernel/kthread.c b/kernel/kthread.c
index 1c19edf..8f36c99 100644
--- a/kernel/kthread.c
+++ b/kernel/kthread.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /* Kernel thread helper functions.
  *   Copyright (C) 2004 IBM Corporation, Rusty Russell.
  *
@@ -124,6 +126,7 @@ bool kthread_freezable_should_stop(bool *was_frozen)
 {
 	bool frozen = false;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	might_sleep();
 
 	if (unlikely(freezing(current)))
@@ -160,6 +163,7 @@ void *kthread_data(struct task_struct *task)
  */
 void *kthread_probe_data(struct task_struct *task)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct kthread *kthread = to_kthread(task);
 	void *data = NULL;
 
@@ -182,6 +186,7 @@ static void __kthread_parkme(struct kthread *self)
 
 void kthread_parkme(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	__kthread_parkme(to_kthread(current));
 }
 EXPORT_SYMBOL_GPL(kthread_parkme);
@@ -202,11 +207,13 @@ static int kthread(void *_create)
 	/* If user was SIGKILLed, I release the structure. */
 	done = xchg(&create->done, NULL);
 	if (!done) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		kfree(create);
 		do_exit(-EINTR);
 	}
 
 	if (!self) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		create->result = ERR_PTR(-ENOMEM);
 		complete(done);
 		do_exit(-ENOMEM);
@@ -238,7 +245,9 @@ int tsk_fork_get_node(struct task_struct *tsk)
 {
 #ifdef CONFIG_NUMA
 	if (tsk == kthreadd_task)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return tsk->pref_node_fork;
+}
 #endif
 	return NUMA_NO_NODE;
 }
@@ -257,9 +266,11 @@ static void create_kthread(struct kthread_create_info *create)
 		struct completion *done = xchg(&create->done, NULL);
 
 		if (!done) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			kfree(create);
 			return;
 		}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		create->result = ERR_PTR(pid);
 		complete(done);
 	}
@@ -277,7 +288,9 @@ struct task_struct *__kthread_create_on_node(int (*threadfn)(void *data),
 						     GFP_KERNEL);
 
 	if (!create)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ERR_PTR(-ENOMEM);
+}
 	create->threadfn = threadfn;
 	create->data = data;
 	create->node = node;
@@ -300,7 +313,9 @@ struct task_struct *__kthread_create_on_node(int (*threadfn)(void *data),
 		 * that thread.
 		 */
 		if (xchg(&create->done, NULL))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return ERR_PTR(-EINTR);
+}
 		/*
 		 * kthreadd (or new kernel thread) will call complete()
 		 * shortly.
@@ -367,6 +382,7 @@ static void __kthread_bind_mask(struct task_struct *p, const struct cpumask *mas
 	unsigned long flags;
 
 	if (!wait_task_inactive(p, state)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		WARN_ON(1);
 		return;
 	}
@@ -423,7 +439,9 @@ struct task_struct *kthread_create_on_cpu(int (*threadfn)(void *data),
 	p = kthread_create_on_node(threadfn, data, cpu_to_node(cpu), namefmt,
 				   cpu);
 	if (IS_ERR(p))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return p;
+}
 	kthread_bind(p, cpu);
 	/* CPU hotplug need to bind once again when unparking the thread. */
 	set_bit(KTHREAD_IS_PER_CPU, &to_kthread(p)->flags);
@@ -479,7 +497,9 @@ int kthread_park(struct task_struct *k)
 	struct kthread *kthread = to_kthread(k);
 
 	if (WARN_ON(k->flags & PF_EXITING))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOSYS;
+}
 
 	if (!test_bit(KTHREAD_IS_PARKED, &kthread->flags)) {
 		set_bit(KTHREAD_SHOULD_PARK, &kthread->flags);
@@ -489,6 +509,7 @@ int kthread_park(struct task_struct *k)
 		}
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 EXPORT_SYMBOL_GPL(kthread_park);
@@ -515,6 +536,7 @@ int kthread_stop(struct task_struct *k)
 
 	trace_sched_kthread_stop(k);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	get_task_struct(k);
 	kthread = to_kthread(k);
 	set_bit(KTHREAD_SHOULD_STOP, &kthread->flags);
@@ -531,6 +553,7 @@ EXPORT_SYMBOL(kthread_stop);
 
 int kthreadd(void *unused)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct task_struct *tsk = current;
 
 	/* Setup a clean context for our children to inherit. */
@@ -548,6 +571,7 @@ int kthreadd(void *unused)
 			schedule();
 		__set_current_state(TASK_RUNNING);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		spin_lock(&kthread_create_lock);
 		while (!list_empty(&kthread_create_list)) {
 			struct kthread_create_info *create;
@@ -561,9 +585,11 @@ int kthreadd(void *unused)
 
 			spin_lock(&kthread_create_lock);
 		}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		spin_unlock(&kthread_create_lock);
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
@@ -571,6 +597,7 @@ void __kthread_init_worker(struct kthread_worker *worker,
 				const char *name,
 				struct lock_class_key *key)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	memset(worker, 0, sizeof(struct kthread_worker));
 	spin_lock_init(&worker->lock);
 	lockdep_set_class_and_name(&worker->lock, key, name);
@@ -652,7 +679,9 @@ __kthread_create_worker(int cpu, unsigned int flags,
 
 	worker = kzalloc(sizeof(*worker), GFP_KERNEL);
 	if (!worker)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ERR_PTR(-ENOMEM);
+}
 
 	kthread_init_worker(worker);
 
@@ -740,6 +769,7 @@ EXPORT_SYMBOL(kthread_create_worker_on_cpu);
 static inline bool queuing_blocked(struct kthread_worker *worker,
 				   struct kthread_work *work)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&worker->lock);
 
 	return !list_empty(&work->node) || work->canceling;
@@ -748,6 +778,7 @@ static inline bool queuing_blocked(struct kthread_worker *worker,
 static void kthread_insert_work_sanity_check(struct kthread_worker *worker,
 					     struct kthread_work *work)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&worker->lock);
 	WARN_ON_ONCE(!list_empty(&work->node));
 	/* Do not use a work with >1 worker, see kthread_queue_work() */
@@ -759,6 +790,7 @@ static void kthread_insert_work(struct kthread_worker *worker,
 				struct kthread_work *work,
 				struct list_head *pos)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	kthread_insert_work_sanity_check(worker, work);
 
 	list_add_tail(&work->node, pos);
@@ -785,6 +817,7 @@ bool kthread_queue_work(struct kthread_worker *worker,
 	bool ret = false;
 	unsigned long flags;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_lock_irqsave(&worker->lock, flags);
 	if (!queuing_blocked(worker, work)) {
 		kthread_insert_work(worker, work, &worker->work_list);
@@ -837,6 +870,7 @@ void __kthread_queue_delayed_work(struct kthread_worker *worker,
 	struct timer_list *timer = &dwork->timer;
 	struct kthread_work *work = &dwork->work;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WARN_ON_ONCE(timer->function != kthread_delayed_work_timer_fn ||
 		     timer->data != (unsigned long)dwork);
 
@@ -883,6 +917,7 @@ bool kthread_queue_delayed_work(struct kthread_worker *worker,
 	unsigned long flags;
 	bool ret = false;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_lock_irqsave(&worker->lock, flags);
 
 	if (!queuing_blocked(worker, work)) {
@@ -1020,6 +1055,7 @@ bool kthread_mod_delayed_work(struct kthread_worker *worker,
 	unsigned long flags;
 	int ret = false;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_lock_irqsave(&worker->lock, flags);
 
 	/* Do not bother with canceling when never queued. */
@@ -1051,6 +1087,7 @@ static bool __kthread_cancel_work_sync(struct kthread_work *work, bool is_dwork)
 	if (!worker)
 		goto out;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_lock_irqsave(&worker->lock, flags);
 	/* Work must not be used with >1 worker, see kthread_queue_work(). */
 	WARN_ON_ONCE(work->worker != worker);
@@ -1094,6 +1131,7 @@ static bool __kthread_cancel_work_sync(struct kthread_work *work, bool is_dwork)
  */
 bool kthread_cancel_work_sync(struct kthread_work *work)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return __kthread_cancel_work_sync(work, false);
 }
 EXPORT_SYMBOL_GPL(kthread_cancel_work_sync);
@@ -1109,6 +1147,7 @@ EXPORT_SYMBOL_GPL(kthread_cancel_work_sync);
  */
 bool kthread_cancel_delayed_work_sync(struct kthread_delayed_work *dwork)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return __kthread_cancel_work_sync(&dwork->work, true);
 }
 EXPORT_SYMBOL_GPL(kthread_cancel_delayed_work_sync);
@@ -1145,6 +1184,7 @@ void kthread_destroy_worker(struct kthread_worker *worker)
 	struct task_struct *task;
 
 	task = worker->task;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (WARN_ON(!task))
 		return;
 
diff --git a/kernel/locking/mutex.c b/kernel/locking/mutex.c
index 858a075..23d8f1a 100644
--- a/kernel/locking/mutex.c
+++ b/kernel/locking/mutex.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * kernel/locking/mutex.c
  *
@@ -38,6 +40,7 @@
 void
 __mutex_init(struct mutex *lock, const char *name, struct lock_class_key *key)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	atomic_long_set(&lock->owner, 0);
 	spin_lock_init(&lock->wait_lock);
 	INIT_LIST_HEAD(&lock->wait_list);
@@ -45,6 +48,7 @@ __mutex_init(struct mutex *lock, const char *name, struct lock_class_key *key)
 	osq_lock_init(&lock->osq);
 #endif
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	debug_mutex_init(lock, name, key);
 }
 EXPORT_SYMBOL(__mutex_init);
@@ -109,8 +113,11 @@ static inline struct task_struct *__mutex_trylock_or_owner(struct mutex *lock)
 
 		old = atomic_long_cmpxchg_acquire(&lock->owner, owner, curr | flags);
 		if (old == owner)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return NULL;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		owner = old;
 	}
 
@@ -138,11 +145,15 @@ static inline bool __mutex_trylock(struct mutex *lock)
  */
 static __always_inline bool __mutex_trylock_fast(struct mutex *lock)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	unsigned long curr = (unsigned long)current;
 
 	if (!atomic_long_cmpxchg_acquire(&lock->owner, 0UL, curr))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return true;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return false;
 }
 
@@ -151,8 +162,11 @@ static __always_inline bool __mutex_unlock_fast(struct mutex *lock)
 	unsigned long curr = (unsigned long)current;
 
 	if (atomic_long_cmpxchg_release(&lock->owner, curr, 0UL) == curr)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return true;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return false;
 }
 #endif
@@ -180,6 +194,7 @@ static inline bool __mutex_waiter_is_first(struct mutex *lock, struct mutex_wait
  */
 static void __mutex_handoff(struct mutex *lock, struct task_struct *task)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	unsigned long owner = atomic_long_read(&lock->owner);
 
 	for (;;) {
@@ -199,6 +214,7 @@ static void __mutex_handoff(struct mutex *lock, struct task_struct *task)
 		if (old == owner)
 			break;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		owner = old;
 	}
 }
@@ -286,6 +302,7 @@ ww_mutex_lock_acquired(struct ww_mutex *ww, struct ww_acquire_ctx *ww_ctx)
 static inline bool __sched
 __ww_ctx_stamp_after(struct ww_acquire_ctx *a, struct ww_acquire_ctx *b)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return a->stamp - b->stamp <= LONG_MAX &&
 	       (a->stamp != b->stamp || a > b);
 }
@@ -304,6 +321,7 @@ __ww_mutex_wakeup_for_backoff(struct mutex *lock, struct ww_acquire_ctx *ww_ctx)
 {
 	struct mutex_waiter *cur;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&lock->wait_lock);
 
 	list_for_each_entry(cur, &lock->wait_list, list) {
@@ -327,6 +345,7 @@ __ww_mutex_wakeup_for_backoff(struct mutex *lock, struct ww_acquire_ctx *ww_ctx)
 static __always_inline void
 ww_mutex_set_context_fastpath(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	ww_mutex_lock_acquired(lock, ctx);
 
 	lock->ctx = ctx;
@@ -366,6 +385,7 @@ ww_mutex_set_context_fastpath(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)
 static __always_inline void
 ww_mutex_set_context_slowpath(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	ww_mutex_lock_acquired(lock, ctx);
 	lock->ctx = ctx;
 }
@@ -378,6 +398,7 @@ bool ww_mutex_spin_on_owner(struct mutex *lock, struct ww_acquire_ctx *ww_ctx,
 {
 	struct ww_mutex *ww;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	ww = container_of(lock, struct ww_mutex, base);
 
 	/*
@@ -441,17 +462,22 @@ bool mutex_spin_on_owner(struct mutex *lock, struct task_struct *owner,
 		 */
 		if (!owner->on_cpu || need_resched() ||
 				vcpu_is_preempted(task_cpu(owner))) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			ret = false;
 			break;
 		}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (ww_ctx && !ww_mutex_spin_on_owner(lock, ww_ctx, waiter)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			ret = false;
 			break;
 		}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		cpu_relax();
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rcu_read_unlock();
 
 	return ret;
@@ -466,8 +492,11 @@ static inline int mutex_can_spin_on_owner(struct mutex *lock)
 	int retval = 1;
 
 	if (need_resched())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rcu_read_lock();
 	owner = __mutex_owner(lock);
 
@@ -477,6 +506,7 @@ static inline int mutex_can_spin_on_owner(struct mutex *lock)
 	 */
 	if (owner)
 		retval = owner->on_cpu && !vcpu_is_preempted(task_cpu(owner));
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rcu_read_unlock();
 
 	/*
@@ -512,6 +542,7 @@ static __always_inline bool
 mutex_optimistic_spin(struct mutex *lock, struct ww_acquire_ctx *ww_ctx,
 		      const bool use_ww_ctx, struct mutex_waiter *waiter)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!waiter) {
 		/*
 		 * The purpose of the mutex_can_spin_on_owner() function is
@@ -556,15 +587,21 @@ mutex_optimistic_spin(struct mutex *lock, struct ww_acquire_ctx *ww_ctx,
 		cpu_relax();
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!waiter)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		osq_unlock(&lock->osq);
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return true;
 
 
 fail_unlock:
 	if (!waiter)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		osq_unlock(&lock->osq);
+}
 
 fail:
 	/*
@@ -581,6 +618,7 @@ mutex_optimistic_spin(struct mutex *lock, struct ww_acquire_ctx *ww_ctx,
 		schedule_preempt_disabled();
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return false;
 }
 #else
@@ -609,7 +647,9 @@ void __sched mutex_unlock(struct mutex *lock)
 {
 #ifndef CONFIG_DEBUG_LOCK_ALLOC
 	if (__mutex_unlock_fast(lock))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 #endif
 	__mutex_unlock_slowpath(lock, _RET_IP_);
 }
@@ -649,6 +689,7 @@ static inline int __sched
 __ww_mutex_lock_check_stamp(struct mutex *lock, struct mutex_waiter *waiter,
 			    struct ww_acquire_ctx *ctx)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct ww_mutex *ww = container_of(lock, struct ww_mutex, base);
 	struct ww_acquire_ctx *hold_ctx = READ_ONCE(ww->ctx);
 	struct mutex_waiter *cur;
@@ -685,6 +726,7 @@ __ww_mutex_add_waiter(struct mutex_waiter *waiter,
 	struct list_head *pos;
 
 	if (!ww_ctx) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		list_add_tail(&waiter->list, &lock->wait_list);
 		return 0;
 	}
@@ -746,41 +788,58 @@ __mutex_lock_common(struct mutex *lock, long state, unsigned int subclass,
 
 	might_sleep();
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	ww = container_of(lock, struct ww_mutex, base);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (use_ww_ctx && ww_ctx) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (unlikely(ww_ctx == READ_ONCE(ww->ctx)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -EALREADY;
+}
 	}
 
 	preempt_disable();
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	mutex_acquire_nest(&lock->dep_map, subclass, 0, nest_lock, ip);
 
 	if (__mutex_trylock(lock) ||
 	    mutex_optimistic_spin(lock, ww_ctx, use_ww_ctx, NULL)) {
 		/* got the lock, yay! */
 		lock_acquired(&lock->dep_map, ip);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (use_ww_ctx && ww_ctx)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			ww_mutex_set_context_fastpath(ww, ww_ctx);
+}
 		preempt_enable();
 		return 0;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_lock(&lock->wait_lock);
 	/*
 	 * After waiting to acquire the wait_lock, try again.
 	 */
 	if (__mutex_trylock(lock)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (use_ww_ctx && ww_ctx)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			__ww_mutex_wakeup_for_backoff(lock, ww_ctx);
+}
 
 		goto skip_wait;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	debug_mutex_lock_common(lock, &waiter);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	debug_mutex_add_waiter(lock, &waiter, current);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lock_contended(&lock->dep_map, ip);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!use_ww_ctx) {
 		/* add waiting tasks to the end of the waitqueue (FIFO): */
 		list_add_tail(&waiter.list, &lock->wait_list);
@@ -794,13 +853,16 @@ __mutex_lock_common(struct mutex *lock, long state, unsigned int subclass,
 		if (ret)
 			goto err_early_backoff;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		waiter.ww_ctx = ww_ctx;
 	}
 
 	waiter.task = current;
 
 	if (__mutex_waiter_is_first(lock, &waiter))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		__mutex_set_flag(lock, MUTEX_FLAG_WAITERS);
+}
 
 	set_current_state(state);
 	for (;;) {
@@ -819,16 +881,20 @@ __mutex_lock_common(struct mutex *lock, long state, unsigned int subclass,
 		 * against mutex_unlock() and wake-ups do not go missing.
 		 */
 		if (unlikely(signal_pending_state(state, current))) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			ret = -EINTR;
 			goto err;
 		}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (use_ww_ctx && ww_ctx && ww_ctx->acquired > 0) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			ret = __ww_mutex_lock_check_stamp(lock, &waiter, ww_ctx);
 			if (ret)
 				goto err;
 		}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		spin_unlock(&lock->wait_lock);
 		schedule_preempt_disabled();
 
@@ -839,7 +905,9 @@ __mutex_lock_common(struct mutex *lock, long state, unsigned int subclass,
 		if ((use_ww_ctx && ww_ctx) || !first) {
 			first = __mutex_waiter_is_first(lock, &waiter);
 			if (first)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				__mutex_set_flag(lock, MUTEX_FLAG_HANDOFF);
+}
 		}
 
 		set_current_state(state);
@@ -852,36 +920,49 @@ __mutex_lock_common(struct mutex *lock, long state, unsigned int subclass,
 		    (first && mutex_optimistic_spin(lock, ww_ctx, use_ww_ctx, &waiter)))
 			break;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		spin_lock(&lock->wait_lock);
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_lock(&lock->wait_lock);
 acquired:
 	__set_current_state(TASK_RUNNING);
 
 	mutex_remove_waiter(lock, &waiter, current);
 	if (likely(list_empty(&lock->wait_list)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		__mutex_clear_flag(lock, MUTEX_FLAGS);
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	debug_mutex_free_waiter(&waiter);
 
 skip_wait:
 	/* got the lock - cleanup and rejoice! */
 	lock_acquired(&lock->dep_map, ip);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (use_ww_ctx && ww_ctx)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ww_mutex_set_context_slowpath(ww, ww_ctx);
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_unlock(&lock->wait_lock);
 	preempt_enable();
 	return 0;
 
 err:
 	__set_current_state(TASK_RUNNING);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	mutex_remove_waiter(lock, &waiter, current);
 err_early_backoff:
 	spin_unlock(&lock->wait_lock);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	debug_mutex_free_waiter(&waiter);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	mutex_release(&lock->dep_map, 1, ip);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	preempt_enable();
 	return ret;
 }
@@ -898,6 +979,7 @@ __ww_mutex_lock(struct mutex *lock, long state, unsigned int subclass,
 		struct lockdep_map *nest_lock, unsigned long ip,
 		struct ww_acquire_ctx *ww_ctx)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return __mutex_lock_common(lock, state, subclass, nest_lock, ip, ww_ctx, true);
 }
 
@@ -1015,6 +1097,7 @@ static noinline void __sched __mutex_unlock_slowpath(struct mutex *lock, unsigne
 	DEFINE_WAKE_Q(wake_q);
 	unsigned long owner;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	mutex_release(&lock->dep_map, 1, ip);
 
 	/*
@@ -1042,13 +1125,17 @@ static noinline void __sched __mutex_unlock_slowpath(struct mutex *lock, unsigne
 			if (owner & MUTEX_FLAG_WAITERS)
 				break;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return;
 		}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		owner = old;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_lock(&lock->wait_lock);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	debug_mutex_unlock(lock);
 	if (!list_empty(&lock->wait_list)) {
 		/* get the first entry from the wait-list: */
@@ -1058,6 +1145,7 @@ static noinline void __sched __mutex_unlock_slowpath(struct mutex *lock, unsigne
 
 		next = waiter->task;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		debug_mutex_wake_waiter(lock, waiter);
 		wake_q_add(&wake_q, next);
 	}
@@ -1065,6 +1153,7 @@ static noinline void __sched __mutex_unlock_slowpath(struct mutex *lock, unsigne
 	if (owner & MUTEX_FLAG_HANDOFF)
 		__mutex_handoff(lock, next);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_unlock(&lock->wait_lock);
 
 	wake_up_q(&wake_q);
@@ -1097,7 +1186,9 @@ int __sched mutex_lock_interruptible(struct mutex *lock)
 	might_sleep();
 
 	if (__mutex_trylock_fast(lock))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	return __mutex_lock_interruptible_slowpath(lock);
 }
@@ -1109,8 +1200,11 @@ int __sched mutex_lock_killable(struct mutex *lock)
 	might_sleep();
 
 	if (__mutex_trylock_fast(lock))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return __mutex_lock_killable_slowpath(lock);
 }
 EXPORT_SYMBOL(mutex_lock_killable);
@@ -1134,6 +1228,7 @@ __mutex_lock_slowpath(struct mutex *lock)
 static noinline int __sched
 __mutex_lock_killable_slowpath(struct mutex *lock)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return __mutex_lock(lock, TASK_KILLABLE, 0, NULL, _RET_IP_);
 }
 
@@ -1179,7 +1274,9 @@ int __sched mutex_trylock(struct mutex *lock)
 	bool locked = __mutex_trylock(lock);
 
 	if (locked)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		mutex_acquire(&lock->dep_map, 0, 1, _RET_IP_);
+}
 
 	return locked;
 }
@@ -1189,6 +1286,7 @@ EXPORT_SYMBOL(mutex_trylock);
 int __sched
 ww_mutex_lock(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	might_sleep();
 
 	if (__mutex_trylock_fast(&lock->base)) {
@@ -1204,6 +1302,7 @@ EXPORT_SYMBOL(ww_mutex_lock);
 int __sched
 ww_mutex_lock_interruptible(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	might_sleep();
 
 	if (__mutex_trylock_fast(&lock->base)) {
@@ -1229,7 +1328,9 @@ int atomic_dec_and_mutex_lock(atomic_t *cnt, struct mutex *lock)
 {
 	/* dec if we can't possibly hit 0 */
 	if (atomic_add_unless(cnt, -1, 1))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 	/* we might hit 0, so take the lock */
 	mutex_lock(lock);
 	if (!atomic_dec_and_test(cnt)) {
diff --git a/kernel/locking/percpu-rwsem.c b/kernel/locking/percpu-rwsem.c
index 883cf1b..c6f72b8 100644
--- a/kernel/locking/percpu-rwsem.c
+++ b/kernel/locking/percpu-rwsem.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 #include <linux/atomic.h>
 #include <linux/rwsem.h>
 #include <linux/percpu.h>
@@ -12,7 +14,9 @@ int __percpu_init_rwsem(struct percpu_rw_semaphore *sem,
 {
 	sem->read_count = alloc_percpu(int);
 	if (unlikely(!sem->read_count))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 
 	/* ->rw_sem represents the whole percpu_rw_semaphore for lockdep */
 	rcu_sync_init(&sem->rss, RCU_SCHED_SYNC);
@@ -30,7 +34,9 @@ void percpu_free_rwsem(struct percpu_rw_semaphore *sem)
 	 * assumes that percpu_free_rwsem() is safe after kzalloc().
 	 */
 	if (!sem->read_count)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	rcu_sync_dtor(&sem->rss);
 	free_percpu(sem->read_count);
@@ -62,7 +68,9 @@ int __percpu_down_read(struct percpu_rw_semaphore *sem, int try)
 	 * release in percpu_up_write().
 	 */
 	if (likely(!smp_load_acquire(&sem->readers_block)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 1;
+}
 
 	/*
 	 * Per the above comment; we still have preemption disabled and
@@ -71,7 +79,9 @@ int __percpu_down_read(struct percpu_rw_semaphore *sem, int try)
 	__percpu_up_read(sem);
 
 	if (try)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	/*
 	 * We either call schedule() in the wait, or we'll fall through
@@ -125,7 +135,9 @@ EXPORT_SYMBOL_GPL(__percpu_up_read);
 static bool readers_active_check(struct percpu_rw_semaphore *sem)
 {
 	if (per_cpu_sum(*sem->read_count) != 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return false;
+}
 
 	/*
 	 * If we observed the decrement; ensure we see the entire critical
diff --git a/kernel/locking/rtmutex.c b/kernel/locking/rtmutex.c
index 65cc0cb..848fe46 100644
--- a/kernel/locking/rtmutex.c
+++ b/kernel/locking/rtmutex.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * RT-Mutexes: simple blocking mutual exclusion locks with PI support
  *
@@ -54,13 +56,16 @@ rt_mutex_set_owner(struct rt_mutex *lock, struct task_struct *owner)
 	unsigned long val = (unsigned long)owner;
 
 	if (rt_mutex_has_waiters(lock))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		val |= RT_MUTEX_HAS_WAITERS;
+}
 
 	lock->owner = (struct task_struct *)val;
 }
 
 static inline void clear_rt_mutex_waiters(struct rt_mutex *lock)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lock->owner = (struct task_struct *)
 			((unsigned long)lock->owner & ~RT_MUTEX_HAS_WAITERS);
 }
@@ -70,7 +75,9 @@ static void fixup_rt_mutex_waiters(struct rt_mutex *lock)
 	unsigned long owner, *p = (unsigned long *) &lock->owner;
 
 	if (rt_mutex_has_waiters(lock))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	/*
 	 * The rbtree has no waiters enqueued, now make sure that the
@@ -154,6 +161,7 @@ static inline void mark_rt_mutex_waiters(struct rt_mutex *lock)
 	unsigned long owner, *p = (unsigned long *) &lock->owner;
 
 	do {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		owner = *p;
 	} while (cmpxchg_relaxed(p, owner,
 				 owner | RT_MUTEX_HAS_WAITERS) != owner);
@@ -169,6 +177,7 @@ static inline bool unlock_rt_mutex_safe(struct rt_mutex *lock,
 					unsigned long flags)
 	__releases(lock->wait_lock)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct task_struct *owner = rt_mutex_owner(lock);
 
 	clear_rt_mutex_waiters(lock);
diff --git a/kernel/locking/rwsem-xadd.c b/kernel/locking/rwsem-xadd.c
index e795908..8752dee 100644
--- a/kernel/locking/rwsem-xadd.c
+++ b/kernel/locking/rwsem-xadd.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 /* rwsem.c: R/W semaphores: contention handling functions
  *
@@ -149,6 +151,7 @@ static void __rwsem_mark_wake(struct rw_semaphore *sem,
 			wake_q_add(wake_q, waiter->task);
 		}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
 	}
 
@@ -158,6 +161,7 @@ static void __rwsem_mark_wake(struct rw_semaphore *sem,
 	 * so we can bail out early if a writer stole the lock.
 	 */
 	if (wake_type != RWSEM_WAKE_READ_OWNED) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		adjustment = RWSEM_ACTIVE_READ_BIAS;
  try_reader_grant:
 		oldcount = atomic_long_fetch_add(adjustment, &sem->count);
@@ -234,7 +238,9 @@ __rwsem_down_read_failed_common(struct rw_semaphore *sem, int state)
 
 	raw_spin_lock_irq(&sem->wait_lock);
 	if (list_empty(&sem->wait_list))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		adjustment += RWSEM_WAITING_BIAS;
+}
 	list_add_tail(&waiter.list, &sem->wait_list);
 
 	/* we're now waiting on the lock, but no longer actively locking */
@@ -260,9 +266,11 @@ __rwsem_down_read_failed_common(struct rw_semaphore *sem, int state)
 		if (!waiter.task)
 			break;
 		if (signal_pending_state(state, current)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			raw_spin_lock_irq(&sem->wait_lock);
 			if (waiter.task)
 				goto out_nolock;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			raw_spin_unlock_irq(&sem->wait_lock);
 			break;
 		}
@@ -274,9 +282,14 @@ __rwsem_down_read_failed_common(struct rw_semaphore *sem, int state)
 out_nolock:
 	list_del(&waiter.list);
 	if (list_empty(&sem->wait_list))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		atomic_long_add(-RWSEM_WAITING_BIAS, &sem->count);
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	raw_spin_unlock_irq(&sem->wait_lock);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	__set_current_state(TASK_RUNNING);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return ERR_PTR(-EINTR);
 }
 
@@ -290,6 +303,7 @@ EXPORT_SYMBOL(rwsem_down_read_failed);
 __visible struct rw_semaphore * __sched
 rwsem_down_read_failed_killable(struct rw_semaphore *sem)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return __rwsem_down_read_failed_common(sem, TASK_KILLABLE);
 }
 EXPORT_SYMBOL(rwsem_down_read_failed_killable);
@@ -305,7 +319,9 @@ static inline bool rwsem_try_write_lock(long count, struct rw_semaphore *sem)
 	 * Avoid trying to acquire write lock if count isn't RWSEM_WAITING_BIAS.
 	 */
 	if (count != RWSEM_WAITING_BIAS)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return false;
+}
 
 	/*
 	 * Acquire the lock by trying to set it to ACTIVE_WRITE_BIAS. If there
@@ -317,10 +333,12 @@ static inline bool rwsem_try_write_lock(long count, struct rw_semaphore *sem)
 
 	if (atomic_long_cmpxchg_acquire(&sem->count, RWSEM_WAITING_BIAS, count)
 							== RWSEM_WAITING_BIAS) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		rwsem_set_owner(sem);
 		return true;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return false;
 }
 
@@ -332,6 +350,7 @@ static inline bool rwsem_try_write_lock_unqueued(struct rw_semaphore *sem)
 {
 	long old, count = atomic_long_read(&sem->count);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	while (true) {
 		if (!(count == 0 || count == RWSEM_WAITING_BIAS))
 			return false;
@@ -353,8 +372,11 @@ static inline bool rwsem_can_spin_on_owner(struct rw_semaphore *sem)
 	bool ret = true;
 
 	if (need_resched())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return false;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rcu_read_lock();
 	owner = READ_ONCE(sem->owner);
 	if (!rwsem_owner_is_writer(owner)) {
@@ -380,6 +402,7 @@ static inline bool rwsem_can_spin_on_owner(struct rw_semaphore *sem)
  */
 static noinline bool rwsem_spin_on_owner(struct rw_semaphore *sem)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct task_struct *owner = READ_ONCE(sem->owner);
 
 	if (!rwsem_owner_is_writer(owner))
@@ -426,6 +449,7 @@ static bool rwsem_optimistic_spin(struct rw_semaphore *sem)
 	if (!rwsem_can_spin_on_owner(sem))
 		goto done;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!osq_lock(&sem->osq))
 		goto done;
 
@@ -441,6 +465,7 @@ static bool rwsem_optimistic_spin(struct rw_semaphore *sem)
 		 * Try to acquire the lock
 		 */
 		if (rwsem_try_write_lock_unqueued(sem)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			taken = true;
 			break;
 		}
@@ -462,6 +487,7 @@ static bool rwsem_optimistic_spin(struct rw_semaphore *sem)
 		 */
 		cpu_relax();
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	osq_unlock(&sem->osq);
 done:
 	preempt_enable();
@@ -473,6 +499,7 @@ static bool rwsem_optimistic_spin(struct rw_semaphore *sem)
  */
 static inline bool rwsem_has_spinner(struct rw_semaphore *sem)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return osq_is_locked(&sem->osq);
 }
 
@@ -505,7 +532,9 @@ __rwsem_down_write_failed_common(struct rw_semaphore *sem, int state)
 
 	/* do optimistic spinning and steal lock if possible */
 	if (rwsem_optimistic_spin(sem))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return sem;
+}
 
 	/*
 	 * Optimistic spinning failed, proceed to the slowpath
@@ -518,12 +547,15 @@ __rwsem_down_write_failed_common(struct rw_semaphore *sem, int state)
 
 	/* account for this before adding a new element to the list */
 	if (list_empty(&sem->wait_list))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		waiting = false;
+}
 
 	list_add_tail(&waiter.list, &sem->wait_list);
 
 	/* we're now waiting on the lock, but no longer actively locking */
 	if (waiting) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		count = atomic_long_read(&sem->count);
 
 		/*
@@ -553,6 +585,7 @@ __rwsem_down_write_failed_common(struct rw_semaphore *sem, int state)
 
 	/* wait until we successfully acquire the lock */
 	set_current_state(state);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	while (true) {
 		if (rwsem_try_write_lock(count, sem))
 			break;
@@ -577,12 +610,16 @@ __rwsem_down_write_failed_common(struct rw_semaphore *sem, int state)
 
 out_nolock:
 	__set_current_state(TASK_RUNNING);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	raw_spin_lock_irq(&sem->wait_lock);
 	list_del(&waiter.list);
 	if (list_empty(&sem->wait_list))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		atomic_long_add(-RWSEM_WAITING_BIAS, &sem->count);
+}
 	else
 		__rwsem_mark_wake(sem, RWSEM_WAKE_ANY, &wake_q);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	raw_spin_unlock_irq(&sem->wait_lock);
 	wake_up_q(&wake_q);
 
@@ -666,8 +703,11 @@ struct rw_semaphore *rwsem_wake(struct rw_semaphore *sem)
 		 * state is consulted before reading the wait_lock.
 		 */
 		smp_rmb();
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (!raw_spin_trylock_irqsave(&sem->wait_lock, flags))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return sem;
+}
 		goto locked;
 	}
 	raw_spin_lock_irqsave(&sem->wait_lock, flags);
@@ -694,6 +734,7 @@ struct rw_semaphore *rwsem_downgrade_wake(struct rw_semaphore *sem)
 	unsigned long flags;
 	DEFINE_WAKE_Q(wake_q);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	raw_spin_lock_irqsave(&sem->wait_lock, flags);
 
 	if (!list_empty(&sem->wait_list))
diff --git a/kernel/locking/rwsem.c b/kernel/locking/rwsem.c
index a6c76a4..e80600b 100644
--- a/kernel/locking/rwsem.c
+++ b/kernel/locking/rwsem.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 /* kernel/rwsem.c: R/W semaphores, public implementation
  *
@@ -21,6 +23,7 @@
 void __sched down_read(struct rw_semaphore *sem)
 {
 	might_sleep();
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rwsem_acquire_read(&sem->dep_map, 0, 0, _RET_IP_);
 
 	LOCK_CONTENDED(sem, __down_read_trylock, __down_read);
@@ -37,6 +40,7 @@ int down_read_trylock(struct rw_semaphore *sem)
 	int ret = __down_read_trylock(sem);
 
 	if (ret == 1) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		rwsem_acquire_read(&sem->dep_map, 0, 1, _RET_IP_);
 		rwsem_set_reader_owned(sem);
 	}
@@ -51,6 +55,7 @@ EXPORT_SYMBOL(down_read_trylock);
 void __sched down_write(struct rw_semaphore *sem)
 {
 	might_sleep();
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rwsem_acquire(&sem->dep_map, 0, 0, _RET_IP_);
 
 	LOCK_CONTENDED(sem, __down_write_trylock, __down_write);
@@ -65,13 +70,17 @@ EXPORT_SYMBOL(down_write);
 int __sched down_write_killable(struct rw_semaphore *sem)
 {
 	might_sleep();
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rwsem_acquire(&sem->dep_map, 0, 0, _RET_IP_);
 
 	if (LOCK_CONTENDED_RETURN(sem, __down_write_trylock, __down_write_killable)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		rwsem_release(&sem->dep_map, 1, _RET_IP_);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINTR;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rwsem_set_owner(sem);
 	return 0;
 }
@@ -83,6 +92,7 @@ EXPORT_SYMBOL(down_write_killable);
  */
 int down_write_trylock(struct rw_semaphore *sem)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	int ret = __down_write_trylock(sem);
 
 	if (ret == 1) {
@@ -100,6 +110,7 @@ EXPORT_SYMBOL(down_write_trylock);
  */
 void up_read(struct rw_semaphore *sem)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rwsem_release(&sem->dep_map, 1, _RET_IP_);
 
 	__up_read(sem);
@@ -112,8 +123,10 @@ EXPORT_SYMBOL(up_read);
  */
 void up_write(struct rw_semaphore *sem)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rwsem_release(&sem->dep_map, 1, _RET_IP_);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rwsem_clear_owner(sem);
 	__up_write(sem);
 }
@@ -125,6 +138,7 @@ EXPORT_SYMBOL(up_write);
  */
 void downgrade_write(struct rw_semaphore *sem)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lock_downgrade(&sem->dep_map, _RET_IP_);
 
 	rwsem_set_reader_owned(sem);
diff --git a/kernel/locking/rwsem.h b/kernel/locking/rwsem.h
index a883b8f..ff72842 100644
--- a/kernel/locking/rwsem.h
+++ b/kernel/locking/rwsem.h
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /* SPDX-License-Identifier: GPL-2.0 */
 /*
  * The owner field of the rw_semaphore structure will be set to
diff --git a/kernel/locking/semaphore.c b/kernel/locking/semaphore.c
index 561acdd..ef6285e 100644
--- a/kernel/locking/semaphore.c
+++ b/kernel/locking/semaphore.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * Copyright (c) 2008 Intel Corporation
  * Author: Matthew Wilcox <willy@linux.intel.com>
@@ -78,6 +80,7 @@ int down_interruptible(struct semaphore *sem)
 	unsigned long flags;
 	int result = 0;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	raw_spin_lock_irqsave(&sem->lock, flags);
 	if (likely(sem->count > 0))
 		sem->count--;
@@ -104,6 +107,7 @@ int down_killable(struct semaphore *sem)
 	unsigned long flags;
 	int result = 0;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	raw_spin_lock_irqsave(&sem->lock, flags);
 	if (likely(sem->count > 0))
 		sem->count--;
@@ -221,7 +225,9 @@ static inline int __sched __down_common(struct semaphore *sem, long state,
 		timeout = schedule_timeout(timeout);
 		raw_spin_lock_irq(&sem->lock);
 		if (waiter.up)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return 0;
+}
 	}
 
  timed_out:
@@ -240,16 +246,19 @@ static noinline void __sched __down(struct semaphore *sem)
 
 static noinline int __sched __down_interruptible(struct semaphore *sem)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return __down_common(sem, TASK_INTERRUPTIBLE, MAX_SCHEDULE_TIMEOUT);
 }
 
 static noinline int __sched __down_killable(struct semaphore *sem)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return __down_common(sem, TASK_KILLABLE, MAX_SCHEDULE_TIMEOUT);
 }
 
 static noinline int __sched __down_timeout(struct semaphore *sem, long timeout)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return __down_common(sem, TASK_UNINTERRUPTIBLE, timeout);
 }
 
diff --git a/kernel/locking/spinlock.c b/kernel/locking/spinlock.c
index 6e40fdf..4ad6c18 100644
--- a/kernel/locking/spinlock.c
+++ b/kernel/locking/spinlock.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 /*
  * Copyright (2004) Linus Torvalds
@@ -149,6 +151,7 @@ EXPORT_SYMBOL(_raw_spin_trylock_bh);
 #ifndef CONFIG_INLINE_SPIN_LOCK
 void __lockfunc _raw_spin_lock(raw_spinlock_t *lock)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	__raw_spin_lock(lock);
 }
 EXPORT_SYMBOL(_raw_spin_lock);
@@ -213,6 +216,7 @@ EXPORT_SYMBOL(_raw_spin_unlock_bh);
 #ifndef CONFIG_INLINE_READ_TRYLOCK
 int __lockfunc _raw_read_trylock(rwlock_t *lock)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return __raw_read_trylock(lock);
 }
 EXPORT_SYMBOL(_raw_read_trylock);
@@ -221,6 +225,7 @@ EXPORT_SYMBOL(_raw_read_trylock);
 #ifndef CONFIG_INLINE_READ_LOCK
 void __lockfunc _raw_read_lock(rwlock_t *lock)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	__raw_read_lock(lock);
 }
 EXPORT_SYMBOL(_raw_read_lock);
@@ -237,6 +242,7 @@ EXPORT_SYMBOL(_raw_read_lock_irqsave);
 #ifndef CONFIG_INLINE_READ_LOCK_IRQ
 void __lockfunc _raw_read_lock_irq(rwlock_t *lock)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	__raw_read_lock_irq(lock);
 }
 EXPORT_SYMBOL(_raw_read_lock_irq);
@@ -285,6 +291,7 @@ EXPORT_SYMBOL(_raw_read_unlock_bh);
 #ifndef CONFIG_INLINE_WRITE_TRYLOCK
 int __lockfunc _raw_write_trylock(rwlock_t *lock)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return __raw_write_trylock(lock);
 }
 EXPORT_SYMBOL(_raw_write_trylock);
@@ -293,6 +300,7 @@ EXPORT_SYMBOL(_raw_write_trylock);
 #ifndef CONFIG_INLINE_WRITE_LOCK
 void __lockfunc _raw_write_lock(rwlock_t *lock)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	__raw_write_lock(lock);
 }
 EXPORT_SYMBOL(_raw_write_lock);
@@ -333,6 +341,7 @@ EXPORT_SYMBOL(_raw_write_unlock);
 #ifndef CONFIG_INLINE_WRITE_UNLOCK_IRQRESTORE
 void __lockfunc _raw_write_unlock_irqrestore(rwlock_t *lock, unsigned long flags)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	__raw_write_unlock_irqrestore(lock, flags);
 }
 EXPORT_SYMBOL(_raw_write_unlock_irqrestore);
@@ -394,6 +403,7 @@ notrace int in_lock_functions(unsigned long addr)
 	/* Linker adds these: start and end of __lockfunc functions */
 	extern char __lock_text_start[], __lock_text_end[];
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return addr >= (unsigned long)__lock_text_start
 	&& addr < (unsigned long)__lock_text_end;
 }
diff --git a/kernel/memremap.c b/kernel/memremap.c
index 4712ce6..7492415 100644
--- a/kernel/memremap.c
+++ b/kernel/memremap.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * Copyright(c) 2015 Intel Corporation. All rights reserved.
  *
@@ -91,9 +93,12 @@ void *memremap(resource_size_t offset, size_t size, unsigned long flags)
 	void *addr = NULL;
 
 	if (!flags)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 
 	if (is_ram == REGION_MIXED) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		WARN_ONCE(1, "memremap attempted on mixed range %pa size: %#lx\n",
 				&offset, (unsigned long) size);
 		return NULL;
@@ -108,7 +113,9 @@ void *memremap(resource_size_t offset, size_t size, unsigned long flags)
 		 * the requested range is potentially in System RAM.
 		 */
 		if (is_ram == REGION_INTERSECTS)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			addr = try_ram_remap(offset, size, flags);
+}
 		if (!addr)
 			addr = arch_memremap_wb(offset, size);
 	}
@@ -120,17 +127,23 @@ void *memremap(resource_size_t offset, size_t size, unsigned long flags)
 	 * System RAM.
 	 */
 	if (!addr && is_ram == REGION_INTERSECTS && flags != MEMREMAP_WB) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		WARN_ONCE(1, "memremap attempted on ram %pa size: %#lx\n",
 				&offset, (unsigned long) size);
 		return NULL;
 	}
 
 	if (!addr && (flags & MEMREMAP_WT))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		addr = ioremap_wt(offset, size);
+}
 
 	if (!addr && (flags & MEMREMAP_WC))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		addr = ioremap_wc(offset, size);
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return addr;
 }
 EXPORT_SYMBOL(memremap);
@@ -144,11 +157,13 @@ EXPORT_SYMBOL(memunmap);
 
 static void devm_memremap_release(struct device *dev, void *res)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	memunmap(*(void **)res);
 }
 
 static int devm_memremap_match(struct device *dev, void *res, void *match_data)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return *(void **)res == match_data;
 }
 
@@ -160,7 +175,9 @@ void *devm_memremap(struct device *dev, resource_size_t offset,
 	ptr = devres_alloc_node(devm_memremap_release, sizeof(*ptr), GFP_KERNEL,
 			dev_to_node(dev));
 	if (!ptr)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ERR_PTR(-ENOMEM);
+}
 
 	addr = memremap(offset, size, flags);
 	if (addr) {
@@ -177,6 +194,7 @@ EXPORT_SYMBOL(devm_memremap);
 
 void devm_memunmap(struct device *dev, void *addr)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WARN_ON(devres_release(dev, devm_memremap_release,
 				devm_memremap_match, addr));
 }
diff --git a/kernel/module.c b/kernel/module.c
index 690c065..b39bdec 100644
--- a/kernel/module.c
+++ b/kernel/module.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
    Copyright (C) 2002 Richard Henderson
    Copyright (C) 2001 Rusty Russell, 2002, 2010 Rusty Russell IBM.
@@ -111,6 +113,7 @@ static LIST_HEAD(modules);
 
 static __always_inline unsigned long __mod_tree_val(struct latch_tree_node *n)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct module_layout *layout = container_of(n, struct module_layout, mtn.node);
 
 	return (unsigned long)layout->base;
@@ -118,6 +121,7 @@ static __always_inline unsigned long __mod_tree_val(struct latch_tree_node *n)
 
 static __always_inline unsigned long __mod_tree_size(struct latch_tree_node *n)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct module_layout *layout = container_of(n, struct module_layout, mtn.node);
 
 	return (unsigned long)layout->size;
@@ -126,6 +130,7 @@ static __always_inline unsigned long __mod_tree_size(struct latch_tree_node *n)
 static __always_inline bool
 mod_tree_less(struct latch_tree_node *a, struct latch_tree_node *b)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return __mod_tree_val(a) < __mod_tree_val(b);
 }
 
@@ -137,7 +142,9 @@ mod_tree_comp(void *key, struct latch_tree_node *n)
 
 	start = __mod_tree_val(n);
 	if (val < start)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -1;
+}
 
 	end = start + __mod_tree_size(n);
 	if (val >= end)
@@ -164,11 +171,13 @@ static struct mod_tree_root {
 
 static noinline void __mod_tree_insert(struct mod_tree_node *node)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	latch_tree_insert(&node->node, &mod_tree.root, &mod_tree_ops);
 }
 
 static void __mod_tree_remove(struct mod_tree_node *node)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	latch_tree_erase(&node->node, &mod_tree.root, &mod_tree_ops);
 }
 
@@ -178,6 +187,7 @@ static void __mod_tree_remove(struct mod_tree_node *node)
  */
 static void mod_tree_insert(struct module *mod)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	mod->core_layout.mtn.mod = mod;
 	mod->init_layout.mtn.mod = mod;
 
@@ -188,12 +198,14 @@ static void mod_tree_insert(struct module *mod)
 
 static void mod_tree_remove_init(struct module *mod)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (mod->init_layout.size)
 		__mod_tree_remove(&mod->init_layout.mtn);
 }
 
 static void mod_tree_remove(struct module *mod)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	__mod_tree_remove(&mod->core_layout.mtn);
 	mod_tree_remove_init(mod);
 }
@@ -204,7 +216,9 @@ static struct module *mod_find(unsigned long addr)
 
 	ltn = latch_tree_find((void *)addr, &mod_tree.root, &mod_tree_ops);
 	if (!ltn)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 
 	return container_of(ltn, struct mod_tree_node, node)->mod;
 }
@@ -324,6 +338,7 @@ struct load_info {
  */
 static inline int strong_try_module_get(struct module *mod)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	BUG_ON(mod && mod->state == MODULE_STATE_UNFORMED);
 	if (mod && mod->state == MODULE_STATE_COMING)
 		return -EBUSY;
@@ -336,6 +351,7 @@ static inline int strong_try_module_get(struct module *mod)
 static inline void add_taint_module(struct module *mod, unsigned flag,
 				    enum lockdep_ok lockdep_ok)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	add_taint(flag, lockdep_ok);
 	set_bit(flag, &mod->taints);
 }
@@ -356,6 +372,7 @@ static unsigned int find_sec(const struct load_info *info, const char *name)
 {
 	unsigned int i;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (i = 1; i < info->hdr->e_shnum; i++) {
 		Elf_Shdr *shdr = &info->sechdrs[i];
 		/* Alloc bit cleared means "ignore it." */
@@ -379,6 +396,7 @@ static void *section_objs(const struct load_info *info,
 			  size_t object_size,
 			  unsigned int *num)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	unsigned int sec = find_sec(info, name);
 
 	/* Section 0 has sh_addr 0 and sh_size 0. */
@@ -421,6 +439,7 @@ static bool each_symbol_in_section(const struct symsearch *arr,
 {
 	unsigned int j;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (j = 0; j < arrsize; j++) {
 		if (fn(&arr[j], owner, data))
 			return true;
@@ -458,7 +477,9 @@ bool each_symbol_section(bool (*fn)(const struct symsearch *arr,
 	module_assert_mutex_or_preempt();
 
 	if (each_symbol_in_section(arr, ARRAY_SIZE(arr), NULL, fn, data))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return true;
+}
 
 	list_for_each_entry_rcu(mod, &modules, list) {
 		struct symsearch arr[] = {
@@ -512,6 +533,7 @@ static bool check_symbol(const struct symsearch *syms,
 	struct find_symbol_arg *fsa = data;
 
 	if (!fsa->gplok) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (syms->licence == GPL_ONLY)
 			return false;
 		if (syms->licence == WILL_BE_GPL_ONLY && fsa->warn) {
@@ -557,6 +579,7 @@ static bool find_symbol_in_section(const struct symsearch *syms,
 	sym = bsearch(fsa->name, syms->start, syms->stop - syms->start,
 			sizeof(struct kernel_symbol), cmp_name);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (sym != NULL && check_symbol(syms, owner, sym - syms->start, data))
 		return true;
 
@@ -578,6 +601,7 @@ const struct kernel_symbol *find_symbol(const char *name,
 	fsa.warn = warn;
 
 	if (each_symbol_section(find_symbol_in_section, &fsa)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (owner)
 			*owner = fsa.owner;
 		if (crc)
@@ -601,6 +625,7 @@ static struct module *find_module_all(const char *name, size_t len,
 
 	module_assert_mutex_or_preempt();
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry_rcu(mod, &modules, list) {
 		if (!even_unformed && mod->state == MODULE_STATE_UNFORMED)
 			continue;
@@ -612,6 +637,7 @@ static struct module *find_module_all(const char *name, size_t len,
 
 struct module *find_module(const char *name)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	module_assert_mutex();
 	return find_module_all(name, strlen(name), false);
 }
@@ -621,6 +647,7 @@ EXPORT_SYMBOL_GPL(find_module);
 
 static inline void __percpu *mod_percpu(struct module *mod)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return mod->percpu;
 }
 
@@ -630,7 +657,9 @@ static int percpu_modalloc(struct module *mod, struct load_info *info)
 	unsigned long align = pcpusec->sh_addralign;
 
 	if (!pcpusec->sh_size)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	if (align > PAGE_SIZE) {
 		pr_warn("%s: per-cpu alignment %li > %li\n",
@@ -650,11 +679,13 @@ static int percpu_modalloc(struct module *mod, struct load_info *info)
 
 static void percpu_modfree(struct module *mod)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	free_percpu(mod->percpu);
 }
 
 static unsigned int find_pcpusec(struct load_info *info)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return find_sec(info, ".data..percpu");
 }
 
@@ -663,6 +694,7 @@ static void percpu_modcopy(struct module *mod,
 {
 	int cpu;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for_each_possible_cpu(cpu)
 		memcpy(per_cpu_ptr(mod->percpu, cpu), from, size);
 }
@@ -674,6 +706,7 @@ bool __is_module_percpu_address(unsigned long addr, unsigned long *can_addr)
 
 	preempt_disable();
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry_rcu(mod, &modules, list) {
 		if (mod->state == MODULE_STATE_UNFORMED)
 			continue;
@@ -711,6 +744,7 @@ bool __is_module_percpu_address(unsigned long addr, unsigned long *can_addr)
  */
 bool is_module_percpu_address(unsigned long addr)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return __is_module_percpu_address(addr, NULL);
 }
 
@@ -814,6 +848,7 @@ static int already_uses(struct module *a, struct module *b)
 {
 	struct module_use *use;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry(use, &b->source_list, source_list) {
 		if (use->source == a) {
 			pr_debug("%s uses %s!\n", a->name, b->name);
@@ -835,6 +870,7 @@ static int add_module_usage(struct module *a, struct module *b)
 {
 	struct module_use *use;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pr_debug("Allocating new usage for %s.\n", a->name);
 	use = kmalloc(sizeof(*use), GFP_ATOMIC);
 	if (!use) {
@@ -854,6 +890,7 @@ int ref_module(struct module *a, struct module *b)
 {
 	int err;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (b == NULL || already_uses(a, b))
 		return 0;
 
@@ -877,6 +914,7 @@ static void module_unload_free(struct module *mod)
 	struct module_use *use, *tmp;
 
 	mutex_lock(&module_mutex);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry_safe(use, tmp, &mod->target_list, target_list) {
 		struct module *i = use->target;
 		pr_debug("%s unusing %s\n", mod->name, i->name);
@@ -893,7 +931,9 @@ static inline int try_force_unload(unsigned int flags)
 {
 	int ret = (flags & O_TRUNC);
 	if (ret)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		add_taint(TAINT_FORCED_RMMOD, LOCKDEP_NOW_UNRELIABLE);
+}
 	return ret;
 }
 #else
@@ -910,6 +950,7 @@ static int try_release_module_ref(struct module *mod)
 
 	/* Try to decrement refcnt which we set at loading */
 	ret = atomic_sub_return(MODULE_REF_BASE, &mod->refcnt);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	BUG_ON(ret < 0);
 	if (ret)
 		/* Someone can put this right now, recover with checking */
@@ -944,6 +985,7 @@ static int try_stop_module(struct module *mod, int flags, int *forced)
  */
 int module_refcount(struct module *mod)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return atomic_read(&mod->refcnt) - MODULE_REF_BASE;
 }
 EXPORT_SYMBOL(module_refcount);
@@ -958,6 +1000,7 @@ SYSCALL_DEFINE2(delete_module, const char __user *, name_user,
 	char name[MODULE_NAME_LEN];
 	int ret, forced = 0;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!capable(CAP_SYS_MODULE) || modules_disabled)
 		return -EPERM;
 
@@ -1057,7 +1100,9 @@ void __symbol_put(const char *symbol)
 
 	preempt_disable();
 	if (!find_symbol(symbol, &owner, NULL, true, false))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		BUG();
+}
 	module_put(owner);
 	preempt_enable();
 }
@@ -1070,7 +1115,9 @@ void symbol_put_addr(void *addr)
 	unsigned long a = (unsigned long)dereference_function_descriptor(addr);
 
 	if (core_kernel_text(a))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	/*
 	 * Even though we hold a reference on the module; we still need to
@@ -1087,6 +1134,7 @@ EXPORT_SYMBOL_GPL(symbol_put_addr);
 static ssize_t show_refcnt(struct module_attribute *mattr,
 			   struct module_kobject *mk, char *buffer)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return sprintf(buffer, "%i\n", module_refcount(mk->mod));
 }
 
@@ -1096,6 +1144,7 @@ static struct module_attribute modinfo_refcnt =
 void __module_get(struct module *module)
 {
 	if (module) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		preempt_disable();
 		atomic_inc(&module->refcnt);
 		trace_module_get(module, _RET_IP_);
@@ -1109,6 +1158,7 @@ bool try_module_get(struct module *module)
 	bool ret = true;
 
 	if (module) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		preempt_disable();
 		/* Note: here, we can fail to get a reference */
 		if (likely(module_is_live(module) &&
@@ -1117,6 +1167,7 @@ bool try_module_get(struct module *module)
 		else
 			ret = false;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		preempt_enable();
 	}
 	return ret;
@@ -1128,8 +1179,10 @@ void module_put(struct module *module)
 	int ret;
 
 	if (module) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		preempt_disable();
 		ret = atomic_dec_if_positive(&module->refcnt);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		WARN_ON(ret < 0);	/* Failed to put refcount */
 		trace_module_put(module, _RET_IP_);
 		preempt_enable();
@@ -1165,6 +1218,7 @@ static size_t module_flags_taint(struct module *mod, char *buf)
 	size_t l = 0;
 	int i;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (i = 0; i < TAINT_FLAGS_COUNT; i++) {
 		if (taint_flags[i].module && test_bit(i, &mod->taints))
 			buf[l++] = taint_flags[i].c_true;
@@ -1201,6 +1255,7 @@ static ssize_t store_uevent(struct module_attribute *mattr,
 			    struct module_kobject *mk,
 			    const char *buffer, size_t count)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	kobject_synth_uevent(&mk->kobj, buffer, count);
 	return count;
 }
@@ -1211,6 +1266,7 @@ struct module_attribute module_uevent =
 static ssize_t show_coresize(struct module_attribute *mattr,
 			     struct module_kobject *mk, char *buffer)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return sprintf(buffer, "%u\n", mk->mod->core_layout.size);
 }
 
@@ -1220,6 +1276,7 @@ static struct module_attribute modinfo_coresize =
 static ssize_t show_initsize(struct module_attribute *mattr,
 			     struct module_kobject *mk, char *buffer)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return sprintf(buffer, "%u\n", mk->mod->init_layout.size);
 }
 
@@ -1359,18 +1416,21 @@ static inline int check_version(const struct load_info *info,
 				struct module *mod,
 				const s32 *crc)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 1;
 }
 
 static inline int check_modstruct_version(const struct load_info *info,
 					  struct module *mod)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 1;
 }
 
 static inline int same_magic(const char *amagic, const char *bmagic,
 			     bool has_crcs)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return strcmp(amagic, bmagic) == 0;
 }
 #endif /* CONFIG_MODVERSIONS */
@@ -1425,6 +1485,7 @@ resolve_symbol_wait(struct module *mod,
 	const struct kernel_symbol *ksym;
 	char owner[MODULE_NAME_LEN];
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (wait_event_interruptible_timeout(module_wq,
 			!IS_ERR(ksym = resolve_symbol(mod, info, name, owner))
 			|| PTR_ERR(ksym) != -EBUSY,
@@ -1444,6 +1505,7 @@ resolve_symbol_wait(struct module *mod,
 #ifdef CONFIG_KALLSYMS
 static inline bool sect_empty(const Elf_Shdr *sect)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return !(sect->sh_flags & SHF_ALLOC) || sect->sh_size == 0;
 }
 
@@ -1471,6 +1533,7 @@ static void free_sect_attrs(struct module_sect_attrs *sect_attrs)
 {
 	unsigned int section;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (section = 0; section < sect_attrs->nsections; section++)
 		kfree(sect_attrs->attrs[section].name);
 	kfree(sect_attrs);
@@ -1532,6 +1595,7 @@ static void add_sect_attrs(struct module *mod, const struct load_info *info)
 
 static void remove_sect_attrs(struct module *mod)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (mod->sect_attrs) {
 		sysfs_remove_group(&mod->mkobj.kobj,
 				   &mod->sect_attrs->grp);
@@ -1566,6 +1630,7 @@ static ssize_t module_notes_read(struct file *filp, struct kobject *kobj,
 static void free_notes_attrs(struct module_notes_attrs *notes_attrs,
 			     unsigned int i)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (notes_attrs->dir) {
 		while (i-- > 0)
 			sysfs_remove_bin_file(notes_attrs->dir,
@@ -1583,7 +1648,9 @@ static void add_notes_attrs(struct module *mod, const struct load_info *info)
 
 	/* failed to create section attributes, so can't create notes */
 	if (!mod->sect_attrs)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	/* Count notes sections and allocate structures.  */
 	notes = 0;
@@ -1636,6 +1703,7 @@ static void add_notes_attrs(struct module *mod, const struct load_info *info)
 
 static void remove_notes_attrs(struct module *mod)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (mod->notes_attrs)
 		free_notes_attrs(mod->notes_attrs, mod->notes_attrs->notes);
 }
@@ -1667,6 +1735,7 @@ static void del_usage_links(struct module *mod)
 	struct module_use *use;
 
 	mutex_lock(&module_mutex);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry(use, &mod->target_list, target_list)
 		sysfs_remove_link(use->target->holders_dir, mod->name);
 	mutex_unlock(&module_mutex);
@@ -1680,6 +1749,7 @@ static int add_usage_links(struct module *mod)
 	struct module_use *use;
 
 	mutex_lock(&module_mutex);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry(use, &mod->target_list, target_list) {
 		ret = sysfs_create_link(use->target->holders_dir,
 					&mod->mkobj.kobj, mod->name);
@@ -1704,7 +1774,9 @@ static int module_add_modinfo_attrs(struct module *mod)
 					(ARRAY_SIZE(modinfo_attrs) + 1)),
 					GFP_KERNEL);
 	if (!mod->modinfo_attrs)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 
 	temp_attr = mod->modinfo_attrs;
 	for (i = 0; (attr = modinfo_attrs[i]) && !error; i++) {
@@ -1724,6 +1796,7 @@ static void module_remove_modinfo_attrs(struct module *mod)
 	struct module_attribute *attr;
 	int i;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (i = 0; (attr = &mod->modinfo_attrs[i]); i++) {
 		/* pick a field to test for end of list */
 		if (!attr->attr.name)
@@ -1749,6 +1822,7 @@ static int mod_sysfs_init(struct module *mod)
 	struct kobject *kobj;
 
 	if (!module_sysfs_initialized) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_err("%s: module sysfs not initialized\n", mod->name);
 		err = -EINVAL;
 		goto out;
@@ -1787,6 +1861,7 @@ static int mod_sysfs_setup(struct module *mod,
 	if (err)
 		goto out;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	mod->holders_dir = kobject_create_and_add("holders", &mod->mkobj.kobj);
 	if (!mod->holders_dir) {
 		err = -ENOMEM;
@@ -1825,6 +1900,7 @@ static int mod_sysfs_setup(struct module *mod,
 
 static void mod_sysfs_fini(struct module *mod)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	remove_notes_attrs(mod);
 	remove_sect_attrs(mod);
 	mod_kobject_put(mod);
@@ -1832,6 +1908,7 @@ static void mod_sysfs_fini(struct module *mod)
 
 static void init_param_lock(struct module *mod)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	mutex_init(&mod->param_lock);
 }
 #else /* !CONFIG_SYSFS */
@@ -1863,6 +1940,7 @@ static void init_param_lock(struct module *mod)
 
 static void mod_sysfs_teardown(struct module *mod)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	del_usage_links(mod);
 	module_remove_modinfo_attrs(mod);
 	module_param_sysfs_remove(mod);
@@ -1888,6 +1966,7 @@ static void mod_sysfs_teardown(struct module *mod)
 static void frob_text(const struct module_layout *layout,
 		      int (*set_memory)(unsigned long start, int num_pages))
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	BUG_ON((unsigned long)layout->base & (PAGE_SIZE-1));
 	BUG_ON((unsigned long)layout->text_size & (PAGE_SIZE-1));
 	set_memory((unsigned long)layout->base,
@@ -1897,6 +1976,7 @@ static void frob_text(const struct module_layout *layout,
 static void frob_rodata(const struct module_layout *layout,
 			int (*set_memory)(unsigned long start, int num_pages))
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	BUG_ON((unsigned long)layout->base & (PAGE_SIZE-1));
 	BUG_ON((unsigned long)layout->text_size & (PAGE_SIZE-1));
 	BUG_ON((unsigned long)layout->ro_size & (PAGE_SIZE-1));
@@ -1907,6 +1987,7 @@ static void frob_rodata(const struct module_layout *layout,
 static void frob_ro_after_init(const struct module_layout *layout,
 				int (*set_memory)(unsigned long start, int num_pages))
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	BUG_ON((unsigned long)layout->base & (PAGE_SIZE-1));
 	BUG_ON((unsigned long)layout->ro_size & (PAGE_SIZE-1));
 	BUG_ON((unsigned long)layout->ro_after_init_size & (PAGE_SIZE-1));
@@ -1917,6 +1998,7 @@ static void frob_ro_after_init(const struct module_layout *layout,
 static void frob_writable_data(const struct module_layout *layout,
 			       int (*set_memory)(unsigned long start, int num_pages))
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	BUG_ON((unsigned long)layout->base & (PAGE_SIZE-1));
 	BUG_ON((unsigned long)layout->ro_after_init_size & (PAGE_SIZE-1));
 	BUG_ON((unsigned long)layout->size & (PAGE_SIZE-1));
@@ -1927,6 +2009,7 @@ static void frob_writable_data(const struct module_layout *layout,
 /* livepatching wants to disable read-only so it can frob module. */
 void module_disable_ro(const struct module *mod)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!rodata_enabled)
 		return;
 
@@ -1939,6 +2022,7 @@ void module_disable_ro(const struct module *mod)
 
 void module_enable_ro(const struct module *mod, bool after_init)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!rodata_enabled)
 		return;
 
@@ -1953,6 +2037,7 @@ void module_enable_ro(const struct module *mod, bool after_init)
 
 static void module_enable_nx(const struct module *mod)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	frob_rodata(&mod->core_layout, set_memory_nx);
 	frob_ro_after_init(&mod->core_layout, set_memory_nx);
 	frob_writable_data(&mod->core_layout, set_memory_nx);
@@ -1962,6 +2047,7 @@ static void module_enable_nx(const struct module *mod)
 
 static void module_disable_nx(const struct module *mod)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	frob_rodata(&mod->core_layout, set_memory_x);
 	frob_ro_after_init(&mod->core_layout, set_memory_x);
 	frob_writable_data(&mod->core_layout, set_memory_x);
@@ -1975,7 +2061,9 @@ void set_all_modules_text_rw(void)
 	struct module *mod;
 
 	if (!rodata_enabled)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	mutex_lock(&module_mutex);
 	list_for_each_entry_rcu(mod, &modules, list) {
@@ -1994,7 +2082,9 @@ void set_all_modules_text_ro(void)
 	struct module *mod;
 
 	if (!rodata_enabled)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	mutex_lock(&module_mutex);
 	list_for_each_entry_rcu(mod, &modules, list) {
@@ -2015,6 +2105,7 @@ void set_all_modules_text_ro(void)
 
 static void disable_ro_nx(const struct module_layout *layout)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (rodata_enabled) {
 		frob_text(layout, set_memory_rw);
 		frob_rodata(layout, set_memory_rw);
@@ -2218,6 +2309,7 @@ static int verify_export_symbols(struct module *mod)
 #endif
 	};
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (i = 0; i < ARRAY_SIZE(arr); i++) {
 		for (s = arr[i].sym; s < arr[i].sym + arr[i].num; s++) {
 			if (find_symbol(s->name, &owner, NULL, true, false)) {
@@ -2241,6 +2333,7 @@ static int simplify_symbols(struct module *mod, const struct load_info *info)
 	int ret = 0;
 	const struct kernel_symbol *ksym;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (i = 1; i < symsec->sh_size / sizeof(Elf_Sym); i++) {
 		const char *name = info->strtab + sym[i].st_name;
 
@@ -2347,6 +2440,7 @@ static long get_offset(struct module *mod, unsigned int *size,
 	long ret;
 
 	*size += arch_mod_section_prepend(mod, section);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	ret = ALIGN(*size, sechdr->sh_addralign ?: 1);
 	*size = ret + sechdr->sh_size;
 	return ret;
@@ -2370,6 +2464,7 @@ static void layout_sections(struct module *mod, struct load_info *info)
 	};
 	unsigned int m, i;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (i = 0; i < info->hdr->e_shnum; i++)
 		info->sechdrs[i].sh_entsize = ~0UL;
 
@@ -2446,6 +2541,7 @@ static void layout_sections(struct module *mod, struct load_info *info)
 
 static void set_license(struct module *mod, const char *license)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!license)
 		license = "unspecified";
 
@@ -2484,6 +2580,7 @@ static char *get_modinfo(struct load_info *info, const char *tag)
 	Elf_Shdr *infosec = &info->sechdrs[info->index.info];
 	unsigned long size = infosec->sh_size;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (p = (char *)infosec->sh_addr; p; p = next_string(p, &size)) {
 		if (strncmp(p, tag, taglen) == 0 && p[taglen] == '=')
 			return p + taglen + 1;
@@ -2496,6 +2593,7 @@ static void setup_modinfo(struct module *mod, struct load_info *info)
 	struct module_attribute *attr;
 	int i;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (i = 0; (attr = modinfo_attrs[i]); i++) {
 		if (attr->setup)
 			attr->setup(mod, get_modinfo(info, attr->attr.name));
@@ -2507,6 +2605,7 @@ static void free_modinfo(struct module *mod)
 	struct module_attribute *attr;
 	int i;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (i = 0; (attr = modinfo_attrs[i]); i++) {
 		if (attr->free)
 			attr->free(mod);
@@ -2520,6 +2619,7 @@ static const struct kernel_symbol *lookup_symbol(const char *name,
 	const struct kernel_symbol *start,
 	const struct kernel_symbol *stop)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return bsearch(name, start, stop - start,
 			sizeof(struct kernel_symbol), cmp_name);
 }
@@ -2529,7 +2629,9 @@ static int is_exported(const char *name, unsigned long value,
 {
 	const struct kernel_symbol *ks;
 	if (!mod)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ks = lookup_symbol(name, __start___ksymtab, __stop___ksymtab);
+}
 	else
 		ks = lookup_symbol(name, mod->syms, mod->syms + mod->num_syms);
 	return ks != NULL && ks->value == value;
@@ -2541,6 +2643,7 @@ static char elf_type(const Elf_Sym *sym, const struct load_info *info)
 	const Elf_Shdr *sechdrs = info->sechdrs;
 
 	if (ELF_ST_BIND(sym->st_info) == STB_WEAK) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (ELF_ST_TYPE(sym->st_info) == STT_OBJECT)
 			return 'v';
 		else
@@ -2620,6 +2723,7 @@ static void layout_symtab(struct module *mod, struct load_info *info)
 	symsect->sh_flags |= SHF_ALLOC;
 	symsect->sh_entsize = get_offset(mod, &mod->init_layout.size, symsect,
 					 info->index.sym) | INIT_OFFSET_MASK;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pr_debug("\t%s\n", info->secstrings + symsect->sh_name);
 
 	src = (void *)info->hdr + symsect->sh_offset;
@@ -2709,6 +2813,7 @@ static void add_kallsyms(struct module *mod, const struct load_info *info)
 
 static void dynamic_debug_setup(struct module *mod, struct _ddebug *debug, unsigned int num)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!debug)
 		return;
 #ifdef CONFIG_DYNAMIC_DEBUG
@@ -2720,12 +2825,14 @@ static void dynamic_debug_setup(struct module *mod, struct _ddebug *debug, unsig
 
 static void dynamic_debug_remove(struct module *mod, struct _ddebug *debug)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (debug)
 		ddebug_remove_module(mod->name);
 }
 
 void * __weak module_alloc(unsigned long size)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return vmalloc_exec(size);
 }
 
@@ -2789,6 +2896,7 @@ static int module_sig_check(struct load_info *info, int flags)
 #else /* !CONFIG_MODULE_SIG */
 static int module_sig_check(struct load_info *info, int flags)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 #endif /* !CONFIG_MODULE_SIG */
@@ -2796,6 +2904,7 @@ static int module_sig_check(struct load_info *info, int flags)
 /* Sanity checks against invalid binaries, wrong arch, weird elf version. */
 static int elf_header_check(struct load_info *info)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (info->len < sizeof(*(info->hdr)))
 		return -ENOEXEC;
 
@@ -2818,6 +2927,7 @@ static int elf_header_check(struct load_info *info)
 static int copy_chunked_from_user(void *dst, const void __user *usrc, unsigned long len)
 {
 	do {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		unsigned long n = min(len, COPY_CHUNK_SIZE);
 
 		if (copy_from_user(dst, usrc, n) != 0)
@@ -2845,6 +2955,7 @@ static int check_modinfo_livepatch(struct module *mod, struct load_info *info)
 #else /* !CONFIG_LIVEPATCH */
 static int check_modinfo_livepatch(struct module *mod, struct load_info *info)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (get_modinfo(info, "livepatch")) {
 		pr_err("%s: module is marked as livepatch module, but livepatch support is disabled",
 		       mod->name);
@@ -2857,6 +2968,7 @@ static int check_modinfo_livepatch(struct module *mod, struct load_info *info)
 
 static void check_modinfo_retpoline(struct module *mod, struct load_info *info)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (retpoline_module_ok(get_modinfo(info, "retpoline")))
 		return;
 
@@ -2872,7 +2984,9 @@ static int copy_module_from_user(const void __user *umod, unsigned long len,
 
 	info->len = len;
 	if (info->len < sizeof(*(info->hdr)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOEXEC;
+}
 
 	err = security_kernel_read_file(NULL, READING_MODULE);
 	if (err)
@@ -2894,6 +3008,7 @@ static int copy_module_from_user(const void __user *umod, unsigned long len,
 
 static void free_copy(struct load_info *info)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	vfree(info->hdr);
 }
 
@@ -2904,6 +3019,7 @@ static int rewrite_section_headers(struct load_info *info, int flags)
 	/* This should always be true, but let's be sure. */
 	info->sechdrs[0].sh_addr = 0;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (i = 1; i < info->hdr->e_shnum; i++) {
 		Elf_Shdr *shdr = &info->sechdrs[i];
 		if (shdr->sh_type != SHT_NOBITS
@@ -2961,7 +3077,9 @@ static struct module *setup_load_info(struct load_info *info, int flags)
 
 	err = rewrite_section_headers(info, flags);
 	if (err)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ERR_PTR(err);
+}
 
 	/* Find internal symbols and strings. */
 	for (i = 1; i < info->hdr->e_shnum; i++) {
@@ -3006,6 +3124,7 @@ static struct module *setup_load_info(struct load_info *info, int flags)
 
 static int check_modinfo(struct module *mod, struct load_info *info, int flags)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	const char *modmagic = get_modinfo(info, "vermagic");
 	int err;
 
@@ -3050,6 +3169,7 @@ static int check_modinfo(struct module *mod, struct load_info *info, int flags)
 
 static int find_module_sections(struct module *mod, struct load_info *info)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	mod->kp = section_objs(info, "__param",
 			       sizeof(*mod->kp), &mod->num_kp);
 	mod->syms = section_objs(info, "__ksymtab",
@@ -3148,7 +3268,9 @@ static int move_module(struct module *mod, struct load_info *info)
 	 */
 	kmemleak_not_leak(ptr);
 	if (!ptr)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 
 	memset(ptr, 0, mod->core_layout.size);
 	mod->core_layout.base = ptr;
@@ -3199,6 +3321,7 @@ static int move_module(struct module *mod, struct load_info *info)
 
 static int check_module_license_and_versions(struct module *mod)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	int prev_taint = test_taint(TAINT_PROPRIETARY_MODULE);
 
 	/*
@@ -3252,9 +3375,11 @@ static void flush_module_icache(const struct module *mod)
 	 * can provide parameter accessor functions of its own.
 	 */
 	if (mod->init_layout.base)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		flush_icache_range((unsigned long)mod->init_layout.base,
 				   (unsigned long)mod->init_layout.base
 				   + mod->init_layout.size);
+}
 	flush_icache_range((unsigned long)mod->core_layout.base,
 			   (unsigned long)mod->core_layout.base + mod->core_layout.size);
 
@@ -3266,6 +3391,7 @@ int __weak module_frob_arch_sections(Elf_Ehdr *hdr,
 				     char *secstrings,
 				     struct module *mod)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
@@ -3277,7 +3403,9 @@ static bool blacklisted(const char *module_name)
 	size_t len;
 
 	if (!module_blacklist)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return false;
+}
 
 	for (p = module_blacklist; *p; p += len) {
 		len = strcspn(p, ",");
@@ -3299,7 +3427,9 @@ static struct module *layout_and_allocate(struct load_info *info, int flags)
 
 	mod = setup_load_info(info, flags);
 	if (IS_ERR(mod))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return mod;
+}
 
 	if (blacklisted(info->name))
 		return ERR_PTR(-EPERM);
@@ -3346,6 +3476,7 @@ static struct module *layout_and_allocate(struct load_info *info, int flags)
 /* mod is no longer valid after this! */
 static void module_deallocate(struct module *mod, struct load_info *info)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	percpu_modfree(mod);
 	module_arch_freeing_init(mod);
 	module_memfree(mod->init_layout.base);
@@ -3356,6 +3487,7 @@ int __weak module_finalize(const Elf_Ehdr *hdr,
 			   const Elf_Shdr *sechdrs,
 			   struct module *me)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
@@ -3415,6 +3547,7 @@ struct mod_initfree {
 
 static void do_free_init(struct rcu_head *head)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct mod_initfree *m = container_of(head, struct mod_initfree, rcu);
 	module_memfree(m->module_init);
 	kfree(m);
@@ -3433,6 +3566,7 @@ static noinline int do_init_module(struct module *mod)
 
 	freeinit = kmalloc(sizeof(*freeinit), GFP_KERNEL);
 	if (!freeinit) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ret = -ENOMEM;
 		goto fail;
 	}
@@ -3531,6 +3665,7 @@ static noinline int do_init_module(struct module *mod)
 
 static int may_init_module(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!capable(CAP_SYS_MODULE) || modules_disabled)
 		return -EPERM;
 
@@ -3613,7 +3748,9 @@ static int prepare_coming_module(struct module *mod)
 	ftrace_module_enable(mod);
 	err = klp_module_coming(mod);
 	if (err)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return err;
+}
 
 	blocking_notifier_call_chain(&module_notify_list,
 				     MODULE_STATE_COMING, mod);
@@ -3627,6 +3764,7 @@ static int unknown_module_param_cb(char *param, char *val, const char *modname,
 	int ret;
 
 	if (strcmp(param, "async_probe") == 0) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		mod->async_probe_requested = true;
 		return 0;
 	}
@@ -3651,6 +3789,7 @@ static int load_module(struct load_info *info, const char __user *uargs,
 	if (err)
 		goto free_copy;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	err = elf_header_check(info);
 	if (err)
 		goto free_copy;
@@ -3832,7 +3971,9 @@ SYSCALL_DEFINE3(init_module, void __user *, umod,
 
 	err = may_init_module();
 	if (err)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return err;
+}
 
 	pr_debug("init_module: umod=%p, len=%lu, uargs=%p\n",
 	       umod, len, uargs);
@@ -3853,7 +3994,9 @@ SYSCALL_DEFINE3(finit_module, int, fd, const char __user *, uargs, int, flags)
 
 	err = may_init_module();
 	if (err)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return err;
+}
 
 	pr_debug("finit_module: fd=%d, uargs=%p, flags=%i\n", fd, uargs, flags);
 
@@ -3873,6 +4016,7 @@ SYSCALL_DEFINE3(finit_module, int, fd, const char __user *, uargs, int, flags)
 
 static inline int within(unsigned long addr, void *start, unsigned long size)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return ((void *)addr >= start && (void *)addr < start + size);
 }
 
@@ -3883,6 +4027,7 @@ static inline int within(unsigned long addr, void *start, unsigned long size)
  */
 static inline int is_arm_mapping_symbol(const char *str)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (str[0] == '.' && str[1] == 'L')
 		return true;
 	return str[0] == '$' && strchr("axtd", str[1])
@@ -3891,6 +4036,7 @@ static inline int is_arm_mapping_symbol(const char *str)
 
 static const char *symname(struct mod_kallsyms *kallsyms, unsigned int symnum)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return kallsyms->strtab + kallsyms->symtab[symnum].st_name;
 }
 
@@ -3901,6 +4047,7 @@ static const char *get_ksymbol(struct module *mod,
 {
 	unsigned int i, best = 0;
 	unsigned long nextval;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct mod_kallsyms *kallsyms = rcu_dereference_sched(mod->kallsyms);
 
 	/* At worse, next value is at end of module */
@@ -3953,6 +4100,7 @@ const char *module_address_lookup(unsigned long addr,
 	preempt_disable();
 	mod = __module_address(addr);
 	if (mod) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (modname)
 			*modname = mod->name;
 		ret = get_ksymbol(mod, addr, size, offset);
@@ -3972,6 +4120,7 @@ int lookup_module_symbol_name(unsigned long addr, char *symname)
 	struct module *mod;
 
 	preempt_disable();
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry_rcu(mod, &modules, list) {
 		if (mod->state == MODULE_STATE_UNFORMED)
 			continue;
@@ -3997,6 +4146,7 @@ int lookup_module_symbol_attrs(unsigned long addr, unsigned long *size,
 	struct module *mod;
 
 	preempt_disable();
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry_rcu(mod, &modules, list) {
 		if (mod->state == MODULE_STATE_UNFORMED)
 			continue;
@@ -4025,6 +4175,7 @@ int module_get_kallsym(unsigned int symnum, unsigned long *value, char *type,
 	struct module *mod;
 
 	preempt_disable();
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry_rcu(mod, &modules, list) {
 		struct mod_kallsyms *kallsyms;
 
@@ -4049,6 +4200,7 @@ int module_get_kallsym(unsigned int symnum, unsigned long *value, char *type,
 static unsigned long mod_find_symname(struct module *mod, const char *name)
 {
 	unsigned int i;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct mod_kallsyms *kallsyms = rcu_dereference_sched(mod->kallsyms);
 
 	for (i = 0; i < kallsyms->num_symtab; i++)
@@ -4068,6 +4220,7 @@ unsigned long module_kallsyms_lookup_name(const char *name)
 	/* Don't lock: we're in enough trouble already. */
 	preempt_disable();
 	if ((colon = strnchr(name, MODULE_NAME_LEN, ':')) != NULL) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if ((mod = find_module_all(name, colon - name, false)) != NULL)
 			ret = mod_find_symname(mod, colon+1);
 	} else {
@@ -4092,6 +4245,7 @@ int module_kallsyms_on_each_symbol(int (*fn)(void *, const char *,
 
 	module_assert_mutex();
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry(mod, &modules, list) {
 		/* We hold module_mutex: no need for rcu_dereference_sched */
 		struct mod_kallsyms *kallsyms = mod->kallsyms;
@@ -4117,6 +4271,7 @@ static char *module_flags(struct module *mod, char *buf)
 {
 	int bx = 0;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	BUG_ON(mod->state == MODULE_STATE_UNFORMED);
 	if (mod->taints ||
 	    mod->state == MODULE_STATE_GOING ||
@@ -4146,6 +4301,7 @@ static void *m_start(struct seq_file *m, loff_t *pos)
 
 static void *m_next(struct seq_file *m, void *p, loff_t *pos)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return seq_list_next(p, &modules, pos);
 }
 
@@ -4156,6 +4312,7 @@ static void m_stop(struct seq_file *m, void *p)
 
 static int m_show(struct seq_file *m, void *p)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct module *mod = list_entry(p, struct module, list);
 	char buf[MODULE_FLAGS_BUF_SIZE];
 
@@ -4226,6 +4383,7 @@ const struct exception_table_entry *search_module_extables(unsigned long addr)
 	if (!mod)
 		goto out;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!mod->num_exentries)
 		goto out;
 
@@ -4272,16 +4430,24 @@ struct module *__module_address(unsigned long addr)
 	struct module *mod;
 
 	if (addr < module_addr_min || addr > module_addr_max)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	module_assert_mutex_or_preempt();
 
 	mod = mod_find(addr);
 	if (mod) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		BUG_ON(!within_module(addr, mod));
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (mod->state == MODULE_STATE_UNFORMED)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			mod = NULL;
+}
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return mod;
 }
 EXPORT_SYMBOL_GPL(__module_address);
@@ -4314,6 +4480,7 @@ bool is_module_text_address(unsigned long addr)
  */
 struct module *__module_text_address(unsigned long addr)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct module *mod = __module_address(addr);
 	if (mod) {
 		/* Make sure it's within the text section. */
@@ -4334,6 +4501,7 @@ void print_modules(void)
 	printk(KERN_DEFAULT "Modules linked in:");
 	/* Most callers should already have preempt disabled, but make sure */
 	preempt_disable();
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry_rcu(mod, &modules, list) {
 		if (mod->state == MODULE_STATE_UNFORMED)
 			continue;
diff --git a/kernel/notifier.c b/kernel/notifier.c
index 6196af8..5e61773 100644
--- a/kernel/notifier.c
+++ b/kernel/notifier.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 #include <linux/kdebug.h>
 #include <linux/kprobes.h>
 #include <linux/export.h>
@@ -34,6 +36,7 @@ static int notifier_chain_register(struct notifier_block **nl,
 static int notifier_chain_cond_register(struct notifier_block **nl,
 		struct notifier_block *n)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	while ((*nl) != NULL) {
 		if ((*nl) == n)
 			return 0;
@@ -49,6 +52,7 @@ static int notifier_chain_cond_register(struct notifier_block **nl,
 static int notifier_chain_unregister(struct notifier_block **nl,
 		struct notifier_block *n)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	while ((*nl) != NULL) {
 		if ((*nl) == n) {
 			rcu_assign_pointer(*nl, n->next);
@@ -93,10 +97,13 @@ static int notifier_call_chain(struct notifier_block **nl,
 		ret = nb->notifier_call(nb, val, v);
 
 		if (nr_calls)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			(*nr_calls)++;
+}
 
 		if (ret & NOTIFY_STOP_MASK)
 			break;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		nb = next_nb;
 		nr_to_call--;
 	}
@@ -146,6 +153,7 @@ int atomic_notifier_chain_unregister(struct atomic_notifier_head *nh,
 	unsigned long flags;
 	int ret;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_lock_irqsave(&nh->lock, flags);
 	ret = notifier_chain_unregister(&nh->head, n);
 	spin_unlock_irqrestore(&nh->lock, flags);
@@ -274,7 +282,9 @@ int blocking_notifier_chain_unregister(struct blocking_notifier_head *nh,
 	 * such times we must not call down_write().
 	 */
 	if (unlikely(system_state == SYSTEM_BOOTING))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return notifier_chain_unregister(&nh->head, n);
+}
 
 	down_write(&nh->rwsem);
 	ret = notifier_chain_unregister(&nh->head, n);
@@ -364,6 +374,7 @@ EXPORT_SYMBOL_GPL(raw_notifier_chain_register);
 int raw_notifier_chain_unregister(struct raw_notifier_head *nh,
 		struct notifier_block *n)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return notifier_chain_unregister(&nh->head, n);
 }
 EXPORT_SYMBOL_GPL(raw_notifier_chain_unregister);
@@ -429,7 +440,9 @@ int srcu_notifier_chain_register(struct srcu_notifier_head *nh,
 	 * such times we must not call mutex_lock().
 	 */
 	if (unlikely(system_state == SYSTEM_BOOTING))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return notifier_chain_register(&nh->head, n);
+}
 
 	mutex_lock(&nh->mutex);
 	ret = notifier_chain_register(&nh->head, n);
@@ -459,7 +472,9 @@ int srcu_notifier_chain_unregister(struct srcu_notifier_head *nh,
 	 * such times we must not call mutex_lock().
 	 */
 	if (unlikely(system_state == SYSTEM_BOOTING))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return notifier_chain_unregister(&nh->head, n);
+}
 
 	mutex_lock(&nh->mutex);
 	ret = notifier_chain_unregister(&nh->head, n);
@@ -504,6 +519,7 @@ EXPORT_SYMBOL_GPL(__srcu_notifier_call_chain);
 int srcu_notifier_call_chain(struct srcu_notifier_head *nh,
 		unsigned long val, void *v)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return __srcu_notifier_call_chain(nh, val, v, -1, NULL);
 }
 EXPORT_SYMBOL_GPL(srcu_notifier_call_chain);
@@ -524,7 +540,9 @@ void srcu_init_notifier_head(struct srcu_notifier_head *nh)
 {
 	mutex_init(&nh->mutex);
 	if (init_srcu_struct(&nh->srcu) < 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		BUG();
+}
 	nh->head = NULL;
 }
 EXPORT_SYMBOL_GPL(srcu_init_notifier_head);
@@ -544,6 +562,7 @@ int notrace notify_die(enum die_val val, const char *str,
 		.signr	= sig,
 
 	};
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	RCU_LOCKDEP_WARN(!rcu_is_watching(),
 			   "notify_die called but RCU thinks we're quiescent");
 	return atomic_notifier_call_chain(&die_chain, val, &args);
@@ -559,6 +578,7 @@ EXPORT_SYMBOL_GPL(register_die_notifier);
 
 int unregister_die_notifier(struct notifier_block *nb)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return atomic_notifier_chain_unregister(&die_chain, nb);
 }
 EXPORT_SYMBOL_GPL(unregister_die_notifier);
diff --git a/kernel/nsproxy.c b/kernel/nsproxy.c
index f6c5d33..a1957c1 100644
--- a/kernel/nsproxy.c
+++ b/kernel/nsproxy.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  *  Copyright (C) 2006 IBM Corporation
  *
@@ -52,7 +54,9 @@ static inline struct nsproxy *create_nsproxy(void)
 
 	nsproxy = kmem_cache_alloc(nsproxy_cachep, GFP_KERNEL);
 	if (nsproxy)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		atomic_set(&nsproxy->count, 1);
+}
 	return nsproxy;
 }
 
@@ -70,22 +74,27 @@ static struct nsproxy *create_new_namespaces(unsigned long flags,
 
 	new_nsp = create_nsproxy();
 	if (!new_nsp)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ERR_PTR(-ENOMEM);
+}
 
 	new_nsp->mnt_ns = copy_mnt_ns(flags, tsk->nsproxy->mnt_ns, user_ns, new_fs);
 	if (IS_ERR(new_nsp->mnt_ns)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		err = PTR_ERR(new_nsp->mnt_ns);
 		goto out_ns;
 	}
 
 	new_nsp->uts_ns = copy_utsname(flags, user_ns, tsk->nsproxy->uts_ns);
 	if (IS_ERR(new_nsp->uts_ns)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		err = PTR_ERR(new_nsp->uts_ns);
 		goto out_uts;
 	}
 
 	new_nsp->ipc_ns = copy_ipcs(flags, user_ns, tsk->nsproxy->ipc_ns);
 	if (IS_ERR(new_nsp->ipc_ns)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		err = PTR_ERR(new_nsp->ipc_ns);
 		goto out_ipc;
 	}
@@ -93,6 +102,7 @@ static struct nsproxy *create_new_namespaces(unsigned long flags,
 	new_nsp->pid_ns_for_children =
 		copy_pid_ns(flags, user_ns, tsk->nsproxy->pid_ns_for_children);
 	if (IS_ERR(new_nsp->pid_ns_for_children)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		err = PTR_ERR(new_nsp->pid_ns_for_children);
 		goto out_pid;
 	}
@@ -100,32 +110,43 @@ static struct nsproxy *create_new_namespaces(unsigned long flags,
 	new_nsp->cgroup_ns = copy_cgroup_ns(flags, user_ns,
 					    tsk->nsproxy->cgroup_ns);
 	if (IS_ERR(new_nsp->cgroup_ns)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		err = PTR_ERR(new_nsp->cgroup_ns);
 		goto out_cgroup;
 	}
 
 	new_nsp->net_ns = copy_net_ns(flags, user_ns, tsk->nsproxy->net_ns);
 	if (IS_ERR(new_nsp->net_ns)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		err = PTR_ERR(new_nsp->net_ns);
 		goto out_net;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return new_nsp;
 
 out_net:
 	put_cgroup_ns(new_nsp->cgroup_ns);
 out_cgroup:
 	if (new_nsp->pid_ns_for_children)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		put_pid_ns(new_nsp->pid_ns_for_children);
+}
 out_pid:
 	if (new_nsp->ipc_ns)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		put_ipc_ns(new_nsp->ipc_ns);
+}
 out_ipc:
 	if (new_nsp->uts_ns)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		put_uts_ns(new_nsp->uts_ns);
+}
 out_uts:
 	if (new_nsp->mnt_ns)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		put_mnt_ns(new_nsp->mnt_ns);
+}
 out_ns:
 	kmem_cache_free(nsproxy_cachep, new_nsp);
 	return ERR_PTR(err);
@@ -148,8 +169,11 @@ int copy_namespaces(unsigned long flags, struct task_struct *tsk)
 		return 0;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!ns_capable(user_ns, CAP_SYS_ADMIN))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EPERM;
+}
 
 	/*
 	 * CLONE_NEWIPC must detach from the undolist: after switching
@@ -162,10 +186,14 @@ int copy_namespaces(unsigned long flags, struct task_struct *tsk)
 		(CLONE_NEWIPC | CLONE_SYSVSEM)) 
 		return -EINVAL;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	new_ns = create_new_namespaces(flags, tsk, user_ns, tsk->fs);
 	if (IS_ERR(new_ns))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return  PTR_ERR(new_ns);
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	tsk->nsproxy = new_ns;
 	return 0;
 }
@@ -201,11 +229,14 @@ int unshare_nsproxy_namespaces(unsigned long unshare_flags,
 
 	user_ns = new_cred ? new_cred->user_ns : current_user_ns();
 	if (!ns_capable(user_ns, CAP_SYS_ADMIN))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EPERM;
+}
 
 	*new_nsp = create_new_namespaces(unshare_flags, current, user_ns,
 					 new_fs ? new_fs : current->fs);
 	if (IS_ERR(*new_nsp)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		err = PTR_ERR(*new_nsp);
 		goto out;
 	}
@@ -220,6 +251,7 @@ void switch_task_namespaces(struct task_struct *p, struct nsproxy *new)
 
 	might_sleep();
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	task_lock(p);
 	ns = p->nsproxy;
 	p->nsproxy = new;
@@ -244,8 +276,11 @@ SYSCALL_DEFINE2(setns, int, fd, int, nstype)
 
 	file = proc_ns_fget(fd);
 	if (IS_ERR(file))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return PTR_ERR(file);
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	err = -EINVAL;
 	ns = get_proc_ns(file_inode(file));
 	if (nstype && (ns->ops->type != nstype))
@@ -253,12 +288,14 @@ SYSCALL_DEFINE2(setns, int, fd, int, nstype)
 
 	new_nsproxy = create_new_namespaces(0, tsk, current_user_ns(), tsk->fs);
 	if (IS_ERR(new_nsproxy)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		err = PTR_ERR(new_nsproxy);
 		goto out;
 	}
 
 	err = ns->ops->install(new_nsproxy, ns);
 	if (err) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		free_nsproxy(new_nsproxy);
 		goto out;
 	}
diff --git a/kernel/panic.c b/kernel/panic.c
index bdd18af..7be77f1 100644
--- a/kernel/panic.c
+++ b/kernel/panic.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  *  linux/kernel/panic.c
  *
@@ -48,6 +50,7 @@ EXPORT_SYMBOL(panic_notifier_list);
 
 static long no_blink(int state)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
@@ -60,6 +63,7 @@ EXPORT_SYMBOL(panic_blink);
  */
 void __weak panic_smp_self_stop(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	while (1)
 		cpu_relax();
 }
@@ -70,6 +74,7 @@ void __weak panic_smp_self_stop(void)
  */
 void __weak nmi_panic_self_stop(struct pt_regs *regs)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	panic_smp_self_stop();
 }
 
@@ -88,7 +93,9 @@ void __weak crash_smp_send_stop(void)
 	 * we execute this only once.
 	 */
 	if (cpus_stopped)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	/*
 	 * Note smp_send_stop is the usual smp shutdown function, which
@@ -111,6 +118,7 @@ void nmi_panic(struct pt_regs *regs, const char *msg)
 {
 	int old_cpu, cpu;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	cpu = raw_smp_processor_id();
 	old_cpu = atomic_cmpxchg(&panic_cpu, PANIC_CPU_INVALID, cpu);
 
@@ -355,6 +363,7 @@ const char *print_tainted(void)
 		int i;
 
 		s = buf + sprintf(buf, "Tainted: ");
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		for (i = 0; i < TAINT_FLAGS_COUNT; i++) {
 			const struct taint_flag *t = &taint_flags[i];
 			*s++ = test_bit(i, &tainted_mask) ?
@@ -375,6 +384,7 @@ EXPORT_SYMBOL(test_taint);
 
 unsigned long get_taint(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return tainted_mask;
 }
 
@@ -388,6 +398,7 @@ unsigned long get_taint(void)
  */
 void add_taint(unsigned flag, enum lockdep_ok lockdep_ok)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (lockdep_ok == LOCKDEP_NOW_UNRELIABLE && __debug_locks_off())
 		pr_warn("Disabling lock debugging due to kernel taint\n");
 
@@ -399,6 +410,7 @@ static void spin_msec(int msecs)
 {
 	int i;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (i = 0; i < msecs; i++) {
 		touch_nmi_watchdog();
 		mdelay(1);
@@ -415,7 +427,9 @@ static void do_oops_enter_exit(void)
 	static int spin_counter;
 
 	if (!pause_on_oops)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	spin_lock_irqsave(&pause_on_oops_lock, flags);
 	if (pause_on_oops_flag == 0) {
@@ -450,6 +464,7 @@ static void do_oops_enter_exit(void)
  */
 int oops_may_print(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return pause_on_oops_flag == 0;
 }
 
@@ -469,6 +484,7 @@ int oops_may_print(void)
  */
 void oops_enter(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	tracing_off();
 	/* can't trust the integrity of the kernel anymore: */
 	debug_locks_off();
@@ -493,6 +509,7 @@ late_initcall(init_oops_id);
 
 void print_oops_end_marker(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	init_oops_id();
 	pr_warn("---[ end trace %016llx ]---\n", (unsigned long long)oops_id);
 }
@@ -503,6 +520,7 @@ void print_oops_end_marker(void)
  */
 void oops_exit(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	do_oops_enter_exit();
 	print_oops_end_marker();
 	kmsg_dump(KMSG_DUMP_OOPS);
@@ -516,6 +534,7 @@ struct warn_args {
 void __warn(const char *file, int line, void *caller, unsigned taint,
 	    struct pt_regs *regs, struct warn_args *args)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	disable_trace_on_warning();
 
 	pr_warn("------------[ cut here ]------------\n");
@@ -605,6 +624,7 @@ EXPORT_SYMBOL(__stack_chk_fail);
 #ifdef CONFIG_ARCH_HAS_REFCOUNT
 void refcount_error_report(struct pt_regs *regs, const char *err)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WARN_RATELIMIT(1, "refcount_t %s at %pB in %s[%d], uid/euid: %u/%u\n",
 		err, (void *)instruction_pointer(regs),
 		current->comm, task_pid_nr(current),
@@ -620,6 +640,7 @@ core_param(crash_kexec_post_notifiers, crash_kexec_post_notifiers, bool, 0644);
 
 static int __init oops_setup(char *s)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!s)
 		return -EINVAL;
 	if (!strcmp(s, "panic"))
diff --git a/kernel/params.c b/kernel/params.c
index cc9108c..c161285 100644
--- a/kernel/params.c
+++ b/kernel/params.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /* Helpers for initial module or kernel cmdline parsing
    Copyright (C) 2001 Rusty Russell.
 
@@ -38,6 +40,7 @@ static DEFINE_MUTEX(param_lock);
 
 static inline void check_kparam_locked(struct module *mod)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	BUG_ON(!mutex_is_locked(KPARAM_MUTEX(mod)));
 }
 #else
@@ -60,7 +63,9 @@ static void *kmalloc_parameter(unsigned int size)
 
 	p = kmalloc(sizeof(*p) + size, GFP_KERNEL);
 	if (!p)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 
 	spin_lock(&kmalloced_params_lock);
 	list_add(&p->list, &kmalloced_params);
@@ -75,6 +80,7 @@ static void maybe_kfree_parameter(void *param)
 	struct kmalloced_param *p;
 
 	spin_lock(&kmalloced_params_lock);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry(p, &kmalloced_params, list) {
 		if (p->val == param) {
 			list_del(&p->list);
@@ -88,7 +94,10 @@ static void maybe_kfree_parameter(void *param)
 static char dash2underscore(char c)
 {
 	if (c == '-')
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return '_';
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return c;
 }
 
@@ -98,8 +107,11 @@ bool parameqn(const char *a, const char *b, size_t n)
 
 	for (i = 0; i < n; i++) {
 		if (dash2underscore(a[i]) != dash2underscore(b[i]))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return false;
+}
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return true;
 }
 
@@ -110,6 +122,7 @@ bool parameq(const char *a, const char *b)
 
 static void param_check_unsafe(const struct kernel_param *kp)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (kp->flags & KERNEL_PARAM_FL_UNSAFE) {
 		pr_warn("Setting dangerous option %s - tainting kernel\n",
 			kp->name);
@@ -134,6 +147,7 @@ static int parse_one(char *param,
 	/* Find parameter */
 	for (i = 0; i < num_params; i++) {
 		if (parameq(param, params[i].name)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			if (params[i].level < min_level
 			    || params[i].level > max_level)
 				return 0;
@@ -141,6 +155,7 @@ static int parse_one(char *param,
 			if (!val &&
 			    !(params[i].ops->flags & KERNEL_PARAM_OPS_FL_NOARG))
 				return -EINVAL;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			pr_debug("handling %s with %p\n", param,
 				params[i].ops->set);
 			kernel_param_lock(params[i].mod);
@@ -152,10 +167,12 @@ static int parse_one(char *param,
 	}
 
 	if (handle_unknown) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_debug("doing %s: %s='%s'\n", doing, param, val);
 		return handle_unknown(param, val, doing, arg);
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pr_debug("Unknown argument '%s'\n", param);
 	return -ENOENT;
 }
@@ -177,7 +194,9 @@ char *parse_args(const char *doing,
 	args = skip_spaces(args);
 
 	if (*args)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_debug("doing %s, parsing ARGS: '%s'\n", doing, args);
+}
 
 	while (*args) {
 		int ret;
@@ -186,13 +205,17 @@ char *parse_args(const char *doing,
 		args = next_arg(args, &param, &val);
 		/* Stop at -- */
 		if (!val && strcmp(param, "--") == 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return err ?: args;
+}
 		irq_was_disabled = irqs_disabled();
 		ret = parse_one(param, val, doing, params, num,
 				min_level, max_level, arg, unknown);
 		if (irq_was_disabled && !irqs_disabled())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			pr_warn("%s: option '%s' enabled irq's!\n",
 				doing, param);
+}
 
 		switch (ret) {
 		case 0:
@@ -210,9 +233,11 @@ char *parse_args(const char *doing,
 			break;
 		}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		err = ERR_PTR(ret);
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return err;
 }
 
@@ -247,6 +272,7 @@ STANDARD_PARAM_DEF(ullong,	unsigned long long,	"%llu", kstrtoull);
 
 int param_set_charp(const char *val, const struct kernel_param *kp)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (strlen(val) > 1024) {
 		pr_err("%s: string parameter too long\n", kp->name);
 		return -ENOSPC;
@@ -270,12 +296,14 @@ EXPORT_SYMBOL(param_set_charp);
 
 int param_get_charp(char *buffer, const struct kernel_param *kp)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return scnprintf(buffer, PAGE_SIZE, "%s\n", *((char **)kp->arg));
 }
 EXPORT_SYMBOL(param_get_charp);
 
 void param_free_charp(void *arg)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	maybe_kfree_parameter(*((char **)arg));
 }
 EXPORT_SYMBOL(param_free_charp);
@@ -323,7 +351,9 @@ int param_set_bool_enable_only(const char *val, const struct kernel_param *kp)
 
 	err = param_set_bool(val, &dummy_kp);
 	if (err)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return err;
+}
 
 	/* Don't let them unset it once it's set! */
 	if (!new_value && orig_value)
@@ -353,13 +383,16 @@ int param_set_invbool(const char *val, const struct kernel_param *kp)
 	dummy.arg = &boolval;
 	ret = param_set_bool(val, &dummy);
 	if (ret == 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		*(bool *)kp->arg = !boolval;
+}
 	return ret;
 }
 EXPORT_SYMBOL(param_set_invbool);
 
 int param_get_invbool(char *buffer, const struct kernel_param *kp)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return sprintf(buffer, "%c\n", (*(bool *)kp->arg) ? 'N' : 'Y');
 }
 EXPORT_SYMBOL(param_get_invbool);
@@ -381,7 +414,9 @@ int param_set_bint(const char *val, const struct kernel_param *kp)
 
 	ret = param_set_bool(val, &boolkp);
 	if (ret == 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		*(int *)kp->arg = v;
+}
 	return ret;
 }
 EXPORT_SYMBOL(param_set_bint);
@@ -418,6 +453,7 @@ static int param_array(struct module *mod,
 		int len;
 
 		if (*num == max) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			pr_err("%s: can only take %i arguments\n", name, max);
 			return -EINVAL;
 		}
@@ -459,6 +495,7 @@ static int param_array_get(char *buffer, const struct kernel_param *kp)
 	const struct kparam_array *arr = kp->arr;
 	struct kernel_param p = *kp;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (i = off = 0; i < (arr->num ? *arr->num : arr->max); i++) {
 		/* Replace \n with comma */
 		if (i)
@@ -480,9 +517,11 @@ static void param_array_free(void *arg)
 	const struct kparam_array *arr = arg;
 
 	if (arr->ops->free)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		for (i = 0; i < (arr->num ? *arr->num : arr->max); i++)
 			arr->ops->free(arr->elem + arr->elemsize * i);
 }
+}
 
 const struct kernel_param_ops param_array_ops = {
 	.set = param_array_set,
@@ -496,6 +535,7 @@ int param_set_copystring(const char *val, const struct kernel_param *kp)
 	const struct kparam_string *kps = kp->str;
 
 	if (strlen(val)+1 > kps->maxlen) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_err("%s: string doesn't fit in %u chars.\n",
 		       kp->name, kps->maxlen-1);
 		return -ENOSPC;
@@ -542,6 +582,7 @@ static ssize_t param_attr_show(struct module_attribute *mattr,
 			       struct module_kobject *mk, char *buf)
 {
 	int count;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct param_attribute *attribute = to_param_attr(mattr);
 
 	if (!attribute->param->ops->get)
@@ -559,6 +600,7 @@ static ssize_t param_attr_store(struct module_attribute *mattr,
 				const char *buf, size_t len)
 {
  	int err;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct param_attribute *attribute = to_param_attr(mattr);
 
 	if (!attribute->param->ops->set)
@@ -583,11 +625,13 @@ static ssize_t param_attr_store(struct module_attribute *mattr,
 #ifdef CONFIG_SYSFS
 void kernel_param_lock(struct module *mod)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	mutex_lock(KPARAM_MUTEX(mod));
 }
 
 void kernel_param_unlock(struct module *mod)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	mutex_unlock(KPARAM_MUTEX(mod));
 }
 
@@ -619,14 +663,18 @@ static __modinit int add_sysfs_param(struct module_kobject *mk,
 		/* First allocation. */
 		mk->mp = kzalloc(sizeof(*mk->mp), GFP_KERNEL);
 		if (!mk->mp)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -ENOMEM;
+}
 		mk->mp->grp.name = "parameters";
 		/* NULL-terminated attribute array. */
 		mk->mp->grp.attrs = kzalloc(sizeof(mk->mp->grp.attrs[0]),
 					    GFP_KERNEL);
 		/* Caller will cleanup via free_module_param_attrs */
 		if (!mk->mp->grp.attrs)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -ENOMEM;
+}
 	}
 
 	/* Enlarge allocations. */
@@ -635,7 +683,9 @@ static __modinit int add_sysfs_param(struct module_kobject *mk,
 			  sizeof(mk->mp->attrs[0]) * (mk->mp->num + 1),
 			  GFP_KERNEL);
 	if (!new_mp)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 	mk->mp = new_mp;
 
 	/* Extra pointer for NULL terminator */
@@ -643,11 +693,14 @@ static __modinit int add_sysfs_param(struct module_kobject *mk,
 			     sizeof(mk->mp->grp.attrs[0]) * (mk->mp->num + 2),
 			     GFP_KERNEL);
 	if (!new_attrs)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 	mk->mp->grp.attrs = new_attrs;
 
 	/* Tack new one on the end. */
 	memset(&mk->mp->attrs[mk->mp->num], 0, sizeof(mk->mp->attrs[0]));
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	sysfs_attr_init(&mk->mp->attrs[mk->mp->num].mattr.attr);
 	mk->mp->attrs[mk->mp->num].param = kp;
 	mk->mp->attrs[mk->mp->num].mattr.show = param_attr_show;
@@ -670,6 +723,7 @@ static __modinit int add_sysfs_param(struct module_kobject *mk,
 #ifdef CONFIG_MODULES
 static void free_module_param_attrs(struct module_kobject *mk)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (mk->mp)
 		kfree(mk->mp->grp.attrs);
 	kfree(mk->mp);
@@ -692,6 +746,7 @@ int module_param_sysfs_setup(struct module *mod,
 	int i, err;
 	bool params = false;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (i = 0; i < num_params; i++) {
 		if (kparam[i].perm == 0)
 			continue;
@@ -722,6 +777,7 @@ int module_param_sysfs_setup(struct module *mod,
  */
 void module_param_sysfs_remove(struct module *mod)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (mod->mkobj.mp) {
 		sysfs_remove_group(&mod->mkobj.kobj, &mod->mkobj.mp->grp);
 		/* We are positive that no one is using any param
@@ -735,6 +791,7 @@ void destroy_params(const struct kernel_param *params, unsigned num)
 {
 	unsigned int i;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (i = 0; i < num; i++)
 		if (params[i].ops->free)
 			params[i].ops->free(params[i].arg);
@@ -748,6 +805,7 @@ static struct module_kobject * __init locate_module_kobject(const char *name)
 
 	kobj = kset_find_obj(module_kset, name);
 	if (kobj) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		mk = to_module_kobject(kobj);
 	} else {
 		mk = kzalloc(sizeof(struct module_kobject), GFP_KERNEL);
@@ -762,6 +820,7 @@ static struct module_kobject * __init locate_module_kobject(const char *name)
 			err = sysfs_create_file(&mk->kobj, &module_uevent.attr);
 #endif
 		if (err) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			kobject_put(&mk->kobj);
 			pr_crit("Adding module '%s' to sysfs failed (%d), the system may be unstable.\n",
 				name, err);
@@ -772,6 +831,7 @@ static struct module_kobject * __init locate_module_kobject(const char *name)
 		kobject_get(&mk->kobj);
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return mk;
 }
 
@@ -784,7 +844,9 @@ static void __init kernel_add_sysfs_param(const char *name,
 
 	mk = locate_module_kobject(name);
 	if (!mk)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	/* We need to remove old parameters before adding more. */
 	if (mk->mp)
@@ -875,6 +937,7 @@ static ssize_t module_attr_show(struct kobject *kobj,
 	struct module_kobject *mk;
 	int ret;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	attribute = to_module_attr(attr);
 	mk = to_module_kobject(kobj);
 
@@ -894,6 +957,7 @@ static ssize_t module_attr_store(struct kobject *kobj,
 	struct module_kobject *mk;
 	int ret;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	attribute = to_module_attr(attr);
 	mk = to_module_kobject(kobj);
 
@@ -912,10 +976,14 @@ static const struct sysfs_ops module_sysfs_ops = {
 
 static int uevent_filter(struct kset *kset, struct kobject *kobj)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct kobj_type *ktype = get_ktype(kobj);
 
 	if (ktype == &module_ktype)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 1;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
@@ -928,6 +996,7 @@ int module_sysfs_initialized;
 
 static void module_kobj_release(struct kobject *kobj)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct module_kobject *mk = to_module_kobject(kobj);
 	complete(mk->kobj_completion);
 }
@@ -944,6 +1013,7 @@ static int __init param_sysfs_init(void)
 {
 	module_kset = kset_create_and_add("module", &module_uevent_ops, NULL);
 	if (!module_kset) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		printk(KERN_WARNING "%s (%d): error creating kset\n",
 			__FILE__, __LINE__);
 		return -ENOMEM;
diff --git a/kernel/pid.c b/kernel/pid.c
index 020dedb..0cbbe91 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * Generic pidhash and scalable, time-bounded PID allocator
  *
@@ -145,6 +147,7 @@ static void set_last_pid(struct pid_namespace *pid_ns, int base, int pid)
 	int prev;
 	int last_write = base;
 	do {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		prev = last_write;
 		last_write = cmpxchg(&pid_ns->last_pid, prev, pid);
 	} while ((prev != last_write) && (pid_before(base, last_write, pid)));
@@ -157,7 +160,9 @@ static int alloc_pidmap(struct pid_namespace *pid_ns)
 
 	pid = last + 1;
 	if (pid >= pid_max)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pid = RESERVED_PIDS;
+}
 	offset = pid & BITS_PER_PAGE_MASK;
 	map = &pid_ns->pidmap[pid/BITS_PER_PAGE];
 	/*
@@ -168,6 +173,7 @@ static int alloc_pidmap(struct pid_namespace *pid_ns)
 	max_scan = DIV_ROUND_UP(pid_max, BITS_PER_PAGE) - !offset;
 	for (i = 0; i <= max_scan; ++i) {
 		if (unlikely(!map->page)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			void *page = kzalloc(PAGE_SIZE, GFP_KERNEL);
 			/*
 			 * Free the page if someone raced with us
@@ -175,13 +181,17 @@ static int alloc_pidmap(struct pid_namespace *pid_ns)
 			 */
 			spin_lock_irq(&pidmap_lock);
 			if (!map->page) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				map->page = page;
 				page = NULL;
 			}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			spin_unlock_irq(&pidmap_lock);
 			kfree(page);
 			if (unlikely(!map->page))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				return -ENOMEM;
+}
 		}
 		if (likely(atomic_read(&map->nr_free))) {
 			for ( ; ; ) {
@@ -190,25 +200,32 @@ static int alloc_pidmap(struct pid_namespace *pid_ns)
 					set_last_pid(pid_ns, last, pid);
 					return pid;
 				}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				offset = find_next_offset(map, offset);
 				if (offset >= BITS_PER_PAGE)
 					break;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				pid = mk_pid(pid_ns, map, offset);
 				if (pid >= pid_max)
 					break;
 			}
 		}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (map < &pid_ns->pidmap[(pid_max-1)/BITS_PER_PAGE]) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			++map;
 			offset = 0;
 		} else {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			map = &pid_ns->pidmap[0];
 			offset = RESERVED_PIDS;
 			if (unlikely(last == offset))
 				break;
 		}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pid = mk_pid(pid_ns, map, offset);
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return -EAGAIN;
 }
 
@@ -218,7 +235,9 @@ int next_pidmap(struct pid_namespace *pid_ns, unsigned int last)
 	struct pidmap *map, *end;
 
 	if (last >= PID_MAX_LIMIT)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -1;
+}
 
 	offset = (last + 1) & BITS_PER_PAGE_MASK;
 	map = &pid_ns->pidmap[(last + 1)/BITS_PER_PAGE];
@@ -230,6 +249,7 @@ int next_pidmap(struct pid_namespace *pid_ns, unsigned int last)
 		if (offset < BITS_PER_PAGE)
 			return mk_pid(pid_ns, map, offset);
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return -1;
 }
 
@@ -238,7 +258,9 @@ void put_pid(struct pid *pid)
 	struct pid_namespace *ns;
 
 	if (!pid)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	ns = pid->numbers[pid->level].ns;
 	if ((atomic_read(&pid->count) == 1) ||
@@ -285,6 +307,7 @@ void free_pid(struct pid *pid)
 			break;
 		}
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_unlock_irqrestore(&pidmap_lock, flags);
 
 	for (i = 0; i <= pid->level; i++)
@@ -304,13 +327,17 @@ struct pid *alloc_pid(struct pid_namespace *ns)
 
 	pid = kmem_cache_alloc(ns->pid_cachep, GFP_KERNEL);
 	if (!pid)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ERR_PTR(retval);
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	tmp = ns;
 	pid->level = ns->level;
 	for (i = ns->level; i >= 0; i--) {
 		nr = alloc_pidmap(tmp);
 		if (nr < 0) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			retval = nr;
 			goto out_free;
 		}
@@ -322,6 +349,7 @@ struct pid *alloc_pid(struct pid_namespace *ns)
 
 	if (unlikely(is_child_reaper(pid))) {
 		if (pid_ns_prepare_proc(ns)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			disable_pid_allocation(ns);
 			goto out_free;
 		}
@@ -341,6 +369,7 @@ struct pid *alloc_pid(struct pid_namespace *ns)
 				&pid_hash[pid_hashfn(upid->nr, upid->ns)]);
 		upid->ns->nr_hashed++;
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_unlock_irq(&pidmap_lock);
 
 	return pid;
@@ -353,12 +382,14 @@ struct pid *alloc_pid(struct pid_namespace *ns)
 	while (++i <= ns->level)
 		free_pidmap(pid->numbers + i);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	kmem_cache_free(ns->pid_cachep, pid);
 	return ERR_PTR(retval);
 }
 
 void disable_pid_allocation(struct pid_namespace *ns)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_lock_irq(&pidmap_lock);
 	ns->nr_hashed &= ~PIDNS_HASH_ADDING;
 	spin_unlock_irq(&pidmap_lock);
@@ -374,6 +405,7 @@ struct pid *find_pid_ns(int nr, struct pid_namespace *ns)
 			return container_of(pnr, struct pid,
 					numbers[ns->level]);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return NULL;
 }
 EXPORT_SYMBOL_GPL(find_pid_ns);
@@ -408,7 +440,9 @@ static void __change_pid(struct task_struct *task, enum pid_type type,
 
 	for (tmp = PIDTYPE_MAX; --tmp >= 0; )
 		if (!hlist_empty(&pid->tasks[tmp]))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return;
+}
 
 	free_pid(pid);
 }
@@ -452,6 +486,7 @@ EXPORT_SYMBOL(pid_task);
  */
 struct task_struct *find_task_by_pid_ns(pid_t nr, struct pid_namespace *ns)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	RCU_LOCKDEP_WARN(!rcu_read_lock_held(),
 			 "find_task_by_pid_ns() needs rcu_read_lock() protection");
 	return pid_task(find_pid_ns(nr, ns), PIDTYPE_PID);
@@ -467,7 +502,9 @@ struct pid *get_task_pid(struct task_struct *task, enum pid_type type)
 	struct pid *pid;
 	rcu_read_lock();
 	if (type != PIDTYPE_PID)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		task = task->group_leader;
+}
 	pid = get_pid(rcu_dereference(task->pids[type].pid));
 	rcu_read_unlock();
 	return pid;
@@ -481,6 +518,7 @@ struct task_struct *get_pid_task(struct pid *pid, enum pid_type type)
 	result = pid_task(pid, type);
 	if (result)
 		get_task_struct(result);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rcu_read_unlock();
 	return result;
 }
@@ -504,6 +542,7 @@ pid_t pid_nr_ns(struct pid *pid, struct pid_namespace *ns)
 	pid_t nr = 0;
 
 	if (pid && ns->level <= pid->level) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		upid = &pid->numbers[ns->level];
 		if (upid->ns == ns)
 			nr = upid->nr;
@@ -529,11 +568,14 @@ pid_t __task_pid_nr_ns(struct task_struct *task, enum pid_type type,
 	if (likely(pid_alive(task))) {
 		if (type != PIDTYPE_PID) {
 			if (type == __PIDTYPE_TGID)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				type = PIDTYPE_PID;
+}
 			task = task->group_leader;
 		}
 		nr = pid_nr_ns(rcu_dereference(task->pids[type].pid), ns);
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rcu_read_unlock();
 
 	return nr;
diff --git a/kernel/pid_namespace.c b/kernel/pid_namespace.c
index 4918314..0b7e794 100644
--- a/kernel/pid_namespace.c
+++ b/kernel/pid_namespace.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * Pid namespaces
  *
@@ -48,6 +50,7 @@ static struct kmem_cache *create_pid_cachep(int nr_ids)
 		if (pcache->nr_ids == nr_ids)
 			goto out;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pcache = kmalloc(sizeof(struct pid_cache), GFP_KERNEL);
 	if (pcache == NULL)
 		goto err_alloc;
@@ -105,6 +108,7 @@ static struct pid_namespace *create_pid_namespace(struct user_namespace *user_ns
 	if (!in_userns(parent_pid_ns->user_ns, user_ns))
 		goto out;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	err = -ENOSPC;
 	if (level > MAX_PID_NS_LEVEL)
 		goto out;
@@ -112,6 +116,7 @@ static struct pid_namespace *create_pid_namespace(struct user_namespace *user_ns
 	if (!ucounts)
 		goto out;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	err = -ENOMEM;
 	ns = kmem_cache_zalloc(pid_ns_cachep, GFP_KERNEL);
 	if (ns == NULL)
@@ -144,6 +149,7 @@ static struct pid_namespace *create_pid_namespace(struct user_namespace *user_ns
 	for (i = 1; i < PIDMAP_ENTRIES; i++)
 		atomic_set(&ns->pidmap[i].nr_free, BITS_PER_PAGE);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return ns;
 
 out_free_map:
@@ -182,7 +188,9 @@ struct pid_namespace *copy_pid_ns(unsigned long flags,
 	if (!(flags & CLONE_NEWPID))
 		return get_pid_ns(old_ns);
 	if (task_active_pid_ns(current) != old_ns)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ERR_PTR(-EINVAL);
+}
 	return create_pid_namespace(user_ns, old_ns);
 }
 
@@ -202,6 +210,7 @@ void put_pid_ns(struct pid_namespace *ns)
 		parent = ns->parent;
 		if (!kref_put(&ns->kref, free_pid_ns))
 			break;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ns = parent;
 	}
 }
@@ -242,16 +251,19 @@ void zap_pid_ns_processes(struct pid_namespace *pid_ns)
 	read_lock(&tasklist_lock);
 	nr = next_pidmap(pid_ns, 1);
 	while (nr > 0) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		rcu_read_lock();
 
 		task = pid_task(find_vpid(nr), PIDTYPE_PID);
 		if (task && !__fatal_signal_pending(task))
 			send_sig_info(SIGKILL, SEND_SIG_FORCED, task);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		rcu_read_unlock();
 
 		nr = next_pidmap(pid_ns, nr);
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	read_unlock(&tasklist_lock);
 
 	/*
@@ -289,7 +301,9 @@ void zap_pid_ns_processes(struct pid_namespace *pid_ns)
 	__set_current_state(TASK_RUNNING);
 
 	if (pid_ns->reboot)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		current->signal->group_exit_code = pid_ns->reboot;
+}
 
 	acct_exit_ns(pid_ns);
 	return;
@@ -334,7 +348,9 @@ static struct ctl_path kern_path[] = { { .procname = "kernel", }, { } };
 int reboot_pid_ns(struct pid_namespace *pid_ns, int cmd)
 {
 	if (pid_ns == &init_pid_ns)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	switch (cmd) {
 	case LINUX_REBOOT_CMD_RESTART2:
@@ -350,6 +366,7 @@ int reboot_pid_ns(struct pid_namespace *pid_ns, int cmd)
 		return -EINVAL;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	read_lock(&tasklist_lock);
 	force_sig(SIGKILL, pid_ns->child_reaper);
 	read_unlock(&tasklist_lock);
@@ -373,6 +390,7 @@ static struct ns_common *pidns_get(struct task_struct *task)
 	ns = task_active_pid_ns(task);
 	if (ns)
 		get_pid_ns(ns);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rcu_read_unlock();
 
 	return ns ? &ns->ns : NULL;
@@ -384,6 +402,7 @@ static struct ns_common *pidns_for_children_get(struct task_struct *task)
 
 	task_lock(task);
 	if (task->nsproxy) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ns = task->nsproxy->pid_ns_for_children;
 		get_pid_ns(ns);
 	}
@@ -424,13 +443,18 @@ static int pidns_install(struct nsproxy *nsproxy, struct ns_common *ns)
 	 * children can not escape their current pid namespace.
 	 */
 	if (new->level < active->level)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	ancestor = new;
 	while (ancestor->level > active->level)
 		ancestor = ancestor->parent;
 	if (ancestor != active)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	put_pid_ns(nsproxy->pid_ns_for_children);
 	nsproxy->pid_ns_for_children = get_pid_ns(new);
@@ -439,6 +463,7 @@ static int pidns_install(struct nsproxy *nsproxy, struct ns_common *ns)
 
 static struct ns_common *pidns_get_parent(struct ns_common *ns)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct pid_namespace *active = task_active_pid_ns(current);
 	struct pid_namespace *pid_ns, *p;
 
@@ -457,6 +482,7 @@ static struct ns_common *pidns_get_parent(struct ns_common *ns)
 
 static struct user_namespace *pidns_owner(struct ns_common *ns)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return to_pid_ns(ns)->user_ns;
 }
 
diff --git a/kernel/power/main.c b/kernel/power/main.c
index 3a2ca90..2685170 100644
--- a/kernel/power/main.c
+++ b/kernel/power/main.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * kernel/power/main.c - PM subsystem core functionality.
  *
@@ -34,6 +36,7 @@ EXPORT_SYMBOL_GPL(register_pm_notifier);
 
 int unregister_pm_notifier(struct notifier_block *nb)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return blocking_notifier_chain_unregister(&pm_chain_head, nb);
 }
 EXPORT_SYMBOL_GPL(unregister_pm_notifier);
@@ -49,6 +52,7 @@ int __pm_notifier_call_chain(unsigned long val, int nr_to_call, int *nr_calls)
 }
 int pm_notifier_call_chain(unsigned long val)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return __pm_notifier_call_chain(val, -1, NULL);
 }
 
@@ -58,6 +62,7 @@ int pm_async_enabled = 1;
 static ssize_t pm_async_show(struct kobject *kobj, struct kobj_attribute *attr,
 			     char *buf)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return sprintf(buf, "%d\n", pm_async_enabled);
 }
 
@@ -67,7 +72,9 @@ static ssize_t pm_async_store(struct kobject *kobj, struct kobj_attribute *attr,
 	unsigned long val;
 
 	if (kstrtoul(buf, 10, &val))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	if (val > 1)
 		return -EINVAL;
@@ -85,6 +92,7 @@ static ssize_t mem_sleep_show(struct kobject *kobj, struct kobj_attribute *attr,
 	char *s = buf;
 	suspend_state_t i;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (i = PM_SUSPEND_MIN; i < PM_SUSPEND_MAX; i++)
 		if (mem_sleep_states[i]) {
 			const char *label = mem_sleep_states[i];
@@ -109,6 +117,7 @@ static suspend_state_t decode_suspend_state(const char *buf, size_t n)
 	int len;
 
 	p = memchr(buf, '\n', n);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	len = p ? p - buf : n;
 
 	for (state = PM_SUSPEND_MIN; state < PM_SUSPEND_MAX; state++) {
@@ -129,7 +138,9 @@ static ssize_t mem_sleep_store(struct kobject *kobj, struct kobj_attribute *attr
 
 	error = pm_autosleep_lock();
 	if (error)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return error;
+}
 
 	if (pm_autosleep_state() > PM_SUSPEND_ON) {
 		error = -EBUSY;
@@ -168,6 +179,7 @@ static ssize_t pm_test_show(struct kobject *kobj, struct kobj_attribute *attr,
 	char *s = buf;
 	int level;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (level = TEST_FIRST; level <= TEST_MAX; level++)
 		if (pm_tests[level]) {
 			if (level == pm_test_level)
@@ -193,6 +205,7 @@ static ssize_t pm_test_store(struct kobject *kobj, struct kobj_attribute *attr,
 	int error = -EINVAL;
 
 	p = memchr(buf, '\n', n);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	len = p ? p - buf : n;
 
 	lock_system_sleep();
@@ -216,6 +229,7 @@ power_attr(pm_test);
 #ifdef CONFIG_DEBUG_FS
 static char *suspend_step_name(enum suspend_stat_step step)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	switch (step) {
 	case SUSPEND_FREEZE:
 		return "freeze";
@@ -262,6 +276,7 @@ static int suspend_stats_show(struct seq_file *s, void *unused)
 				suspend_stats.failed_resume_noirq);
 	seq_printf(s,	"failures:\n  last_failed_dev:\t%-s\n",
 			suspend_stats.failed_devs[last_dev]);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (i = 1; i < REC_FAILED_NUM; i++) {
 		index = last_dev + REC_FAILED_NUM - i;
 		index %= REC_FAILED_NUM;
@@ -292,6 +307,7 @@ static int suspend_stats_show(struct seq_file *s, void *unused)
 
 static int suspend_stats_open(struct inode *inode, struct file *file)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return single_open(file, suspend_stats_show, NULL);
 }
 
@@ -326,6 +342,7 @@ bool pm_print_times_enabled;
 static ssize_t pm_print_times_show(struct kobject *kobj,
 				   struct kobj_attribute *attr, char *buf)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return sprintf(buf, "%d\n", pm_print_times_enabled);
 }
 
@@ -336,7 +353,9 @@ static ssize_t pm_print_times_store(struct kobject *kobj,
 	unsigned long val;
 
 	if (kstrtoul(buf, 10, &val))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	if (val > 1)
 		return -EINVAL;
@@ -349,6 +368,7 @@ power_attr(pm_print_times);
 
 static inline void pm_print_times_init(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pm_print_times_enabled = !!initcall_debug;
 }
 
@@ -356,6 +376,7 @@ static ssize_t pm_wakeup_irq_show(struct kobject *kobj,
 					struct kobj_attribute *attr,
 					char *buf)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return pm_wakeup_irq ? sprintf(buf, "%u\n", pm_wakeup_irq) : -ENODATA;
 }
 
@@ -366,6 +387,7 @@ bool pm_debug_messages_on __read_mostly;
 static ssize_t pm_debug_messages_show(struct kobject *kobj,
 				      struct kobj_attribute *attr, char *buf)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return sprintf(buf, "%d\n", pm_debug_messages_on);
 }
 
@@ -376,7 +398,9 @@ static ssize_t pm_debug_messages_store(struct kobject *kobj,
 	unsigned long val;
 
 	if (kstrtoul(buf, 10, &val))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	if (val > 1)
 		return -EINVAL;
@@ -401,7 +425,9 @@ void __pm_pr_dbg(bool defer, const char *fmt, ...)
 	va_list args;
 
 	if (!pm_debug_messages_on)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	va_start(args, fmt);
 
@@ -439,6 +465,7 @@ static ssize_t state_show(struct kobject *kobj, struct kobj_attribute *attr,
 #ifdef CONFIG_SUSPEND
 	suspend_state_t i;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (i = PM_SUSPEND_MIN; i < PM_SUSPEND_MAX; i++)
 		if (pm_states[i])
 			s += sprintf(s,"%s ", pm_states[i]);
@@ -461,6 +488,7 @@ static suspend_state_t decode_state(const char *buf, size_t n)
 	int len;
 
 	p = memchr(buf, '\n', n);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	len = p ? p - buf : n;
 
 	/* Check hibernation first. */
@@ -487,7 +515,9 @@ static ssize_t state_store(struct kobject *kobj, struct kobj_attribute *attr,
 
 	error = pm_autosleep_lock();
 	if (error)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return error;
+}
 
 	if (pm_autosleep_state() > PM_SUSPEND_ON) {
 		error = -EBUSY;
@@ -548,6 +578,7 @@ static ssize_t wakeup_count_show(struct kobject *kobj,
 {
 	unsigned int val;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return pm_get_wakeup_count(&val, true) ?
 		sprintf(buf, "%u\n", val) : -EINTR;
 }
@@ -561,7 +592,9 @@ static ssize_t wakeup_count_store(struct kobject *kobj,
 
 	error = pm_autosleep_lock();
 	if (error)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return error;
+}
 
 	if (pm_autosleep_state() > PM_SUSPEND_ON) {
 		error = -EBUSY;
@@ -670,6 +703,7 @@ int pm_trace_enabled;
 static ssize_t pm_trace_show(struct kobject *kobj, struct kobj_attribute *attr,
 			     char *buf)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return sprintf(buf, "%d\n", pm_trace_enabled);
 }
 
@@ -680,6 +714,7 @@ pm_trace_store(struct kobject *kobj, struct kobj_attribute *attr,
 	int val;
 
 	if (sscanf(buf, "%d", &val) == 1) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pm_trace_enabled = !!val;
 		if (pm_trace_enabled) {
 			pr_warn("PM: Enabling pm_trace changes system date and time during resume.\n"
@@ -696,6 +731,7 @@ static ssize_t pm_trace_dev_match_show(struct kobject *kobj,
 				       struct kobj_attribute *attr,
 				       char *buf)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return show_trace_dev_match(buf, PAGE_SIZE);
 }
 
@@ -707,6 +743,7 @@ power_attr_ro(pm_trace_dev_match);
 static ssize_t pm_freeze_timeout_show(struct kobject *kobj,
 				      struct kobj_attribute *attr, char *buf)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return sprintf(buf, "%u\n", freeze_timeout_msecs);
 }
 
@@ -717,7 +754,9 @@ static ssize_t pm_freeze_timeout_store(struct kobject *kobj,
 	unsigned long val;
 
 	if (kstrtoul(buf, 10, &val))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	freeze_timeout_msecs = val;
 	return n;
@@ -777,16 +816,24 @@ static int __init pm_init(void)
 {
 	int error = pm_start_workqueue();
 	if (error)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return error;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	hibernate_image_size_init();
 	hibernate_reserved_size_init();
 	pm_states_init();
 	power_kobj = kobject_create_and_add("power", NULL);
 	if (!power_kobj)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 	error = sysfs_create_group(power_kobj, &attr_group);
 	if (error)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return error;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pm_print_times_init();
 	return pm_autosleep_init();
 }
diff --git a/kernel/power/poweroff.c b/kernel/power/poweroff.c
index 7ef6866..6b1767d 100644
--- a/kernel/power/poweroff.c
+++ b/kernel/power/poweroff.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * poweroff.c - sysrq handler to gracefully power down machine.
  *
@@ -19,6 +21,7 @@
 
 static void do_poweroff(struct work_struct *dummy)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	kernel_power_off();
 }
 
diff --git a/kernel/power/qos.c b/kernel/power/qos.c
index 97b0df7..7b05e9b 100644
--- a/kernel/power/qos.c
+++ b/kernel/power/qos.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * This module exposes the interface to kernel space for specifying
  * QoS dependencies.  It provides infrastructure for registration of:
@@ -165,17 +167,20 @@ static inline int pm_qos_get_value(struct pm_qos_constraints *c)
 		plist_for_each(node, &c->list)
 			total_value += node->prio;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return total_value;
 
 	default:
 		/* runtime check for not using enum */
 		BUG();
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return PM_QOS_DEFAULT_VALUE;
 	}
 }
 
 s32 pm_qos_read_value(struct pm_qos_constraints *c)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return c->target_value;
 }
 
@@ -196,6 +201,7 @@ static int pm_qos_dbg_show_requests(struct seq_file *s, void *unused)
 	int active_reqs = 0;
 
 	if (IS_ERR_OR_NULL(qos)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_err("%s: bad qos param!\n", __func__);
 		return -EINVAL;
 	}
@@ -248,6 +254,7 @@ static int pm_qos_dbg_show_requests(struct seq_file *s, void *unused)
 
 static int pm_qos_dbg_open(struct inode *inode, struct file *file)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return single_open(file, pm_qos_dbg_show_requests,
 			   inode->i_private);
 }
@@ -280,7 +287,9 @@ int pm_qos_update_target(struct pm_qos_constraints *c, struct plist_node *node,
 	spin_lock_irqsave(&pm_qos_lock, flags);
 	prev_value = pm_qos_get_value(c);
 	if (value == PM_QOS_DEFAULT_VALUE)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		new_value = c->default_value;
+}
 	else
 		new_value = value;
 
@@ -311,12 +320,16 @@ int pm_qos_update_target(struct pm_qos_constraints *c, struct plist_node *node,
 
 	trace_pm_qos_update_target(action, prev_value, curr_value);
 	if (prev_value != curr_value) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ret = 1;
 		if (c->notifiers)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			blocking_notifier_call_chain(c->notifiers,
 						     (unsigned long)curr_value,
 						     NULL);
+}
 	} else {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ret = 0;
 	}
 	return ret;
@@ -333,6 +346,7 @@ static void pm_qos_flags_remove_req(struct pm_qos_flags *pqf,
 	s32 val = 0;
 
 	list_del(&req->node);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry(req, &pqf->list, node)
 		val |= req->flags;
 
@@ -357,6 +371,7 @@ bool pm_qos_update_flags(struct pm_qos_flags *pqf,
 	unsigned long irqflags;
 	s32 prev_value, curr_value;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_lock_irqsave(&pm_qos_lock, irqflags);
 
 	prev_value = list_empty(&pqf->list) ? 0 : pqf->effective_flags;
@@ -394,12 +409,14 @@ bool pm_qos_update_flags(struct pm_qos_flags *pqf,
  */
 int pm_qos_request(int pm_qos_class)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return pm_qos_read_value(pm_qos_array[pm_qos_class]->constraints);
 }
 EXPORT_SYMBOL_GPL(pm_qos_request);
 
 int pm_qos_request_active(struct pm_qos_request *req)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return req->pm_qos_class != 0;
 }
 EXPORT_SYMBOL_GPL(pm_qos_request_active);
@@ -407,6 +424,7 @@ EXPORT_SYMBOL_GPL(pm_qos_request_active);
 static void __pm_qos_update_request(struct pm_qos_request *req,
 			   s32 new_value)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	trace_pm_qos_update_request(req->pm_qos_class, new_value);
 
 	if (new_value != req->node.prio)
@@ -423,6 +441,7 @@ static void __pm_qos_update_request(struct pm_qos_request *req,
  */
 static void pm_qos_work_fn(struct work_struct *work)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct pm_qos_request *req = container_of(to_delayed_work(work),
 						  struct pm_qos_request,
 						  work);
@@ -446,6 +465,7 @@ static void pm_qos_work_fn(struct work_struct *work)
 void pm_qos_add_request(struct pm_qos_request *req,
 			int pm_qos_class, s32 value)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!req) /*guard against callers passing in null */
 		return;
 
@@ -474,6 +494,7 @@ EXPORT_SYMBOL_GPL(pm_qos_add_request);
 void pm_qos_update_request(struct pm_qos_request *req,
 			   s32 new_value)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!req) /*guard against callers passing in null */
 		return;
 
@@ -498,6 +519,7 @@ EXPORT_SYMBOL_GPL(pm_qos_update_request);
 void pm_qos_update_request_timeout(struct pm_qos_request *req, s32 new_value,
 				   unsigned long timeout_us)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!req)
 		return;
 	if (WARN(!pm_qos_request_active(req),
@@ -526,6 +548,7 @@ void pm_qos_update_request_timeout(struct pm_qos_request *req, s32 new_value,
  */
 void pm_qos_remove_request(struct pm_qos_request *req)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!req) /*guard against callers passing in null */
 		return;
 		/* silent return to keep pcm code cleaner */
@@ -619,6 +642,7 @@ static int pm_qos_power_open(struct inode *inode, struct file *filp)
 
 	pm_qos_class = find_pm_qos_object_by_minor(iminor(inode));
 	if (pm_qos_class >= PM_QOS_CPU_DMA_LATENCY) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		struct pm_qos_request *req = kzalloc(sizeof(*req), GFP_KERNEL);
 		if (!req)
 			return -ENOMEM;
@@ -651,7 +675,9 @@ static ssize_t pm_qos_power_read(struct file *filp, char __user *buf,
 	struct pm_qos_request *req = filp->private_data;
 
 	if (!req)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 	if (!pm_qos_request_active(req))
 		return -EINVAL;
 
@@ -669,6 +695,7 @@ static ssize_t pm_qos_power_write(struct file *filp, const char __user *buf,
 	struct pm_qos_request *req;
 
 	if (count == sizeof(s32)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (copy_from_user(&value, buf, sizeof(s32)))
 			return -EFAULT;
 	} else {
@@ -692,21 +719,26 @@ static int __init pm_qos_power_init(void)
 	int i;
 	struct dentry *d;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	BUILD_BUG_ON(ARRAY_SIZE(pm_qos_array) != PM_QOS_NUM_CLASSES);
 
 	d = debugfs_create_dir("pm_qos", NULL);
 	if (IS_ERR_OR_NULL(d))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		d = NULL;
+}
 
 	for (i = PM_QOS_CPU_DMA_LATENCY; i < PM_QOS_NUM_CLASSES; i++) {
 		ret = register_pm_qos_misc(pm_qos_array[i], d);
 		if (ret < 0) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			printk(KERN_ERR "pm_qos_param: %s setup failed\n",
 			       pm_qos_array[i]->name);
 			return ret;
 		}
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return ret;
 }
 
diff --git a/kernel/printk/printk.c b/kernel/printk/printk.c
index 512f7c2..3d42da9 100644
--- a/kernel/printk/printk.c
+++ b/kernel/printk/printk.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  *  linux/kernel/printk.c
  *
@@ -107,6 +109,7 @@ static unsigned int __read_mostly devkmsg_log = DEVKMSG_LOG_MASK_DEFAULT;
 
 static int __control_devkmsg(char *str)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!str)
 		return -EINVAL;
 
@@ -125,6 +128,7 @@ static int __control_devkmsg(char *str)
 
 static int __init control_devkmsg(char *str)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (__control_devkmsg(str) < 0)
 		return 1;
 
@@ -162,6 +166,7 @@ int devkmsg_sysctl_set_loglvl(struct ctl_table *table, int write,
 	int err;
 
 	if (write) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (devkmsg_log & DEVKMSG_LOG_MASK_LOCK)
 			return -EINVAL;
 
@@ -229,8 +234,12 @@ static int __down_trylock_console_sem(unsigned long ip)
 	printk_safe_exit_irqrestore(flags);
 
 	if (lock_failed)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 1;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	mutex_acquire(&console_lock_dep_map, 0, 1, ip);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 #define down_trylock_console_sem() __down_trylock_console_sem(_RET_IP_)
@@ -239,6 +248,7 @@ static void __up_console_sem(unsigned long ip)
 {
 	unsigned long flags;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	mutex_release(&console_lock_dep_map, 1, ip);
 
 	printk_safe_enter_irqsave(flags);
@@ -764,24 +774,33 @@ static ssize_t devkmsg_write(struct kiocb *iocb, struct iov_iter *from)
 	ssize_t ret = len;
 
 	if (!user || len > LOG_LINE_MAX)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	/* Ignore when user logging is disabled. */
 	if (devkmsg_log & DEVKMSG_LOG_MASK_OFF)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return len;
+}
 
 	/* Ratelimit when not explicitly enabled. */
 	if (!(devkmsg_log & DEVKMSG_LOG_MASK_ON)) {
 		if (!___ratelimit(&user->rs, current->comm))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return ret;
+}
 	}
 
 	buf = kmalloc(len+1, GFP_KERNEL);
 	if (buf == NULL)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 
 	buf[len] = '\0';
 	if (!copy_from_iter_full(buf, len, from)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		kfree(buf);
 		return -EFAULT;
 	}
@@ -804,7 +823,9 @@ static ssize_t devkmsg_write(struct kiocb *iocb, struct iov_iter *from)
 		if (endp && endp[0] == '>') {
 			level = LOG_LEVEL(u);
 			if (LOG_FACILITY(u) != 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				facility = LOG_FACILITY(u);
+}
 			endp++;
 			len -= endp - line;
 			line = endp;
@@ -825,7 +846,9 @@ static ssize_t devkmsg_read(struct file *file, char __user *buf,
 	ssize_t ret;
 
 	if (!user)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EBADF;
+}
 
 	ret = mutex_lock_interruptible(&user->lock);
 	if (ret)
@@ -888,7 +911,9 @@ static loff_t devkmsg_llseek(struct file *file, loff_t offset, int whence)
 	loff_t ret = 0;
 
 	if (!user)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EBADF;
+}
 	if (offset)
 		return -ESPIPE;
 
@@ -926,7 +951,9 @@ static unsigned int devkmsg_poll(struct file *file, poll_table *wait)
 	int ret = 0;
 
 	if (!user)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return POLLERR|POLLNVAL;
+}
 
 	poll_wait(file, &log_wait, wait);
 
@@ -949,19 +976,27 @@ static int devkmsg_open(struct inode *inode, struct file *file)
 	int err;
 
 	if (devkmsg_log & DEVKMSG_LOG_MASK_OFF)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EPERM;
+}
 
 	/* write-only does not need any file context */
 	if ((file->f_flags & O_ACCMODE) != O_WRONLY) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		err = check_syslog_permissions(SYSLOG_ACTION_READ_ALL,
 					       SYSLOG_FROM_READER);
 		if (err)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return err;
+}
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	user = kmalloc(sizeof(struct devkmsg_user), GFP_KERNEL);
 	if (!user)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 
 	ratelimit_default_init(&user->rs);
 	ratelimit_set_flags(&user->rs, RATELIMIT_MSG_ON_RELEASE);
@@ -982,7 +1017,9 @@ static int devkmsg_release(struct inode *inode, struct file *file)
 	struct devkmsg_user *user = file->private_data;
 
 	if (!user)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	ratelimit_state_exit(&user->rs);
 
@@ -1011,6 +1048,7 @@ const struct file_operations kmsg_fops = {
  */
 void log_buf_vmcoreinfo_setup(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	VMCOREINFO_SYMBOL(log_buf);
 	VMCOREINFO_SYMBOL(log_buf_len);
 	VMCOREINFO_SYMBOL(log_first_idx);
@@ -1034,6 +1072,7 @@ static unsigned long __initdata new_log_buf_len;
 /* we practice scaling the ring buffer by powers of 2 */
 static void __init log_buf_len_update(unsigned size)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (size)
 		size = roundup_pow_of_two(size);
 	if (size > log_buf_len)
@@ -1043,6 +1082,7 @@ static void __init log_buf_len_update(unsigned size)
 /* save requested log_buf_len since it's too early to process it */
 static int __init log_buf_len_setup(char *str)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	unsigned size = memparse(str, &str);
 
 	log_buf_len_update(size);
@@ -1064,14 +1104,20 @@ static void __init log_buf_add_cpu(void)
 	 * case lets ensure this is valid.
 	 */
 	if (num_possible_cpus() == 1)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	cpu_extra = (num_possible_cpus() - 1) * __LOG_CPU_MAX_BUF_LEN;
 
 	/* by default this will only continue through for large > 64 CPUs */
 	if (cpu_extra <= __LOG_BUF_LEN / 2)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pr_info("log_buf_len individual max cpu contribution: %d bytes\n",
 		__LOG_CPU_MAX_BUF_LEN);
 	pr_info("log_buf_len total cpu_extra contributions: %d bytes\n",
@@ -1091,36 +1137,49 @@ void __init setup_log_buf(int early)
 	int free;
 
 	if (log_buf != __log_buf)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	if (!early && !new_log_buf_len)
 		log_buf_add_cpu();
 
 	if (!new_log_buf_len)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (early) {
 		new_log_buf =
 			memblock_virt_alloc(new_log_buf_len, LOG_ALIGN);
 	} else {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		new_log_buf = memblock_virt_alloc_nopanic(new_log_buf_len,
 							  LOG_ALIGN);
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (unlikely(!new_log_buf)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_err("log_buf_len: %ld bytes not available\n",
 			new_log_buf_len);
 		return;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	logbuf_lock_irqsave(flags);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	log_buf_len = new_log_buf_len;
 	log_buf = new_log_buf;
 	new_log_buf_len = 0;
 	free = __LOG_BUF_LEN - log_next_idx;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	memcpy(log_buf, __log_buf, __LOG_BUF_LEN);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	logbuf_unlock_irqrestore(flags);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pr_info("log_buf_len: %d bytes\n", log_buf_len);
 	pr_info("early log buf free: %d(%d%%)\n",
 		free, (free * 100) / __LOG_BUF_LEN);
@@ -1130,6 +1189,7 @@ static bool __read_mostly ignore_loglevel;
 
 static int __init ignore_loglevel_setup(char *str)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	ignore_loglevel = true;
 	pr_info("debug: ignoring loglevel setting.\n");
 
@@ -1209,7 +1269,9 @@ static size_t print_time(u64 ts, char *buf)
 	unsigned long rem_nsec;
 
 	if (!printk_time)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	rem_nsec = do_div(ts, 1000000000);
 
@@ -1229,13 +1291,20 @@ static size_t print_prefix(const struct printk_log *msg, bool syslog, char *buf)
 		if (buf) {
 			len += sprintf(buf, "<%u>", prefix);
 		} else {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			len += 3;
 			if (prefix > 999)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				len += 3;
+}
 			else if (prefix > 99)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				len += 2;
+}
 			else if (prefix > 9)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				len++;
+}
 		}
 	}
 
@@ -1245,19 +1314,23 @@ static size_t print_prefix(const struct printk_log *msg, bool syslog, char *buf)
 
 static size_t msg_print_text(const struct printk_log *msg, bool syslog, char *buf, size_t size)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	const char *text = log_text(msg);
 	size_t text_size = msg->text_len;
 	size_t len = 0;
 
 	do {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		const char *next = memchr(text, '\n', text_size);
 		size_t text_len;
 
 		if (next) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			text_len = next - text;
 			next++;
 			text_size -= next - text;
 		} else {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			text_len = text_size;
 		}
 
@@ -1277,6 +1350,7 @@ static size_t msg_print_text(const struct printk_log *msg, bool syslog, char *bu
 			len++;
 		}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		text = next;
 	} while (text);
 
@@ -1291,7 +1365,9 @@ static int syslog_print(char __user *buf, int size)
 
 	text = kmalloc(LOG_LINE_MAX + PREFIX_MAX, GFP_KERNEL);
 	if (!text)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 
 	while (size > 0) {
 		size_t n;
@@ -1323,15 +1399,20 @@ static int syslog_print(char __user *buf, int size)
 			n = size;
 			syslog_partial += n;
 		} else
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			n = 0;
+}
 		logbuf_unlock_irq();
 
 		if (!n)
 			break;
 
 		if (copy_to_user(buf, text + skip, n)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			if (!len)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				len = -EFAULT;
+}
 			break;
 		}
 
@@ -1351,7 +1432,9 @@ static int syslog_print_all(char __user *buf, int size, bool clear)
 
 	text = kmalloc(LOG_LINE_MAX + PREFIX_MAX, GFP_KERNEL);
 	if (!text)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 
 	logbuf_lock_irq();
 	if (buf) {
@@ -1377,6 +1460,7 @@ static int syslog_print_all(char __user *buf, int size, bool clear)
 		seq = clear_seq;
 		idx = clear_idx;
 		while (len > size && seq < log_next_seq) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			struct printk_log *msg = log_from_idx(idx);
 
 			len -= msg_print_text(msg, true, NULL, 0);
@@ -1395,6 +1479,7 @@ static int syslog_print_all(char __user *buf, int size, bool clear)
 			textlen = msg_print_text(msg, true, text,
 						 LOG_LINE_MAX + PREFIX_MAX);
 			if (textlen < 0) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				len = textlen;
 				break;
 			}
@@ -1403,7 +1488,9 @@ static int syslog_print_all(char __user *buf, int size, bool clear)
 
 			logbuf_unlock_irq();
 			if (copy_to_user(buf + len, text, textlen))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				len = -EFAULT;
+}
 			else
 				len += textlen;
 			logbuf_lock_irq();
@@ -1417,6 +1504,7 @@ static int syslog_print_all(char __user *buf, int size, bool clear)
 	}
 
 	if (clear) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		clear_seq = log_next_seq;
 		clear_idx = log_next_idx;
 	}
@@ -1434,7 +1522,9 @@ int do_syslog(int type, char __user *buf, int len, int source)
 
 	error = check_syslog_permissions(type, source);
 	if (error)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return error;
+}
 
 	switch (type) {
 	case SYSLOG_ACTION_CLOSE:	/* Close log */
@@ -1443,15 +1533,23 @@ int do_syslog(int type, char __user *buf, int len, int source)
 		break;
 	case SYSLOG_ACTION_READ:	/* Read from log */
 		if (!buf || len < 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -EINVAL;
+}
 		if (!len)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return 0;
+}
 		if (!access_ok(VERIFY_WRITE, buf, len))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -EFAULT;
+}
 		error = wait_event_interruptible(log_wait,
 						 syslog_seq != log_next_seq);
 		if (error)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return error;
+}
 		error = syslog_print(buf, len);
 		break;
 	/* Read/clear last kernel messages */
@@ -1461,11 +1559,17 @@ int do_syslog(int type, char __user *buf, int len, int source)
 	/* Read last kernel messages */
 	case SYSLOG_ACTION_READ_ALL:
 		if (!buf || len < 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -EINVAL;
+}
 		if (!len)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return 0;
+}
 		if (!access_ok(VERIFY_WRITE, buf, len))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -EFAULT;
+}
 		error = syslog_print_all(buf, len, clear);
 		break;
 	/* Clear ring buffer */
@@ -1475,12 +1579,16 @@ int do_syslog(int type, char __user *buf, int len, int source)
 	/* Disable logging to console */
 	case SYSLOG_ACTION_CONSOLE_OFF:
 		if (saved_console_loglevel == LOGLEVEL_DEFAULT)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			saved_console_loglevel = console_loglevel;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		console_loglevel = minimum_console_loglevel;
 		break;
 	/* Enable logging to console */
 	case SYSLOG_ACTION_CONSOLE_ON:
 		if (saved_console_loglevel != LOGLEVEL_DEFAULT) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			console_loglevel = saved_console_loglevel;
 			saved_console_loglevel = LOGLEVEL_DEFAULT;
 		}
@@ -1488,9 +1596,15 @@ int do_syslog(int type, char __user *buf, int len, int source)
 	/* Set level of messages printed to console */
 	case SYSLOG_ACTION_CONSOLE_LEVEL:
 		if (len < 1 || len > 8)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -EINVAL;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (len < minimum_console_loglevel)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			len = minimum_console_loglevel;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		console_loglevel = len;
 		/* Implicitly re-enable logging to console */
 		saved_console_loglevel = LOGLEVEL_DEFAULT;
@@ -1498,12 +1612,14 @@ int do_syslog(int type, char __user *buf, int len, int source)
 	/* Number of chars in the log buffer */
 	case SYSLOG_ACTION_SIZE_UNREAD:
 		logbuf_lock_irq();
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (syslog_seq < log_first_seq) {
 			/* messages are gone, move to first one */
 			syslog_seq = log_first_seq;
 			syslog_idx = log_first_idx;
 			syslog_partial = 0;
 		}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (source == SYSLOG_FROM_PROC) {
 			/*
 			 * Short-cut for poll(/"proc/kmsg") which simply checks
@@ -1515,15 +1631,19 @@ int do_syslog(int type, char __user *buf, int len, int source)
 			u64 seq = syslog_seq;
 			u32 idx = syslog_idx;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			while (seq < log_next_seq) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				struct printk_log *msg = log_from_idx(idx);
 
 				error += msg_print_text(msg, true, NULL, 0);
 				idx = log_next(idx);
 				seq++;
 			}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			error -= syslog_partial;
 		}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		logbuf_unlock_irq();
 		break;
 	/* Size of the log buffer */
@@ -1535,6 +1655,7 @@ int do_syslog(int type, char __user *buf, int len, int source)
 		break;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return error;
 }
 
@@ -1556,7 +1677,9 @@ static void call_console_drivers(const char *ext_text, size_t ext_len,
 	trace_console_rcuidle(text, len);
 
 	if (!console_drivers)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	for_each_console(con) {
 		if (exclusive_console && con != exclusive_console)
@@ -1569,7 +1692,9 @@ static void call_console_drivers(const char *ext_text, size_t ext_len,
 		    !(con->flags & CON_ANYTIME))
 			continue;
 		if (con->flags & CON_EXTENDED)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			con->write(con, ext_text, ext_len);
+}
 		else
 			con->write(con, text, len);
 	}
@@ -1582,7 +1707,9 @@ static inline void printk_delay(void)
 	if (unlikely(printk_delay_msec)) {
 		int m = printk_delay_msec;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		while (m--) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			mdelay(1);
 			touch_nmi_watchdog();
 		}
@@ -2708,7 +2835,9 @@ void wake_up_klogd(void)
 {
 	preempt_disable();
 	if (waitqueue_active(&log_wait)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		this_cpu_or(printk_pending, PRINTK_PENDING_WAKEUP);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		irq_work_queue(this_cpu_ptr(&wake_up_klogd_work));
 	}
 	preempt_enable();
@@ -2721,6 +2850,7 @@ int vprintk_deferred(const char *fmt, va_list args)
 	r = vprintk_emit(0, LOGLEVEL_SCHED, NULL, 0, fmt, args);
 
 	preempt_disable();
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	__this_cpu_or(printk_pending, PRINTK_PENDING_OUTPUT);
 	irq_work_queue(this_cpu_ptr(&wake_up_klogd_work));
 	preempt_enable();
@@ -2768,6 +2898,7 @@ bool printk_timed_ratelimit(unsigned long *caller_jiffies,
 {
 	unsigned long elapsed = jiffies - *caller_jiffies;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (*caller_jiffies && elapsed <= msecs_to_jiffies(interval_msecs))
 		return false;
 
@@ -2794,7 +2925,9 @@ int kmsg_dump_register(struct kmsg_dumper *dumper)
 
 	/* The dump callback needs to be set */
 	if (!dumper->dump)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	spin_lock_irqsave(&dump_list_lock, flags);
 	/* Don't allow registering multiple times */
@@ -2821,6 +2954,7 @@ int kmsg_dump_unregister(struct kmsg_dumper *dumper)
 	unsigned long flags;
 	int err = -EINVAL;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_lock_irqsave(&dump_list_lock, flags);
 	if (dumper->registered) {
 		dumper->registered = 0;
@@ -2850,6 +2984,7 @@ void kmsg_dump(enum kmsg_dump_reason reason)
 	struct kmsg_dumper *dumper;
 	unsigned long flags;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if ((reason > KMSG_DUMP_OOPS) && !always_kmsg_dump)
 		return;
 
@@ -2906,6 +3041,7 @@ bool kmsg_dump_get_line_nolock(struct kmsg_dumper *dumper, bool syslog,
 	if (!dumper->active)
 		goto out;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (dumper->cur_seq < log_first_seq) {
 		/* messages are gone, move to first available one */
 		dumper->cur_seq = log_first_seq;
@@ -2951,6 +3087,7 @@ bool kmsg_dump_get_line(struct kmsg_dumper *dumper, bool syslog,
 	unsigned long flags;
 	bool ret;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	logbuf_lock_irqsave(flags);
 	ret = kmsg_dump_get_line_nolock(dumper, syslog, line, size, len);
 	logbuf_unlock_irqrestore(flags);
@@ -2992,6 +3129,7 @@ bool kmsg_dump_get_buffer(struct kmsg_dumper *dumper, bool syslog,
 	if (!dumper->active)
 		goto out;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	logbuf_lock_irqsave(flags);
 	if (dumper->cur_seq < log_first_seq) {
 		/* messages are gone, move to first available one */
@@ -3063,6 +3201,7 @@ EXPORT_SYMBOL_GPL(kmsg_dump_get_buffer);
  */
 void kmsg_dump_rewind_nolock(struct kmsg_dumper *dumper)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	dumper->cur_seq = clear_seq;
 	dumper->cur_idx = clear_idx;
 	dumper->next_seq = log_next_seq;
@@ -3081,6 +3220,7 @@ void kmsg_dump_rewind(struct kmsg_dumper *dumper)
 {
 	unsigned long flags;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	logbuf_lock_irqsave(flags);
 	kmsg_dump_rewind_nolock(dumper);
 	logbuf_unlock_irqrestore(flags);
@@ -3140,6 +3280,7 @@ void dump_stack_print_info(const char *log_lvl)
  */
 void show_regs_print_info(const char *log_lvl)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	dump_stack_print_info(log_lvl);
 
 	printk("%stask: %p task.stack: %p\n",
diff --git a/kernel/printk/printk_safe.c b/kernel/printk/printk_safe.c
index 3cdaeae..d78f8a8 100644
--- a/kernel/printk/printk_safe.c
+++ b/kernel/printk/printk_safe.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * printk_safe.c - Safe printk for printk-deadlock-prone contexts
  *
@@ -63,6 +65,7 @@ static DEFINE_PER_CPU(struct printk_safe_seq_buf, nmi_print_seq);
 /* Get flushed in a more safe context. */
 static void queue_flush_work(struct printk_safe_seq_buf *s)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (printk_safe_irq_ready) {
 		/* Make sure that IRQ work is really initialized. */
 		smp_rmb();
@@ -182,8 +185,10 @@ static void report_message_lost(struct printk_safe_seq_buf *s)
 	int lost = atomic_xchg(&s->message_lost, 0);
 
 	if (lost)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		printk_deferred("Lost %d message(s)!\n", lost);
 }
+}
 
 /*
  * Flush data from the associated per-CPU buffer. The function
@@ -208,6 +213,7 @@ static void __printk_safe_flush(struct irq_work *work)
 	 */
 	raw_spin_lock_irqsave(&read_lock, flags);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	i = 0;
 more:
 	len = atomic_read(&s->len);
@@ -301,6 +307,7 @@ void printk_safe_flush_on_panic(void)
  */
 static __printf(1, 0) int vprintk_nmi(const char *fmt, va_list args)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct printk_safe_seq_buf *s = this_cpu_ptr(&nmi_print_seq);
 
 	return printk_safe_log_store(s, fmt, args);
@@ -323,6 +330,7 @@ void printk_nmi_enter(void)
 
 void printk_nmi_exit(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	this_cpu_and(printk_context,
 		     ~(PRINTK_NMI_CONTEXT_MASK |
 		       PRINTK_NMI_DEFERRED_CONTEXT_MASK));
@@ -344,6 +352,7 @@ static __printf(1, 0) int vprintk_nmi(const char *fmt, va_list args)
  */
 static __printf(1, 0) int vprintk_safe(const char *fmt, va_list args)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct printk_safe_seq_buf *s = this_cpu_ptr(&safe_print_seq);
 
 	return printk_safe_log_store(s, fmt, args);
@@ -365,18 +374,24 @@ __printf(1, 0) int vprintk_func(const char *fmt, va_list args)
 {
 	/* Use extra buffer in NMI when logbuf_lock is taken or in safe mode. */
 	if (this_cpu_read(printk_context) & PRINTK_NMI_CONTEXT_MASK)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return vprintk_nmi(fmt, args);
+}
 
 	/* Use extra buffer to prevent a recursion deadlock in safe mode. */
 	if (this_cpu_read(printk_context) & PRINTK_SAFE_CONTEXT_MASK)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return vprintk_safe(fmt, args);
+}
 
 	/*
 	 * Use the main logbuf when logbuf_lock is available in NMI.
 	 * But avoid calling console drivers that might have their own locks.
 	 */
 	if (this_cpu_read(printk_context) & PRINTK_NMI_DEFERRED_CONTEXT_MASK)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return vprintk_deferred(fmt, args);
+}
 
 	/* No obstacles. */
 	return vprintk_default(fmt, args);
diff --git a/kernel/profile.c b/kernel/profile.c
index 9aa2a44..c26f1f1 100644
--- a/kernel/profile.c
+++ b/kernel/profile.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  *  linux/kernel/profile.c
  *  Simple profiling. Manages a direct-mapped profile hit count buffer,
@@ -103,30 +105,44 @@ int __ref profile_init(void)
 {
 	int buffer_bytes;
 	if (!prof_on)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	/* only text is profiled */
 	prof_len = (_etext - _stext) >> prof_shift;
 	buffer_bytes = prof_len*sizeof(atomic_t);
 
 	if (!alloc_cpumask_var(&prof_cpu_mask, GFP_KERNEL))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	cpumask_copy(prof_cpu_mask, cpu_possible_mask);
 
 	prof_buffer = kzalloc(buffer_bytes, GFP_KERNEL|__GFP_NOWARN);
 	if (prof_buffer)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	prof_buffer = alloc_pages_exact(buffer_bytes,
 					GFP_KERNEL|__GFP_ZERO|__GFP_NOWARN);
 	if (prof_buffer)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	prof_buffer = vzalloc(buffer_bytes);
 	if (prof_buffer)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	free_cpumask_var(prof_cpu_mask);
 	return -ENOMEM;
 }
@@ -156,12 +172,14 @@ void profile_munmap(unsigned long addr)
 
 int task_handoff_register(struct notifier_block *n)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return atomic_notifier_chain_register(&task_free_notifier, n);
 }
 EXPORT_SYMBOL_GPL(task_handoff_register);
 
 int task_handoff_unregister(struct notifier_block *n)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return atomic_notifier_chain_unregister(&task_free_notifier, n);
 }
 EXPORT_SYMBOL_GPL(task_handoff_unregister);
@@ -238,6 +256,7 @@ EXPORT_SYMBOL_GPL(profile_event_unregister);
  */
 static void __profile_flip_buffers(void *unused)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	int cpu = smp_processor_id();
 
 	per_cpu(cpu_profile_flip, cpu) = !per_cpu(cpu_profile_flip, cpu);
@@ -248,6 +267,7 @@ static void profile_flip_buffers(void)
 	int i, j, cpu;
 
 	mutex_lock(&profile_flip_mutex);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	j = per_cpu(cpu_profile_flip, get_cpu());
 	put_cpu();
 	on_each_cpu(__profile_flip_buffers, NULL, 1);
@@ -271,6 +291,7 @@ static void profile_discard_flip_buffers(void)
 	int i, cpu;
 
 	mutex_lock(&profile_flip_mutex);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	i = per_cpu(cpu_profile_flip, get_cpu());
 	put_cpu();
 	on_each_cpu(__profile_flip_buffers, NULL, 1);
@@ -287,6 +308,7 @@ static void do_profile_hits(int type, void *__pc, unsigned int nr_hits)
 	int i, j, cpu;
 	struct profile_hit *hits;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pc = min((pc - (unsigned long)_stext) >> prof_shift, prof_len - 1);
 	i = primary = (pc & (NR_PROFILE_GRP - 1)) << PROFILE_GRPSHIFT;
 	secondary = (~(pc << 1) & (NR_PROFILE_GRP - 1)) << PROFILE_GRPSHIFT;
@@ -336,7 +358,9 @@ static int profile_dead_cpu(unsigned int cpu)
 	int i;
 
 	if (prof_cpu_mask != NULL)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		cpumask_clear_cpu(cpu, prof_cpu_mask);
+}
 
 	for (i = 0; i < 2; i++) {
 		if (per_cpu(cpu_profile_hits, cpu)[i]) {
@@ -353,6 +377,7 @@ static int profile_prepare_cpu(unsigned int cpu)
 	int i, node = cpu_to_mem(cpu);
 	struct page *page;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	per_cpu(cpu_profile_flip, cpu) = 0;
 
 	for (i = 0; i < 2; i++) {
@@ -372,6 +397,7 @@ static int profile_prepare_cpu(unsigned int cpu)
 
 static int profile_online_cpu(unsigned int cpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (prof_cpu_mask != NULL)
 		cpumask_set_cpu(cpu, prof_cpu_mask);
 
@@ -392,6 +418,7 @@ static void do_profile_hits(int type, void *__pc, unsigned int nr_hits)
 
 void profile_hits(int type, void *__pc, unsigned int nr_hits)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (prof_on != type || !prof_buffer)
 		return;
 	do_profile_hits(type, __pc, nr_hits);
@@ -400,6 +427,7 @@ EXPORT_SYMBOL_GPL(profile_hits);
 
 void profile_tick(int type)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct pt_regs *regs = get_irq_regs();
 
 	if (!user_mode(regs) && prof_cpu_mask != NULL &&
@@ -414,12 +442,14 @@ void profile_tick(int type)
 
 static int prof_cpu_mask_proc_show(struct seq_file *m, void *v)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	seq_printf(m, "%*pb\n", cpumask_pr_args(prof_cpu_mask));
 	return 0;
 }
 
 static int prof_cpu_mask_proc_open(struct inode *inode, struct file *file)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return single_open(file, prof_cpu_mask_proc_show, NULL);
 }
 
@@ -430,7 +460,9 @@ static ssize_t prof_cpu_mask_proc_write(struct file *file,
 	int err;
 
 	if (!alloc_cpumask_var(&new_value, GFP_KERNEL))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 
 	err = cpumask_parse_user(buffer, count, new_value);
 	if (!err) {
@@ -471,7 +503,9 @@ read_profile(struct file *file, char __user *buf, size_t count, loff_t *ppos)
 
 	profile_flip_buffers();
 	if (p >= (prof_len+1)*sizeof(unsigned int))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 	if (count > (prof_len+1)*sizeof(unsigned int) - p)
 		count = (prof_len+1)*sizeof(unsigned int) - p;
 	read = 0;
@@ -501,6 +535,7 @@ static ssize_t write_profile(struct file *file, const char __user *buf,
 #ifdef CONFIG_SMP
 	extern int setup_profiling_timer(unsigned int multiplier);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (count == sizeof(int)) {
 		unsigned int multiplier;
 
@@ -532,17 +567,23 @@ int __ref create_proc_profile(void)
 	int err = 0;
 
 	if (!prof_on)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 #ifdef CONFIG_SMP
 	err = cpuhp_setup_state(CPUHP_PROFILE_PREPARE, "PROFILE_PREPARE",
 				profile_prepare_cpu, profile_dead_cpu);
 	if (err)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return err;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	err = cpuhp_setup_state(CPUHP_AP_ONLINE_DYN, "AP_PROFILE_ONLINE",
 				profile_online_cpu, NULL);
 	if (err < 0)
 		goto err_state_prep;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	online_state = err;
 	err = 0;
 #endif
@@ -550,6 +591,7 @@ int __ref create_proc_profile(void)
 			    NULL, &proc_profile_operations);
 	if (!entry)
 		goto err_state_onl;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	proc_set_size(entry, (1 + prof_len) * sizeof(atomic_t));
 
 	return err;
diff --git a/kernel/ptrace.c b/kernel/ptrace.c
index 84b1367..cca53ebf 100644
--- a/kernel/ptrace.c
+++ b/kernel/ptrace.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * linux/kernel/ptrace.c
  *
@@ -43,7 +45,9 @@ int ptrace_access_vm(struct task_struct *tsk, unsigned long addr,
 
 	mm = get_task_mm(tsk);
 	if (!mm)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	if (!tsk->ptrace ||
 	    (current != tsk->parent) ||
@@ -77,6 +81,7 @@ void __ptrace_link(struct task_struct *child, struct task_struct *new_parent,
  */
 static void ptrace_link(struct task_struct *child, struct task_struct *new_parent)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rcu_read_lock();
 	__ptrace_link(child, new_parent, __task_cred(new_parent));
 	rcu_read_unlock();
@@ -115,6 +120,7 @@ void __ptrace_unlink(struct task_struct *child)
 	const struct cred *old_cred;
 	BUG_ON(!child->ptrace);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	clear_tsk_thread_flag(child, TIF_SYSCALL_TRACE);
 
 	child->parent = child->real_parent;
@@ -139,6 +145,7 @@ void __ptrace_unlink(struct task_struct *child)
 	if (!(child->flags & PF_EXITING) &&
 	    (child->signal->flags & SIGNAL_STOP_STOPPED ||
 	     child->signal->group_stop_count)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		child->jobctl |= JOBCTL_STOP_PENDING;
 
 		/*
@@ -149,7 +156,9 @@ void __ptrace_unlink(struct task_struct *child)
 		 * case.
 		 */
 		if (!(child->jobctl & JOBCTL_STOP_SIGMASK))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			child->jobctl |= SIGSTOP;
+}
 	}
 
 	/*
@@ -159,7 +168,9 @@ void __ptrace_unlink(struct task_struct *child)
 	 * TASK_KILLABLE sleeps.
 	 */
 	if (child->jobctl & JOBCTL_STOP_PENDING || task_is_traced(child))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ptrace_signal_wake_up(child, true);
+}
 
 	spin_unlock(&child->sighand->siglock);
 }
@@ -171,7 +182,9 @@ static bool ptrace_freeze_traced(struct task_struct *task)
 
 	/* Lockless, nobody but us can set this flag */
 	if (task->jobctl & JOBCTL_LISTENING)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ret;
+}
 
 	spin_lock_irq(&task->sighand->siglock);
 	if (task_is_traced(task) && !__fatal_signal_pending(task)) {
@@ -186,7 +199,9 @@ static bool ptrace_freeze_traced(struct task_struct *task)
 static void ptrace_unfreeze_traced(struct task_struct *task)
 {
 	if (task->state != __TASK_TRACED)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	WARN_ON(!task->ptrace || task->parent != current);
 
@@ -197,7 +212,9 @@ static void ptrace_unfreeze_traced(struct task_struct *task)
 	spin_lock_irq(&task->sighand->siglock);
 	if (task->state == __TASK_TRACED) {
 		if (__fatal_signal_pending(task))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			wake_up_state(task, __TASK_TRACED);
+}
 		else
 			task->state = TASK_TRACED;
 	}
@@ -240,8 +257,11 @@ static int ptrace_check_attach(struct task_struct *child, bool ignore_state)
 		 * does ptrace_unlink() before __exit_signal().
 		 */
 		if (ignore_state || ptrace_freeze_traced(child))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			ret = 0;
+}
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	read_unlock(&tasklist_lock);
 
 	if (!ret && !ignore_state) {
@@ -276,6 +296,7 @@ static int __ptrace_may_access(struct task_struct *task, unsigned int mode)
 	kgid_t caller_gid;
 
 	if (!(mode & PTRACE_MODE_FSCREDS) == !(mode & PTRACE_MODE_REALCREDS)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		WARN(1, "denying ptrace access check without PTRACE_MODE_*CREDS\n");
 		return -EPERM;
 	}
@@ -291,7 +312,10 @@ static int __ptrace_may_access(struct task_struct *task, unsigned int mode)
 
 	/* Don't let security modules deny introspection */
 	if (same_thread_group(task, current))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rcu_read_lock();
 	if (mode & PTRACE_MODE_FSCREDS) {
 		caller_uid = cred->fsuid;
@@ -318,6 +342,7 @@ static int __ptrace_may_access(struct task_struct *task, unsigned int mode)
 		goto ok;
 	if (ptrace_has_cap(tcred->user_ns, mode))
 		goto ok;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rcu_read_unlock();
 	return -EPERM;
 ok:
@@ -349,6 +374,7 @@ static int ptrace_attach(struct task_struct *task, long request,
 
 	retval = -EIO;
 	if (seize) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (addr != 0)
 			goto out;
 		if (flags & ~(unsigned long)PTRACE_O_MASK)
@@ -468,6 +494,7 @@ static int ptrace_traceme(void)
 			ptrace_link(current, current->real_parent);
 		}
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	write_unlock_irq(&tasklist_lock);
 
 	return ret;
@@ -480,6 +507,7 @@ static int ignoring_children(struct sighand_struct *sigh)
 {
 	int ret;
 	spin_lock(&sigh->siglock);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	ret = (sigh->action[SIGCHLD-1].sa.sa_handler == SIG_IGN) ||
 	      (sigh->action[SIGCHLD-1].sa.sa_flags & SA_NOCLDWAIT);
 	spin_unlock(&sigh->siglock);
@@ -508,28 +536,42 @@ static bool __ptrace_detach(struct task_struct *tracer, struct task_struct *p)
 	__ptrace_unlink(p);
 
 	if (p->exit_state != EXIT_ZOMBIE)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return false;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	dead = !thread_group_leader(p);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!dead && thread_group_empty(p)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (!same_thread_group(p->real_parent, tracer))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			dead = do_notify_parent(p, p->exit_signal);
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		else if (ignoring_children(tracer->sighand)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			__wake_up_parent(p, tracer);
 			dead = true;
 		}
 	}
 	/* Mark it as in the process of being reaped. */
 	if (dead)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		p->exit_state = EXIT_DEAD;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return dead;
 }
 
 static int ptrace_detach(struct task_struct *child, unsigned int data)
 {
 	if (!valid_signal(data))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EIO;
+}
 
 	/* Architecture-specific hardware disable .. */
 	ptrace_disable(child);
@@ -561,6 +603,7 @@ void exit_ptrace(struct task_struct *tracer, struct list_head *dead)
 {
 	struct task_struct *p, *n;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry_safe(p, n, &tracer->ptraced, ptrace_entry) {
 		if (unlikely(p->ptrace & PT_EXITKILL))
 			send_sig_info(SIGKILL, SEND_SIG_FORCED, p);
@@ -574,6 +617,7 @@ int ptrace_readdata(struct task_struct *tsk, unsigned long src, char __user *dst
 {
 	int copied = 0;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	while (len > 0) {
 		char buf[128];
 		int this_len, retval;
@@ -600,6 +644,7 @@ int ptrace_writedata(struct task_struct *tsk, char __user *src, unsigned long ds
 {
 	int copied = 0;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	while (len > 0) {
 		char buf[128];
 		int this_len, retval;
@@ -627,16 +672,23 @@ static int ptrace_setoptions(struct task_struct *child, unsigned long data)
 	unsigned flags;
 
 	if (data & ~(unsigned long)PTRACE_O_MASK)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	if (unlikely(data & PTRACE_O_SUSPEND_SECCOMP)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (!IS_ENABLED(CONFIG_CHECKPOINT_RESTORE) ||
 		    !IS_ENABLED(CONFIG_SECCOMP))
 			return -EINVAL;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (!capable(CAP_SYS_ADMIN))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -EPERM;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (seccomp_mode(&current->seccomp) != SECCOMP_MODE_DISABLED ||
 		    current->ptrace & PT_SUSPEND_SECCOMP)
 			return -EPERM;
@@ -657,6 +709,7 @@ static int ptrace_getsiginfo(struct task_struct *child, siginfo_t *info)
 	int error = -ESRCH;
 
 	if (lock_task_sighand(child, &flags)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		error = -EINVAL;
 		if (likely(child->last_siginfo != NULL)) {
 			*info = *child->last_siginfo;
@@ -673,6 +726,7 @@ static int ptrace_setsiginfo(struct task_struct *child, const siginfo_t *info)
 	int error = -ESRCH;
 
 	if (lock_task_sighand(child, &flags)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		error = -EINVAL;
 		if (likely(child->last_siginfo != NULL)) {
 			*child->last_siginfo = *info;
@@ -695,7 +749,9 @@ static int ptrace_peek_siginfo(struct task_struct *child,
 	ret = copy_from_user(&arg, (void __user *) addr,
 				sizeof(struct ptrace_peeksiginfo_args));
 	if (ret)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EFAULT;
+}
 
 	if (arg.flags & ~PTRACE_PEEKSIGINFO_SHARED)
 		return -EINVAL; /* unknown flags */
@@ -783,27 +839,41 @@ static int ptrace_resume(struct task_struct *child, long request,
 	bool need_siglock;
 
 	if (!valid_signal(data))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EIO;
+}
 
 	if (request == PTRACE_SYSCALL)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		set_tsk_thread_flag(child, TIF_SYSCALL_TRACE);
+}
 	else
 		clear_tsk_thread_flag(child, TIF_SYSCALL_TRACE);
 
 #ifdef TIF_SYSCALL_EMU
 	if (request == PTRACE_SYSEMU || request == PTRACE_SYSEMU_SINGLESTEP)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		set_tsk_thread_flag(child, TIF_SYSCALL_EMU);
+}
 	else
 		clear_tsk_thread_flag(child, TIF_SYSCALL_EMU);
 #endif
 
 	if (is_singleblock(request)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (unlikely(!arch_has_block_step()))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -EIO;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		user_enable_block_step(child);
 	} else if (is_singlestep(request) || is_sysemu_singlestep(request)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (unlikely(!arch_has_single_step()))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -EIO;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		user_enable_single_step(child);
 	} else {
 		user_disable_single_step(child);
@@ -824,12 +894,17 @@ static int ptrace_resume(struct task_struct *child, long request,
 	 */
 	need_siglock = data && !thread_group_empty(current);
 	if (need_siglock)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		spin_lock_irq(&child->sighand->siglock);
+}
 	child->exit_code = data;
 	wake_up_state(child, __TASK_TRACED);
 	if (need_siglock)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		spin_unlock_irq(&child->sighand->siglock);
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
@@ -841,6 +916,7 @@ find_regset(const struct user_regset_view *view, unsigned int type)
 	const struct user_regset *regset;
 	int n;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (n = 0; n < view->n; ++n) {
 		regset = view->regsets + n;
 		if (regset->core_note_type == type)
@@ -853,6 +929,7 @@ find_regset(const struct user_regset_view *view, unsigned int type)
 static int ptrace_regset(struct task_struct *task, int req, unsigned int type,
 			 struct iovec *kiov)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	const struct user_regset_view *view = task_user_regset_view(task);
 	const struct user_regset *regset = find_regset(view, type);
 	int regset_no;
@@ -915,24 +992,32 @@ int ptrace_request(struct task_struct *child, long request,
 	case PTRACE_GETSIGINFO:
 		ret = ptrace_getsiginfo(child, &siginfo);
 		if (!ret)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			ret = copy_siginfo_to_user(datavp, &siginfo);
+}
 		break;
 
 	case PTRACE_SETSIGINFO:
 		if (copy_from_user(&siginfo, datavp, sizeof siginfo))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			ret = -EFAULT;
+}
 		else
 			ret = ptrace_setsiginfo(child, &siginfo);
 		break;
 
 	case PTRACE_GETSIGMASK:
 		if (addr != sizeof(sigset_t)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			ret = -EINVAL;
 			break;
 		}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (copy_to_user(datavp, &child->blocked, sizeof(sigset_t)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			ret = -EFAULT;
+}
 		else
 			ret = 0;
 
@@ -942,15 +1027,19 @@ int ptrace_request(struct task_struct *child, long request,
 		sigset_t new_set;
 
 		if (addr != sizeof(sigset_t)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			ret = -EINVAL;
 			break;
 		}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (copy_from_user(&new_set, datavp, sizeof(sigset_t))) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			ret = -EFAULT;
 			break;
 		}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		sigdelsetmask(&new_set, sigmask(SIGKILL)|sigmask(SIGSTOP));
 
 		/*
@@ -987,8 +1076,11 @@ int ptrace_request(struct task_struct *child, long request,
 		 * tracee into STOP.
 		 */
 		if (likely(task_set_jobctl_pending(child, JOBCTL_TRAP_STOP)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			ptrace_signal_wake_up(child, child->jobctl & JOBCTL_LISTENING);
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		unlock_task_sighand(child, &flags);
 		ret = 0;
 		break;
@@ -1005,17 +1097,24 @@ int ptrace_request(struct task_struct *child, long request,
 		if (unlikely(!seized || !lock_task_sighand(child, &flags)))
 			break;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		si = child->last_siginfo;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (likely(si && (si->si_code >> 8) == PTRACE_EVENT_STOP)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			child->jobctl |= JOBCTL_LISTENING;
 			/*
 			 * If NOTIFY is set, it means event happened between
 			 * start of this trap and now.  Trigger re-trap.
 			 */
 			if (child->jobctl & JOBCTL_TRAP_NOTIFY)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				ptrace_signal_wake_up(child, true);
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			ret = 0;
 		}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		unlock_task_sighand(child, &flags);
 		break;
 
@@ -1065,7 +1164,10 @@ int ptrace_request(struct task_struct *child, long request,
 
 	case PTRACE_KILL:
 		if (child->exit_state)	/* already dead */
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return 0;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ptrace_resume(child, request, SIGKILL);
 
 #ifdef CONFIG_HAVE_ARCH_TRACEHOOK
@@ -1075,15 +1177,21 @@ int ptrace_request(struct task_struct *child, long request,
 		struct iovec __user *uiov = datavp;
 
 		if (!access_ok(VERIFY_WRITE, uiov, sizeof(*uiov)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -EFAULT;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (__get_user(kiov.iov_base, &uiov->iov_base) ||
 		    __get_user(kiov.iov_len, &uiov->iov_len))
 			return -EFAULT;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ret = ptrace_regset(child, request, addr, &kiov);
 		if (!ret)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			ret = __put_user(kiov.iov_len, &uiov->iov_len);
+}
 		break;
 	}
 #endif
@@ -1096,6 +1204,7 @@ int ptrace_request(struct task_struct *child, long request,
 		break;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return ret;
 }
 
@@ -1107,10 +1216,13 @@ static struct task_struct *ptrace_get_task_struct(pid_t pid)
 	child = find_task_by_vpid(pid);
 	if (child)
 		get_task_struct(child);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rcu_read_unlock();
 
 	if (!child)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ERR_PTR(-ESRCH);
+}
 	return child;
 }
 
@@ -1133,11 +1245,13 @@ SYSCALL_DEFINE4(ptrace, long, request, long, pid, unsigned long, addr,
 
 	child = ptrace_get_task_struct(pid);
 	if (IS_ERR(child)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ret = PTR_ERR(child);
 		goto out;
 	}
 
 	if (request == PTRACE_ATTACH || request == PTRACE_SEIZE) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ret = ptrace_attach(child, request, addr, data);
 		/*
 		 * Some architectures need to do book-keeping after
@@ -1171,7 +1285,9 @@ int generic_ptrace_peekdata(struct task_struct *tsk, unsigned long addr,
 
 	copied = ptrace_access_vm(tsk, addr, &tmp, sizeof(tmp), FOLL_FORCE);
 	if (copied != sizeof(tmp))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EIO;
+}
 	return put_user(tmp, (unsigned long __user *)data);
 }
 
@@ -1182,6 +1298,7 @@ int generic_ptrace_pokedata(struct task_struct *tsk, unsigned long addr,
 
 	copied = ptrace_access_vm(tsk, addr, &data, sizeof(data),
 			FOLL_FORCE | FOLL_WRITE);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return (copied == sizeof(data)) ? 0 : -EIO;
 }
 
@@ -1190,6 +1307,7 @@ int generic_ptrace_pokedata(struct task_struct *tsk, unsigned long addr,
 int compat_ptrace_request(struct task_struct *child, compat_long_t request,
 			  compat_ulong_t addr, compat_ulong_t data)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	compat_ulong_t __user *datap = compat_ptr(data);
 	compat_ulong_t word;
 	siginfo_t siginfo;
@@ -1274,6 +1392,7 @@ COMPAT_SYSCALL_DEFINE4(ptrace, compat_long_t, request, compat_long_t, pid,
 	long ret;
 
 	if (request == PTRACE_TRACEME) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ret = ptrace_traceme();
 		goto out;
 	}
diff --git a/kernel/range.c b/kernel/range.c
index d84de67..3325f77 100644
--- a/kernel/range.c
+++ b/kernel/range.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 /*
  * Range add and subtract
@@ -11,11 +13,15 @@
 int add_range(struct range *range, int az, int nr_range, u64 start, u64 end)
 {
 	if (start >= end)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return nr_range;
+}
 
 	/* Out of slots: */
 	if (nr_range >= az)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return nr_range;
+}
 
 	range[nr_range].start = start;
 	range[nr_range].end = end;
@@ -31,7 +37,9 @@ int add_range_with_merge(struct range *range, int az, int nr_range,
 	int i;
 
 	if (start >= end)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return nr_range;
+}
 
 	/* get new start/end: */
 	for (i = 0; i < nr_range; i++) {
@@ -66,7 +74,9 @@ void subtract_range(struct range *range, int az, u64 start, u64 end)
 	int i, j;
 
 	if (start >= end)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	for (j = 0; j < az; j++) {
 		if (!range[j].end)
@@ -116,9 +126,14 @@ static int cmp_range(const void *x1, const void *x2)
 	const struct range *r2 = x2;
 
 	if (r1->start < r2->start)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -1;
+}
 	if (r1->start > r2->start)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 1;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
@@ -131,12 +146,14 @@ int clean_sort_range(struct range *range, int az)
 			continue;
 		for (j = k; j > i; j--) {
 			if (range[j].end) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				k = j;
 				break;
 			}
 		}
 		if (j == i)
 			break;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		range[i].start = range[k].start;
 		range[i].end   = range[k].end;
 		range[k].start = 0;
@@ -146,6 +163,7 @@ int clean_sort_range(struct range *range, int az)
 	/* count it */
 	for (i = 0; i < az; i++) {
 		if (!range[i].end) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			nr_range = i;
 			break;
 		}
diff --git a/kernel/rcu/rcu.h b/kernel/rcu/rcu.h
index e4b43fe..02ad246 100644
--- a/kernel/rcu/rcu.h
+++ b/kernel/rcu/rcu.h
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * Read-Copy Update definitions shared among RCU implementations.
  *
diff --git a/kernel/rcu/rcu_segcblist.c b/kernel/rcu/rcu_segcblist.c
index 7649fcd..0a6561f 100644
--- a/kernel/rcu/rcu_segcblist.c
+++ b/kernel/rcu/rcu_segcblist.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * RCU segmented callback lists, function definitions
  *
@@ -48,11 +50,14 @@ struct rcu_head *rcu_cblist_dequeue(struct rcu_cblist *rclp)
 
 	rhp = rclp->head;
 	if (!rhp)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 	rclp->len--;
 	rclp->head = rhp->next;
 	if (!rclp->head)
 		rclp->tail = &rclp->head;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return rhp;
 }
 
@@ -63,7 +68,9 @@ void rcu_segcblist_init(struct rcu_segcblist *rsclp)
 {
 	int i;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	BUILD_BUG_ON(RCU_NEXT_TAIL + 1 != ARRAY_SIZE(rsclp->gp_seq));
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	BUILD_BUG_ON(ARRAY_SIZE(rsclp->tails) != ARRAY_SIZE(rsclp->gp_seq));
 	rsclp->head = NULL;
 	for (i = 0; i < RCU_CBLIST_NSEGS; i++)
@@ -78,6 +85,7 @@ void rcu_segcblist_init(struct rcu_segcblist *rsclp)
  */
 void rcu_segcblist_disable(struct rcu_segcblist *rsclp)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WARN_ON_ONCE(!rcu_segcblist_empty(rsclp));
 	WARN_ON_ONCE(rcu_segcblist_n_cbs(rsclp));
 	WARN_ON_ONCE(rcu_segcblist_n_lazy_cbs(rsclp));
@@ -110,6 +118,7 @@ bool rcu_segcblist_pend_cbs(struct rcu_segcblist *rsclp)
  */
 struct rcu_head *rcu_segcblist_first_cb(struct rcu_segcblist *rsclp)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (rcu_segcblist_is_enabled(rsclp))
 		return rsclp->head;
 	return NULL;
@@ -124,6 +133,7 @@ struct rcu_head *rcu_segcblist_first_cb(struct rcu_segcblist *rsclp)
  */
 struct rcu_head *rcu_segcblist_first_pend_cb(struct rcu_segcblist *rsclp)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (rcu_segcblist_is_enabled(rsclp))
 		return *rsclp->tails[RCU_DONE_TAIL];
 	return NULL;
@@ -166,10 +176,14 @@ bool rcu_segcblist_entrain(struct rcu_segcblist *rsclp,
 	int i;
 
 	if (rcu_segcblist_n_cbs(rsclp) == 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return false;
+}
 	WRITE_ONCE(rsclp->len, rsclp->len + 1);
 	if (lazy)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		rsclp->len_lazy++;
+}
 	smp_mb(); /* Ensure counts are updated before callback is entrained. */
 	rhp->next = NULL;
 	for (i = RCU_NEXT_TAIL; i > RCU_DONE_TAIL; i--)
@@ -178,6 +192,7 @@ bool rcu_segcblist_entrain(struct rcu_segcblist *rsclp,
 	*rsclp->tails[i] = rhp;
 	for (; i <= RCU_NEXT_TAIL; i++)
 		rsclp->tails[i] = &rhp->next;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return true;
 }
 
@@ -193,6 +208,7 @@ bool rcu_segcblist_entrain(struct rcu_segcblist *rsclp,
 void rcu_segcblist_extract_count(struct rcu_segcblist *rsclp,
 					       struct rcu_cblist *rclp)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rclp->len_lazy += rsclp->len_lazy;
 	rclp->len += rsclp->len;
 	rsclp->len_lazy = 0;
@@ -210,7 +226,9 @@ void rcu_segcblist_extract_done_cbs(struct rcu_segcblist *rsclp,
 	int i;
 
 	if (!rcu_segcblist_ready_cbs(rsclp))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return; /* Nothing to do. */
+}
 	*rclp->tail = rsclp->head;
 	rsclp->head = *rsclp->tails[RCU_DONE_TAIL];
 	*rsclp->tails[RCU_DONE_TAIL] = NULL;
@@ -233,7 +251,9 @@ void rcu_segcblist_extract_pend_cbs(struct rcu_segcblist *rsclp,
 	int i;
 
 	if (!rcu_segcblist_pend_cbs(rsclp))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return; /* Nothing to do. */
+}
 	*rclp->tail = *rsclp->tails[RCU_DONE_TAIL];
 	rclp->tail = rsclp->tails[RCU_NEXT_TAIL];
 	*rsclp->tails[RCU_DONE_TAIL] = NULL;
@@ -265,7 +285,9 @@ void rcu_segcblist_insert_done_cbs(struct rcu_segcblist *rsclp,
 	int i;
 
 	if (!rclp->head)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return; /* No callbacks to move. */
+}
 	*rclp->tail = rsclp->head;
 	rsclp->head = rclp->head;
 	for (i = RCU_DONE_TAIL; i < RCU_CBLIST_NSEGS; i++)
@@ -284,6 +306,7 @@ void rcu_segcblist_insert_done_cbs(struct rcu_segcblist *rsclp,
 void rcu_segcblist_insert_pend_cbs(struct rcu_segcblist *rsclp,
 				   struct rcu_cblist *rclp)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!rclp->head)
 		return; /* Nothing to do. */
 	*rsclp->tails[RCU_NEXT_TAIL] = rclp->head;
@@ -302,7 +325,9 @@ void rcu_segcblist_advance(struct rcu_segcblist *rsclp, unsigned long seq)
 
 	WARN_ON_ONCE(!rcu_segcblist_is_enabled(rsclp));
 	if (rcu_segcblist_restempty(rsclp, RCU_DONE_TAIL))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	/*
 	 * Find all callbacks whose ->gp_seq numbers indicate that they
@@ -316,7 +341,9 @@ void rcu_segcblist_advance(struct rcu_segcblist *rsclp, unsigned long seq)
 
 	/* If no callbacks moved, nothing more need be done. */
 	if (i == RCU_WAIT_TAIL)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	/* Clean up tail pointers that might have been misordered above. */
 	for (j = RCU_WAIT_TAIL; j < i; j++)
@@ -357,7 +384,9 @@ bool rcu_segcblist_accelerate(struct rcu_segcblist *rsclp, unsigned long seq)
 
 	WARN_ON_ONCE(!rcu_segcblist_is_enabled(rsclp));
 	if (rcu_segcblist_restempty(rsclp, RCU_DONE_TAIL))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return false;
+}
 
 	/*
 	 * Find the segment preceding the oldest segment of callbacks
@@ -386,7 +415,9 @@ bool rcu_segcblist_accelerate(struct rcu_segcblist *rsclp, unsigned long seq)
 	 * skipping any empty segments.
 	 */
 	if (++i >= RCU_NEXT_TAIL)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return false;
+}
 
 	/*
 	 * Merge all later callbacks, including newly arrived callbacks,
@@ -399,6 +430,7 @@ bool rcu_segcblist_accelerate(struct rcu_segcblist *rsclp, unsigned long seq)
 		rsclp->tails[i] = rsclp->tails[RCU_NEXT_TAIL];
 		rsclp->gp_seq[i] = seq;
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return true;
 }
 
@@ -417,6 +449,7 @@ bool rcu_segcblist_future_gp_needed(struct rcu_segcblist *rsclp,
 		if (rsclp->tails[i - 1] != rsclp->tails[i] &&
 		    ULONG_CMP_LT(seq, rsclp->gp_seq[i]))
 			return true;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return false;
 }
 
diff --git a/kernel/rcu/rcu_segcblist.h b/kernel/rcu/rcu_segcblist.h
index 581c12b..283e5f7 100644
--- a/kernel/rcu/rcu_segcblist.h
+++ b/kernel/rcu/rcu_segcblist.h
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * RCU segmented callback lists, internal-to-rcu header file
  *
diff --git a/kernel/rcu/srcutree.c b/kernel/rcu/srcutree.c
index 6d58800..c1eebd1 100644
--- a/kernel/rcu/srcutree.c
+++ b/kernel/rcu/srcutree.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * Sleepable Read-Copy Update mechanism for mutual exclusion.
  *
@@ -72,12 +74,15 @@ static void init_srcu_struct_nodes(struct srcu_struct *sp, bool is_static)
 	/* Work out the overall tree geometry. */
 	sp->level[0] = &sp->node[0];
 	for (i = 1; i < rcu_num_lvls; i++)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		sp->level[i] = sp->level[i - 1] + num_rcu_lvl[i - 1];
+}
 	rcu_init_levelspread(levelspread, num_rcu_lvl);
 
 	/* Each pass through this loop initializes one srcu_node structure. */
 	rcu_for_each_node_breadth_first(sp, snp) {
 		raw_spin_lock_init(&ACCESS_PRIVATE(snp, lock));
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		WARN_ON_ONCE(ARRAY_SIZE(snp->srcu_have_cbs) !=
 			     ARRAY_SIZE(snp->srcu_data_have_cbs));
 		for (i = 0; i < ARRAY_SIZE(snp->srcu_have_cbs); i++) {
@@ -95,7 +100,10 @@ static void init_srcu_struct_nodes(struct srcu_struct *sp, bool is_static)
 
 		/* Non-root node. */
 		if (snp == sp->level[level + 1])
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			level++;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		snp->srcu_parent = sp->level[level - 1] +
 				   (snp - sp->level[level]) /
 				   levelspread[level - 1];
@@ -151,6 +159,7 @@ static int init_srcu_struct_fields(struct srcu_struct *sp, bool is_static)
 	sp->srcu_gp_seq = 0;
 	sp->srcu_barrier_seq = 0;
 	mutex_init(&sp->srcu_barrier_mutex);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	atomic_set(&sp->srcu_barrier_cpu_cnt, 0);
 	INIT_DELAYED_WORK(&sp->work, process_srcu);
 	if (!is_static)
@@ -209,10 +218,14 @@ static void check_init_srcu_struct(struct srcu_struct *sp)
 	WARN_ON_ONCE(rcu_scheduler_active == RCU_SCHEDULER_INIT);
 	/* The smp_load_acquire() pairs with the smp_store_release(). */
 	if (!rcu_seq_state(smp_load_acquire(&sp->srcu_gp_seq_needed))) /*^^^*/
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return; /* Already initialized. */
+}
 	raw_spin_lock_irqsave_rcu_node(sp, flags);
 	if (!rcu_seq_state(sp->srcu_gp_seq_needed)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		raw_spin_unlock_irqrestore_rcu_node(sp, flags);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
 	}
 	init_srcu_struct_fields(sp, true);
@@ -314,6 +327,7 @@ static bool srcu_readers_active(struct srcu_struct *sp)
 	int cpu;
 	unsigned long sum = 0;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for_each_possible_cpu(cpu) {
 		struct srcu_data *cpuc = per_cpu_ptr(sp->sda, cpu);
 
@@ -350,6 +364,7 @@ void cleanup_srcu_struct(struct srcu_struct *sp)
 {
 	int cpu;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (WARN_ON(!srcu_get_delay(sp)))
 		return; /* Leakage unless caller handles error. */
 	if (WARN_ON(srcu_readers_active(sp)))
@@ -412,6 +427,7 @@ static void srcu_gp_start(struct srcu_struct *sp)
 	struct srcu_data *sdp = this_cpu_ptr(sp->sda);
 	int state;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&sp->lock);
 	WARN_ON_ONCE(ULONG_CMP_GE(sp->srcu_gp_seq, sp->srcu_gp_seq_needed));
 	rcu_segcblist_advance(&sdp->srcu_cblist,
@@ -420,6 +436,7 @@ static void srcu_gp_start(struct srcu_struct *sp)
 				       rcu_seq_snap(&sp->srcu_gp_seq));
 	smp_mb(); /* Order prior store to ->srcu_gp_seq_needed vs. GP start. */
 	rcu_seq_start(&sp->srcu_gp_seq);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	state = rcu_seq_state(READ_ONCE(sp->srcu_gp_seq));
 	WARN_ON_ONCE(state != SRCU_STATE_SCAN1);
 }
@@ -436,6 +453,7 @@ void srcu_online_cpu(unsigned int cpu)
 
 void srcu_offline_cpu(unsigned int cpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WRITE_ONCE(per_cpu(srcu_online, cpu), false);
 }
 
@@ -521,7 +539,9 @@ static void srcu_gp_end(struct srcu_struct *sp)
 	rcu_seq_end(&sp->srcu_gp_seq);
 	gpseq = rcu_seq_current(&sp->srcu_gp_seq);
 	if (ULONG_CMP_LT(sp->srcu_gp_seq_needed_exp, gpseq))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		sp->srcu_gp_seq_needed_exp = gpseq;
+}
 	raw_spin_unlock_irq_rcu_node(sp);
 	mutex_unlock(&sp->srcu_gp_mutex);
 	/* A new grace period can start at this point.  But only one. */
@@ -531,13 +551,16 @@ static void srcu_gp_end(struct srcu_struct *sp)
 	idxnext = (idx + 1) % ARRAY_SIZE(snp->srcu_have_cbs);
 	rcu_for_each_node_breadth_first(sp, snp) {
 		raw_spin_lock_irq_rcu_node(snp);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		cbs = false;
 		if (snp >= sp->level[rcu_num_lvls - 1])
 			cbs = snp->srcu_have_cbs[idx] == gpseq;
 		snp->srcu_have_cbs[idx] = gpseq;
 		rcu_seq_set_state(&snp->srcu_have_cbs[idx], 1);
 		if (ULONG_CMP_LT(snp->srcu_gp_seq_needed_exp, gpseq))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			snp->srcu_gp_seq_needed_exp = gpseq;
+}
 		mask = snp->srcu_data_have_cbs[idx];
 		snp->srcu_data_have_cbs[idx] = 0;
 		raw_spin_unlock_irq_rcu_node(snp);
@@ -546,12 +569,18 @@ static void srcu_gp_end(struct srcu_struct *sp)
 
 		/* Occasionally prevent srcu_data counter wrap. */
 		if (!(gpseq & counter_wrap_check))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			for (cpu = snp->grplo; cpu <= snp->grphi; cpu++) {
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				sdp = per_cpu_ptr(sp->sda, cpu);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				raw_spin_lock_irqsave_rcu_node(sdp, flags);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				if (ULONG_CMP_GE(gpseq,
 						 sdp->srcu_gp_seq_needed + 100))
 					sdp->srcu_gp_seq_needed = gpseq;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				raw_spin_unlock_irqrestore_rcu_node(sdp, flags);
 			}
 	}
@@ -561,9 +590,11 @@ static void srcu_gp_end(struct srcu_struct *sp)
 
 	/* Start a new grace period if needed. */
 	raw_spin_lock_irq_rcu_node(sp);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	gpseq = rcu_seq_current(&sp->srcu_gp_seq);
 	if (!rcu_seq_state(gpseq) &&
 	    ULONG_CMP_LT(gpseq, sp->srcu_gp_seq_needed)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		srcu_gp_start(sp);
 		raw_spin_unlock_irq_rcu_node(sp);
 		/* Throttle expedited grace periods: Should be rare! */
@@ -586,6 +617,7 @@ static void srcu_funnel_exp_start(struct srcu_struct *sp, struct srcu_node *snp,
 {
 	unsigned long flags;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (; snp != NULL; snp = snp->srcu_parent) {
 		if (rcu_seq_done(&sp->srcu_gp_seq, s) ||
 		    ULONG_CMP_GE(READ_ONCE(snp->srcu_gp_seq_needed_exp), s))
@@ -622,21 +654,34 @@ static void srcu_funnel_gp_start(struct srcu_struct *sp, struct srcu_data *sdp,
 	/* Each pass through the loop does one level of the srcu_node tree. */
 	for (; snp != NULL; snp = snp->srcu_parent) {
 		if (rcu_seq_done(&sp->srcu_gp_seq, s) && snp != sdp->mynode)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return; /* GP already done and CBs recorded. */
+}
 		raw_spin_lock_irqsave_rcu_node(snp, flags);
 		if (ULONG_CMP_GE(snp->srcu_have_cbs[idx], s)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			snp_seq = snp->srcu_have_cbs[idx];
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			if (snp == sdp->mynode && snp_seq == s)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				snp->srcu_data_have_cbs[idx] |= sdp->grpmask;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			raw_spin_unlock_irqrestore_rcu_node(snp, flags);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			if (snp == sdp->mynode && snp_seq != s) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				srcu_schedule_cbs_sdp(sdp, do_norm
 							   ? SRCU_INTERVAL
 							   : 0);
 				return;
 			}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			if (!do_norm)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				srcu_funnel_exp_start(sp, snp, s);
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return;
 		}
 		snp->srcu_have_cbs[idx] = s;
@@ -679,9 +724,15 @@ static bool try_check_zero(struct srcu_struct *sp, int idx, int trycount)
 {
 	for (;;) {
 		if (srcu_readers_active_idx_check(sp, idx))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return true;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (--trycount + !srcu_get_delay(sp) <= 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return false;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		udelay(SRCU_RETRY_CHECK_DELAY);
 	}
 }
@@ -747,7 +798,9 @@ static bool srcu_might_be_idle(struct srcu_struct *sp)
 	local_irq_save(flags);
 	sdp = this_cpu_ptr(sp->sda);
 	if (rcu_segcblist_pend_cbs(&sdp->srcu_cblist)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		local_irq_restore(flags);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return false; /* Callbacks already present, so not idle. */
 	}
 	local_irq_restore(flags);
@@ -769,10 +822,14 @@ static bool srcu_might_be_idle(struct srcu_struct *sp)
 	curseq = rcu_seq_current(&sp->srcu_gp_seq);
 	smp_mb(); /* Order ->srcu_gp_seq with ->srcu_gp_seq_needed. */
 	if (ULONG_CMP_LT(curseq, READ_ONCE(sp->srcu_gp_seq_needed)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return false; /* Grace period in progress, so not idle. */
+}
 	smp_mb(); /* Order ->srcu_gp_seq with prior access. */
 	if (curseq != rcu_seq_current(&sp->srcu_gp_seq))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return false; /* GP # changed, so not idle. */
+}
 	return true; /* With reasonable probability, idle! */
 }
 
@@ -824,6 +881,7 @@ void __call_srcu(struct srcu_struct *sp, struct rcu_head *rhp,
 	if (debug_rcu_head_queue(rhp)) {
 		/* Probable double call_srcu(), so leak the callback. */
 		WRITE_ONCE(rhp->func, srcu_leak_callback);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		WARN_ONCE(1, "call_srcu(): Leaked duplicate callback\n");
 		return;
 	}
@@ -847,9 +905,12 @@ void __call_srcu(struct srcu_struct *sp, struct rcu_head *rhp,
 	raw_spin_unlock_irqrestore_rcu_node(sdp, flags);
 	if (needgp)
 		srcu_funnel_gp_start(sp, sdp, s, do_norm);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	else if (needexp)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		srcu_funnel_exp_start(sp, sdp->mynode, s);
 }
+}
 
 /**
  * call_srcu() - Queue a callback for invocation after an SRCU grace period
@@ -871,6 +932,7 @@ void __call_srcu(struct srcu_struct *sp, struct rcu_head *rhp,
 void call_srcu(struct srcu_struct *sp, struct rcu_head *rhp,
 	       rcu_callback_t func)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	__call_srcu(sp, rhp, func, true);
 }
 EXPORT_SYMBOL_GPL(call_srcu);
@@ -882,6 +944,7 @@ static void __synchronize_srcu(struct srcu_struct *sp, bool do_norm)
 {
 	struct rcu_synchronize rcu;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	RCU_LOCKDEP_WARN(lock_is_held(&sp->dep_map) ||
 			 lock_is_held(&rcu_bh_lock_map) ||
 			 lock_is_held(&rcu_lock_map) ||
@@ -889,7 +952,9 @@ static void __synchronize_srcu(struct srcu_struct *sp, bool do_norm)
 			 "Illegal synchronize_srcu() in same-type SRCU (or in RCU) read-side critical section");
 
 	if (rcu_scheduler_active == RCU_SCHEDULER_INACTIVE)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 	might_sleep();
 	check_init_srcu_struct(sp);
 	init_completion(&rcu.completion);
@@ -985,6 +1050,7 @@ static void srcu_barrier_cb(struct rcu_head *rhp)
 	struct srcu_data *sdp;
 	struct srcu_struct *sp;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	sdp = container_of(rhp, struct srcu_data, srcu_barrier_head);
 	sp = sdp->sp;
 	if (atomic_dec_and_test(&sp->srcu_barrier_cpu_cnt))
@@ -1004,6 +1070,7 @@ void srcu_barrier(struct srcu_struct *sp)
 	check_init_srcu_struct(sp);
 	mutex_lock(&sp->srcu_barrier_mutex);
 	if (rcu_seq_done(&sp->srcu_barrier_seq, s)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		smp_mb(); /* Force ordering following return. */
 		mutex_unlock(&sp->srcu_barrier_mutex);
 		return; /* Someone else did our work for us. */
@@ -1055,6 +1122,7 @@ EXPORT_SYMBOL_GPL(srcu_barrier);
  */
 unsigned long srcu_batches_completed(struct srcu_struct *sp)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return sp->srcu_idx;
 }
 EXPORT_SYMBOL_GPL(srcu_batches_completed);
@@ -1082,18 +1150,26 @@ static void srcu_advance_state(struct srcu_struct *sp)
 	 */
 	idx = rcu_seq_state(smp_load_acquire(&sp->srcu_gp_seq)); /* ^^^ */
 	if (idx == SRCU_STATE_IDLE) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		raw_spin_lock_irq_rcu_node(sp);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (ULONG_CMP_GE(sp->srcu_gp_seq, sp->srcu_gp_seq_needed)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			WARN_ON_ONCE(rcu_seq_state(sp->srcu_gp_seq));
 			raw_spin_unlock_irq_rcu_node(sp);
 			mutex_unlock(&sp->srcu_gp_mutex);
 			return;
 		}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		idx = rcu_seq_state(READ_ONCE(sp->srcu_gp_seq));
 		if (idx == SRCU_STATE_IDLE)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			srcu_gp_start(sp);
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		raw_spin_unlock_irq_rcu_node(sp);
 		if (idx != SRCU_STATE_IDLE) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			mutex_unlock(&sp->srcu_gp_mutex);
 			return; /* Someone else started the grace period. */
 		}
@@ -1102,6 +1178,7 @@ static void srcu_advance_state(struct srcu_struct *sp)
 	if (rcu_seq_state(READ_ONCE(sp->srcu_gp_seq)) == SRCU_STATE_SCAN1) {
 		idx = 1 ^ (sp->srcu_idx & 1);
 		if (!try_check_zero(sp, idx, 1)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			mutex_unlock(&sp->srcu_gp_mutex);
 			return; /* readers present, retry later. */
 		}
@@ -1117,6 +1194,7 @@ static void srcu_advance_state(struct srcu_struct *sp)
 		 */
 		idx = 1 ^ (sp->srcu_idx & 1);
 		if (!try_check_zero(sp, idx, 2)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			mutex_unlock(&sp->srcu_gp_mutex);
 			return; /* readers present, retry later. */
 		}
@@ -1146,6 +1224,7 @@ static void srcu_invoke_callbacks(struct work_struct *work)
 			      rcu_seq_current(&sp->srcu_gp_seq));
 	if (sdp->srcu_cblist_invoking ||
 	    !rcu_segcblist_ready_cbs(&sdp->srcu_cblist)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		raw_spin_unlock_irq_rcu_node(sdp);
 		return;  /* Someone else on the job or nothing to do. */
 	}
@@ -1156,6 +1235,7 @@ static void srcu_invoke_callbacks(struct work_struct *work)
 	raw_spin_unlock_irq_rcu_node(sdp);
 	rhp = rcu_cblist_dequeue(&ready_cbs);
 	for (; rhp != NULL; rhp = rcu_cblist_dequeue(&ready_cbs)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		debug_rcu_head_unqueue(rhp);
 		local_bh_disable();
 		rhp->func(rhp);
@@ -1174,8 +1254,10 @@ static void srcu_invoke_callbacks(struct work_struct *work)
 	more = rcu_segcblist_ready_cbs(&sdp->srcu_cblist);
 	raw_spin_unlock_irq_rcu_node(sdp);
 	if (more)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		srcu_schedule_cbs_sdp(sdp, 0);
 }
+}
 
 /*
  * Finished one round of SRCU grace period.  Start another if there are
@@ -1198,8 +1280,10 @@ static void srcu_reschedule(struct srcu_struct *sp, unsigned long delay)
 	raw_spin_unlock_irq_rcu_node(sp);
 
 	if (pushgp)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		queue_delayed_work(system_power_efficient_wq, &sp->work, delay);
 }
+}
 
 /*
  * This is the work-queue function that handles SRCU grace periods.
@@ -1218,6 +1302,7 @@ void srcutorture_get_gp_data(enum rcutorture_type test_type,
 			     struct srcu_struct *sp, int *flags,
 			     unsigned long *gpnum, unsigned long *completed)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (test_type != SRCU_FLAVOR)
 		return;
 	*flags = 0;
@@ -1234,6 +1319,7 @@ void srcu_torture_stats_print(struct srcu_struct *sp, char *tt, char *tf)
 
 	idx = sp->srcu_idx & 0x1;
 	pr_alert("%s%s Tree SRCU per-CPU(idx=%d):", tt, tf, idx);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for_each_possible_cpu(cpu) {
 		unsigned long l0, l1;
 		unsigned long u0, u1;
@@ -1267,7 +1353,9 @@ static int __init srcu_bootup_announce(void)
 {
 	pr_info("Hierarchical SRCU implementation.\n");
 	if (exp_holdoff != DEFAULT_SRCU_EXP_HOLDOFF)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_info("\tNon-default auto-expedite holdoff of %lu ns.\n", exp_holdoff);
+}
 	return 0;
 }
 early_initcall(srcu_bootup_announce);
diff --git a/kernel/rcu/sync.c b/kernel/rcu/sync.c
index 3f943ef..74b7893 100644
--- a/kernel/rcu/sync.c
+++ b/kernel/rcu/sync.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * RCU-based infrastructure for lightweight reader-writer locking
  *
@@ -79,6 +81,7 @@ EXPORT_SYMBOL_GPL(rcu_sync_lockdep_assert);
  */
 void rcu_sync_init(struct rcu_sync *rsp, enum rcu_sync_type type)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	memset(rsp, 0, sizeof(*rsp));
 	init_waitqueue_head(&rsp->gp_wait);
 	rsp->gp_type = type;
@@ -122,12 +125,16 @@ void rcu_sync_enter(struct rcu_sync *rsp)
 	need_wait = rsp->gp_count++;
 	need_sync = rsp->gp_state == GP_IDLE;
 	if (need_sync)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		rsp->gp_state = GP_PENDING;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_unlock_irq(&rsp->rss_lock);
 
 	BUG_ON(need_wait && need_sync);
 
 	if (need_sync) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		gp_ops[rsp->gp_type].sync();
 		rsp->gp_state = GP_PASSED;
 		wake_up_all(&rsp->gp_wait);
@@ -163,6 +170,7 @@ void rcu_sync_enter(struct rcu_sync *rsp)
  */
 static void rcu_sync_func(struct rcu_head *rhp)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct rcu_sync *rsp = container_of(rhp, struct rcu_sync, cb_head);
 	unsigned long flags;
 
@@ -205,15 +213,20 @@ static void rcu_sync_func(struct rcu_head *rhp)
  */
 void rcu_sync_exit(struct rcu_sync *rsp)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_lock_irq(&rsp->rss_lock);
 	if (!--rsp->gp_count) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (rsp->cb_state == CB_IDLE) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			rsp->cb_state = CB_PENDING;
 			gp_ops[rsp->gp_type].call(&rsp->cb_head, rcu_sync_func);
 		} else if (rsp->cb_state == CB_PENDING) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			rsp->cb_state = CB_REPLAY;
 		}
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_unlock_irq(&rsp->rss_lock);
 }
 
@@ -227,14 +240,19 @@ void rcu_sync_dtor(struct rcu_sync *rsp)
 
 	BUG_ON(rsp->gp_count);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_lock_irq(&rsp->rss_lock);
 	if (rsp->cb_state == CB_REPLAY)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		rsp->cb_state = CB_PENDING;
+}
 	cb_state = rsp->cb_state;
 	spin_unlock_irq(&rsp->rss_lock);
 
 	if (cb_state != CB_IDLE) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		gp_ops[rsp->gp_type].wait();
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		BUG_ON(rsp->cb_state != CB_IDLE);
 	}
 }
diff --git a/kernel/rcu/tree.c b/kernel/rcu/tree.c
index 3e3650e..352bf49 100644
--- a/kernel/rcu/tree.c
+++ b/kernel/rcu/tree.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * Read-Copy Update mechanism for mutual exclusion
  *
@@ -280,6 +282,7 @@ static DEFINE_PER_CPU(bool, disable_rcu_irq_enter);
 
 bool rcu_irq_enter_disabled(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return this_cpu_read(disable_rcu_irq_enter);
 }
 
@@ -321,9 +324,11 @@ static void rcu_dynticks_eqs_exit(void)
 	 * critical section.
 	 */
 	seq = atomic_add_return(RCU_DYNTICK_CTRL_CTR, &rdtp->dynticks);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WARN_ON_ONCE(IS_ENABLED(CONFIG_RCU_EQS_DEBUG) &&
 		     !(seq & RCU_DYNTICK_CTRL_CTR));
 	if (seq & RCU_DYNTICK_CTRL_MASK) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		atomic_andnot(RCU_DYNTICK_CTRL_MASK, &rdtp->dynticks);
 		smp_mb__after_atomic(); /* _exit after clearing mask. */
 		/* Prefer duplicate flushes to losing a flush. */
@@ -346,7 +351,10 @@ static void rcu_dynticks_eqs_online(void)
 	struct rcu_dynticks *rdtp = this_cpu_ptr(&rcu_dynticks);
 
 	if (atomic_read(&rdtp->dynticks) & RCU_DYNTICK_CTRL_CTR)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	atomic_add(RCU_DYNTICK_CTRL_CTR, &rdtp->dynticks);
 }
 
@@ -389,6 +397,7 @@ static bool rcu_dynticks_in_eqs(int snap)
  */
 static bool rcu_dynticks_in_eqs_since(struct rcu_dynticks *rdtp, int snap)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return snap != rcu_dynticks_snap(rdtp);
 }
 
@@ -398,6 +407,7 @@ static bool rcu_dynticks_in_eqs_since(struct rcu_dynticks *rdtp, int snap)
  */
 static void rcu_dynticks_momentary_idle(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct rcu_dynticks *rdtp = this_cpu_ptr(&rcu_dynticks);
 	int special = atomic_add_return(2 * RCU_DYNTICK_CTRL_CTR,
 					&rdtp->dynticks);
@@ -417,6 +427,7 @@ bool rcu_eqs_special_set(int cpu)
 {
 	int old;
 	int new;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct rcu_dynticks *rdtp = &per_cpu(rcu_dynticks, cpu);
 
 	do {
@@ -441,6 +452,7 @@ bool rcu_eqs_special_set(int cpu)
  */
 static void rcu_momentary_dyntick_idle(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	raw_cpu_write(rcu_dynticks.rcu_need_heavy_qs, false);
 	rcu_dynticks_momentary_idle();
 }
@@ -459,12 +471,20 @@ void rcu_note_context_switch(bool preempt)
 	/* Load rcu_urgent_qs before other flags. */
 	if (!smp_load_acquire(this_cpu_ptr(&rcu_dynticks.rcu_urgent_qs)))
 		goto out;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	this_cpu_write(rcu_dynticks.rcu_urgent_qs, false);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (unlikely(raw_cpu_read(rcu_dynticks.rcu_need_heavy_qs)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		rcu_momentary_dyntick_idle();
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	this_cpu_inc(rcu_dynticks.rcu_qs_ctr);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!preempt)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		rcu_note_voluntary_context_switch_lite(current);
+}
 out:
 	trace_rcu_utilization(TPS("End context switch"));
 	barrier(); /* Avoid RCU read-side critical sections leaking up. */
@@ -489,23 +509,38 @@ void rcu_all_qs(void)
 	unsigned long flags;
 
 	if (!raw_cpu_read(rcu_dynticks.rcu_urgent_qs))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	preempt_disable();
 	/* Load rcu_urgent_qs before other flags. */
 	if (!smp_load_acquire(this_cpu_ptr(&rcu_dynticks.rcu_urgent_qs))) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		preempt_enable();
 		return;
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	this_cpu_write(rcu_dynticks.rcu_urgent_qs, false);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	barrier(); /* Avoid RCU read-side critical sections leaking down. */
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (unlikely(raw_cpu_read(rcu_dynticks.rcu_need_heavy_qs))) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		local_irq_save(flags);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		rcu_momentary_dyntick_idle();
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		local_irq_restore(flags);
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (unlikely(raw_cpu_read(rcu_sched_data.cpu_no_qs.b.exp)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		rcu_sched_qs();
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	this_cpu_inc(rcu_dynticks.rcu_qs_ctr);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	barrier(); /* Avoid RCU read-side critical sections leaking up. */
 	preempt_enable();
 }
@@ -548,6 +583,7 @@ static int rcu_pending(void);
  */
 unsigned long rcu_batches_started(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return rcu_state_p->gpnum;
 }
 EXPORT_SYMBOL_GPL(rcu_batches_started);
@@ -557,6 +593,7 @@ EXPORT_SYMBOL_GPL(rcu_batches_started);
  */
 unsigned long rcu_batches_started_sched(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return rcu_sched_state.gpnum;
 }
 EXPORT_SYMBOL_GPL(rcu_batches_started_sched);
@@ -566,6 +603,7 @@ EXPORT_SYMBOL_GPL(rcu_batches_started_sched);
  */
 unsigned long rcu_batches_started_bh(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return rcu_bh_state.gpnum;
 }
 EXPORT_SYMBOL_GPL(rcu_batches_started_bh);
@@ -575,6 +613,7 @@ EXPORT_SYMBOL_GPL(rcu_batches_started_bh);
  */
 unsigned long rcu_batches_completed(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return rcu_state_p->completed;
 }
 EXPORT_SYMBOL_GPL(rcu_batches_completed);
@@ -584,6 +623,7 @@ EXPORT_SYMBOL_GPL(rcu_batches_completed);
  */
 unsigned long rcu_batches_completed_sched(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return rcu_sched_state.completed;
 }
 EXPORT_SYMBOL_GPL(rcu_batches_completed_sched);
@@ -593,6 +633,7 @@ EXPORT_SYMBOL_GPL(rcu_batches_completed_sched);
  */
 unsigned long rcu_batches_completed_bh(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return rcu_bh_state.completed;
 }
 EXPORT_SYMBOL_GPL(rcu_batches_completed_bh);
@@ -605,6 +646,7 @@ EXPORT_SYMBOL_GPL(rcu_batches_completed_bh);
  */
 unsigned long rcu_exp_batches_completed(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return rcu_state_p->expedited_sequence;
 }
 EXPORT_SYMBOL_GPL(rcu_exp_batches_completed);
@@ -615,6 +657,7 @@ EXPORT_SYMBOL_GPL(rcu_exp_batches_completed);
  */
 unsigned long rcu_exp_batches_completed_sched(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return rcu_sched_state.expedited_sequence;
 }
 EXPORT_SYMBOL_GPL(rcu_exp_batches_completed_sched);
@@ -624,6 +667,7 @@ EXPORT_SYMBOL_GPL(rcu_exp_batches_completed_sched);
  */
 void rcu_force_quiescent_state(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	force_quiescent_state(rcu_state_p);
 }
 EXPORT_SYMBOL_GPL(rcu_force_quiescent_state);
@@ -633,6 +677,7 @@ EXPORT_SYMBOL_GPL(rcu_force_quiescent_state);
  */
 void rcu_bh_force_quiescent_state(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	force_quiescent_state(&rcu_bh_state);
 }
 EXPORT_SYMBOL_GPL(rcu_bh_force_quiescent_state);
@@ -642,6 +687,7 @@ EXPORT_SYMBOL_GPL(rcu_bh_force_quiescent_state);
  */
 void rcu_sched_force_quiescent_state(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	force_quiescent_state(&rcu_sched_state);
 }
 EXPORT_SYMBOL_GPL(rcu_sched_force_quiescent_state);
@@ -653,6 +699,7 @@ void show_rcu_gp_kthreads(void)
 {
 	struct rcu_state *rsp;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for_each_rcu_flavor(rsp) {
 		pr_info("%s: wait state: %d ->state: %#lx\n",
 			rsp->name, rsp->gp_state, rsp->gp_kthread->state);
@@ -670,6 +717,7 @@ EXPORT_SYMBOL_GPL(show_rcu_gp_kthreads);
  */
 void rcutorture_record_test_transition(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rcutorture_testseq++;
 	rcutorture_vernum = 0;
 }
@@ -711,6 +759,7 @@ EXPORT_SYMBOL_GPL(rcutorture_get_gp_data);
  */
 void rcutorture_record_progress(unsigned long vernum)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rcutorture_vernum++;
 }
 EXPORT_SYMBOL_GPL(rcutorture_record_progress);
@@ -730,10 +779,12 @@ static struct rcu_node *rcu_get_root(struct rcu_state *rsp)
  */
 static int rcu_future_needs_gp(struct rcu_state *rsp)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct rcu_node *rnp = rcu_get_root(rsp);
 	int idx = (READ_ONCE(rnp->completed) + 1) & 0x1;
 	int *fp = &rnp->need_future_gp[idx];
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	RCU_LOCKDEP_WARN(!irqs_disabled(), "rcu_future_needs_gp() invoked with irqs enabled!!!");
 	return READ_ONCE(*fp);
 }
@@ -746,15 +797,24 @@ static int rcu_future_needs_gp(struct rcu_state *rsp)
 static bool
 cpu_needs_another_gp(struct rcu_state *rsp, struct rcu_data *rdp)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	RCU_LOCKDEP_WARN(!irqs_disabled(), "cpu_needs_another_gp() invoked with irqs enabled!!!");
 	if (rcu_gp_in_progress(rsp))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return false;  /* No, a grace period is already in progress. */
+}
 	if (rcu_future_needs_gp(rsp))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return true;  /* Yes, a no-CBs CPU needs one. */
+}
 	if (!rcu_segcblist_is_enabled(&rdp->cblist))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return false;  /* No, this is a no-CBs (or offline) CPU. */
+}
 	if (!rcu_segcblist_restempty(&rdp->cblist, RCU_NEXT_READY_TAIL))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return true;  /* Yes, CPU has newly registered callbacks. */
+}
 	if (rcu_segcblist_future_gp_needed(&rdp->cblist,
 					   READ_ONCE(rsp->completed)))
 		return true;  /* Yes, CBs for future grace period. */
@@ -773,6 +833,7 @@ static void rcu_eqs_enter_common(bool user)
 	struct rcu_data *rdp;
 	struct rcu_dynticks *rdtp = this_cpu_ptr(&rcu_dynticks);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	RCU_LOCKDEP_WARN(!irqs_disabled(), "rcu_eqs_enter_common() invoked with irqs enabled!!!");
 	trace_rcu_dyntick(TPS("Start"), rdtp->dynticks_nesting, 0);
 	if (IS_ENABLED(CONFIG_RCU_EQS_DEBUG) &&
@@ -781,7 +842,9 @@ static void rcu_eqs_enter_common(bool user)
 			idle_task(smp_processor_id());
 
 		trace_rcu_dyntick(TPS("Error on entry: not idle task"), rdtp->dynticks_nesting, 0);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		rcu_ftrace_dump(DUMP_ORIG);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		WARN_ONCE(1, "Current pid: %d comm: %s / Idle pid: %d comm: %s",
 			  current->pid, current->comm,
 			  idle->pid, idle->comm); /* must be idle task! */
@@ -790,6 +853,7 @@ static void rcu_eqs_enter_common(bool user)
 		rdp = this_cpu_ptr(rsp->rda);
 		do_nocb_deferred_wakeup(rdp);
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rcu_prepare_for_idle();
 	__this_cpu_inc(disable_rcu_irq_enter);
 	rdtp->dynticks_nesting = 0; /* Breaks tracing momentarily. */
@@ -803,8 +867,10 @@ static void rcu_eqs_enter_common(bool user)
 	 */
 	RCU_LOCKDEP_WARN(lock_is_held(&rcu_lock_map),
 			 "Illegal idle entry in RCU read-side critical section.");
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	RCU_LOCKDEP_WARN(lock_is_held(&rcu_bh_lock_map),
 			 "Illegal idle entry in RCU-bh read-side critical section.");
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	RCU_LOCKDEP_WARN(lock_is_held(&rcu_sched_lock_map),
 			 "Illegal idle entry in RCU-sched read-side critical section.");
 }
@@ -818,6 +884,7 @@ static void rcu_eqs_enter(bool user)
 	struct rcu_dynticks *rdtp;
 
 	rdtp = this_cpu_ptr(&rcu_dynticks);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WARN_ON_ONCE(IS_ENABLED(CONFIG_RCU_EQS_DEBUG) &&
 		     (rdtp->dynticks_nesting & DYNTICK_TASK_NEST_MASK) == 0);
 	if ((rdtp->dynticks_nesting & DYNTICK_TASK_NEST_MASK) == DYNTICK_TASK_NEST_VALUE)
@@ -840,6 +907,7 @@ static void rcu_eqs_enter(bool user)
  */
 void rcu_idle_enter(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	RCU_LOCKDEP_WARN(!irqs_disabled(), "rcu_idle_enter() invoked with irqs enabled!!!");
 	rcu_eqs_enter(false);
 }
@@ -880,13 +948,17 @@ void rcu_irq_exit(void)
 {
 	struct rcu_dynticks *rdtp;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	RCU_LOCKDEP_WARN(!irqs_disabled(), "rcu_irq_exit() invoked with irqs enabled!!!");
 	rdtp = this_cpu_ptr(&rcu_dynticks);
 
 	/* Page faults can happen in NMI handlers, so check... */
 	if (rdtp->dynticks_nmi_nesting)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WARN_ON_ONCE(IS_ENABLED(CONFIG_RCU_EQS_DEBUG) &&
 		     rdtp->dynticks_nesting < 1);
 	if (rdtp->dynticks_nesting <= 1) {
@@ -904,6 +976,7 @@ void rcu_irq_exit_irqson(void)
 {
 	unsigned long flags;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	local_irq_save(flags);
 	rcu_irq_exit();
 	local_irq_restore(flags);
@@ -918,6 +991,7 @@ void rcu_irq_exit_irqson(void)
  */
 static void rcu_eqs_exit_common(long long oldval, int user)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	RCU_TRACE(struct rcu_dynticks *rdtp = this_cpu_ptr(&rcu_dynticks);)
 
 	rcu_dynticks_task_exit();
@@ -931,7 +1005,9 @@ static void rcu_eqs_exit_common(long long oldval, int user)
 
 		trace_rcu_dyntick(TPS("Error on exit: not idle task"),
 				  oldval, rdtp->dynticks_nesting);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		rcu_ftrace_dump(DUMP_ORIG);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		WARN_ONCE(1, "Current pid: %d comm: %s / Idle pid: %d comm: %s",
 			  current->pid, current->comm,
 			  idle->pid, idle->comm); /* must be idle task! */
@@ -947,11 +1023,14 @@ static void rcu_eqs_exit(bool user)
 	struct rcu_dynticks *rdtp;
 	long long oldval;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	RCU_LOCKDEP_WARN(!irqs_disabled(), "rcu_eqs_exit() invoked with irqs enabled!!!");
 	rdtp = this_cpu_ptr(&rcu_dynticks);
 	oldval = rdtp->dynticks_nesting;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WARN_ON_ONCE(IS_ENABLED(CONFIG_RCU_EQS_DEBUG) && oldval < 0);
 	if (oldval & DYNTICK_TASK_NEST_MASK) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		rdtp->dynticks_nesting += DYNTICK_TASK_NEST_VALUE;
 	} else {
 		__this_cpu_inc(disable_rcu_irq_enter);
@@ -1018,15 +1097,19 @@ void rcu_irq_enter(void)
 	struct rcu_dynticks *rdtp;
 	long long oldval;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	RCU_LOCKDEP_WARN(!irqs_disabled(), "rcu_irq_enter() invoked with irqs enabled!!!");
 	rdtp = this_cpu_ptr(&rcu_dynticks);
 
 	/* Page faults can happen in NMI handlers, so check... */
 	if (rdtp->dynticks_nmi_nesting)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	oldval = rdtp->dynticks_nesting;
 	rdtp->dynticks_nesting++;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WARN_ON_ONCE(IS_ENABLED(CONFIG_RCU_EQS_DEBUG) &&
 		     rdtp->dynticks_nesting == 0);
 	if (oldval)
@@ -1042,6 +1125,7 @@ void rcu_irq_enter_irqson(void)
 {
 	unsigned long flags;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	local_irq_save(flags);
 	rcu_irq_enter();
 	local_irq_restore(flags);
@@ -1058,6 +1142,7 @@ void rcu_irq_enter_irqson(void)
  */
 void rcu_nmi_enter(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct rcu_dynticks *rdtp = this_cpu_ptr(&rcu_dynticks);
 	int incby = 2;
 
@@ -1090,6 +1175,7 @@ void rcu_nmi_enter(void)
  */
 void rcu_nmi_exit(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct rcu_dynticks *rdtp = this_cpu_ptr(&rcu_dynticks);
 
 	/*
@@ -1147,7 +1233,9 @@ void rcu_request_urgent_qs_task(struct task_struct *t)
 	barrier();
 	cpu = task_cpu(t);
 	if (!task_curr(t))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return; /* This task is not running on that CPU. */
+}
 	smp_store_release(per_cpu_ptr(&rcu_dynticks.rcu_urgent_qs, cpu), true);
 }
 
@@ -1213,6 +1301,7 @@ static int rcu_is_cpu_rrupt_from_idle(void)
  */
 static int dyntick_save_progress_counter(struct rcu_data *rdp)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rdp->dynticks_snap = rcu_dynticks_snap(rdp->dynticks);
 	if (rcu_dynticks_in_eqs(rdp->dynticks_snap)) {
 		trace_rcu_fqs(rdp->rsp->name, rdp->gpnum, rdp->cpu, TPS("dti"));
@@ -1347,6 +1436,7 @@ static void record_gp_stall_check_time(struct rcu_state *rsp)
  */
 static const char *gp_state_getname(short gs)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (gs < 0 || gs >= ARRAY_SIZE(gp_state_names))
 		return "???";
 	return gp_state_names[gs];
@@ -1361,6 +1451,7 @@ static void rcu_check_gp_kthread_starvation(struct rcu_state *rsp)
 	unsigned long j;
 
 	j = jiffies;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	gpa = READ_ONCE(rsp->gp_activity);
 	if (j - gpa > 2 * HZ) {
 		pr_err("%s kthread starved for %ld jiffies! g%lu c%lu f%#x %s(%d) ->state=%#lx ->cpu=%d\n",
@@ -1389,6 +1480,7 @@ static void rcu_dump_cpu_stacks(struct rcu_state *rsp)
 	unsigned long flags;
 	struct rcu_node *rnp;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rcu_for_each_leaf_node(rsp, rnp) {
 		raw_spin_lock_irqsave_rcu_node(rnp, flags);
 		for_each_leaf_node_possible_cpu(rnp, cpu)
@@ -1408,12 +1500,19 @@ static void rcu_stall_kick_kthreads(struct rcu_state *rsp)
 	unsigned long j;
 
 	if (!rcu_kick_kthreads)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	j = READ_ONCE(rsp->jiffies_kick_kthreads);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (time_after(jiffies, j) && rsp->gp_kthread &&
 	    (rcu_gp_in_progress(rsp) || READ_ONCE(rsp->gp_flags))) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		WARN_ONCE(1, "Kicking %s grace-period kthread\n", rsp->name);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		rcu_ftrace_dump(DUMP_ALL);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		wake_up_process(rsp->gp_kthread);
 		WRITE_ONCE(rsp->jiffies_kick_kthreads, j + HZ);
 	}
@@ -1421,6 +1520,7 @@ static void rcu_stall_kick_kthreads(struct rcu_state *rsp)
 
 static inline void panic_on_rcu_stall(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (sysctl_panic_on_rcu_stall)
 		panic("RCU Stall\n");
 }
@@ -1439,7 +1539,9 @@ static void print_other_cpu_stall(struct rcu_state *rsp, unsigned long gpnum)
 	/* Kick and suppress, if so configured. */
 	rcu_stall_kick_kthreads(rsp);
 	if (rcu_cpu_stall_suppress)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	/* Only let one CPU complain about others per time interval. */
 
@@ -1519,7 +1621,9 @@ static void print_cpu_stall(struct rcu_state *rsp)
 	/* Kick and suppress, if so configured. */
 	rcu_stall_kick_kthreads(rsp);
 	if (rcu_cpu_stall_suppress)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	/*
 	 * OK, time to rat on ourselves...
@@ -1593,15 +1697,19 @@ static void check_cpu_stall(struct rcu_state *rsp, struct rcu_data *rdp)
 	 */
 	gpnum = READ_ONCE(rsp->gpnum);
 	smp_rmb(); /* Pick up ->gpnum first... */
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	js = READ_ONCE(rsp->jiffies_stall);
 	smp_rmb(); /* ...then ->jiffies_stall before the rest... */
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	gps = READ_ONCE(rsp->gp_start);
 	smp_rmb(); /* ...and finally ->gp_start before ->completed. */
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	completed = READ_ONCE(rsp->completed);
 	if (ULONG_CMP_GE(completed, gpnum) ||
 	    ULONG_CMP_LT(j, js) ||
 	    ULONG_CMP_GE(gps, js))
 		return; /* No stall or GP completed since entering function. */
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rnp = rdp->mynode;
 	if (rcu_gp_in_progress(rsp) &&
 	    (READ_ONCE(rnp->qsmask) & rdp->grpmask)) {
@@ -1630,6 +1738,7 @@ void rcu_cpu_stall_reset(void)
 {
 	struct rcu_state *rsp;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for_each_rcu_flavor(rsp)
 		WRITE_ONCE(rsp->jiffies_stall, jiffies + ULONG_MAX / 2);
 }
@@ -1646,6 +1755,7 @@ void rcu_cpu_stall_reset(void)
 static unsigned long rcu_cbs_completed(struct rcu_state *rsp,
 				       struct rcu_node *rnp)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&rnp->lock);
 
 	/*
@@ -1672,6 +1782,7 @@ static unsigned long rcu_cbs_completed(struct rcu_state *rsp,
 static void trace_rcu_future_gp(struct rcu_node *rnp, struct rcu_data *rdp,
 				unsigned long c, const char *s)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	trace_rcu_future_grace_period(rdp->rsp->name, rnp->gpnum,
 				      rnp->completed, c, rnp->level,
 				      rnp->grplo, rnp->grphi, s);
@@ -1693,6 +1804,7 @@ rcu_start_future_gp(struct rcu_node *rnp, struct rcu_data *rdp,
 	bool ret = false;
 	struct rcu_node *rnp_root = rcu_get_root(rdp->rsp);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&rnp->lock);
 
 	/*
@@ -1732,7 +1844,9 @@ rcu_start_future_gp(struct rcu_node *rnp, struct rcu_data *rdp,
 	 * start one (if needed).
 	 */
 	if (rnp != rnp_root)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		raw_spin_lock_rcu_node(rnp_root);
+}
 
 	/*
 	 * Get a new grace-period number.  If there really is no grace
@@ -1764,10 +1878,14 @@ rcu_start_future_gp(struct rcu_node *rnp, struct rcu_data *rdp,
 	}
 unlock_out:
 	if (rnp != rnp_root)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		raw_spin_unlock_rcu_node(rnp_root);
+}
 out:
 	if (c_out != NULL)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		*c_out = c;
+}
 	return ret;
 }
 
@@ -1821,11 +1939,14 @@ static bool rcu_accelerate_cbs(struct rcu_state *rsp, struct rcu_node *rnp,
 {
 	bool ret = false;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&rnp->lock);
 
 	/* If no pending (not yet ready to invoke) callbacks, nothing to do. */
 	if (!rcu_segcblist_pend_cbs(&rdp->cblist))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return false;
+}
 
 	/*
 	 * Callbacks are often registered with incomplete grace-period
@@ -1861,11 +1982,14 @@ static bool rcu_accelerate_cbs(struct rcu_state *rsp, struct rcu_node *rnp,
 static bool rcu_advance_cbs(struct rcu_state *rsp, struct rcu_node *rnp,
 			    struct rcu_data *rdp)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&rnp->lock);
 
 	/* If no pending (not yet ready to invoke) callbacks, nothing to do. */
 	if (!rcu_segcblist_pend_cbs(&rdp->cblist))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return false;
+}
 
 	/*
 	 * Find all callbacks whose ->completed numbers indicate that they
@@ -1889,6 +2013,7 @@ static bool __note_gp_changes(struct rcu_state *rsp, struct rcu_node *rnp,
 	bool ret;
 	bool need_gp;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&rnp->lock);
 
 	/* Handle the ends of any preceding grace periods first. */
@@ -1941,11 +2066,16 @@ static void note_gp_changes(struct rcu_state *rsp, struct rcu_data *rdp)
 		local_irq_restore(flags);
 		return;
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	needwake = __note_gp_changes(rsp, rnp, rdp);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	raw_spin_unlock_irqrestore_rcu_node(rnp, flags);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (needwake)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		rcu_gp_kthread_wake(rsp);
 }
+}
 
 static void rcu_gp_slow(struct rcu_state *rsp, int delay)
 {
@@ -2012,8 +2142,11 @@ static bool rcu_gp_init(struct rcu_state *rsp)
 		if (!oldmask != !rnp->qsmaskinit) {
 			if (!oldmask) /* First online CPU for this rcu_node. */
 				rcu_init_new_rnp(rnp);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			else if (rcu_preempt_has_tasks(rnp)) /* blocked tasks */
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				rnp->wait_blkd_tasks = true;
+}
 			else /* Last offline CPU and can propagate. */
 				rcu_cleanup_dead_rnp(rnp);
 		}
@@ -2030,6 +2163,7 @@ static bool rcu_gp_init(struct rcu_state *rsp)
 		if (rnp->wait_blkd_tasks &&
 		    (!rcu_preempt_has_tasks(rnp) ||
 		     rnp->qsmaskinit)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			rnp->wait_blkd_tasks = false;
 			rcu_cleanup_dead_rnp(rnp);
 		}
@@ -2060,6 +2194,7 @@ static bool rcu_gp_init(struct rcu_state *rsp)
 			WRITE_ONCE(rnp->completed, rsp->completed);
 		if (rnp == rdp->mynode)
 			(void)__note_gp_changes(rsp, rnp, rdp);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		rcu_preempt_boost_start_gp(rnp);
 		trace_rcu_grace_period_init(rsp->name, rnp->gpnum,
 					    rnp->level, rnp->grplo,
@@ -2069,6 +2204,7 @@ static bool rcu_gp_init(struct rcu_state *rsp)
 		WRITE_ONCE(rsp->gp_activity, jiffies);
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return true;
 }
 
@@ -2078,17 +2214,23 @@ static bool rcu_gp_init(struct rcu_state *rsp)
  */
 static bool rcu_gp_fqs_check_wake(struct rcu_state *rsp, int *gfp)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct rcu_node *rnp = rcu_get_root(rsp);
 
 	/* Someone like call_rcu() requested a force-quiescent-state scan. */
 	*gfp = READ_ONCE(rsp->gp_flags);
 	if (*gfp & RCU_GP_FLAG_FQS)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return true;
+}
 
 	/* The current grace period has completed. */
 	if (!READ_ONCE(rnp->qsmask) && !rcu_preempt_blocked_readers_cgp(rnp))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return true;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return false;
 }
 
@@ -2097,6 +2239,7 @@ static bool rcu_gp_fqs_check_wake(struct rcu_state *rsp, int *gfp)
  */
 static void rcu_gp_fqs(struct rcu_state *rsp, bool first_time)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct rcu_node *rnp = rcu_get_root(rsp);
 
 	WRITE_ONCE(rsp->gp_activity, jiffies);
@@ -2156,6 +2299,7 @@ static void rcu_gp_cleanup(struct rcu_state *rsp)
 	 */
 	rcu_for_each_node_breadth_first(rsp, rnp) {
 		raw_spin_lock_irq_rcu_node(rnp);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		WARN_ON_ONCE(rcu_preempt_blocked_readers_cgp(rnp));
 		WARN_ON_ONCE(rnp->qsmask);
 		WRITE_ONCE(rnp->completed, rsp->gpnum);
@@ -2171,8 +2315,10 @@ static void rcu_gp_cleanup(struct rcu_state *rsp)
 		WRITE_ONCE(rsp->gp_activity, jiffies);
 		rcu_gp_slow(rsp, gp_cleanup_delay);
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rnp = rcu_get_root(rsp);
 	raw_spin_lock_irq_rcu_node(rnp); /* Order GP before ->completed update. */
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rcu_nocb_gp_set(rnp, nocb);
 
 	/* Declare grace period done. */
@@ -2218,8 +2364,10 @@ static int __noreturn rcu_gp_kthread(void *arg)
 			/* Locking provides needed memory barrier. */
 			if (rcu_gp_init(rsp))
 				break;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			cond_resched_rcu_qs();
 			WRITE_ONCE(rsp->gp_activity, jiffies);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			WARN_ON(signal_pending(current));
 			trace_rcu_grace_period(rsp->name,
 					       READ_ONCE(rsp->gpnum),
@@ -2230,9 +2378,11 @@ static int __noreturn rcu_gp_kthread(void *arg)
 		first_gp_fqs = true;
 		j = jiffies_till_first_fqs;
 		if (j > HZ) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			j = HZ;
 			jiffies_till_first_fqs = HZ;
 		}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ret = 0;
 		for (;;) {
 			if (!ret) {
@@ -2263,14 +2413,17 @@ static int __noreturn rcu_gp_kthread(void *arg)
 				trace_rcu_grace_period(rsp->name,
 						       READ_ONCE(rsp->gpnum),
 						       TPS("fqsend"));
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				cond_resched_rcu_qs();
 				WRITE_ONCE(rsp->gp_activity, jiffies);
 				ret = 0; /* Force full wait till next FQS. */
 				j = jiffies_till_next_fqs;
 				if (j > HZ) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 					j = HZ;
 					jiffies_till_next_fqs = HZ;
 				} else if (j < 1) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 					j = 1;
 					jiffies_till_next_fqs = 1;
 				}
@@ -2278,14 +2431,18 @@ static int __noreturn rcu_gp_kthread(void *arg)
 				/* Deal with stray signal. */
 				cond_resched_rcu_qs();
 				WRITE_ONCE(rsp->gp_activity, jiffies);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				WARN_ON(signal_pending(current));
 				trace_rcu_grace_period(rsp->name,
 						       READ_ONCE(rsp->gpnum),
 						       TPS("fqswaitsig"));
 				ret = 1; /* Keep old FQS timing. */
 				j = jiffies;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				if (time_after(jiffies, rsp->jiffies_force_qs))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 					j = 1;
+}
 				else
 					j = rsp->jiffies_force_qs - j;
 			}
@@ -2313,6 +2470,7 @@ static bool
 rcu_start_gp_advanced(struct rcu_state *rsp, struct rcu_node *rnp,
 		      struct rcu_data *rdp)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&rnp->lock);
 	if (!rsp->gp_kthread || !cpu_needs_another_gp(rsp, rdp)) {
 		/*
@@ -2324,6 +2482,7 @@ rcu_start_gp_advanced(struct rcu_state *rsp, struct rcu_node *rnp,
 		return false;
 	}
 	WRITE_ONCE(rsp->gp_flags, RCU_GP_FLAG_INIT);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	trace_rcu_grace_period(rsp->name, READ_ONCE(rsp->gpnum),
 			       TPS("newreq"));
 
@@ -2375,6 +2534,7 @@ static bool rcu_start_gp(struct rcu_state *rsp)
 static void rcu_report_qs_rsp(struct rcu_state *rsp, unsigned long flags)
 	__releases(rcu_get_root(rsp)->lock)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&rcu_get_root(rsp)->lock);
 	WARN_ON_ONCE(!rcu_gp_in_progress(rsp));
 	WRITE_ONCE(rsp->gp_flags, READ_ONCE(rsp->gp_flags) | RCU_GP_FLAG_FQS);
@@ -2400,6 +2560,7 @@ rcu_report_qs_rnp(unsigned long mask, struct rcu_state *rsp,
 	unsigned long oldmask = 0;
 	struct rcu_node *rnp_c;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&rnp->lock);
 
 	/* Walk up the rcu_node hierarchy. */
@@ -2411,9 +2572,11 @@ rcu_report_qs_rnp(unsigned long mask, struct rcu_state *rsp,
 			 * relevant grace period is already over, so done.
 			 */
 			raw_spin_unlock_irqrestore_rcu_node(rnp, flags);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return;
 		}
 		WARN_ON_ONCE(oldmask); /* Any child must be all zeroed! */
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		WARN_ON_ONCE(rnp->level != rcu_num_lvls - 1 &&
 			     rcu_preempt_blocked_readers_cgp(rnp));
 		rnp->qsmask &= ~mask;
@@ -2425,6 +2588,7 @@ rcu_report_qs_rnp(unsigned long mask, struct rcu_state *rsp,
 
 			/* Other bits still set at this level, so done. */
 			raw_spin_unlock_irqrestore_rcu_node(rnp, flags);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return;
 		}
 		mask = rnp->grpmask;
@@ -2434,10 +2598,14 @@ rcu_report_qs_rnp(unsigned long mask, struct rcu_state *rsp,
 
 			break;
 		}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		raw_spin_unlock_irqrestore_rcu_node(rnp, flags);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		rnp_c = rnp;
 		rnp = rnp->parent;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		raw_spin_lock_irqsave_rcu_node(rnp, flags);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		oldmask = rnp_c->qsmask;
 	}
 
@@ -2464,6 +2632,7 @@ static void rcu_report_unblock_qs_rnp(struct rcu_state *rsp,
 	unsigned long mask;
 	struct rcu_node *rnp_p;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&rnp->lock);
 	if (rcu_state_p == &rcu_sched_state || rsp != rcu_state_p ||
 	    rnp->qsmask != 0 || rcu_preempt_blocked_readers_cgp(rnp)) {
@@ -2513,12 +2682,16 @@ rcu_report_qs_rdp(int cpu, struct rcu_state *rsp, struct rcu_data *rdp)
 		 * within the current grace period.
 		 */
 		rdp->cpu_no_qs.b.norm = true;	/* need qs for new gp. */
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		rdp->rcu_qs_ctr_snap = __this_cpu_read(rcu_dynticks.rcu_qs_ctr);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		raw_spin_unlock_irqrestore_rcu_node(rnp, flags);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
 	}
 	mask = rdp->grpmask;
 	if ((rnp->qsmask & mask) == 0) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		raw_spin_unlock_irqrestore_rcu_node(rnp, flags);
 	} else {
 		rdp->core_needs_qs = false;
@@ -2532,7 +2705,9 @@ rcu_report_qs_rdp(int cpu, struct rcu_state *rsp, struct rcu_data *rdp)
 		rcu_report_qs_rnp(mask, rsp, rnp, rnp->gpnum, flags);
 		/* ^^^ Released rnp->lock */
 		if (needwake)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			rcu_gp_kthread_wake(rsp);
+}
 	}
 }
 
@@ -2553,14 +2728,18 @@ rcu_check_quiescent_state(struct rcu_state *rsp, struct rcu_data *rdp)
 	 * If no, return and let the other CPUs do their part as well.
 	 */
 	if (!rdp->core_needs_qs)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	/*
 	 * Was there a quiescent state since the beginning of the grace
 	 * period? If no, then exit and wait for the next call.
 	 */
 	if (rdp->cpu_no_qs.b.norm)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	/*
 	 * Tell RCU we are done (but rcu_report_qs_rdp() will be the
@@ -2609,6 +2788,7 @@ static void rcu_cleanup_dead_rnp(struct rcu_node *rnp_leaf)
 	long mask;
 	struct rcu_node *rnp = rnp_leaf;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&rnp->lock);
 	if (!IS_ENABLED(CONFIG_HOTPLUG_CPU) ||
 	    rnp->qsmaskinit || rcu_preempt_has_tasks(rnp))
@@ -2638,6 +2818,7 @@ static void rcu_cleanup_dead_rnp(struct rcu_node *rnp_leaf)
  */
 static void rcu_cleanup_dead_cpu(int cpu, struct rcu_state *rsp)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct rcu_data *rdp = per_cpu_ptr(rsp->rda, cpu);
 	struct rcu_node *rnp = rdp->mynode;  /* Outgoing CPU's rdp & rnp. */
 
@@ -2687,9 +2868,12 @@ static void rcu_do_batch(struct rcu_state *rsp, struct rcu_data *rdp)
 	/* Invoke callbacks. */
 	rhp = rcu_cblist_dequeue(&rcl);
 	for (; rhp; rhp = rcu_cblist_dequeue(&rcl)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		debug_rcu_head_unqueue(rhp);
 		if (__rcu_reclaim(rsp->name, rhp))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			rcu_cblist_dequeued_lazy(&rcl);
+}
 		/*
 		 * Stop only if limit reached and CPU has something to do.
 		 * Note: The rcl structure counts down from zero.
@@ -2714,14 +2898,19 @@ static void rcu_do_batch(struct rcu_state *rsp, struct rcu_data *rdp)
 	/* Reinstate batch limit if we have worked down the excess. */
 	count = rcu_segcblist_n_cbs(&rdp->cblist);
 	if (rdp->blimit == LONG_MAX && count <= qlowmark)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		rdp->blimit = blimit;
+}
 
 	/* Reset ->qlen_last_fqs_check trigger if enough CBs have drained. */
 	if (count == 0 && rdp->qlen_last_fqs_check != 0) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		rdp->qlen_last_fqs_check = 0;
 		rdp->n_force_qs_snap = rsp->n_force_qs;
 	} else if (count < rdp->qlen_last_fqs_check - qhimark)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		rdp->qlen_last_fqs_check = count;
+}
 	WARN_ON_ONCE(rcu_segcblist_empty(&rdp->cblist) != (count == 0));
 
 	local_irq_restore(flags);
@@ -2771,6 +2960,7 @@ void rcu_check_callbacks(int user)
 
 		rcu_bh_qs();
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rcu_preempt_check_callbacks();
 	if (rcu_pending())
 		invoke_rcu_core();
@@ -2793,6 +2983,7 @@ static void force_qs_rnp(struct rcu_state *rsp, int (*f)(struct rcu_data *rsp))
 	unsigned long mask;
 	struct rcu_node *rnp;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rcu_for_each_leaf_node(rsp, rnp) {
 		cond_resched_rcu_qs();
 		mask = 0;
@@ -2923,7 +3114,9 @@ static __latent_entropy void rcu_process_callbacks(struct softirq_action *unused
 	struct rcu_state *rsp;
 
 	if (cpu_is_offline(smp_processor_id()))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 	trace_rcu_utilization(TPS("Start RCU core"));
 	for_each_rcu_flavor(rsp)
 		__rcu_process_callbacks(rsp);
@@ -2940,11 +3133,14 @@ static __latent_entropy void rcu_process_callbacks(struct softirq_action *unused
 static void invoke_rcu_callbacks(struct rcu_state *rsp, struct rcu_data *rdp)
 {
 	if (unlikely(!READ_ONCE(rcu_scheduler_fully_active)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 	if (likely(!rsp->boost)) {
 		rcu_do_batch(rsp, rdp);
 		return;
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	invoke_rcu_callbacks_kthread();
 }
 
@@ -2967,11 +3163,15 @@ static void __call_rcu_core(struct rcu_state *rsp, struct rcu_data *rdp,
 	 * core in order to force a re-evaluation of RCU's idleness.
 	 */
 	if (!rcu_is_watching())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		invoke_rcu_core();
+}
 
 	/* If interrupts were disabled or CPU offline, don't invoke RCU core. */
 	if (irqs_disabled_flags(flags) || cpu_is_offline(smp_processor_id()))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	/*
 	 * Force the grace period if too many callbacks or too long waiting.
@@ -2988,19 +3188,25 @@ static void __call_rcu_core(struct rcu_state *rsp, struct rcu_data *rdp,
 
 		/* Start a new grace period if one not already started. */
 		if (!rcu_gp_in_progress(rsp)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			struct rcu_node *rnp_root = rcu_get_root(rsp);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			raw_spin_lock_rcu_node(rnp_root);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			needwake = rcu_start_gp(rsp);
 			raw_spin_unlock_rcu_node(rnp_root);
 			if (needwake)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				rcu_gp_kthread_wake(rsp);
+}
 		} else {
 			/* Give the grace period a kick. */
 			rdp->blimit = LONG_MAX;
 			if (rsp->n_force_qs == rdp->n_force_qs_snap &&
 			    rcu_segcblist_first_pend_cb(&rdp->cblist) != head)
 				force_quiescent_state(rsp);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			rdp->n_force_qs_snap = rsp->n_force_qs;
 			rdp->qlen_last_fqs_check = rcu_segcblist_n_cbs(&rdp->cblist);
 		}
@@ -3051,13 +3257,18 @@ __call_rcu(struct rcu_head *head, rcu_callback_t func,
 		int offline;
 
 		if (cpu != -1)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			rdp = per_cpu_ptr(rsp->rda, cpu);
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (likely(rdp->mynode)) {
 			/* Post-boot, so this should be for a no-CBs CPU. */
 			offline = !__call_rcu_nocb(rdp, head, lazy, flags);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			WARN_ON_ONCE(offline);
 			/* Offline CPU, _call_rcu() illegal, leak callback.  */
 			local_irq_restore(flags);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return;
 		}
 		/*
@@ -3065,14 +3276,20 @@ __call_rcu(struct rcu_head *head, rcu_callback_t func,
 		 * and then drop through to queue the callback.
 		 */
 		BUG_ON(cpu != -1);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		WARN_ON_ONCE(!rcu_is_watching());
 		if (rcu_segcblist_empty(&rdp->cblist))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			rcu_segcblist_init(&rdp->cblist);
+}
 	}
 	rcu_segcblist_enqueue(&rdp->cblist, head, lazy);
 	if (!lazy)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		rcu_idle_count_callbacks_posted();
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (__is_kfree_rcu_offset((unsigned long)func))
 		trace_rcu_kfree_callback(rsp->name, head, (unsigned long)func,
 					 rcu_segcblist_n_lazy_cbs(&rdp->cblist),
@@ -3137,6 +3354,7 @@ EXPORT_SYMBOL_GPL(call_rcu_sched);
  */
 void call_rcu_bh(struct rcu_head *head, rcu_callback_t func)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	__call_rcu(head, func, &rcu_bh_state, -1, 0);
 }
 EXPORT_SYMBOL_GPL(call_rcu_bh);
@@ -3212,14 +3430,20 @@ static inline int rcu_blocking_is_gp(void)
  */
 void synchronize_sched(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	RCU_LOCKDEP_WARN(lock_is_held(&rcu_bh_lock_map) ||
 			 lock_is_held(&rcu_lock_map) ||
 			 lock_is_held(&rcu_sched_lock_map),
 			 "Illegal synchronize_sched() in RCU-sched read-side critical section");
 	if (rcu_blocking_is_gp())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (rcu_gp_is_expedited())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		synchronize_sched_expedited();
+}
 	else
 		wait_rcu_gp(call_rcu_sched);
 }
@@ -3239,6 +3463,7 @@ EXPORT_SYMBOL_GPL(synchronize_sched);
  */
 void synchronize_rcu_bh(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	RCU_LOCKDEP_WARN(lock_is_held(&rcu_bh_lock_map) ||
 			 lock_is_held(&rcu_lock_map) ||
 			 lock_is_held(&rcu_sched_lock_map),
@@ -3374,7 +3599,9 @@ static int __rcu_pending(struct rcu_state *rsp, struct rcu_data *rdp)
 
 	/* Is this CPU a NO_HZ_FULL CPU that should ignore RCU? */
 	if (rcu_nohz_full_cpu(rsp))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	/* Is the RCU core waiting for a quiescent state from this CPU? */
 	if (rcu_scheduler_fully_active &&
@@ -3400,6 +3627,7 @@ static int __rcu_pending(struct rcu_state *rsp, struct rcu_data *rdp)
 
 	/* Has another RCU grace period completed?  */
 	if (READ_ONCE(rnp->completed) != rdp->completed) { /* outside lock */
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		rdp->n_rp_gp_completed++;
 		return 1;
 	}
@@ -3407,12 +3635,14 @@ static int __rcu_pending(struct rcu_state *rsp, struct rcu_data *rdp)
 	/* Has a new RCU grace period started? */
 	if (READ_ONCE(rnp->gpnum) != rdp->gpnum ||
 	    unlikely(READ_ONCE(rdp->gpwrap))) { /* outside lock */
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		rdp->n_rp_gp_started++;
 		return 1;
 	}
 
 	/* Does this CPU need a deferred NOCB wakeup? */
 	if (rcu_nocb_need_deferred_wakeup(rdp)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		rdp->n_rp_nocb_defer_wakeup++;
 		return 1;
 	}
@@ -3433,7 +3663,10 @@ static int rcu_pending(void)
 
 	for_each_rcu_flavor(rsp)
 		if (__rcu_pending(rsp, this_cpu_ptr(rsp->rda)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return 1;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
@@ -3453,14 +3686,18 @@ static bool __maybe_unused rcu_cpu_has_callbacks(bool *all_lazy)
 		rdp = this_cpu_ptr(rsp->rda);
 		if (rcu_segcblist_empty(&rdp->cblist))
 			continue;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		hc = true;
 		if (rcu_segcblist_n_nonlazy_cbs(&rdp->cblist) || !all_lazy) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			al = false;
 			break;
 		}
 	}
 	if (all_lazy)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		*all_lazy = al;
+}
 	return hc;
 }
 
@@ -3481,6 +3718,7 @@ static void _rcu_barrier_trace(struct rcu_state *rsp, const char *s,
  */
 static void rcu_barrier_callback(struct rcu_head *rhp)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct rcu_data *rdp = container_of(rhp, struct rcu_data, barrier_head);
 	struct rcu_state *rsp = rdp->rsp;
 
@@ -3507,6 +3745,7 @@ static void rcu_barrier_func(void *type)
 	if (rcu_segcblist_entrain(&rdp->cblist, &rdp->barrier_head, 0)) {
 		atomic_inc(&rsp->barrier_cpu_count);
 	} else {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		debug_rcu_head_unqueue(&rdp->barrier_head);
 		_rcu_barrier_trace(rsp, TPS("IRQNQ"), -1,
 				   rsp->barrier_sequence);
@@ -3561,6 +3800,7 @@ static void _rcu_barrier(struct rcu_state *rsp)
 			continue;
 		rdp = per_cpu_ptr(rsp->rda, cpu);
 		if (rcu_is_nocb_cpu(cpu)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			if (!rcu_nocb_cpu_needs_barrier(rsp, cpu)) {
 				_rcu_barrier_trace(rsp, TPS("OfflineNoCB"), cpu,
 						   rsp->barrier_sequence);
@@ -3581,6 +3821,7 @@ static void _rcu_barrier(struct rcu_state *rsp)
 					   rsp->barrier_sequence);
 		}
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	put_online_cpus();
 
 	/*
@@ -3588,7 +3829,9 @@ static void _rcu_barrier(struct rcu_state *rsp)
 	 * CPU, and thus each counted, remove the initial count.
 	 */
 	if (atomic_dec_and_test(&rsp->barrier_cpu_count))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		complete(&rsp->barrier_completion);
+}
 
 	/* Wait for all rcu_barrier_callback() callbacks to be invoked. */
 	wait_for_completion(&rsp->barrier_completion);
@@ -3606,6 +3849,7 @@ static void _rcu_barrier(struct rcu_state *rsp)
  */
 void rcu_barrier_bh(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	_rcu_barrier(&rcu_bh_state);
 }
 EXPORT_SYMBOL_GPL(rcu_barrier_bh);
@@ -3630,13 +3874,16 @@ static void rcu_init_new_rnp(struct rcu_node *rnp_leaf)
 	long mask;
 	struct rcu_node *rnp = rnp_leaf;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&rnp->lock);
 	for (;;) {
 		mask = rnp->grpmask;
 		rnp = rnp->parent;
 		if (rnp == NULL)
 			return;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		raw_spin_lock_rcu_node(rnp); /* Interrupts already disabled. */
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		rnp->qsmaskinit |= mask;
 		raw_spin_unlock_rcu_node(rnp); /* Interrupts remain disabled. */
 	}
@@ -3717,6 +3964,7 @@ int rcutree_prepare_cpu(unsigned int cpu)
 	for_each_rcu_flavor(rsp)
 		rcu_init_percpu_data(cpu, rsp);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rcu_prepare_kthreads(cpu);
 	rcu_spawn_all_nocb_kthreads(cpu);
 
@@ -3728,6 +3976,7 @@ int rcutree_prepare_cpu(unsigned int cpu)
  */
 static void rcutree_affinity_setting(unsigned int cpu, int outgoing)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct rcu_data *rdp = per_cpu_ptr(rcu_state_p->rda, cpu);
 
 	rcu_boost_kthread_setaffinity(rdp->mynode, outgoing);
@@ -3739,6 +3988,7 @@ static void rcutree_affinity_setting(unsigned int cpu, int outgoing)
  */
 int rcutree_online_cpu(unsigned int cpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	sync_sched_exp_online_cleanup(cpu);
 	rcutree_affinity_setting(cpu, -1);
 	if (IS_ENABLED(CONFIG_TREE_SRCU))
@@ -3752,6 +4002,7 @@ int rcutree_online_cpu(unsigned int cpu)
  */
 int rcutree_offline_cpu(unsigned int cpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rcutree_affinity_setting(cpu, cpu);
 	if (IS_ENABLED(CONFIG_TREE_SRCU))
 		srcu_offline_cpu(cpu);
@@ -3765,6 +4016,7 @@ int rcutree_dying_cpu(unsigned int cpu)
 {
 	struct rcu_state *rsp;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for_each_rcu_flavor(rsp)
 		rcu_cleanup_dying_cpu(rsp);
 	return 0;
@@ -3777,6 +4029,7 @@ int rcutree_dead_cpu(unsigned int cpu)
 {
 	struct rcu_state *rsp;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for_each_rcu_flavor(rsp) {
 		rcu_cleanup_dead_cpu(cpu, rsp);
 		do_nocb_deferred_wakeup(per_cpu_ptr(rsp->rda, cpu));
@@ -3832,6 +4085,7 @@ static void rcu_cleanup_dying_idle_cpu(int cpu, struct rcu_state *rsp)
 {
 	unsigned long flags;
 	unsigned long mask;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct rcu_data *rdp = per_cpu_ptr(rsp->rda, cpu);
 	struct rcu_node *rnp = rdp->mynode;  /* Outgoing CPU's rdp & rnp. */
 
@@ -3868,6 +4122,7 @@ static void rcu_migrate_callbacks(int cpu, struct rcu_state *rsp)
 {
 	unsigned long flags;
 	struct rcu_data *my_rdp;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct rcu_data *rdp = per_cpu_ptr(rsp->rda, cpu);
 	struct rcu_node *rnp_root = rcu_get_root(rdp->rsp);
 
@@ -3903,6 +4158,7 @@ void rcutree_migrate_callbacks(int cpu)
 {
 	struct rcu_state *rsp;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for_each_rcu_flavor(rsp)
 		rcu_migrate_callbacks(cpu, rsp);
 }
@@ -3915,6 +4171,7 @@ void rcutree_migrate_callbacks(int cpu)
 static int rcu_pm_notify(struct notifier_block *self,
 			 unsigned long action, void *hcpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	switch (action) {
 	case PM_HIBERNATION_PREPARE:
 	case PM_SUSPEND_PREPARE:
@@ -3946,29 +4203,40 @@ static int __init rcu_spawn_gp_kthread(void)
 
 	/* Force priority into range. */
 	if (IS_ENABLED(CONFIG_RCU_BOOST) && kthread_prio < 1)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		kthread_prio = 1;
+}
 	else if (kthread_prio < 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		kthread_prio = 0;
+}
 	else if (kthread_prio > 99)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		kthread_prio = 99;
+}
 	if (kthread_prio != kthread_prio_in)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_alert("rcu_spawn_gp_kthread(): Limited prio to %d from %d\n",
 			 kthread_prio, kthread_prio_in);
+}
 
 	rcu_scheduler_fully_active = 1;
 	for_each_rcu_flavor(rsp) {
 		t = kthread_create(rcu_gp_kthread, rsp, "%s", rsp->name);
 		BUG_ON(IS_ERR(t));
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		rnp = rcu_get_root(rsp);
 		raw_spin_lock_irqsave_rcu_node(rnp, flags);
 		rsp->gp_kthread = t;
 		if (kthread_prio) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			sp.sched_priority = kthread_prio;
 			sched_setscheduler_nocheck(t, SCHED_FIFO, &sp);
 		}
 		raw_spin_unlock_irqrestore_rcu_node(rnp, flags);
 		wake_up_process(t);
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rcu_spawn_nocb_kthreads();
 	rcu_spawn_boost_kthreads();
 	return 0;
@@ -4010,16 +4278,22 @@ static void __init rcu_init_one(struct rcu_state *rsp)
 	int j;
 	struct rcu_node *rnp;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	BUILD_BUG_ON(RCU_NUM_LVLS > ARRAY_SIZE(buf));  /* Fix buf[] init! */
 
 	/* Silence gcc 4.8 false positive about array index out of range. */
 	if (rcu_num_lvls <= 0 || rcu_num_lvls > RCU_NUM_LVLS)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		panic("rcu_init_one: rcu_num_lvls out of range");
+}
 
 	/* Initialize the level-tracking arrays. */
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (i = 1; i < rcu_num_lvls; i++)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		rsp->level[i] = rsp->level[i - 1] + num_rcu_lvl[i - 1];
+}
 	rcu_init_levelspread(levelspread, num_rcu_lvl);
 
 	/* Initialize the elements themselves, starting from the leaves. */
@@ -4029,9 +4303,11 @@ static void __init rcu_init_one(struct rcu_state *rsp)
 		rnp = rsp->level[i];
 		for (j = 0; j < num_rcu_lvl[i]; j++, rnp++) {
 			raw_spin_lock_init(&ACCESS_PRIVATE(rnp, lock));
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			lockdep_set_class_and_name(&ACCESS_PRIVATE(rnp, lock),
 						   &rcu_node_class[i], buf[i]);
 			raw_spin_lock_init(&rnp->fqslock);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			lockdep_set_class_and_name(&rnp->fqslock,
 						   &rcu_fqs_class[i], fqs[i]);
 			rnp->gpnum = rsp->gpnum;
@@ -4041,12 +4317,15 @@ static void __init rcu_init_one(struct rcu_state *rsp)
 			rnp->grplo = j * cpustride;
 			rnp->grphi = (j + 1) * cpustride - 1;
 			if (rnp->grphi >= nr_cpu_ids)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				rnp->grphi = nr_cpu_ids - 1;
+}
 			if (i == 0) {
 				rnp->grpnum = 0;
 				rnp->grpmask = 0;
 				rnp->parent = NULL;
 			} else {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				rnp->grpnum = j % levelspread[i - 1];
 				rnp->grpmask = 1UL << rnp->grpnum;
 				rnp->parent = rsp->level[i - 1] +
@@ -4114,7 +4393,9 @@ static void __init rcu_init_geometry(void)
 	 */
 	if (rcu_fanout_leaf < 2 ||
 	    rcu_fanout_leaf > sizeof(unsigned long) * 8) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		rcu_fanout_leaf = RCU_FANOUT_LEAF;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		WARN_ON(1);
 		return;
 	}
@@ -4132,7 +4413,9 @@ static void __init rcu_init_geometry(void)
 	 * If this limit is exceeded, fall back to the compile-time values.
 	 */
 	if (nr_cpu_ids > rcu_capacity[RCU_NUM_LVLS - 1]) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		rcu_fanout_leaf = RCU_FANOUT_LEAF;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		WARN_ON(1);
 		return;
 	}
@@ -4165,6 +4448,7 @@ static void __init rcu_dump_rcu_node_tree(struct rcu_state *rsp)
 
 	pr_info("rcu_node tree layout dump\n");
 	pr_info(" ");
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rcu_for_each_node_breadth_first(rsp, rnp) {
 		if (rnp->level != level) {
 			pr_cont("\n");
@@ -4187,7 +4471,10 @@ void __init rcu_init(void)
 	rcu_init_one(&rcu_bh_state);
 	rcu_init_one(&rcu_sched_state);
 	if (dump_tree)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		rcu_dump_rcu_node_tree(&rcu_sched_state);
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	__rcu_init_preempt();
 	open_softirq(RCU_SOFTIRQ, rcu_process_callbacks);
 
diff --git a/kernel/rcu/tree_exp.h b/kernel/rcu/tree_exp.h
index 46d61b5..46b699d 100644
--- a/kernel/rcu/tree_exp.h
+++ b/kernel/rcu/tree_exp.h
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * RCU expedited grace periods
  *
diff --git a/kernel/rcu/tree_plugin.h b/kernel/rcu/tree_plugin.h
index fed95fa..3e16ff6 100644
--- a/kernel/rcu/tree_plugin.h
+++ b/kernel/rcu/tree_plugin.h
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * Read-Copy Update mechanism for mutual exclusion (tree-based version)
  * Internal non-public definitions that provide either classic
diff --git a/kernel/rcu/update.c b/kernel/rcu/update.c
index 7a577bd..d09dcda 100644
--- a/kernel/rcu/update.c
+++ b/kernel/rcu/update.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * Read-Copy Update mechanism for mutual exclusion
  *
@@ -147,6 +149,7 @@ static atomic_t rcu_expedited_nesting = ATOMIC_INIT(1);
  */
 bool rcu_gp_is_expedited(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return rcu_expedited || atomic_read(&rcu_expedited_nesting) ||
 	       rcu_scheduler_active == RCU_SCHEDULER_INIT;
 }
@@ -161,6 +164,7 @@ EXPORT_SYMBOL_GPL(rcu_gp_is_expedited);
  */
 void rcu_expedite_gp(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	atomic_inc(&rcu_expedited_nesting);
 }
 EXPORT_SYMBOL_GPL(rcu_expedite_gp);
@@ -176,6 +180,7 @@ EXPORT_SYMBOL_GPL(rcu_expedite_gp);
  */
 void rcu_unexpedite_gp(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	atomic_dec(&rcu_expedited_nesting);
 }
 EXPORT_SYMBOL_GPL(rcu_unexpedite_gp);
@@ -199,8 +204,12 @@ void rcu_end_inkernel_boot(void)
  */
 void rcu_test_sync_prims(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!IS_ENABLED(CONFIG_PROVE_RCU))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	synchronize_rcu();
 	synchronize_rcu_bh();
 	synchronize_sched();
@@ -216,6 +225,7 @@ void rcu_test_sync_prims(void)
  */
 static int __init rcu_set_runtime_mode(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rcu_test_sync_prims();
 	rcu_scheduler_active = RCU_SCHEDULER_RUNNING;
 	rcu_test_sync_prims();
@@ -372,6 +382,7 @@ void wakeme_after_rcu(struct rcu_head *head)
 {
 	struct rcu_synchronize *rcu;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rcu = container_of(head, struct rcu_synchronize, head);
 	complete(&rcu->completion);
 }
@@ -479,6 +490,7 @@ void do_trace_rcu_torture_read(const char *rcutorturename, struct rcu_head *rhp,
 			       unsigned long secs,
 			       unsigned long c_old, unsigned long c)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	trace_rcu_torture_read(rcutorturename, rhp, secs, c_old, c);
 }
 EXPORT_SYMBOL_GPL(do_trace_rcu_torture_read);
@@ -521,18 +533,21 @@ int rcu_jiffies_till_stall_check(void)
 
 void rcu_sysrq_start(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!rcu_cpu_stall_suppress)
 		rcu_cpu_stall_suppress = 2;
 }
 
 void rcu_sysrq_end(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (rcu_cpu_stall_suppress == 2)
 		rcu_cpu_stall_suppress = 0;
 }
 
 static int rcu_panic(struct notifier_block *this, unsigned long ev, void *ptr)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rcu_cpu_stall_suppress = 1;
 	return NOTIFY_DONE;
 }
@@ -1005,15 +1020,26 @@ void rcu_early_boot_tests(void) {}
 void __init rcupdate_announce_bootup_oddness(void)
 {
 	if (rcu_normal)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_info("\tNo expedited grace period (rcu_normal).\n");
+}
 	else if (rcu_normal_after_boot)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_info("\tNo expedited grace period (rcu_normal_after_boot).\n");
+}
 	else if (rcu_expedited)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_info("\tAll grace periods are expedited (rcu_expedited).\n");
+}
 	if (rcu_cpu_stall_suppress)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_info("\tRCU CPU stall warnings suppressed (rcu_cpu_stall_suppress).\n");
+}
 	if (rcu_cpu_stall_timeout != CONFIG_RCU_CPU_STALL_TIMEOUT)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_info("\tRCU CPU stall warnings timeout set to %d (rcu_cpu_stall_timeout).\n", rcu_cpu_stall_timeout);
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rcu_tasks_bootup_oddness();
 }
 
diff --git a/kernel/reboot.c b/kernel/reboot.c
index bd30a97..bdd3ee2 100644
--- a/kernel/reboot.c
+++ b/kernel/reboot.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  *  linux/kernel/reboot.c
  *
@@ -60,6 +62,7 @@ void (*pm_power_off_prepare)(void);
  */
 void emergency_restart(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	kmsg_dump(KMSG_DUMP_EMERG);
 	machine_emergency_restart();
 }
@@ -67,6 +70,7 @@ EXPORT_SYMBOL_GPL(emergency_restart);
 
 void kernel_restart_prepare(char *cmd)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	blocking_notifier_call_chain(&reboot_notifier_list, SYS_RESTART, cmd);
 	system_state = SYSTEM_RESTART;
 	usermodehelper_disable();
@@ -100,6 +104,7 @@ EXPORT_SYMBOL(register_reboot_notifier);
  */
 int unregister_reboot_notifier(struct notifier_block *nb)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return blocking_notifier_chain_unregister(&reboot_notifier_list, nb);
 }
 EXPORT_SYMBOL(unregister_reboot_notifier);
@@ -150,6 +155,7 @@ static ATOMIC_NOTIFIER_HEAD(restart_handler_list);
  */
 int register_restart_handler(struct notifier_block *nb)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return atomic_notifier_chain_register(&restart_handler_list, nb);
 }
 EXPORT_SYMBOL(register_restart_handler);
@@ -165,6 +171,7 @@ EXPORT_SYMBOL(register_restart_handler);
  */
 int unregister_restart_handler(struct notifier_block *nb)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return atomic_notifier_chain_unregister(&restart_handler_list, nb);
 }
 EXPORT_SYMBOL(unregister_restart_handler);
@@ -182,6 +189,7 @@ EXPORT_SYMBOL(unregister_restart_handler);
  */
 void do_kernel_restart(char *cmd)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	atomic_notifier_call_chain(&restart_handler_list, reboot_mode, cmd);
 }
 
@@ -194,7 +202,9 @@ void migrate_to_reboot_cpu(void)
 
 	/* Make certain the cpu I'm about to reboot on is online */
 	if (!cpu_online(cpu))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		cpu = cpumask_first(cpu_online_mask);
+}
 
 	/* Prevent races with other tasks migrating this task */
 	current->flags |= PF_NO_SETAFFINITY;
@@ -213,6 +223,7 @@ void migrate_to_reboot_cpu(void)
  */
 void kernel_restart(char *cmd)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	kernel_restart_prepare(cmd);
 	migrate_to_reboot_cpu();
 	syscore_shutdown();
@@ -240,6 +251,7 @@ static void kernel_shutdown_prepare(enum system_states state)
  */
 void kernel_halt(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	kernel_shutdown_prepare(SYSTEM_HALT);
 	migrate_to_reboot_cpu();
 	syscore_shutdown();
@@ -256,6 +268,7 @@ EXPORT_SYMBOL_GPL(kernel_halt);
  */
 void kernel_power_off(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	kernel_shutdown_prepare(SYSTEM_POWER_OFF);
 	if (pm_power_off_prepare)
 		pm_power_off_prepare();
@@ -286,7 +299,9 @@ SYSCALL_DEFINE4(reboot, int, magic1, int, magic2, unsigned int, cmd,
 
 	/* We only trust the superuser with rebooting the system. */
 	if (!ns_capable(pid_ns->user_ns, CAP_SYS_BOOT))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EPERM;
+}
 
 	/* For safety, we require "magic" arguments. */
 	if (magic1 != LINUX_REBOOT_MAGIC1 ||
@@ -309,7 +324,9 @@ SYSCALL_DEFINE4(reboot, int, magic1, int, magic2, unsigned int, cmd,
 	 * halt when pm_power_off is not set do it the easy way.
 	 */
 	if ((cmd == LINUX_REBOOT_CMD_POWER_OFF) && !pm_power_off)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		cmd = LINUX_REBOOT_CMD_HALT;
+}
 
 	mutex_lock(&reboot_mutex);
 	switch (cmd) {
@@ -328,6 +345,7 @@ SYSCALL_DEFINE4(reboot, int, magic1, int, magic2, unsigned int, cmd,
 	case LINUX_REBOOT_CMD_HALT:
 		kernel_halt();
 		do_exit(0);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		panic("cannot halt");
 
 	case LINUX_REBOOT_CMD_POWER_OFF:
@@ -338,9 +356,11 @@ SYSCALL_DEFINE4(reboot, int, magic1, int, magic2, unsigned int, cmd,
 	case LINUX_REBOOT_CMD_RESTART2:
 		ret = strncpy_from_user(&buffer[0], arg, sizeof(buffer) - 1);
 		if (ret < 0) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			ret = -EFAULT;
 			break;
 		}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		buffer[sizeof(buffer) - 1] = '\0';
 
 		kernel_restart(buffer);
@@ -368,6 +388,7 @@ SYSCALL_DEFINE4(reboot, int, magic1, int, magic2, unsigned int, cmd,
 
 static void deferred_cad(struct work_struct *dummy)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	kernel_restart(NULL);
 }
 
@@ -381,7 +402,9 @@ void ctrl_alt_del(void)
 	static DECLARE_WORK(cad_work, deferred_cad);
 
 	if (C_A_D)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		schedule_work(&cad_work);
+}
 	else
 		kill_cad_pid(SIGINT, 1);
 }
@@ -400,6 +423,7 @@ static int run_cmd(const char *cmd)
 	int ret;
 	argv = argv_split(GFP_KERNEL, cmd, NULL);
 	if (argv) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ret = call_usermodehelper(argv[0], argv, envp, UMH_WAIT_EXEC);
 		argv_free(argv);
 	} else {
@@ -416,6 +440,7 @@ static int __orderly_reboot(void)
 	ret = run_cmd(reboot_cmd);
 
 	if (ret) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_warn("Failed to start orderly reboot: forcing the issue\n");
 		emergency_sync();
 		kernel_restart(NULL);
@@ -430,6 +455,7 @@ static int __orderly_poweroff(bool force)
 
 	ret = run_cmd(poweroff_cmd);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (ret && force) {
 		pr_warn("Failed to start orderly shutdown: forcing the issue\n");
 
@@ -449,6 +475,7 @@ static bool poweroff_force;
 
 static void poweroff_work_func(struct work_struct *work)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	__orderly_poweroff(poweroff_force);
 }
 
@@ -463,6 +490,7 @@ static DECLARE_WORK(poweroff_work, poweroff_work_func);
  */
 void orderly_poweroff(bool force)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (force) /* do not override the pending "true" */
 		poweroff_force = true;
 	schedule_work(&poweroff_work);
@@ -471,6 +499,7 @@ EXPORT_SYMBOL_GPL(orderly_poweroff);
 
 static void reboot_work_func(struct work_struct *work)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	__orderly_reboot();
 }
 
@@ -484,6 +513,7 @@ static DECLARE_WORK(reboot_work, reboot_work_func);
  */
 void orderly_reboot(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	schedule_work(&reboot_work);
 }
 EXPORT_SYMBOL_GPL(orderly_reboot);
diff --git a/kernel/resource.c b/kernel/resource.c
index 9b5f044..0b26fcc 100644
--- a/kernel/resource.c
+++ b/kernel/resource.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  *	linux/kernel/resource.c
  *
@@ -67,9 +69,12 @@ static struct resource *next_resource(struct resource *p, bool sibling_only)
 		return p->sibling;
 
 	if (p->child)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return p->child;
+}
 	while (!p->sibling && p->parent)
 		p = p->parent;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return p->sibling;
 }
 
@@ -90,6 +95,7 @@ static void *r_start(struct seq_file *m, loff_t *pos)
 	struct resource *p = m->private;
 	loff_t l = 0;
 	read_lock(&resource_lock);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (p = p->child; p && l < *pos; p = r_next(m, p, &l))
 		;
 	return p;
@@ -98,6 +104,7 @@ static void *r_start(struct seq_file *m, loff_t *pos)
 static void r_stop(struct seq_file *m, void *v)
 	__releases(resource_lock)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	read_unlock(&resource_lock);
 }
 
@@ -106,6 +113,7 @@ static int r_show(struct seq_file *m, void *v)
 	struct resource *root = m->private;
 	struct resource *r = v, *p;
 	unsigned long long start, end;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	int width = root->end < 0x10000 ? 4 : 8;
 	int depth;
 
@@ -137,6 +145,7 @@ static const struct seq_operations resource_op = {
 
 static int ioports_open(struct inode *inode, struct file *file)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	int res = seq_open(file, &resource_op);
 	if (!res) {
 		struct seq_file *m = file->private_data;
@@ -147,6 +156,7 @@ static int ioports_open(struct inode *inode, struct file *file)
 
 static int iomem_open(struct inode *inode, struct file *file)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	int res = seq_open(file, &resource_op);
 	if (!res) {
 		struct seq_file *m = file->private_data;
@@ -182,9 +192,12 @@ __initcall(ioresources_init);
 static void free_resource(struct resource *res)
 {
 	if (!res)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	if (!PageSlab(virt_to_head_page(res))) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		spin_lock(&bootmem_resource_lock);
 		res->sibling = bootmem_resource_free;
 		bootmem_resource_free = res;
@@ -200,13 +213,17 @@ static struct resource *alloc_resource(gfp_t flags)
 
 	spin_lock(&bootmem_resource_lock);
 	if (bootmem_resource_free) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		res = bootmem_resource_free;
 		bootmem_resource_free = res->sibling;
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_unlock(&bootmem_resource_lock);
 
 	if (res)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		memset(res, 0, sizeof(struct resource));
+}
 	else
 		res = kzalloc(sizeof(struct resource), flags);
 
@@ -221,11 +238,17 @@ static struct resource * __request_resource(struct resource *root, struct resour
 	struct resource *tmp, **p;
 
 	if (end < start)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return root;
+}
 	if (start < root->start)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return root;
+}
 	if (end > root->end)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return root;
+}
 	p = &root->child;
 	for (;;) {
 		tmp = *p;
@@ -238,6 +261,7 @@ static struct resource * __request_resource(struct resource *root, struct resour
 		p = &tmp->sibling;
 		if (tmp->end < start)
 			continue;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return tmp;
 	}
 }
@@ -255,11 +279,14 @@ static int __release_resource(struct resource *old, bool release_child)
 			if (release_child || !(tmp->child)) {
 				*p = tmp->sibling;
 			} else {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				for (chd = tmp->child;; chd = chd->sibling) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 					chd->parent = tmp->parent;
 					if (!(chd->sibling))
 						break;
 				}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				*p = tmp->child;
 				chd->sibling = tmp->sibling;
 			}
@@ -268,6 +295,7 @@ static int __release_resource(struct resource *old, bool release_child)
 		}
 		p = &tmp->sibling;
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return -EINVAL;
 }
 
@@ -278,6 +306,7 @@ static void __release_child_resources(struct resource *r)
 
 	p = r->child;
 	r->child = NULL;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	while (p) {
 		tmp = p;
 		p = p->sibling;
@@ -296,6 +325,7 @@ static void __release_child_resources(struct resource *r)
 
 void release_child_resources(struct resource *r)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	write_lock(&resource_lock);
 	__release_child_resources(r);
 	write_unlock(&resource_lock);
@@ -372,7 +402,9 @@ static int find_next_iomem_res(struct resource *res, unsigned long desc,
 	BUG_ON(start >= end);
 
 	if (first_level_children_only)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		sibling_only = true;
+}
 
 	read_lock(&resource_lock);
 
@@ -382,6 +414,7 @@ static int find_next_iomem_res(struct resource *res, unsigned long desc,
 		if ((desc != IORES_DESC_NONE) && (desc != p->desc))
 			continue;
 		if (p->start > end) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			p = NULL;
 			break;
 		}
@@ -389,14 +422,18 @@ static int find_next_iomem_res(struct resource *res, unsigned long desc,
 			break;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	read_unlock(&resource_lock);
 	if (!p)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -1;
+}
 	/* copy data */
 	if (res->start < p->start)
 		res->start = p->start;
 	if (res->end > p->end)
 		res->end = p->end;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
@@ -426,6 +463,7 @@ int walk_iomem_res_desc(unsigned long desc, unsigned long flags, u64 start,
 	res.flags = flags;
 	orig_end = res.end;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	while ((res.start < res.end) &&
 		(!find_next_iomem_res(&res, desc, false))) {
 
@@ -458,6 +496,7 @@ int walk_system_ram_res(u64 start, u64 end, void *arg,
 	res.end = end;
 	res.flags = IORESOURCE_SYSTEM_RAM | IORESOURCE_BUSY;
 	orig_end = res.end;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	while ((res.start < res.end) &&
 		(!find_next_iomem_res(&res, IORES_DESC_NONE, true))) {
 		ret = (*func)(res.start, res.end, arg);
@@ -506,6 +545,7 @@ int walk_system_ram_range(unsigned long start_pfn, unsigned long nr_pages,
 
 static int __is_ram(unsigned long pfn, unsigned long nr_pages, void *arg)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 1;
 }
 /*
@@ -556,15 +596,22 @@ int region_intersects(resource_size_t start, size_t size, unsigned long flags,
 		if (end >= p->start && end <= p->end)
 			is_type ? type++ : other++;
 		if (p->start >= start && p->end <= end)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			is_type ? type++ : other++;
+}
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	read_unlock(&resource_lock);
 
 	if (other == 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return type ? REGION_INTERSECTS : REGION_DISJOINT;
+}
 
 	if (type)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return REGION_MIXED;
+}
 
 	return REGION_DISJOINT;
 }
@@ -579,12 +626,14 @@ static resource_size_t simple_align_resource(void *data,
 					     resource_size_t size,
 					     resource_size_t align)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return avail->start;
 }
 
 static void resource_clip(struct resource *res, resource_size_t min,
 			  resource_size_t max)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (res->start < min)
 		res->start = min;
 	if (res->end > max)
@@ -657,6 +706,7 @@ static int find_resource(struct resource *root, struct resource *new,
 			resource_size_t size,
 			struct resource_constraint  *constraint)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return  __find_resource(root, NULL, new, size, constraint);
 }
 
@@ -683,6 +733,7 @@ static int reallocate_resource(struct resource *root, struct resource *old,
 	if ((err = __find_resource(root, old, &new, newsize, constraint)))
 		goto out;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (resource_contains(&new, old)) {
 		old->start = new.start;
 		old->end = new.end;
@@ -734,7 +785,9 @@ int allocate_resource(struct resource *root, struct resource *new,
 	struct resource_constraint constraint;
 
 	if (!alignf)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		alignf = simple_align_resource;
+}
 
 	constraint.min = min;
 	constraint.max = max;
@@ -770,6 +823,7 @@ struct resource *lookup_resource(struct resource *root, resource_size_t start)
 	struct resource *res;
 
 	read_lock(&resource_lock);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (res = root->child; res; res = res->sibling) {
 		if (res->start == start)
 			break;
@@ -787,15 +841,22 @@ static struct resource * __insert_resource(struct resource *parent, struct resou
 {
 	struct resource *first, *next;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (;; parent = first) {
 		first = __request_resource(parent, new);
 		if (!first)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return first;
+}
 
 		if (first == parent)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return first;
+}
 		if (WARN_ON(first == new))	/* duplicated insertion */
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return first;
+}
 
 		if ((first->start > new->start) || (first->end < new->end))
 			break;
@@ -803,10 +864,13 @@ static struct resource * __insert_resource(struct resource *parent, struct resou
 			break;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (next = first; ; next = next->sibling) {
 		/* Partial overlap? Bad, and unfixable */
 		if (next->start < new->start || next->end > new->end)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return next;
+}
 		if (!next->sibling)
 			break;
 		if (next->sibling->start > new->end)
@@ -824,11 +888,13 @@ static struct resource * __insert_resource(struct resource *parent, struct resou
 	if (parent->child == first) {
 		parent->child = new;
 	} else {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		next = parent->child;
 		while (next->sibling != first)
 			next = next->sibling;
 		next->sibling = new;
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return NULL;
 }
 
@@ -888,7 +954,9 @@ EXPORT_SYMBOL_GPL(insert_resource);
 void insert_resource_expand_to_fit(struct resource *root, struct resource *new)
 {
 	if (new->parent)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	write_lock(&resource_lock);
 	for (;;) {
@@ -897,17 +965,25 @@ void insert_resource_expand_to_fit(struct resource *root, struct resource *new)
 		conflict = __insert_resource(root, new);
 		if (!conflict)
 			break;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (conflict == root)
 			break;
 
 		/* Ok, expand resource to cover the conflict, then try again .. */
 		if (conflict->start < new->start)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			new->start = conflict->start;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (conflict->end > new->end)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			new->end = conflict->end;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		printk("Expanded resource %s due to conflict with %s\n", new->name, conflict->name);
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	write_unlock(&resource_lock);
 }
 
@@ -947,6 +1023,7 @@ static int __adjust_resource(struct resource *res, resource_size_t start,
 	if (!parent)
 		goto skip;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if ((start < parent->start) || (end > parent->end))
 		goto out;
 
@@ -1006,7 +1083,9 @@ static void __init __reserve_region_with_split(struct resource *root,
 	struct resource *next_res = NULL;
 
 	if (!res)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	res->name = name;
 	res->start = start;
@@ -1014,12 +1093,15 @@ static void __init __reserve_region_with_split(struct resource *root,
 	res->flags = IORESOURCE_BUSY;
 	res->desc = IORES_DESC_NONE;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	while (1) {
 
 		conflict = __request_resource(parent, res);
 		if (!conflict) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			if (!next_res)
 				break;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			res = next_res;
 			next_res = NULL;
 			continue;
@@ -1035,14 +1117,18 @@ static void __init __reserve_region_with_split(struct resource *root,
 
 		/* failed, split and try again */
 		if (conflict->start > res->start) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			end = res->end;
 			res->end = conflict->start - 1;
 			if (conflict->end < end) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				next_res = alloc_resource(GFP_ATOMIC);
 				if (!next_res) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 					free_resource(res);
 					break;
 				}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				next_res->name = name;
 				next_res->start = conflict->end + 1;
 				next_res->end = end;
@@ -1050,6 +1136,7 @@ static void __init __reserve_region_with_split(struct resource *root,
 				next_res->desc = IORES_DESC_NONE;
 			}
 		} else {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			res->start = conflict->end + 1;
 		}
 	}
@@ -1064,24 +1151,37 @@ void __init reserve_region_with_split(struct resource *root,
 
 	write_lock(&resource_lock);
 	if (root->start > start || root->end < end) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_err("requested range [0x%llx-0x%llx] not in root %pr\n",
 		       (unsigned long long)start, (unsigned long long)end,
 		       root);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (start > root->end || end < root->start)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			abort = 1;
+}
 		else {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			if (end > root->end)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				end = root->end;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			if (start < root->start)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				start = root->start;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			pr_err("fixing request to [0x%llx-0x%llx]\n",
 			       (unsigned long long)start,
 			       (unsigned long long)end);
 		}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		dump_stack();
 	}
 	if (!abort)
 		__reserve_region_with_split(root, start, end, name);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	write_unlock(&resource_lock);
 }
 
@@ -1093,6 +1193,7 @@ void __init reserve_region_with_split(struct resource *root,
  */
 resource_size_t resource_alignment(struct resource *res)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	switch (res->flags & (IORESOURCE_SIZEALIGN | IORESOURCE_STARTALIGN)) {
 	case IORESOURCE_SIZEALIGN:
 		return resource_size(res);
@@ -1132,7 +1233,9 @@ struct resource * __request_region(struct resource *parent,
 	struct resource *res = alloc_resource(GFP_KERNEL);
 
 	if (!res)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 
 	res->name = name;
 	res->start = start;
@@ -1152,14 +1255,19 @@ struct resource * __request_region(struct resource *parent,
 			break;
 		if (conflict != parent) {
 			if (!(conflict->flags & IORESOURCE_BUSY)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				parent = conflict;
 				continue;
 			}
 		}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (conflict->flags & flags & IORESOURCE_MUXED) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			add_wait_queue(&muxed_resource_wait, &wait);
 			write_unlock(&resource_lock);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			set_current_state(TASK_UNINTERRUPTIBLE);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			schedule();
 			remove_wait_queue(&muxed_resource_wait, &wait);
 			write_lock(&resource_lock);
@@ -1170,6 +1278,7 @@ struct resource * __request_region(struct resource *parent,
 		res = NULL;
 		break;
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	write_unlock(&resource_lock);
 	return res;
 }
@@ -1209,13 +1318,16 @@ void __release_region(struct resource *parent, resource_size_t start,
 			*p = res->sibling;
 			write_unlock(&resource_lock);
 			if (res->flags & IORESOURCE_MUXED)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				wake_up(&muxed_resource_wait);
+}
 			free_resource(res);
 			return;
 		}
 		p = &res->sibling;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	write_unlock(&resource_lock);
 
 	printk(KERN_WARNING "Trying to free nonexistent resource "
@@ -1363,7 +1475,9 @@ int devm_request_resource(struct device *dev, struct resource *root,
 
 	ptr = devres_alloc(devm_resource_release, sizeof(*ptr), GFP_KERNEL);
 	if (!ptr)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 
 	*ptr = new;
 
@@ -1396,6 +1510,7 @@ static int devm_resource_match(struct device *dev, void *res, void *data)
  */
 void devm_release_resource(struct device *dev, struct resource *new)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WARN_ON(devres_release(dev, devm_resource_release, devm_resource_match,
 			       new));
 }
@@ -1418,6 +1533,7 @@ static int devm_region_match(struct device *dev, void *res, void *match_data)
 {
 	struct region_devres *this = res, *match = match_data;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return this->parent == match->parent &&
 		this->start == match->start && this->n == match->n;
 }
@@ -1432,7 +1548,9 @@ struct resource * __devm_request_region(struct device *dev,
 	dr = devres_alloc(devm_region_release, sizeof(struct region_devres),
 			  GFP_KERNEL);
 	if (!dr)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 
 	dr->parent = parent;
 	dr->start = start;
@@ -1454,6 +1572,7 @@ void __devm_release_region(struct device *dev, struct resource *parent,
 	struct region_devres match_data = { parent, start, n };
 
 	__release_region(parent, start, n);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WARN_ON(devres_destroy(dev, devm_region_release, devm_region_match,
 			       &match_data));
 }
@@ -1474,6 +1593,7 @@ static int __init reserve_setup(char *str)
 
 		if (get_option (&str, &io_start) != 2)
 			break;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (get_option (&str, &io_num)   == 0)
 			break;
 		if (x < MAXRESERVE) {
@@ -1525,6 +1645,7 @@ int iomem_map_sanity_check(resource_size_t addr, unsigned long size)
 		if (p->flags & IORESOURCE_BUSY)
 			continue;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		printk(KERN_WARNING "resource sanity check: requesting [mem %#010llx-%#010llx], which spans more than %s %pR\n",
 		       (unsigned long long)addr,
 		       (unsigned long long)(addr + size - 1),
@@ -1532,6 +1653,7 @@ int iomem_map_sanity_check(resource_size_t addr, unsigned long size)
 		err = -1;
 		break;
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	read_unlock(&resource_lock);
 
 	return err;
@@ -1555,7 +1677,9 @@ int iomem_is_exclusive(u64 addr)
 	int size = PAGE_SIZE;
 
 	if (!strict_iomem_checks)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	addr = addr & PAGE_MASK;
 
@@ -1613,6 +1737,7 @@ EXPORT_SYMBOL(resource_list_free);
 
 static int __init strict_iomem(char *str)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (strstr(str, "relaxed"))
 		strict_iomem_checks = 0;
 	if (strstr(str, "strict"))
diff --git a/kernel/sched/autogroup.c b/kernel/sched/autogroup.c
index a43df51..c565427 100644
--- a/kernel/sched/autogroup.c
+++ b/kernel/sched/autogroup.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 #include "sched.h"
 
diff --git a/kernel/sched/autogroup.h b/kernel/sched/autogroup.h
index 27cd22b..591e579 100644
--- a/kernel/sched/autogroup.h
+++ b/kernel/sched/autogroup.h
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /* SPDX-License-Identifier: GPL-2.0 */
 #ifdef CONFIG_SCHED_AUTOGROUP
 
diff --git a/kernel/sched/clock.c b/kernel/sched/clock.c
index ca0f8fc..f189c90 100644
--- a/kernel/sched/clock.c
+++ b/kernel/sched/clock.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * sched_clock for unstable cpu clocks
  *
@@ -73,6 +75,7 @@
  */
 unsigned long long __weak sched_clock(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return (unsigned long long)(jiffies - INITIAL_JIFFIES)
 					* (NSEC_PER_SEC / HZ);
 }
@@ -140,6 +143,7 @@ static void __set_sched_clock_stable(void)
 	 * to disable IRQs in order to get a consistent scd->tick* reading.
 	 */
 	local_irq_disable();
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	scd = this_scd();
 	/*
 	 * Attempt to make the (initial) unstable->stable transition continuous.
@@ -194,6 +198,7 @@ static DECLARE_WORK(sched_clock_work, __sched_clock_work);
 
 static void __clear_sched_clock_stable(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!sched_clock_stable())
 		return;
 
@@ -203,6 +208,7 @@ static void __clear_sched_clock_stable(void)
 
 void clear_sched_clock_stable(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	__sched_clock_stable_early = 0;
 
 	smp_mb(); /* matches sched_clock_init_late() */
@@ -263,7 +269,9 @@ static u64 sched_clock_local(struct sched_clock_data *scd)
 	now = sched_clock();
 	delta = now - scd->tick_raw;
 	if (unlikely(delta < 0))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		delta = 0;
+}
 
 	old_clock = scd->clock;
 
@@ -289,6 +297,7 @@ static u64 sched_clock_local(struct sched_clock_data *scd)
 
 static u64 sched_clock_remote(struct sched_clock_data *scd)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct sched_clock_data *my_scd = this_scd();
 	u64 this_clock, remote_clock;
 	u64 *ptr, old_val, val;
@@ -363,13 +372,17 @@ u64 sched_clock_cpu(int cpu)
 		return sched_clock() + __sched_clock_offset;
 
 	if (unlikely(!sched_clock_running))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0ull;
+}
 
 	preempt_disable_notrace();
 	scd = cpu_sdc(cpu);
 
 	if (cpu != smp_processor_id())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		clock = sched_clock_remote(scd);
+}
 	else
 		clock = sched_clock_local(scd);
 	preempt_enable_notrace();
@@ -383,10 +396,14 @@ void sched_clock_tick(void)
 	struct sched_clock_data *scd;
 
 	if (sched_clock_stable())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	if (unlikely(!sched_clock_running))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	WARN_ON_ONCE(!irqs_disabled());
 
@@ -400,7 +417,9 @@ void sched_clock_tick_stable(void)
 	u64 gtod, clock;
 
 	if (!sched_clock_stable())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	/*
 	 * Called under watchdog_lock.
@@ -410,6 +429,7 @@ void sched_clock_tick_stable(void)
 	 * TSC to be unstable, any computation will be computing crap.
 	 */
 	local_irq_disable();
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	gtod = ktime_get_ns();
 	clock = sched_clock();
 	__gtod_offset = (clock + __sched_clock_offset) - gtod;
@@ -433,10 +453,14 @@ void sched_clock_idle_wakeup_event(void)
 	unsigned long flags;
 
 	if (sched_clock_stable())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	if (unlikely(timekeeping_suspended))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	local_irq_save(flags);
 	sched_clock_tick();
diff --git a/kernel/sched/completion.c b/kernel/sched/completion.c
index 2ddaec4..7bdefed 100644
--- a/kernel/sched/completion.c
+++ b/kernel/sched/completion.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 /*
  * Generic wait-for-completion handler;
@@ -83,17 +85,22 @@ do_wait_for_common(struct completion *x,
 		__add_wait_queue_entry_tail_exclusive(&x->wait, &wait);
 		do {
 			if (signal_pending_state(state, current)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				timeout = -ERESTARTSYS;
 				break;
 			}
 			__set_current_state(state);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			spin_unlock_irq(&x->wait.lock);
 			timeout = action(timeout);
 			spin_lock_irq(&x->wait.lock);
 		} while (!x->done && timeout);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		__remove_wait_queue(&x->wait, &wait);
 		if (!x->done)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return timeout;
+}
 	}
 	if (x->done != UINT_MAX)
 		x->done--;
@@ -106,6 +113,7 @@ __wait_for_common(struct completion *x,
 {
 	might_sleep();
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	complete_acquire(x);
 
 	spin_lock_irq(&x->wait.lock);
@@ -174,6 +182,7 @@ EXPORT_SYMBOL(wait_for_completion_timeout);
  */
 void __sched wait_for_completion_io(struct completion *x)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	wait_for_common_io(x, MAX_SCHEDULE_TIMEOUT, TASK_UNINTERRUPTIBLE);
 }
 EXPORT_SYMBOL(wait_for_completion_io);
@@ -211,7 +220,10 @@ int __sched wait_for_completion_interruptible(struct completion *x)
 {
 	long t = wait_for_common(x, MAX_SCHEDULE_TIMEOUT, TASK_INTERRUPTIBLE);
 	if (t == -ERESTARTSYS)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return t;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 EXPORT_SYMBOL(wait_for_completion_interruptible);
@@ -231,6 +243,7 @@ long __sched
 wait_for_completion_interruptible_timeout(struct completion *x,
 					  unsigned long timeout)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return wait_for_common(x, timeout, TASK_INTERRUPTIBLE);
 }
 EXPORT_SYMBOL(wait_for_completion_interruptible_timeout);
@@ -248,7 +261,10 @@ int __sched wait_for_completion_killable(struct completion *x)
 {
 	long t = wait_for_common(x, MAX_SCHEDULE_TIMEOUT, TASK_KILLABLE);
 	if (t == -ERESTARTSYS)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return t;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 EXPORT_SYMBOL(wait_for_completion_killable);
@@ -322,6 +338,7 @@ bool completion_done(struct completion *x)
 {
 	unsigned long flags;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!READ_ONCE(x->done))
 		return false;
 
diff --git a/kernel/sched/core.c b/kernel/sched/core.c
index 5506246..fd73f72 100644
--- a/kernel/sched/core.c
+++ b/kernel/sched/core.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  *  kernel/sched/core.c
  *
@@ -94,17 +96,21 @@ struct rq *__task_rq_lock(struct task_struct *p, struct rq_flags *rf)
 {
 	struct rq *rq;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&p->pi_lock);
 
 	for (;;) {
 		rq = task_rq(p);
 		raw_spin_lock(&rq->lock);
 		if (likely(rq == task_rq(p) && !task_on_rq_migrating(p))) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			rq_pin_lock(rq, rf);
 			return rq;
 		}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		raw_spin_unlock(&rq->lock);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		while (unlikely(task_on_rq_migrating(p)))
 			cpu_relax();
 	}
@@ -140,12 +146,16 @@ struct rq *task_rq_lock(struct task_struct *p, struct rq_flags *rf)
 		 * pair with the WMB to ensure we must then also see migrating.
 		 */
 		if (likely(rq == task_rq(p) && !task_on_rq_migrating(p))) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			rq_pin_lock(rq, rf);
 			return rq;
 		}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		raw_spin_unlock(&rq->lock);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		raw_spin_unlock_irqrestore(&p->pi_lock, rf->flags);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		while (unlikely(task_on_rq_migrating(p)))
 			cpu_relax();
 	}
@@ -213,10 +223,13 @@ void update_rq_clock(struct rq *rq)
 {
 	s64 delta;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&rq->lock);
 
 	if (rq->clock_update_flags & RQCF_ACT_SKIP)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 #ifdef CONFIG_SCHED_DEBUG
 	if (sched_feat(WARN_DOUBLE_CLOCK))
@@ -226,7 +239,9 @@ void update_rq_clock(struct rq *rq)
 
 	delta = sched_clock_cpu(cpu_of(rq)) - rq->clock;
 	if (delta < 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 	rq->clock += delta;
 	update_rq_clock_task(rq, delta);
 }
@@ -239,6 +254,7 @@ void update_rq_clock(struct rq *rq)
 
 static void hrtick_clear(struct rq *rq)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (hrtimer_active(&rq->hrtick_timer))
 		hrtimer_cancel(&rq->hrtick_timer);
 }
@@ -249,6 +265,7 @@ static void hrtick_clear(struct rq *rq)
  */
 static enum hrtimer_restart hrtick(struct hrtimer *timer)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct rq *rq = container_of(timer, struct rq, hrtick_timer);
 	struct rq_flags rf;
 
@@ -380,6 +397,7 @@ static inline void init_rq_hrtick(struct rq *rq)
  */
 static bool set_nr_and_not_polling(struct task_struct *p)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct thread_info *ti = task_thread_info(p);
 	return !(fetch_or(&ti->flags, _TIF_NEED_RESCHED) & _TIF_POLLING_NRFLAG);
 }
@@ -392,6 +410,7 @@ static bool set_nr_and_not_polling(struct task_struct *p)
  */
 static bool set_nr_if_polling(struct task_struct *p)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct thread_info *ti = task_thread_info(p);
 	typeof(ti->flags) old, val = READ_ONCE(ti->flags);
 
@@ -436,7 +455,9 @@ void wake_q_add(struct wake_q_head *head, struct task_struct *task)
 	 * barrier implied by the wakeup in wake_up_q().
 	 */
 	if (cmpxchg(&node->next, NULL, WAKE_Q_TAIL))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	get_task_struct(task);
 
@@ -481,11 +502,15 @@ void resched_curr(struct rq *rq)
 	struct task_struct *curr = rq->curr;
 	int cpu;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&rq->lock);
 
 	if (test_tsk_need_resched(curr))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	cpu = cpu_of(rq);
 
 	if (cpu == smp_processor_id()) {
@@ -494,14 +519,18 @@ void resched_curr(struct rq *rq)
 		return;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (set_nr_and_not_polling(curr))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		smp_send_reschedule(cpu);
+}
 	else
 		trace_sched_wake_idle_without_ipi(cpu);
 }
 
 void resched_cpu(int cpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct rq *rq = cpu_rq(cpu);
 	unsigned long flags;
 
@@ -526,23 +555,33 @@ int get_nohz_timer_target(void)
 	struct sched_domain *sd;
 
 	if (!idle_cpu(cpu) && is_housekeeping_cpu(cpu))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return cpu;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rcu_read_lock();
 	for_each_domain(cpu, sd) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		for_each_cpu(i, sched_domain_span(sd)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			if (cpu == i)
 				continue;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			if (!idle_cpu(i) && is_housekeeping_cpu(i)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				cpu = i;
 				goto unlock;
 			}
 		}
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!is_housekeeping_cpu(cpu))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		cpu = housekeeping_any_cpu();
+}
 unlock:
 	rcu_read_unlock();
 	return cpu;
@@ -560,6 +599,7 @@ int get_nohz_timer_target(void)
  */
 static void wake_up_idle_cpu(int cpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct rq *rq = cpu_rq(cpu);
 
 	if (cpu == smp_processor_id())
@@ -598,12 +638,14 @@ static bool wake_up_full_nohz_cpu(int cpu)
  */
 void wake_up_nohz_cpu(int cpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!wake_up_full_nohz_cpu(cpu))
 		wake_up_idle_cpu(cpu);
 }
 
 static inline bool got_nohz_idle_kick(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	int cpu = smp_processor_id();
 
 	if (!test_bit(NOHZ_BALANCE_KICK, nohz_flags(cpu)))
@@ -728,6 +770,7 @@ int walk_tg_tree_from(struct task_group *from,
 
 int tg_nop(struct task_group *tg, void *data)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 #endif
@@ -741,6 +784,7 @@ static void set_load_weight(struct task_struct *p)
 	 * SCHED_IDLE tasks get minimal weight:
 	 */
 	if (idle_policy(p->policy)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		load->weight = scale_load(WEIGHT_IDLEPRIO);
 		load->inv_weight = WMULT_IDLEPRIO;
 		return;
@@ -753,7 +797,9 @@ static void set_load_weight(struct task_struct *p)
 static inline void enqueue_task(struct rq *rq, struct task_struct *p, int flags)
 {
 	if (!(flags & ENQUEUE_NOCLOCK))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		update_rq_clock(rq);
+}
 
 	if (!(flags & ENQUEUE_RESTORE))
 		sched_info_queued(rq, p);
@@ -764,7 +810,9 @@ static inline void enqueue_task(struct rq *rq, struct task_struct *p, int flags)
 static inline void dequeue_task(struct rq *rq, struct task_struct *p, int flags)
 {
 	if (!(flags & DEQUEUE_NOCLOCK))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		update_rq_clock(rq);
+}
 
 	if (!(flags & DEQUEUE_SAVE))
 		sched_info_dequeued(rq, p);
@@ -775,7 +823,9 @@ static inline void dequeue_task(struct rq *rq, struct task_struct *p, int flags)
 void activate_task(struct rq *rq, struct task_struct *p, int flags)
 {
 	if (task_contributes_to_load(p))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		rq->nr_uninterruptible--;
+}
 
 	enqueue_task(rq, p, flags);
 }
@@ -808,7 +858,9 @@ static inline int normal_prio(struct task_struct *p)
 	int prio;
 
 	if (task_has_dl_policy(p))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		prio = MAX_DL_PRIO-1;
+}
 	else if (task_has_rt_policy(p))
 		prio = MAX_RT_PRIO-1 - p->rt_priority;
 	else
@@ -832,7 +884,10 @@ static int effective_prio(struct task_struct *p)
 	 * to the normal priority:
 	 */
 	if (!rt_prio(p->prio))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return p->normal_prio;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return p->prio;
 }
 
@@ -864,6 +919,7 @@ static inline void check_class_changed(struct rq *rq, struct task_struct *p,
 
 		p->sched_class->switched_to(rq, p);
 	} else if (oldprio != p->prio || dl_task(p))
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		p->sched_class->prio_changed(rq, p, oldprio);
 }
 
@@ -915,6 +971,7 @@ void check_preempt_curr(struct rq *rq, struct task_struct *p, int flags)
 static struct rq *move_queued_task(struct rq *rq, struct rq_flags *rf,
 				   struct task_struct *p, int new_cpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&rq->lock);
 
 	p->on_rq = TASK_ON_RQ_MIGRATING;
@@ -950,6 +1007,7 @@ struct migration_arg {
 static struct rq *__migrate_task(struct rq *rq, struct rq_flags *rf,
 				 struct task_struct *p, int dest_cpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (p->flags & PF_KTHREAD) {
 		if (unlikely(!cpu_online(dest_cpu)))
 			return rq;
@@ -977,6 +1035,7 @@ static int migration_cpu_stop(void *data)
 {
 	struct migration_arg *arg = data;
 	struct task_struct *p = arg->task;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct rq *rq = this_rq();
 	struct rq_flags rf;
 
@@ -1027,8 +1086,10 @@ void do_set_cpus_allowed(struct task_struct *p, const struct cpumask *new_mask)
 	struct rq *rq = task_rq(p);
 	bool queued, running;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&p->pi_lock);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	queued = task_on_rq_queued(p);
 	running = task_current(rq, p);
 
@@ -1084,6 +1145,7 @@ static int __set_cpus_allowed_ptr(struct task_struct *p,
 	 * sched_setaffinity() is not guaranteed to observe the flag.
 	 */
 	if (check && (p->flags & PF_NO_SETAFFINITY)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ret = -EINVAL;
 		goto out;
 	}
@@ -1092,6 +1154,7 @@ static int __set_cpus_allowed_ptr(struct task_struct *p,
 		goto out;
 
 	if (!cpumask_intersects(new_mask, cpu_valid_mask)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ret = -EINVAL;
 		goto out;
 	}
@@ -1112,13 +1175,17 @@ static int __set_cpus_allowed_ptr(struct task_struct *p,
 	if (cpumask_test_cpu(task_cpu(p), new_mask))
 		goto out;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	dest_cpu = cpumask_any_and(cpu_valid_mask, new_mask);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (task_running(rq, p) || p->state == TASK_WAKING) {
 		struct migration_arg arg = { p, dest_cpu };
 		/* Need help from migration thread: drop lock and wait. */
 		task_rq_unlock(rq, p, &rf);
 		stop_one_cpu(cpu_of(rq), migration_cpu_stop, &arg);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		tlb_migrate_finish(p->mm);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
 	} else if (task_on_rq_queued(p)) {
 		/*
@@ -1178,6 +1245,7 @@ void set_task_cpu(struct task_struct *p, unsigned int new_cpu)
 	WARN_ON_ONCE(!cpu_online(new_cpu));
 #endif
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	trace_sched_migrate_task(p, new_cpu);
 
 	if (task_cpu(p) != new_cpu) {
@@ -1192,6 +1260,7 @@ void set_task_cpu(struct task_struct *p, unsigned int new_cpu)
 
 static void __migrate_swap_task(struct task_struct *p, int cpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (task_on_rq_queued(p)) {
 		struct rq *src_rq, *dst_rq;
 		struct rq_flags srf, drf;
@@ -1233,6 +1302,7 @@ static int migrate_swap_stop(void *data)
 	struct rq *src_rq, *dst_rq;
 	int ret = -EAGAIN;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!cpu_active(arg->src_cpu) || !cpu_active(arg->dst_cpu))
 		return -EAGAIN;
 
@@ -1350,8 +1420,12 @@ unsigned long wait_task_inactive(struct task_struct *p, long match_state)
 		 * is actually now running somewhere else!
 		 */
 		while (task_running(rq, p)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			if (match_state && unlikely(p->state != match_state))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				return 0;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			cpu_relax();
 		}
 
@@ -1382,6 +1456,7 @@ unsigned long wait_task_inactive(struct task_struct *p, long match_state)
 		 * Oops. Go back and try again..
 		 */
 		if (unlikely(running)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			cpu_relax();
 			continue;
 		}
@@ -1398,7 +1473,9 @@ unsigned long wait_task_inactive(struct task_struct *p, long match_state)
 		if (unlikely(queued)) {
 			ktime_t to = NSEC_PER_SEC / HZ;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			set_current_state(TASK_UNINTERRUPTIBLE);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			schedule_hrtimeout(&to, HRTIMER_MODE_REL);
 			continue;
 		}
@@ -1411,6 +1488,7 @@ unsigned long wait_task_inactive(struct task_struct *p, long match_state)
 		break;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return ncsw;
 }
 
@@ -1434,7 +1512,9 @@ void kick_process(struct task_struct *p)
 	preempt_disable();
 	cpu = task_cpu(p);
 	if ((cpu != smp_processor_id()) && task_curr(p))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		smp_send_reschedule(cpu);
+}
 	preempt_enable();
 }
 EXPORT_SYMBOL_GPL(kick_process);
@@ -1463,6 +1543,7 @@ EXPORT_SYMBOL_GPL(kick_process);
  */
 static int select_fallback_rq(int cpu, struct task_struct *p)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	int nid = cpu_to_node(cpu);
 	const struct cpumask *nodemask = NULL;
 	enum { cpuset, possible, fail } state = cpuset;
@@ -1537,6 +1618,7 @@ static int select_fallback_rq(int cpu, struct task_struct *p)
 static inline
 int select_task_rq(struct task_struct *p, int cpu, int sd_flags, int wake_flags)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&p->pi_lock);
 
 	if (p->nr_cpus_allowed > 1)
@@ -1612,6 +1694,7 @@ ttwu_stat(struct task_struct *p, int cpu, int wake_flags)
 {
 	struct rq *rq;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!schedstat_enabled())
 		return;
 
@@ -1697,6 +1780,7 @@ ttwu_do_activate(struct rq *rq, struct task_struct *p, int wake_flags,
 {
 	int en_flags = ENQUEUE_WAKEUP | ENQUEUE_NOCLOCK;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&rq->lock);
 
 #ifdef CONFIG_SMP
@@ -1704,7 +1788,9 @@ ttwu_do_activate(struct rq *rq, struct task_struct *p, int wake_flags,
 		rq->nr_uninterruptible--;
 
 	if (wake_flags & WF_MIGRATED)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		en_flags |= ENQUEUE_MIGRATED;
+}
 #endif
 
 	ttwu_activate(rq, p, en_flags);
@@ -1746,12 +1832,15 @@ void sched_ttwu_pending(void)
 	if (!llist)
 		return;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rq_lock_irqsave(rq, &rf);
 	update_rq_clock(rq);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	llist_for_each_entry_safe(p, t, llist, wake_entry)
 		ttwu_do_activate(rq, p, p->sched_remote_wakeup ? WF_MIGRATED : 0, &rf);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rq_unlock_irqrestore(rq, &rf);
 }
 
@@ -1795,6 +1884,7 @@ void scheduler_ipi(void)
 
 static void ttwu_queue_remote(struct task_struct *p, int cpu, int wake_flags)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct rq *rq = cpu_rq(cpu);
 
 	p->sched_remote_wakeup = !!(wake_flags & WF_MIGRATED);
@@ -1809,6 +1899,7 @@ static void ttwu_queue_remote(struct task_struct *p, int cpu, int wake_flags)
 
 void wake_up_if_idle(int cpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct rq *rq = cpu_rq(cpu);
 	struct rq_flags rf;
 
@@ -1844,6 +1935,7 @@ static void ttwu_queue(struct task_struct *p, int cpu, int wake_flags)
 
 #if defined(CONFIG_SMP)
 	if (sched_feat(TTWU_QUEUE) && !cpus_share_cache(smp_processor_id(), cpu)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		sched_clock_cpu(cpu); /* Sync clocks across CPUs */
 		ttwu_queue_remote(p, cpu, wake_flags);
 		return;
@@ -1976,6 +2068,7 @@ try_to_wake_up(struct task_struct *p, unsigned int state, int wake_flags)
 	 * set_current_state() the waiting thread does.
 	 */
 	raw_spin_lock_irqsave(&p->pi_lock, flags);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	smp_mb__after_spinlock();
 	if (!(p->state & state))
 		goto out;
@@ -2052,6 +2145,7 @@ try_to_wake_up(struct task_struct *p, unsigned int state, int wake_flags)
 
 	cpu = select_task_rq(p, p->wake_cpu, SD_BALANCE_WAKE, wake_flags);
 	if (task_cpu(p) != cpu) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		wake_flags |= WF_MIGRATED;
 		set_task_cpu(p, cpu);
 	}
@@ -2091,6 +2185,7 @@ static void try_to_wake_up_local(struct task_struct *p, struct rq_flags *rf)
 	    WARN_ON_ONCE(p == current))
 		return;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&rq->lock);
 
 	if (!raw_spin_trylock(&p->pi_lock)) {
@@ -2112,6 +2207,7 @@ static void try_to_wake_up_local(struct task_struct *p, struct rq_flags *rf)
 
 	if (!task_on_rq_queued(p)) {
 		if (p->in_iowait) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			delayacct_blkio_end(p);
 			atomic_dec(&rq->nr_iowait);
 		}
@@ -2254,6 +2350,7 @@ static bool __initdata __sched_schedstats = false;
 
 static void set_schedstats(bool enabled)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (enabled)
 		static_branch_enable(&sched_schedstats);
 	else
@@ -2262,6 +2359,7 @@ static void set_schedstats(bool enabled)
 
 void force_schedstat_enabled(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!schedstat_enabled()) {
 		pr_info("kernel profiling enabled schedstats, disable via kernel.sched_schedstats.\n");
 		static_branch_enable(&sched_schedstats);
@@ -2296,6 +2394,7 @@ __setup("schedstats=", setup_schedstats);
 
 static void __init init_schedstats(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	set_schedstats(__sched_schedstats);
 }
 
@@ -2305,6 +2404,7 @@ int sysctl_schedstats(struct ctl_table *table, int write,
 {
 	struct ctl_table t;
 	int err;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	int state = static_branch_likely(&sched_schedstats);
 
 	if (write && !capable(CAP_SYS_ADMIN))
@@ -2349,13 +2449,17 @@ int sched_fork(unsigned long clone_flags, struct task_struct *p)
 	 * Revert to default priority/policy on fork if requested.
 	 */
 	if (unlikely(p->sched_reset_on_fork)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (task_has_dl_policy(p) || task_has_rt_policy(p)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			p->policy = SCHED_NORMAL;
 			p->static_prio = NICE_TO_PRIO(0);
 			p->rt_priority = 0;
 		} else if (PRIO_TO_NICE(p->static_prio) < 0)
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			p->static_prio = NICE_TO_PRIO(0);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		p->prio = p->normal_prio = __normal_prio(p);
 		set_load_weight(p);
 
@@ -2367,9 +2471,11 @@ int sched_fork(unsigned long clone_flags, struct task_struct *p)
 	}
 
 	if (dl_prio(p->prio)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		put_cpu();
 		return -EAGAIN;
 	} else if (rt_prio(p->prio)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		p->sched_class = &rt_sched_class;
 	} else {
 		p->sched_class = &fair_sched_class;
@@ -2414,7 +2520,9 @@ int sched_fork(unsigned long clone_flags, struct task_struct *p)
 unsigned long to_ratio(u64 period, u64 runtime)
 {
 	if (runtime == RUNTIME_INF)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return BW_UNIT;
+}
 
 	/*
 	 * Doing this here saves a lot of checks in all
@@ -2422,7 +2530,9 @@ unsigned long to_ratio(u64 period, u64 runtime)
 	 * safe for them anyway.
 	 */
 	if (period == 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	return div64_u64(runtime << BW_SHIFT, period);
 }
@@ -2582,6 +2692,7 @@ prepare_task_switch(struct rq *rq, struct task_struct *prev,
 	perf_event_task_sched_out(prev, next);
 	fire_sched_out_preempt_notifiers(prev, next);
 	prepare_lock_switch(rq, next);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	prepare_arch_switch(next);
 }
 
@@ -2653,9 +2764,12 @@ static struct rq *finish_task_switch(struct task_struct *prev)
 	 * to use.
 	 */
 	smp_mb__after_unlock_lock();
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	finish_lock_switch(rq, prev);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	finish_arch_post_lock_switch();
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	fire_sched_in_preempt_notifiers(current);
 	if (mm)
 		mmdrop(mm);
@@ -2675,6 +2789,7 @@ static struct rq *finish_task_switch(struct task_struct *prev)
 		put_task_struct(prev);
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	tick_nohz_task_switch();
 	return rq;
 }
@@ -2688,6 +2803,7 @@ static void __balance_callback(struct rq *rq)
 	void (*func)(struct rq *rq);
 	unsigned long flags;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	raw_spin_lock_irqsave(&rq->lock, flags);
 	head = rq->balance_callback;
 	rq->balance_callback = NULL;
@@ -2705,8 +2821,10 @@ static void __balance_callback(struct rq *rq)
 static inline void balance_callback(struct rq *rq)
 {
 	if (unlikely(rq->balance_callback))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		__balance_callback(rq);
 }
+}
 
 #else
 
@@ -2783,6 +2901,7 @@ context_switch(struct rq *rq, struct task_struct *prev,
 	 * do an early lockdep release here:
 	 */
 	rq_unpin_lock(rq, rf);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_release(&rq->lock.dep_map, 1, _THIS_IP_);
 
 	/* Here we just switch the register state and the stack. */
@@ -2823,6 +2942,7 @@ unsigned long nr_running(void)
  */
 bool single_task_running(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return raw_rq()->nr_running == 1;
 }
 EXPORT_SYMBOL(single_task_running);
@@ -2893,6 +3013,7 @@ unsigned long nr_iowait_cpu(int cpu)
 
 void get_iowait_load(unsigned long *nr_waiters, unsigned long *load)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct rq *rq = this_rq();
 	*nr_waiters = atomic_read(&rq->nr_iowait);
 	*load = rq->load.weight;
@@ -2906,6 +3027,7 @@ void get_iowait_load(unsigned long *nr_waiters, unsigned long *load)
  */
 void sched_exec(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct task_struct *p = current;
 	unsigned long flags;
 	int dest_cpu;
@@ -2915,10 +3037,13 @@ void sched_exec(void)
 	if (dest_cpu == smp_processor_id())
 		goto unlock;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (likely(cpu_active(dest_cpu))) {
 		struct migration_arg arg = { p, dest_cpu };
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		raw_spin_unlock_irqrestore(&p->pi_lock, flags);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		stop_one_cpu(task_cpu(p), migration_cpu_stop, &arg);
 		return;
 	}
@@ -2975,7 +3100,9 @@ unsigned long long task_sched_runtime(struct task_struct *p)
 	 * been accounted, so we're correct here as well.
 	 */
 	if (!p->on_cpu || !task_on_rq_queued(p))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return p->se.sum_exec_runtime;
+}
 #endif
 
 	rq = task_rq_lock(p, &rf);
@@ -3181,13 +3308,16 @@ static inline void schedule_debug(struct task_struct *prev)
 #endif
 
 	if (unlikely(in_atomic_preempt_off())) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		__schedule_bug(prev);
 		preempt_count_set(PREEMPT_DISABLED);
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rcu_sleep_check();
 
 	profile_hit(SCHED_PROFILING, __builtin_return_address(0));
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	schedstat_inc(this_rq()->sched_count);
 }
 
@@ -3218,6 +3348,7 @@ pick_next_task(struct rq *rq, struct task_struct *prev, struct rq_flags *rf)
 		if (unlikely(!p))
 			p = idle_sched_class.pick_next_task(rq, prev, rf);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return p;
 	}
 
@@ -3227,6 +3358,7 @@ pick_next_task(struct rq *rq, struct task_struct *prev, struct rq_flags *rf)
 		if (p) {
 			if (unlikely(p == RETRY_TASK))
 				goto again;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return p;
 		}
 	}
@@ -3289,7 +3421,9 @@ static void __sched notrace __schedule(bool preempt)
 	schedule_debug(prev);
 
 	if (sched_feat(HRTICK))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		hrtick_clear(rq);
+}
 
 	local_irq_disable();
 	rcu_note_context_switch(preempt);
@@ -3300,6 +3434,7 @@ static void __sched notrace __schedule(bool preempt)
 	 * done by the caller to avoid the race with signal_wake_up().
 	 */
 	rq_lock(rq, &rf);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	smp_mb__after_spinlock();
 
 	/* Promote REQ to ACT */
@@ -3309,6 +3444,7 @@ static void __sched notrace __schedule(bool preempt)
 	switch_count = &prev->nivcsw;
 	if (!preempt && prev->state) {
 		if (unlikely(signal_pending_state(prev->state, prev))) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			prev->state = TASK_RUNNING;
 		} else {
 			deactivate_task(rq, prev, DEQUEUE_SLEEP | DEQUEUE_NOCLOCK);
@@ -3395,27 +3531,35 @@ void __noreturn do_task_dead(void)
 	current->flags |= PF_NOFREEZE;
 
 	__schedule(false);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	BUG();
 
 	/* Avoid "noreturn function does return" - but don't continue if BUG() is a NOP: */
 	for (;;)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		cpu_relax();
 }
+}
 
 static inline void sched_submit_work(struct task_struct *tsk)
 {
 	if (!tsk->state || tsk_is_pi_blocked(tsk))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 	/*
 	 * If we are going to sleep and we have plugged IO queued,
 	 * make sure to submit it to avoid deadlocks.
 	 */
 	if (blk_needs_flush_plug(tsk))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		blk_schedule_flush_plug(tsk);
 }
+}
 
 asmlinkage __visible void __sched schedule(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct task_struct *tsk = current;
 
 	sched_submit_work(tsk);
@@ -3624,13 +3768,17 @@ EXPORT_SYMBOL(default_wake_function);
 static inline int __rt_effective_prio(struct task_struct *pi_task, int prio)
 {
 	if (pi_task)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		prio = min(prio, pi_task->prio);
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return prio;
 }
 
 static inline int rt_effective_prio(struct task_struct *p, int prio)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct task_struct *pi_task = rt_mutex_get_top_task(p);
 
 	return __rt_effective_prio(pi_task, prio);
@@ -3793,9 +3941,11 @@ void set_user_nice(struct task_struct *p, long nice)
 	 * SCHED_DEADLINE, SCHED_FIFO or SCHED_RR:
 	 */
 	if (task_has_dl_policy(p) || task_has_rt_policy(p)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		p->static_prio = NICE_TO_PRIO(nice);
 		goto out_unlock;
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	queued = task_on_rq_queued(p);
 	running = task_current(rq, p);
 	if (queued)
@@ -3862,7 +4012,9 @@ SYSCALL_DEFINE1(nice, int, increment)
 
 	nice = clamp_val(nice, MIN_NICE, MAX_NICE);
 	if (increment < 0 && !can_nice(current, nice))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EPERM;
+}
 
 	retval = security_task_setnice(current, nice);
 	if (retval)
@@ -3898,14 +4050,20 @@ int idle_cpu(int cpu)
 	struct rq *rq = cpu_rq(cpu);
 
 	if (rq->curr != rq->idle)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	if (rq->nr_running)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 #ifdef CONFIG_SMP
 	if (!llist_empty(&rq->wake_list))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 #endif
 
 	return 1;
@@ -3919,6 +4077,7 @@ int idle_cpu(int cpu)
  */
 struct task_struct *idle_task(int cpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return cpu_rq(cpu)->idle;
 }
 
@@ -3945,14 +4104,20 @@ static void __setscheduler_params(struct task_struct *p,
 	int policy = attr->sched_policy;
 
 	if (policy == SETPARAM_POLICY)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		policy = p->policy;
+}
 
 	p->policy = policy;
 
 	if (dl_policy(policy))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		__setparam_dl(p, attr);
+}
 	else if (fair_policy(policy))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		p->static_prio = NICE_TO_PRIO(attr->sched_nice);
+}
 
 	/*
 	 * __sched_setscheduler() ensures attr->sched_priority == 0 when
@@ -3979,7 +4144,9 @@ static void __setscheduler(struct rq *rq, struct task_struct *p,
 		p->prio = rt_effective_prio(p, p->prio);
 
 	if (dl_prio(p->prio))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		p->sched_class = &dl_sched_class;
+}
 	else if (rt_prio(p->prio))
 		p->sched_class = &rt_sched_class;
 	else
@@ -4021,13 +4188,16 @@ static int __sched_setscheduler(struct task_struct *p,
 recheck:
 	/* Double check policy once rq lock held: */
 	if (policy < 0) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		reset_on_fork = p->sched_reset_on_fork;
 		policy = oldpolicy = p->policy;
 	} else {
 		reset_on_fork = !!(attr->sched_flags & SCHED_FLAG_RESET_ON_FORK);
 
 		if (!valid_policy(policy))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -EINVAL;
+}
 	}
 
 	if (attr->sched_flags &
@@ -4062,7 +4232,9 @@ static int __sched_setscheduler(struct task_struct *p,
 
 			/* Can't set/change the rt policy: */
 			if (policy != p->policy && !rlim_rtprio)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				return -EPERM;
+}
 
 			/* Can't increase priority: */
 			if (attr->sched_priority > p->rt_priority &&
@@ -4077,30 +4249,41 @@ static int __sched_setscheduler(struct task_struct *p,
 		  * or reduce their runtime (both ways reducing utilization)
 		  */
 		if (dl_policy(policy))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -EPERM;
+}
 
 		/*
 		 * Treat SCHED_IDLE as nice 20. Only allow a switch to
 		 * SCHED_NORMAL if the RLIMIT_NICE would normally permit it.
 		 */
 		if (idle_policy(p->policy) && !idle_policy(policy)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			if (!can_nice(p, task_nice(p)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				return -EPERM;
+}
 		}
 
 		/* Can't change other user's priorities: */
 		if (!check_same_owner(p))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -EPERM;
+}
 
 		/* Normal users shall not reset the sched_reset_on_fork flag: */
 		if (p->sched_reset_on_fork && !reset_on_fork)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -EPERM;
+}
 	}
 
 	if (user) {
 		retval = security_task_setscheduler(p);
 		if (retval)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return retval;
+}
 	}
 
 	/*
@@ -4117,6 +4300,7 @@ static int __sched_setscheduler(struct task_struct *p,
 	 * Changing the policy of the stop threads its a very bad idea:
 	 */
 	if (p == rq->stop) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		task_rq_unlock(rq, p, &rf);
 		return -EINVAL;
 	}
@@ -4163,6 +4347,7 @@ static int __sched_setscheduler(struct task_struct *p,
 			 */
 			if (!cpumask_subset(span, &p->cpus_allowed) ||
 			    rq->rd->dl_bw.bw == 0) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				task_rq_unlock(rq, p, &rf);
 				return -EPERM;
 			}
@@ -4172,6 +4357,7 @@ static int __sched_setscheduler(struct task_struct *p,
 
 	/* Re-check policy now with rq lock held: */
 	if (unlikely(oldpolicy != -1 && oldpolicy != p->policy)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		policy = oldpolicy = -1;
 		task_rq_unlock(rq, p, &rf);
 		goto recheck;
@@ -4183,6 +4369,7 @@ static int __sched_setscheduler(struct task_struct *p,
 	 * is available.
 	 */
 	if ((dl_policy(policy) || dl_task(p)) && sched_dl_overflow(p, policy, attr)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		task_rq_unlock(rq, p, &rf);
 		return -EBUSY;
 	}
@@ -4200,9 +4387,12 @@ static int __sched_setscheduler(struct task_struct *p,
 		 */
 		new_effective_prio = rt_effective_prio(p, newprio);
 		if (new_effective_prio == oldprio)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			queue_flags &= ~DEQUEUE_MOVE;
+}
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	queued = task_on_rq_queued(p);
 	running = task_current(rq, p);
 	if (queued)
@@ -4219,7 +4409,9 @@ static int __sched_setscheduler(struct task_struct *p,
 		 * increased (user space view).
 		 */
 		if (oldprio < p->prio)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			queue_flags |= ENQUEUE_HEAD;
+}
 
 		enqueue_task(rq, p, queue_flags);
 	}
@@ -4253,6 +4445,7 @@ static int _sched_setscheduler(struct task_struct *p, int policy,
 
 	/* Fixup the legacy SCHED_RESET_ON_FORK hack. */
 	if ((policy != SETPARAM_POLICY) && (policy & SCHED_RESET_ON_FORK)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		attr.sched_flags |= SCHED_FLAG_RESET_ON_FORK;
 		policy &= ~SCHED_RESET_ON_FORK;
 		attr.sched_policy = policy;
@@ -4279,6 +4472,7 @@ EXPORT_SYMBOL_GPL(sched_setscheduler);
 
 int sched_setattr(struct task_struct *p, const struct sched_attr *attr)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return __sched_setscheduler(p, attr, true, true);
 }
 EXPORT_SYMBOL_GPL(sched_setattr);
@@ -4311,15 +4505,21 @@ do_sched_setscheduler(pid_t pid, int policy, struct sched_param __user *param)
 	int retval;
 
 	if (!param || pid < 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 	if (copy_from_user(&lparam, param, sizeof(struct sched_param)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EFAULT;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rcu_read_lock();
 	retval = -ESRCH;
 	p = find_process_by_pid(pid);
 	if (p != NULL)
 		retval = sched_setscheduler(p, policy, &lparam);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rcu_read_unlock();
 
 	return retval;
@@ -4334,7 +4534,9 @@ static int sched_copy_attr(struct sched_attr __user *uattr, struct sched_attr *a
 	int ret;
 
 	if (!access_ok(VERIFY_WRITE, uattr, SCHED_ATTR_SIZE_VER0))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EFAULT;
+}
 
 	/* Zero the full structure, so that a short copy will be nice: */
 	memset(attr, 0, sizeof(*attr));
@@ -4406,7 +4608,9 @@ static int sched_copy_attr(struct sched_attr __user *uattr, struct sched_attr *a
 SYSCALL_DEFINE3(sched_setscheduler, pid_t, pid, int, policy, struct sched_param __user *, param)
 {
 	if (policy < 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	return do_sched_setscheduler(pid, policy, param);
 }
@@ -4420,6 +4624,7 @@ SYSCALL_DEFINE3(sched_setscheduler, pid_t, pid, int, policy, struct sched_param
  */
 SYSCALL_DEFINE2(sched_setparam, pid_t, pid, struct sched_param __user *, param)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return do_sched_setscheduler(pid, SETPARAM_POLICY, param);
 }
 
@@ -4436,6 +4641,7 @@ SYSCALL_DEFINE3(sched_setattr, pid_t, pid, struct sched_attr __user *, uattr,
 	struct task_struct *p;
 	int retval;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!uattr || pid < 0 || flags)
 		return -EINVAL;
 
@@ -4469,8 +4675,11 @@ SYSCALL_DEFINE1(sched_getscheduler, pid_t, pid)
 	int retval;
 
 	if (pid < 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	retval = -ESRCH;
 	rcu_read_lock();
 	p = find_process_by_pid(pid);
@@ -4480,6 +4689,7 @@ SYSCALL_DEFINE1(sched_getscheduler, pid_t, pid)
 			retval = p->policy
 				| (p->sched_reset_on_fork ? SCHED_RESET_ON_FORK : 0);
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rcu_read_unlock();
 	return retval;
 }
@@ -4499,8 +4709,11 @@ SYSCALL_DEFINE2(sched_getparam, pid_t, pid, struct sched_param __user *, param)
 	int retval;
 
 	if (!param || pid < 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rcu_read_lock();
 	p = find_process_by_pid(pid);
 	retval = -ESRCH;
@@ -4512,7 +4725,10 @@ SYSCALL_DEFINE2(sched_getparam, pid_t, pid, struct sched_param __user *, param)
 		goto out_unlock;
 
 	if (task_has_rt_policy(p))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		lp.sched_priority = p->rt_priority;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rcu_read_unlock();
 
 	/*
@@ -4534,7 +4750,9 @@ static int sched_read_attr(struct sched_attr __user *uattr,
 	int ret;
 
 	if (!access_ok(VERIFY_WRITE, uattr, usize))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EFAULT;
+}
 
 	/*
 	 * If we're handed a smaller struct than we know of,
@@ -4579,6 +4797,7 @@ SYSCALL_DEFINE4(sched_getattr, pid_t, pid, struct sched_attr __user *, uattr,
 	struct task_struct *p;
 	int retval;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!uattr || pid < 0 || size > PAGE_SIZE ||
 	    size < SCHED_ATTR_SIZE_VER0 || flags)
 		return -EINVAL;
@@ -4623,33 +4842,45 @@ long sched_setaffinity(pid_t pid, const struct cpumask *in_mask)
 
 	p = find_process_by_pid(pid);
 	if (!p) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		rcu_read_unlock();
 		return -ESRCH;
 	}
 
 	/* Prevent p going away */
 	get_task_struct(p);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rcu_read_unlock();
 
 	if (p->flags & PF_NO_SETAFFINITY) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		retval = -EINVAL;
 		goto out_put_task;
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!alloc_cpumask_var(&cpus_allowed, GFP_KERNEL)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		retval = -ENOMEM;
 		goto out_put_task;
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!alloc_cpumask_var(&new_mask, GFP_KERNEL)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		retval = -ENOMEM;
 		goto out_free_cpus_allowed;
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	retval = -EPERM;
 	if (!check_same_owner(p)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		rcu_read_lock();
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (!ns_capable(__task_cred(p)->user_ns, CAP_SYS_NICE)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			rcu_read_unlock();
 			goto out_free_new_mask;
 		}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		rcu_read_unlock();
 	}
 
@@ -4669,12 +4900,16 @@ long sched_setaffinity(pid_t pid, const struct cpumask *in_mask)
 	 */
 #ifdef CONFIG_SMP
 	if (task_has_dl_policy(p) && dl_bandwidth_enabled()) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		rcu_read_lock();
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (!cpumask_subset(task_rq(p)->rd->span, new_mask)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			retval = -EBUSY;
 			rcu_read_unlock();
 			goto out_free_new_mask;
 		}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		rcu_read_unlock();
 	}
 #endif
@@ -4706,9 +4941,13 @@ static int get_user_cpu_mask(unsigned long __user *user_mask_ptr, unsigned len,
 			     struct cpumask *new_mask)
 {
 	if (len < cpumask_size())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		cpumask_clear(new_mask);
+}
 	else if (len > cpumask_size())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		len = cpumask_size();
+}
 
 	return copy_from_user(new_mask, user_mask_ptr, len) ? -EFAULT : 0;
 }
@@ -4728,11 +4967,14 @@ SYSCALL_DEFINE3(sched_setaffinity, pid_t, pid, unsigned int, len,
 	int retval;
 
 	if (!alloc_cpumask_var(&new_mask, GFP_KERNEL))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 
 	retval = get_user_cpu_mask(user_mask_ptr, len, new_mask);
 	if (retval == 0)
 		retval = sched_setaffinity(pid, new_mask);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	free_cpumask_var(new_mask);
 	return retval;
 }
@@ -4780,22 +5022,32 @@ SYSCALL_DEFINE3(sched_getaffinity, pid_t, pid, unsigned int, len,
 	cpumask_var_t mask;
 
 	if ((len * BITS_PER_BYTE) < nr_cpu_ids)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 	if (len & (sizeof(unsigned long)-1))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!alloc_cpumask_var(&mask, GFP_KERNEL))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 
 	ret = sched_getaffinity(pid, mask);
 	if (ret == 0) {
 		size_t retlen = min_t(size_t, len, cpumask_size());
 
 		if (copy_to_user(user_mask_ptr, mask, retlen))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			ret = -EFAULT;
+}
 		else
 			ret = retlen;
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	free_cpumask_var(mask);
 
 	return ret;
@@ -4841,6 +5093,7 @@ int __sched _cond_resched(void)
 		preempt_schedule_common();
 		return 1;
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 EXPORT_SYMBOL(_cond_resched);
@@ -4856,17 +5109,21 @@ EXPORT_SYMBOL(_cond_resched);
  */
 int __cond_resched_lock(spinlock_t *lock)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	int resched = should_resched(PREEMPT_LOCK_OFFSET);
 	int ret = 0;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(lock);
 
 	if (spin_needbreak(lock) || resched) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		spin_unlock(lock);
 		if (resched)
 			preempt_schedule_common();
 		else
 			cpu_relax();
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ret = 1;
 		spin_lock(lock);
 	}
@@ -4876,6 +5133,7 @@ EXPORT_SYMBOL(__cond_resched_lock);
 
 int __sched __cond_resched_softirq(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	BUG_ON(!in_softirq());
 
 	if (should_resched(SOFTIRQ_DISABLE_OFFSET)) {
@@ -4912,6 +5170,7 @@ EXPORT_SYMBOL(__cond_resched_softirq);
  */
 void __sched yield(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	set_current_state(TASK_RUNNING);
 	sys_sched_yield();
 }
@@ -4934,6 +5193,7 @@ EXPORT_SYMBOL(yield);
  */
 int __sched yield_to(struct task_struct *p, bool preempt)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct task_struct *curr = current;
 	struct rq *rq, *p_rq;
 	unsigned long flags;
@@ -5108,7 +5368,9 @@ SYSCALL_DEFINE2(sched_rr_get_interval, pid_t, pid,
 	int retval;
 
 	if (pid < 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	retval = -ESRCH;
 	rcu_read_lock();
@@ -5142,7 +5404,9 @@ void sched_show_task(struct task_struct *p)
 	int ppid;
 
 	if (!try_get_task_stack(p))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	printk(KERN_INFO "%-15.15s %c", p->comm, task_state_to_char(p));
 
@@ -5199,6 +5463,7 @@ void show_state_filter(unsigned long state_filter)
 		"  task                        PC stack   pid father\n");
 #endif
 	rcu_read_lock();
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for_each_process_thread(g, p) {
 		/*
 		 * reset the NMI-timeout, listing all files on a slow
@@ -5301,7 +5566,9 @@ int cpuset_cpumask_can_shrink(const struct cpumask *cur,
 	int ret = 1;
 
 	if (!cpumask_weight(cur))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ret;
+}
 
 	ret = dl_cpuset_cpumask_can_shrink(cur, trial);
 
@@ -5323,6 +5590,7 @@ int task_can_attach(struct task_struct *p,
 	 * before cpus_allowed may be changed.
 	 */
 	if (p->flags & PF_NO_SETAFFINITY) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ret = -EINVAL;
 		goto out;
 	}
@@ -5392,6 +5660,7 @@ void sched_setnuma(struct task_struct *p, int nid)
  */
 void idle_task_exit(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct mm_struct *mm = current->active_mm;
 
 	BUG_ON(cpu_online(smp_processor_id()));
@@ -5414,6 +5683,7 @@ void idle_task_exit(void)
  */
 static void calc_load_migrate(struct rq *rq)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	long delta = calc_load_fold_active(rq, 1);
 	if (delta)
 		atomic_long_add(delta, &calc_load_tasks);
@@ -5574,6 +5844,7 @@ static int num_cpus_frozen;
  */
 static void cpuset_cpu_active(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (cpuhp_tasks_frozen) {
 		/*
 		 * num_cpus_frozen tracks how many CPUs are involved in suspend
@@ -5596,6 +5867,7 @@ static void cpuset_cpu_active(void)
 
 static int cpuset_cpu_inactive(unsigned int cpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!cpuhp_tasks_frozen) {
 		if (dl_cpu_busy(cpu))
 			return -EBUSY;
@@ -5609,6 +5881,7 @@ static int cpuset_cpu_inactive(unsigned int cpu)
 
 int sched_cpu_activate(unsigned int cpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct rq *rq = cpu_rq(cpu);
 	struct rq_flags rf;
 
@@ -5676,6 +5949,7 @@ static void sched_rq_cpu_starting(unsigned int cpu)
 
 int sched_cpu_starting(unsigned int cpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	set_cpu_rq_start_time(cpu);
 	sched_rq_cpu_starting(cpu);
 	return 0;
@@ -5684,6 +5958,7 @@ int sched_cpu_starting(unsigned int cpu)
 #ifdef CONFIG_HOTPLUG_CPU
 int sched_cpu_dying(unsigned int cpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct rq *rq = cpu_rq(cpu);
 	struct rq_flags rf;
 
@@ -5740,12 +6015,16 @@ void __init sched_init_smp(void)
 	sched_init_domains(cpu_active_mask);
 	cpumask_andnot(non_isolated_cpus, cpu_possible_mask, cpu_isolated_map);
 	if (cpumask_empty(non_isolated_cpus))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		cpumask_set_cpu(smp_processor_id(), non_isolated_cpus);
+}
 	mutex_unlock(&sched_domains_mutex);
 
 	/* Move init over to a non-isolated CPU */
 	if (set_cpus_allowed_ptr(current, non_isolated_cpus) < 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		BUG();
+}
 	sched_init_granularity();
 	free_cpumask_var(non_isolated_cpus);
 
@@ -5773,6 +6052,7 @@ void __init sched_init_smp(void)
 
 int in_sched_functions(unsigned long addr)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return in_lock_functions(addr) ||
 		(addr >= (unsigned long)__sched_text_start
 		&& addr < (unsigned long)__sched_text_end);
@@ -5953,7 +6233,9 @@ void __init sched_init(void)
 #ifdef CONFIG_SMP
 	/* May be allocated at isolcpus cmdline parse time */
 	if (cpu_isolated_map == NULL)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		zalloc_cpumask_var(&cpu_isolated_map, GFP_NOWAIT);
+}
 	idle_thread_set_boot_cpu();
 	set_cpu_rq_start_time(smp_processor_id());
 #endif
@@ -6048,6 +6330,7 @@ void normalize_rt_tasks(void)
 	};
 
 	read_lock(&tasklist_lock);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for_each_process_thread(g, p) {
 		/*
 		 * Only normalize user tasks:
@@ -6145,7 +6428,9 @@ struct task_group *sched_create_group(struct task_group *parent)
 
 	tg = kmem_cache_alloc(task_group_cache, GFP_KERNEL | __GFP_ZERO);
 	if (!tg)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ERR_PTR(-ENOMEM);
+}
 
 	if (!alloc_fair_sched_group(tg, parent))
 		goto err;
@@ -6153,6 +6438,7 @@ struct task_group *sched_create_group(struct task_group *parent)
 	if (!alloc_rt_sched_group(tg, parent))
 		goto err;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return tg;
 
 err:
@@ -6269,6 +6555,7 @@ static inline struct task_group *css_tg(struct cgroup_subsys_state *css)
 static struct cgroup_subsys_state *
 cpu_cgroup_css_alloc(struct cgroup_subsys_state *parent_css)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct task_group *parent = css_tg(parent_css);
 	struct task_group *tg;
 
@@ -6279,7 +6566,9 @@ cpu_cgroup_css_alloc(struct cgroup_subsys_state *parent_css)
 
 	tg = sched_create_group(parent);
 	if (IS_ERR(tg))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ERR_PTR(-ENOMEM);
+}
 
 	return &tg->css;
 }
@@ -6287,6 +6576,7 @@ cpu_cgroup_css_alloc(struct cgroup_subsys_state *parent_css)
 /* Expose task group only after completing cgroup initialization */
 static int cpu_cgroup_css_online(struct cgroup_subsys_state *css)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct task_group *tg = css_tg(css);
 	struct task_group *parent = css_tg(css->parent);
 
@@ -6297,6 +6587,7 @@ static int cpu_cgroup_css_online(struct cgroup_subsys_state *css)
 
 static void cpu_cgroup_css_released(struct cgroup_subsys_state *css)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct task_group *tg = css_tg(css);
 
 	sched_offline_group(tg);
@@ -6304,6 +6595,7 @@ static void cpu_cgroup_css_released(struct cgroup_subsys_state *css)
 
 static void cpu_cgroup_css_free(struct cgroup_subsys_state *css)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct task_group *tg = css_tg(css);
 
 	/*
@@ -6342,7 +6634,9 @@ static int cpu_cgroup_can_attach(struct cgroup_taskset *tset)
 #else
 		/* We don't support RT-tasks being in separate groups */
 		if (task->sched_class != &fair_sched_class)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -EINVAL;
+}
 #endif
 		/*
 		 * Serialize against wake_up_new_task() such that if its
@@ -6355,12 +6649,15 @@ static int cpu_cgroup_can_attach(struct cgroup_taskset *tset)
 		 * move wanting to detach+attach while we're not attached yet.
 		 */
 		if (task->state == TASK_NEW)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			ret = -EINVAL;
+}
 		raw_spin_unlock_irq(&task->pi_lock);
 
 		if (ret)
 			break;
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return ret;
 }
 
@@ -6377,12 +6674,14 @@ static void cpu_cgroup_attach(struct cgroup_taskset *tset)
 static int cpu_shares_write_u64(struct cgroup_subsys_state *css,
 				struct cftype *cftype, u64 shareval)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return sched_group_set_shares(css_tg(css), scale_load(shareval));
 }
 
 static u64 cpu_shares_read_u64(struct cgroup_subsys_state *css,
 			       struct cftype *cft)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct task_group *tg = css_tg(css);
 
 	return (u64) scale_load_down(tg->shares);
@@ -6715,6 +7014,7 @@ struct cgroup_subsys cpu_cgrp_subsys = {
 
 void dump_cpu_task(int cpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pr_info("Task dump for CPU %d:\n", cpu);
 	sched_show_task(cpu_curr(cpu));
 }
diff --git a/kernel/sched/cpuacct.c b/kernel/sched/cpuacct.c
index 44ab32a..4f50f66 100644
--- a/kernel/sched/cpuacct.c
+++ b/kernel/sched/cpuacct.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 #include <linux/cgroup.h>
 #include <linux/slab.h>
@@ -56,6 +58,7 @@ static inline struct cpuacct *task_ca(struct task_struct *tsk)
 
 static inline struct cpuacct *parent_ca(struct cpuacct *ca)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return css_ca(ca->css.parent);
 }
 
@@ -72,7 +75,9 @@ cpuacct_css_alloc(struct cgroup_subsys_state *parent_css)
 	struct cpuacct *ca;
 
 	if (!parent_css)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return &root_cpuacct.css;
+}
 
 	ca = kzalloc(sizeof(*ca), GFP_KERNEL);
 	if (!ca)
@@ -99,6 +104,7 @@ cpuacct_css_alloc(struct cgroup_subsys_state *parent_css)
 /* destroy an existing cpu accounting group */
 static void cpuacct_css_free(struct cgroup_subsys_state *css)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cpuacct *ca = css_ca(css);
 
 	free_percpu(ca->cpustat);
@@ -109,6 +115,7 @@ static void cpuacct_css_free(struct cgroup_subsys_state *css)
 static u64 cpuacct_cpuusage_read(struct cpuacct *ca, int cpu,
 				 enum cpuacct_stat_index index)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cpuacct_usage *cpuusage = per_cpu_ptr(ca->cpuusage, cpu);
 	u64 data;
 
@@ -144,6 +151,7 @@ static u64 cpuacct_cpuusage_read(struct cpuacct *ca, int cpu,
 
 static void cpuacct_cpuusage_write(struct cpuacct *ca, int cpu, u64 val)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cpuacct_usage *cpuusage = per_cpu_ptr(ca->cpuusage, cpu);
 	int i;
 
@@ -166,6 +174,7 @@ static void cpuacct_cpuusage_write(struct cpuacct *ca, int cpu, u64 val)
 static u64 __cpuusage_read(struct cgroup_subsys_state *css,
 			   enum cpuacct_stat_index index)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cpuacct *ca = css_ca(css);
 	u64 totalcpuusage = 0;
 	int i;
@@ -179,23 +188,27 @@ static u64 __cpuusage_read(struct cgroup_subsys_state *css,
 static u64 cpuusage_user_read(struct cgroup_subsys_state *css,
 			      struct cftype *cft)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return __cpuusage_read(css, CPUACCT_STAT_USER);
 }
 
 static u64 cpuusage_sys_read(struct cgroup_subsys_state *css,
 			     struct cftype *cft)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return __cpuusage_read(css, CPUACCT_STAT_SYSTEM);
 }
 
 static u64 cpuusage_read(struct cgroup_subsys_state *css, struct cftype *cft)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return __cpuusage_read(css, CPUACCT_STAT_NSTATS);
 }
 
 static int cpuusage_write(struct cgroup_subsys_state *css, struct cftype *cft,
 			  u64 val)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cpuacct *ca = css_ca(css);
 	int cpu;
 
@@ -214,6 +227,7 @@ static int cpuusage_write(struct cgroup_subsys_state *css, struct cftype *cft,
 static int __cpuacct_percpu_seq_show(struct seq_file *m,
 				     enum cpuacct_stat_index index)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cpuacct *ca = css_ca(seq_css(m));
 	u64 percpu;
 	int i;
@@ -228,21 +242,25 @@ static int __cpuacct_percpu_seq_show(struct seq_file *m,
 
 static int cpuacct_percpu_user_seq_show(struct seq_file *m, void *V)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return __cpuacct_percpu_seq_show(m, CPUACCT_STAT_USER);
 }
 
 static int cpuacct_percpu_sys_seq_show(struct seq_file *m, void *V)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return __cpuacct_percpu_seq_show(m, CPUACCT_STAT_SYSTEM);
 }
 
 static int cpuacct_percpu_seq_show(struct seq_file *m, void *V)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return __cpuacct_percpu_seq_show(m, CPUACCT_STAT_NSTATS);
 }
 
 static int cpuacct_all_seq_show(struct seq_file *m, void *V)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cpuacct *ca = css_ca(seq_css(m));
 	int index;
 	int cpu;
@@ -279,6 +297,7 @@ static int cpuacct_all_seq_show(struct seq_file *m, void *V)
 
 static int cpuacct_stats_show(struct seq_file *sf, void *v)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cpuacct *ca = css_ca(seq_css(sf));
 	s64 val[CPUACCT_STAT_NSTATS];
 	int cpu;
@@ -353,13 +372,17 @@ void cpuacct_charge(struct task_struct *tsk, u64 cputime)
 	struct pt_regs *regs = task_pt_regs(tsk);
 
 	if (regs && user_mode(regs))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		index = CPUACCT_STAT_USER;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rcu_read_lock();
 
 	for (ca = task_ca(tsk); ca; ca = parent_ca(ca))
 		this_cpu_ptr(ca->cpuusage)->usages[index] += cputime;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rcu_read_unlock();
 }
 
@@ -375,6 +398,7 @@ void cpuacct_account_field(struct task_struct *tsk, int index, u64 val)
 	rcu_read_lock();
 	for (ca = task_ca(tsk); ca != &root_cpuacct; ca = parent_ca(ca))
 		this_cpu_ptr(ca->cpustat)->cpustat[index] += val;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rcu_read_unlock();
 }
 
diff --git a/kernel/sched/cpudeadline.c b/kernel/sched/cpudeadline.c
index 8d9562d..6a7c7b3 100644
--- a/kernel/sched/cpudeadline.c
+++ b/kernel/sched/cpudeadline.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  *  kernel/sched/cpudl.c
  *
@@ -18,16 +20,19 @@
 
 static inline int parent(int i)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return (i - 1) >> 1;
 }
 
 static inline int left_child(int i)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return (i << 1) + 1;
 }
 
 static inline int right_child(int i)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return (i << 1) + 2;
 }
 
@@ -39,7 +44,9 @@ static void cpudl_heapify_down(struct cpudl *cp, int idx)
 	u64 orig_dl = cp->elements[idx].dl;
 
 	if (left_child(idx) >= cp->size)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	/* adapted from lib/prio_heap.c */
 	while(1) {
@@ -81,7 +88,9 @@ static void cpudl_heapify_up(struct cpudl *cp, int idx)
 	u64 orig_dl = cp->elements[idx].dl;
 
 	if (idx == 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	do {
 		p = parent(idx);
@@ -101,6 +110,7 @@ static void cpudl_heapify_up(struct cpudl *cp, int idx)
 
 static void cpudl_heapify(struct cpudl *cp, int idx)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (idx > 0 && dl_time_before(cp->elements[parent(idx)].dl,
 				cp->elements[idx].dl))
 		cpudl_heapify_up(cp, idx);
@@ -110,6 +120,7 @@ static void cpudl_heapify(struct cpudl *cp, int idx)
 
 static inline int cpudl_maximum(struct cpudl *cp)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return cp->elements[0].cpu;
 }
 
@@ -170,6 +181,7 @@ void cpudl_clear(struct cpudl *cp, int cpu)
 		 * called for a CPU without -dl tasks running.
 		 */
 	} else {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		new_cpu = cp->elements[cp->size - 1].cpu;
 		cp->elements[old_idx].dl = cp->elements[cp->size - 1].dl;
 		cp->elements[old_idx].cpu = new_cpu;
@@ -198,6 +210,7 @@ void cpudl_set(struct cpudl *cp, int cpu, u64 dl)
 	int old_idx;
 	unsigned long flags;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WARN_ON(!cpu_present(cpu));
 
 	raw_spin_lock_irqsave(&cp->lock, flags);
@@ -253,9 +266,12 @@ int cpudl_init(struct cpudl *cp)
 			       sizeof(struct cpudl_item),
 			       GFP_KERNEL);
 	if (!cp->elements)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 
 	if (!zalloc_cpumask_var(&cp->free_cpus, GFP_KERNEL)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		kfree(cp->elements);
 		return -ENOMEM;
 	}
@@ -263,6 +279,7 @@ int cpudl_init(struct cpudl *cp)
 	for_each_possible_cpu(i)
 		cp->elements[i].idx = IDX_INVALID;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
@@ -272,6 +289,7 @@ int cpudl_init(struct cpudl *cp)
  */
 void cpudl_cleanup(struct cpudl *cp)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	free_cpumask_var(cp->free_cpus);
 	kfree(cp->elements);
 }
diff --git a/kernel/sched/cpupri.c b/kernel/sched/cpupri.c
index 2511aba..76f6e23 100644
--- a/kernel/sched/cpupri.c
+++ b/kernel/sched/cpupri.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  *  kernel/sched/cpupri.c
  *
@@ -39,11 +41,17 @@ static int convert_prio(int prio)
 	int cpupri;
 
 	if (prio == CPUPRI_INVALID)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		cpupri = CPUPRI_INVALID;
+}
 	else if (prio == MAX_PRIO)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		cpupri = CPUPRI_IDLE;
+}
 	else if (prio >= MAX_RT_PRIO)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		cpupri = CPUPRI_NORMAL;
+}
 	else
 		cpupri = MAX_RT_PRIO - prio + 1;
 
@@ -71,6 +79,7 @@ int cpupri_find(struct cpupri *cp, struct task_struct *p,
 	int idx = 0;
 	int task_pri = convert_prio(p->prio);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	BUG_ON(task_pri >= CPUPRI_NR_PRIORITIES);
 
 	for (idx = 0; idx < task_pri; idx++) {
@@ -148,7 +157,9 @@ void cpupri_set(struct cpupri *cp, int cpu, int newpri)
 	BUG_ON(newpri >= CPUPRI_NR_PRIORITIES);
 
 	if (newpri == oldpri)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	/*
 	 * If the cpu was currently mapped to a different value, we
@@ -224,11 +235,15 @@ int cpupri_init(struct cpupri *cp)
 	for_each_possible_cpu(i)
 		cp->cpu_to_pri[i] = CPUPRI_INVALID;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 
 cleanup:
 	for (i--; i >= 0; i--)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		free_cpumask_var(cp->pri_to_cpu[i].mask);
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return -ENOMEM;
 }
 
@@ -241,6 +256,7 @@ void cpupri_cleanup(struct cpupri *cp)
 	int i;
 
 	kfree(cp->cpu_to_pri);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (i = 0; i < CPUPRI_NR_PRIORITIES; i++)
 		free_cpumask_var(cp->pri_to_cpu[i].mask);
 }
diff --git a/kernel/sched/cputime.c b/kernel/sched/cputime.c
index 14d2dbf..fe756a1 100644
--- a/kernel/sched/cputime.c
+++ b/kernel/sched/cputime.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 #include <linux/export.h>
 #include <linux/sched.h>
 #include <linux/tsacct_kern.h>
@@ -93,6 +95,7 @@ static u64 irqtime_tick_accounted(u64 maxtime)
 
 static u64 irqtime_tick_accounted(u64 dummy)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
@@ -141,6 +144,7 @@ void account_user_time(struct task_struct *p, u64 cputime)
  */
 void account_guest_time(struct task_struct *p, u64 cputime)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	u64 *cpustat = kcpustat_this_cpu->cpustat;
 
 	/* Add guest time to process. */
@@ -189,14 +193,19 @@ void account_system_time(struct task_struct *p, int hardirq_offset, u64 cputime)
 	int index;
 
 	if ((p->flags & PF_VCPU) && (irq_count() - hardirq_offset == 0)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		account_guest_time(p, cputime);
 		return;
 	}
 
 	if (hardirq_count() - hardirq_offset)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		index = CPUTIME_IRQ;
+}
 	else if (in_serving_softirq())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		index = CPUTIME_SOFTIRQ;
+}
 	else
 		index = CPUTIME_SYSTEM;
 
@@ -209,6 +218,7 @@ void account_system_time(struct task_struct *p, int hardirq_offset, u64 cputime)
  */
 void account_steal_time(u64 cputime)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	u64 *cpustat = kcpustat_this_cpu->cpustat;
 
 	cpustat[CPUTIME_STEAL] += cputime;
@@ -313,6 +323,7 @@ void thread_group_cputime(struct task_struct *tsk, struct task_cputime *times)
 	if (same_thread_group(current, tsk))
 		(void) task_sched_runtime(current);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rcu_read_lock();
 	/* Attempt a lockless read on the first round. */
 	nextseq = 0;
@@ -324,6 +335,7 @@ void thread_group_cputime(struct task_struct *tsk, struct task_cputime *times)
 		times->sum_exec_runtime = sig->sum_sched_runtime;
 
 		for_each_thread(tsk, t) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			task_cputime(t, &utime, &stime);
 			times->utime += utime;
 			times->stime += stime;
diff --git a/kernel/sched/deadline.c b/kernel/sched/deadline.c
index 4ae5c1e..69a730d 100644
--- a/kernel/sched/deadline.c
+++ b/kernel/sched/deadline.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 /*
  * Deadline Scheduling Class (SCHED_DEADLINE)
@@ -24,16 +26,19 @@ struct dl_bandwidth def_dl_bandwidth;
 
 static inline struct task_struct *dl_task_of(struct sched_dl_entity *dl_se)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return container_of(dl_se, struct task_struct, dl);
 }
 
 static inline struct rq *rq_of_dl_rq(struct dl_rq *dl_rq)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return container_of(dl_rq, struct rq, dl);
 }
 
 static inline struct dl_rq *dl_rq_of_se(struct sched_dl_entity *dl_se)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct task_struct *p = dl_task_of(dl_se);
 	struct rq *rq = task_rq(p);
 
@@ -42,12 +47,14 @@ static inline struct dl_rq *dl_rq_of_se(struct sched_dl_entity *dl_se)
 
 static inline int on_dl_rq(struct sched_dl_entity *dl_se)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return !RB_EMPTY_NODE(&dl_se->rb_node);
 }
 
 #ifdef CONFIG_SMP
 static inline struct dl_bw *dl_bw_of(int i)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	RCU_LOCKDEP_WARN(!rcu_read_lock_sched_held(),
 			 "sched RCU must be held");
 	return &cpu_rq(i)->rd->dl_bw;
@@ -55,6 +62,7 @@ static inline struct dl_bw *dl_bw_of(int i)
 
 static inline int dl_bw_cpus(int i)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct root_domain *rd = cpu_rq(i)->rd;
 	int cpus = 0;
 
@@ -82,6 +90,7 @@ void add_running_bw(u64 dl_bw, struct dl_rq *dl_rq)
 {
 	u64 old = dl_rq->running_bw;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&(rq_of_dl_rq(dl_rq))->lock);
 	dl_rq->running_bw += dl_bw;
 	SCHED_WARN_ON(dl_rq->running_bw < old); /* overflow */
@@ -93,6 +102,7 @@ void sub_running_bw(u64 dl_bw, struct dl_rq *dl_rq)
 {
 	u64 old = dl_rq->running_bw;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&(rq_of_dl_rq(dl_rq))->lock);
 	dl_rq->running_bw -= dl_bw;
 	SCHED_WARN_ON(dl_rq->running_bw > old); /* underflow */
@@ -105,6 +115,7 @@ void add_rq_bw(u64 dl_bw, struct dl_rq *dl_rq)
 {
 	u64 old = dl_rq->this_bw;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&(rq_of_dl_rq(dl_rq))->lock);
 	dl_rq->this_bw += dl_bw;
 	SCHED_WARN_ON(dl_rq->this_bw < old); /* overflow */
@@ -115,6 +126,7 @@ void sub_rq_bw(u64 dl_bw, struct dl_rq *dl_rq)
 {
 	u64 old = dl_rq->this_bw;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&(rq_of_dl_rq(dl_rq))->lock);
 	dl_rq->this_bw -= dl_bw;
 	SCHED_WARN_ON(dl_rq->this_bw > old); /* underflow */
@@ -128,7 +140,9 @@ void dl_change_utilization(struct task_struct *p, u64 new_bw)
 	struct rq *rq;
 
 	if (task_on_rq_queued(p))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	rq = task_rq(p);
 	if (p->dl.dl_non_contending) {
@@ -215,7 +229,9 @@ static void task_non_contending(struct task_struct *p)
 	 * do nothing
 	 */
 	if (dl_se->dl_runtime == 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	WARN_ON(hrtimer_active(&dl_se->inactive_timer));
 	WARN_ON(dl_se->dl_non_contending);
@@ -258,6 +274,7 @@ static void task_non_contending(struct task_struct *p)
 
 static void task_contending(struct sched_dl_entity *dl_se, int flags)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct dl_rq *dl_rq = dl_rq_of_se(dl_se);
 
 	/*
@@ -312,9 +329,12 @@ void init_dl_bw(struct dl_bw *dl_b)
 	raw_spin_lock_init(&dl_b->lock);
 	raw_spin_lock(&def_dl_bandwidth.dl_runtime_lock);
 	if (global_rt_runtime() == RUNTIME_INF)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		dl_b->bw = -1;
+}
 	else
 		dl_b->bw = to_ratio(global_rt_period(), global_rt_runtime());
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	raw_spin_unlock(&def_dl_bandwidth.dl_runtime_lock);
 	dl_b->total_bw = 0;
 }
@@ -343,11 +363,13 @@ void init_dl_rq(struct dl_rq *dl_rq)
 
 static inline int dl_overloaded(struct rq *rq)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return atomic_read(&rq->rd->dlo_count);
 }
 
 static inline void dl_set_overload(struct rq *rq)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!rq->online)
 		return;
 
@@ -364,6 +386,7 @@ static inline void dl_set_overload(struct rq *rq)
 
 static inline void dl_clear_overload(struct rq *rq)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!rq->online)
 		return;
 
@@ -373,6 +396,7 @@ static inline void dl_clear_overload(struct rq *rq)
 
 static void update_dl_migration(struct dl_rq *dl_rq)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (dl_rq->dl_nr_migratory && dl_rq->dl_nr_running > 1) {
 		if (!dl_rq->overloaded) {
 			dl_set_overload(rq_of_dl_rq(dl_rq));
@@ -386,6 +410,7 @@ static void update_dl_migration(struct dl_rq *dl_rq)
 
 static void inc_dl_migration(struct sched_dl_entity *dl_se, struct dl_rq *dl_rq)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct task_struct *p = dl_task_of(dl_se);
 
 	if (p->nr_cpus_allowed > 1)
@@ -396,6 +421,7 @@ static void inc_dl_migration(struct sched_dl_entity *dl_se, struct dl_rq *dl_rq)
 
 static void dec_dl_migration(struct sched_dl_entity *dl_se, struct dl_rq *dl_rq)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct task_struct *p = dl_task_of(dl_se);
 
 	if (p->nr_cpus_allowed > 1)
@@ -416,6 +442,7 @@ static void enqueue_pushable_dl_task(struct rq *rq, struct task_struct *p)
 	struct task_struct *entry;
 	bool leftmost = true;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	BUG_ON(!RB_EMPTY_NODE(&p->pushable_dl_tasks));
 
 	while (*link) {
@@ -443,7 +470,9 @@ static void dequeue_pushable_dl_task(struct rq *rq, struct task_struct *p)
 	struct dl_rq *dl_rq = &rq->dl;
 
 	if (RB_EMPTY_NODE(&p->pushable_dl_tasks))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	if (dl_rq->pushable_dl_tasks_root.rb_leftmost == &p->pushable_dl_tasks) {
 		struct rb_node *next_node;
@@ -461,6 +490,7 @@ static void dequeue_pushable_dl_task(struct rq *rq, struct task_struct *p)
 
 static inline int has_pushable_dl_tasks(struct rq *rq)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return !RB_EMPTY_ROOT(&rq->dl.pushable_dl_tasks_root.rb_root);
 }
 
@@ -479,6 +509,7 @@ static void pull_dl_task(struct rq *);
 
 static inline void queue_push_tasks(struct rq *rq)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!has_pushable_dl_tasks(rq))
 		return;
 
@@ -487,6 +518,7 @@ static inline void queue_push_tasks(struct rq *rq)
 
 static inline void queue_pull_task(struct rq *rq)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	queue_balance_callback(rq, &per_cpu(dl_pull_head, rq->cpu), pull_dl_task);
 }
 
@@ -588,6 +620,7 @@ static void check_preempt_curr_dl(struct rq *rq, struct task_struct *p,
  */
 static inline void setup_new_dl_entity(struct sched_dl_entity *dl_se)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct dl_rq *dl_rq = dl_rq_of_se(dl_se);
 	struct rq *rq = rq_of_dl_rq(dl_rq);
 
@@ -632,6 +665,7 @@ static inline void setup_new_dl_entity(struct sched_dl_entity *dl_se)
 static void replenish_dl_entity(struct sched_dl_entity *dl_se,
 				struct sched_dl_entity *pi_se)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct dl_rq *dl_rq = dl_rq_of_se(dl_se);
 	struct rq *rq = rq_of_dl_rq(dl_rq);
 
@@ -756,6 +790,7 @@ static bool dl_entity_overflow(struct sched_dl_entity *dl_se,
 static void
 update_dl_revised_wakeup(struct sched_dl_entity *dl_se, struct rq *rq)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	u64 laxity = dl_se->deadline - rq_clock(rq);
 
 	/*
@@ -782,6 +817,7 @@ update_dl_revised_wakeup(struct sched_dl_entity *dl_se, struct rq *rq)
  */
 static inline bool dl_is_implicit(struct sched_dl_entity *dl_se)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return dl_se->dl_deadline == dl_se->dl_period;
 }
 
@@ -818,6 +854,7 @@ static inline bool dl_is_implicit(struct sched_dl_entity *dl_se)
 static void update_dl_entity(struct sched_dl_entity *dl_se,
 			     struct sched_dl_entity *pi_se)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct dl_rq *dl_rq = dl_rq_of_se(dl_se);
 	struct rq *rq = rq_of_dl_rq(dl_rq);
 
@@ -838,6 +875,7 @@ static void update_dl_entity(struct sched_dl_entity *dl_se,
 
 static inline u64 dl_next_period(struct sched_dl_entity *dl_se)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return dl_se->deadline - dl_se->dl_deadline + dl_se->dl_period;
 }
 
@@ -855,6 +893,7 @@ static int start_dl_timer(struct task_struct *p)
 {
 	struct sched_dl_entity *dl_se = &p->dl;
 	struct hrtimer *timer = &dl_se->dl_timer;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct rq *rq = task_rq(p);
 	ktime_t now, act;
 	s64 delta;
@@ -2345,6 +2384,7 @@ const struct sched_class dl_sched_class = {
 
 int sched_dl_global_validate(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	u64 runtime = global_rt_runtime();
 	u64 period = global_rt_period();
 	u64 new_bw = to_ratio(period, runtime);
@@ -2382,6 +2422,7 @@ int sched_dl_global_validate(void)
 void init_dl_rq_bw_ratio(struct dl_rq *dl_rq)
 {
 	if (global_rt_runtime() == RUNTIME_INF) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		dl_rq->bw_ratio = 1 << RATIO_SHIFT;
 		dl_rq->extra_bw = 1 << BW_SHIFT;
 	} else {
@@ -2403,7 +2444,9 @@ void sched_dl_do_global(void)
 	def_dl_bandwidth.dl_runtime = global_rt_runtime();
 
 	if (global_rt_runtime() != RUNTIME_INF)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		new_bw = to_ratio(global_rt_period(), global_rt_runtime());
+}
 
 	/*
 	 * FIXME: As above...
@@ -2432,6 +2475,7 @@ void sched_dl_do_global(void)
 int sched_dl_overflow(struct task_struct *p, int policy,
 		      const struct sched_attr *attr)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct dl_bw *dl_b = dl_bw_of(task_cpu(p));
 	u64 period = attr->sched_period ?: attr->sched_deadline;
 	u64 runtime = attr->sched_runtime;
@@ -2495,6 +2539,7 @@ void __setparam_dl(struct task_struct *p, const struct sched_attr *attr)
 
 	dl_se->dl_runtime = attr->sched_runtime;
 	dl_se->dl_deadline = attr->sched_deadline;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	dl_se->dl_period = attr->sched_period ?: dl_se->dl_deadline;
 	dl_se->flags = attr->sched_flags;
 	dl_se->dl_bw = to_ratio(dl_se->dl_period, dl_se->dl_runtime);
@@ -2587,6 +2632,7 @@ bool dl_param_changed(struct task_struct *p, const struct sched_attr *attr)
 #ifdef CONFIG_SMP
 int dl_task_can_attach(struct task_struct *p, const struct cpumask *cs_cpus_allowed)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	unsigned int dest_cpu = cpumask_any_and(cpu_active_mask,
 							cs_cpus_allowed);
 	struct dl_bw *dl_b;
@@ -2627,6 +2673,7 @@ int dl_cpuset_cpumask_can_shrink(const struct cpumask *cur,
 	cur_dl_b = dl_bw_of(cpumask_any(cur));
 	trial_cpus = cpumask_weight(trial);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	raw_spin_lock_irqsave(&cur_dl_b->lock, flags);
 	if (cur_dl_b->bw != -1 &&
 	    cur_dl_b->bw * trial_cpus < cur_dl_b->total_bw)
@@ -2645,6 +2692,7 @@ bool dl_cpu_busy(unsigned int cpu)
 
 	rcu_read_lock_sched();
 	dl_b = dl_bw_of(cpu);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	raw_spin_lock_irqsave(&dl_b->lock, flags);
 	cpus = dl_bw_cpus(cpu);
 	overflow = __dl_overflow(dl_b, cpus, 0, 0);
diff --git a/kernel/sched/debug.c b/kernel/sched/debug.c
index 2f93e4a..c167765 100644
--- a/kernel/sched/debug.c
+++ b/kernel/sched/debug.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * kernel/sched/debug.c
  *
diff --git a/kernel/sched/fair.c b/kernel/sched/fair.c
index 5c09ddf..face804 100644
--- a/kernel/sched/fair.c
+++ b/kernel/sched/fair.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 /*
  * Completely Fair Scheduling (CFS) Class (SCHED_NORMAL/SCHED_BATCH)
@@ -106,6 +108,7 @@ const_debug unsigned int sysctl_sched_migration_cost	= 500000UL;
  */
 int __weak arch_asym_cpu_priority(int cpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return -cpu;
 }
 #endif
@@ -205,14 +208,20 @@ static void __update_inv_weight(struct load_weight *lw)
 	unsigned long w;
 
 	if (likely(lw->inv_weight))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	w = scale_load_down(lw->weight);
 
 	if (BITS_PER_LONG > 32 && unlikely(w >= WMULT_CONST))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		lw->inv_weight = 1;
+}
 	else if (unlikely(!w))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		lw->inv_weight = WMULT_CONST;
+}
 	else
 		lw->inv_weight = WMULT_CONST / w;
 }
@@ -237,7 +246,9 @@ static u64 __calc_delta(u64 delta_exec, unsigned long weight, struct load_weight
 	__update_inv_weight(lw);
 
 	if (unlikely(fact >> 32)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		while (fact >> 32) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			fact >>= 1;
 			shift--;
 		}
@@ -266,6 +277,7 @@ const struct sched_class fair_sched_class;
 /* cpu runqueue to which this cfs_rq is attached */
 static inline struct rq *rq_of(struct cfs_rq *cfs_rq)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return cfs_rq->rq;
 }
 
@@ -290,18 +302,21 @@ static inline struct cfs_rq *task_cfs_rq(struct task_struct *p)
 /* runqueue on which this entity is (to be) queued */
 static inline struct cfs_rq *cfs_rq_of(struct sched_entity *se)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return se->cfs_rq;
 }
 
 /* runqueue "owned" by this group */
 static inline struct cfs_rq *group_cfs_rq(struct sched_entity *grp)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return grp->my_q;
 }
 
 static inline void list_add_leaf_cfs_rq(struct cfs_rq *cfs_rq)
 {
 	if (!cfs_rq->on_list) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		struct rq *rq = rq_of(cfs_rq);
 		int cpu = cpu_of(rq);
 		/*
@@ -379,13 +394,17 @@ static inline struct cfs_rq *
 is_same_group(struct sched_entity *se, struct sched_entity *pse)
 {
 	if (se->cfs_rq == pse->cfs_rq)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return se->cfs_rq;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return NULL;
 }
 
 static inline struct sched_entity *parent_entity(struct sched_entity *se)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return se->parent;
 }
 
@@ -491,8 +510,11 @@ static inline u64 max_vruntime(u64 max_vruntime, u64 vruntime)
 {
 	s64 delta = (s64)(vruntime - max_vruntime);
 	if (delta > 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		max_vruntime = vruntime;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return max_vruntime;
 }
 
@@ -500,8 +522,11 @@ static inline u64 min_vruntime(u64 min_vruntime, u64 vruntime)
 {
 	s64 delta = (s64)(vruntime - min_vruntime);
 	if (delta < 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		min_vruntime = vruntime;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return min_vruntime;
 }
 
@@ -527,6 +552,7 @@ static void update_min_vruntime(struct cfs_rq *cfs_rq)
 
 	if (leftmost) { /* non-empty tree */
 		struct sched_entity *se;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		se = rb_entry(leftmost, struct sched_entity, run_node);
 
 		if (!curr)
@@ -557,7 +583,9 @@ static void __enqueue_entity(struct cfs_rq *cfs_rq, struct sched_entity *se)
 	 * Find the right place in the rbtree:
 	 */
 	while (*link) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		parent = *link;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		entry = rb_entry(parent, struct sched_entity, run_node);
 		/*
 		 * We dont care about collisions. Nodes with
@@ -586,7 +614,9 @@ struct sched_entity *__pick_first_entity(struct cfs_rq *cfs_rq)
 	struct rb_node *left = rb_first_cached(&cfs_rq->tasks_timeline);
 
 	if (!left)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 
 	return rb_entry(left, struct sched_entity, run_node);
 }
@@ -596,7 +626,9 @@ static struct sched_entity *__pick_next_entity(struct sched_entity *se)
 	struct rb_node *next = rb_next(&se->run_node);
 
 	if (!next)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 
 	return rb_entry(next, struct sched_entity, run_node);
 }
@@ -771,6 +803,7 @@ static void attach_entity_cfs_rq(struct sched_entity *se);
  */
 void post_init_entity_util_avg(struct sched_entity *se)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cfs_rq *cfs_rq = cfs_rq_of(se);
 	struct sched_avg *sa = &se->avg;
 	long cap = (long)(SCHED_CAPACITY_SCALE - cfs_rq->avg.util_avg) / 2;
@@ -831,18 +864,24 @@ static void update_curr(struct cfs_rq *cfs_rq)
 	u64 delta_exec;
 
 	if (unlikely(!curr))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	delta_exec = now - curr->exec_start;
 	if (unlikely((s64)delta_exec <= 0))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	curr->exec_start = now;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	schedstat_set(curr->statistics.exec_max,
 		      max(delta_exec, curr->statistics.exec_max));
 
 	curr->sum_exec_runtime += delta_exec;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	schedstat_add(cfs_rq->exec_clock, delta_exec);
 
 	curr->vruntime += calc_delta_fair(delta_exec, curr);
@@ -856,6 +895,7 @@ static void update_curr(struct cfs_rq *cfs_rq)
 		account_group_exec_runtime(curtask, delta_exec);
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	account_cfs_rq_runtime(cfs_rq, delta_exec);
 }
 
@@ -869,6 +909,7 @@ update_stats_wait_start(struct cfs_rq *cfs_rq, struct sched_entity *se)
 {
 	u64 wait_start, prev_wait_start;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!schedstat_enabled())
 		return;
 
@@ -888,6 +929,7 @@ update_stats_wait_end(struct cfs_rq *cfs_rq, struct sched_entity *se)
 	struct task_struct *p;
 	u64 delta;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!schedstat_enabled())
 		return;
 
@@ -920,6 +962,7 @@ update_stats_enqueue_sleeper(struct cfs_rq *cfs_rq, struct sched_entity *se)
 	struct task_struct *tsk = NULL;
 	u64 sleep_start, block_start;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!schedstat_enabled())
 		return;
 
@@ -988,6 +1031,7 @@ update_stats_enqueue_sleeper(struct cfs_rq *cfs_rq, struct sched_entity *se)
 static inline void
 update_stats_enqueue(struct cfs_rq *cfs_rq, struct sched_entity *se, int flags)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!schedstat_enabled())
 		return;
 
@@ -1006,6 +1050,7 @@ static inline void
 update_stats_dequeue(struct cfs_rq *cfs_rq, struct sched_entity *se, int flags)
 {
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!schedstat_enabled())
 		return;
 
@@ -2669,6 +2714,7 @@ account_entity_enqueue(struct cfs_rq *cfs_rq, struct sched_entity *se)
 		update_load_add(&rq_of(cfs_rq)->load, se->load.weight);
 #ifdef CONFIG_SMP
 	if (entity_is_task(se)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		struct rq *rq = rq_of(cfs_rq);
 
 		account_numa_enqueue(rq, task_of(se));
@@ -2729,9 +2775,13 @@ static long calc_cfs_shares(struct cfs_rq *cfs_rq, struct task_group *tg)
 	 * instead of 0.
 	 */
 	if (shares < MIN_SHARES)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		shares = MIN_SHARES;
+}
 	if (shares > tg->shares)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		shares = tg->shares;
+}
 
 	return shares;
 }
@@ -2752,6 +2802,7 @@ static void reweight_entity(struct cfs_rq *cfs_rq, struct sched_entity *se,
 		account_entity_dequeue(cfs_rq, se);
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	update_load_set(&se->load, weight);
 
 	if (se->on_rq)
@@ -2762,15 +2813,20 @@ static inline int throttled_hierarchy(struct cfs_rq *cfs_rq);
 
 static void update_cfs_shares(struct sched_entity *se)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cfs_rq *cfs_rq = group_cfs_rq(se);
 	struct task_group *tg;
 	long shares;
 
 	if (!cfs_rq)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	if (throttled_hierarchy(cfs_rq))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	tg = cfs_rq->tg;
 
@@ -2791,6 +2847,7 @@ static inline void update_cfs_shares(struct sched_entity *se)
 
 static inline void cfs_rq_util_change(struct cfs_rq *cfs_rq)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct rq *rq = rq_of(cfs_rq);
 
 	if (&rq->cfs == cfs_rq) {
@@ -2824,7 +2881,9 @@ static u64 decay_load(u64 val, u64 n)
 	unsigned int local_n;
 
 	if (unlikely(n > LOAD_AVG_PERIOD * 63))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	/* after bounds checking we can collapse to 32-bit */
 	local_n = n;
@@ -2977,6 +3036,7 @@ ___update_load_avg(u64 now, int cpu, struct sched_avg *sa,
 	 * unfortunately does during sched clock init when we swap over to TSC.
 	 */
 	if ((s64)delta < 0) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		sa->last_update_time = now;
 		return 0;
 	}
@@ -2987,7 +3047,9 @@ ___update_load_avg(u64 now, int cpu, struct sched_avg *sa,
 	 */
 	delta >>= 10;
 	if (!delta)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	sa->last_update_time += delta << 10;
 
@@ -3001,7 +3063,9 @@ ___update_load_avg(u64 now, int cpu, struct sched_avg *sa,
 	 * update_blocked_averages()
 	 */
 	if (!weight)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		running = 0;
+}
 
 	/*
 	 * Now we know we crossed measurement unit boundaries. The *_avg
@@ -3011,7 +3075,9 @@ ___update_load_avg(u64 now, int cpu, struct sched_avg *sa,
 	 * crossed period boundaries, finish.
 	 */
 	if (!accumulate_sum(delta, cpu, sa, weight, running, cfs_rq))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	/*
 	 * Step 2: update *_avg.
@@ -3092,7 +3158,9 @@ static inline void update_tg_load_avg(struct cfs_rq *cfs_rq, int force)
 	 * No need to update load_avg for root_task_group as it is not used.
 	 */
 	if (cfs_rq->tg == &root_task_group)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	if (force || abs(delta) > cfs_rq->tg_load_avg_contrib / 64) {
 		atomic_long_add(delta, &cfs_rq->tg->load_avg);
@@ -3112,7 +3180,9 @@ void set_task_rq_fair(struct sched_entity *se,
 	u64 n_last_update_time;
 
 	if (!sched_feat(ATTACH_AGE_LOAD))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	/*
 	 * We are supposed to update the task to "current" time, then its up to
@@ -3122,7 +3192,9 @@ void set_task_rq_fair(struct sched_entity *se,
 	 * the wakee more load sounds not bad.
 	 */
 	if (!(se->avg.last_update_time && prev))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 #ifndef CONFIG_64BIT
 	{
@@ -3153,12 +3225,15 @@ void set_task_rq_fair(struct sched_entity *se,
 static inline void
 update_tg_cfs_util(struct cfs_rq *cfs_rq, struct sched_entity *se)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cfs_rq *gcfs_rq = group_cfs_rq(se);
 	long delta = gcfs_rq->avg.util_avg - se->avg.util_avg;
 
 	/* Nothing to update */
 	if (!delta)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	/* Set new sched_entity's utilization */
 	se->avg.util_avg = gcfs_rq->avg.util_avg;
@@ -3173,6 +3248,7 @@ update_tg_cfs_util(struct cfs_rq *cfs_rq, struct sched_entity *se)
 static inline void
 update_tg_cfs_load(struct cfs_rq *cfs_rq, struct sched_entity *se)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cfs_rq *gcfs_rq = group_cfs_rq(se);
 	long delta, load = gcfs_rq->avg.load_avg;
 
@@ -3211,7 +3287,9 @@ update_tg_cfs_load(struct cfs_rq *cfs_rq, struct sched_entity *se)
 
 	/* Nothing to update */
 	if (!delta)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	/* Set new sched_entity's load */
 	se->avg.load_avg = load;
@@ -3239,10 +3317,13 @@ static inline void set_tg_cfs_propagate(struct cfs_rq *cfs_rq)
 
 static inline int test_and_clear_tg_cfs_propagate(struct sched_entity *se)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cfs_rq *cfs_rq = group_cfs_rq(se);
 
 	if (!cfs_rq->propagate_avg)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	cfs_rq->propagate_avg = 0;
 	return 1;
@@ -3254,11 +3335,16 @@ static inline int propagate_entity_load_avg(struct sched_entity *se)
 	struct cfs_rq *cfs_rq;
 
 	if (entity_is_task(se))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	if (!test_and_clear_tg_cfs_propagate(se))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	cfs_rq = cfs_rq_of(se);
 
 	set_tg_cfs_propagate(cfs_rq);
@@ -3275,6 +3361,7 @@ static inline int propagate_entity_load_avg(struct sched_entity *se)
  */
 static inline bool skip_blocked_update(struct sched_entity *se)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cfs_rq *gcfs_rq = group_cfs_rq(se);
 
 	/*
@@ -3282,14 +3369,18 @@ static inline bool skip_blocked_update(struct sched_entity *se)
 	 * decay it:
 	 */
 	if (se->avg.load_avg || se->avg.util_avg)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return false;
+}
 
 	/*
 	 * If there is a pending propagation, we have to update the load and
 	 * the utilization of the sched_entity:
 	 */
 	if (gcfs_rq->propagate_avg)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return false;
+}
 
 	/*
 	 * Otherwise, the load and the utilization of the sched_entity is
@@ -5039,10 +5130,14 @@ decay_load_missed(unsigned long load, unsigned long missed_updates, int idx)
 	int j = 0;
 
 	if (!missed_updates)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return load;
+}
 
 	if (missed_updates >= degrade_zero_ticks[idx])
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	if (idx == 1)
 		return load >> missed_updates;
@@ -5054,6 +5149,7 @@ decay_load_missed(unsigned long load, unsigned long missed_updates, int idx)
 		missed_updates >>= 1;
 		j++;
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return load;
 }
 #endif /* CONFIG_NO_HZ_COMMON */
@@ -5139,6 +5235,7 @@ static void cpu_load_update(struct rq *this_rq, unsigned long this_load,
 /* Used instead of source_load when we know the type == 0 */
 static unsigned long weighted_cpuload(struct rq *rq)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return cfs_rq_runnable_load_avg(&rq->cfs);
 }
 
@@ -5221,6 +5318,7 @@ void cpu_load_update_nohz_stop(void)
 	if (curr_jiffies == this_rq->last_load_update_tick)
 		return;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	load = weighted_cpuload(this_rq);
 	rq_lock(this_rq, &rf);
 	update_rq_clock(this_rq);
@@ -5247,6 +5345,7 @@ static void cpu_load_update_periodic(struct rq *this_rq, unsigned long load)
  */
 void cpu_load_update_active(struct rq *this_rq)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	unsigned long load = weighted_cpuload(this_rq);
 
 	if (tick_nohz_tick_stopped())
@@ -5264,6 +5363,7 @@ void cpu_load_update_active(struct rq *this_rq)
  */
 static unsigned long source_load(int cpu, int type)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct rq *rq = cpu_rq(cpu);
 	unsigned long total = weighted_cpuload(rq);
 
@@ -5279,6 +5379,7 @@ static unsigned long source_load(int cpu, int type)
  */
 static unsigned long target_load(int cpu, int type)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct rq *rq = cpu_rq(cpu);
 	unsigned long total = weighted_cpuload(rq);
 
@@ -5290,6 +5391,7 @@ static unsigned long target_load(int cpu, int type)
 
 static unsigned long capacity_of(int cpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return cpu_rq(cpu)->cpu_capacity;
 }
 
@@ -5300,6 +5402,7 @@ static unsigned long capacity_orig_of(int cpu)
 
 static unsigned long cpu_avg_load_per_task(int cpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct rq *rq = cpu_rq(cpu);
 	unsigned long nr_running = READ_ONCE(rq->cfs.h_nr_running);
 	unsigned long load_avg = weighted_cpuload(rq);
@@ -5351,9 +5454,13 @@ static int wake_wide(struct task_struct *p)
 	int factor = this_cpu_read(sd_llc_size);
 
 	if (master < slave)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		swap(master, slave);
+}
 	if (slave < factor || master < slave * factor)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 	return 1;
 }
 
@@ -5374,6 +5481,7 @@ static bool
 wake_affine_idle(struct sched_domain *sd, struct task_struct *p,
 		 int this_cpu, int prev_cpu, int sync)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (idle_cpu(this_cpu))
 		return true;
 
@@ -5394,6 +5502,7 @@ wake_affine_weight(struct sched_domain *sd, struct task_struct *p,
 	prev_eff_load = source_load(prev_cpu, sd->wake_idx);
 
 	if (sync) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		unsigned long current_load = task_h_load(current);
 
 		if (current_load > this_eff_load)
@@ -5420,6 +5529,7 @@ wake_affine_weight(struct sched_domain *sd, struct task_struct *p,
 static int wake_affine(struct sched_domain *sd, struct task_struct *p,
 		       int prev_cpu, int sync)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	int this_cpu = smp_processor_id();
 	bool affine = false;
 
@@ -5443,6 +5553,7 @@ static int cpu_util_wake(int cpu, struct task_struct *p);
 
 static unsigned long capacity_spare_wake(int cpu, struct task_struct *p)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return capacity_orig_of(cpu) - cpu_util_wake(cpu, p);
 }
 
@@ -5465,7 +5576,9 @@ find_idlest_group(struct sched_domain *sd, struct task_struct *p,
 				(sd->imbalance_pct-100) / 100;
 
 	if (sd_flag & SD_BALANCE_WAKE)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		load_idx = sd->wake_idx;
+}
 
 	do {
 		unsigned long load, avg_load, runnable_load;
@@ -5592,7 +5705,9 @@ find_idlest_cpu(struct sched_group *group, struct task_struct *p, int this_cpu)
 
 	/* Check if we have any choice: */
 	if (group->group_weight == 1)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return cpumask_first(sched_group_span(group));
+}
 
 	/* Traverse only the allowed CPUs */
 	for_each_cpu_and(i, sched_group_span(group), &p->cpus_allowed) {
@@ -5636,6 +5751,7 @@ static inline void set_idle_cores(int cpu, int val)
 {
 	struct sched_domain_shared *sds;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	sds = rcu_dereference(per_cpu(sd_llc_shared, cpu));
 	if (sds)
 		WRITE_ONCE(sds->has_idle_cores, val);
@@ -5645,6 +5761,7 @@ static inline bool test_idle_cores(int cpu, bool def)
 {
 	struct sched_domain_shared *sds;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	sds = rcu_dereference(per_cpu(sd_llc_shared, cpu));
 	if (sds)
 		return READ_ONCE(sds->has_idle_cores);
@@ -5661,6 +5778,7 @@ static inline bool test_idle_cores(int cpu, bool def)
  */
 void __update_idle_core(struct rq *rq)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	int core = cpu_of(rq);
 	int cpu;
 
@@ -5688,6 +5806,7 @@ void __update_idle_core(struct rq *rq)
  */
 static int select_idle_core(struct task_struct *p, struct sched_domain *sd, int target)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cpumask *cpus = this_cpu_cpumask_var_ptr(select_idle_mask);
 	int core, cpu;
 
@@ -5727,6 +5846,7 @@ static int select_idle_smt(struct task_struct *p, struct sched_domain *sd, int t
 {
 	int cpu;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!static_branch_likely(&sched_smt_present))
 		return -1;
 
@@ -5767,6 +5887,7 @@ static int select_idle_cpu(struct task_struct *p, struct sched_domain *sd, int t
 	s64 delta;
 	int cpu, nr = INT_MAX;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	this_sd = rcu_dereference(*this_cpu_ptr(&sd_llc));
 	if (!this_sd)
 		return -1;
@@ -5817,30 +5938,46 @@ static int select_idle_sibling(struct task_struct *p, int prev, int target)
 	int i;
 
 	if (idle_cpu(target))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return target;
+}
 
 	/*
 	 * If the previous cpu is cache affine and idle, don't be stupid.
 	 */
 	if (prev != target && cpus_share_cache(prev, target) && idle_cpu(prev))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return prev;
+}
 
 	sd = rcu_dereference(per_cpu(sd_llc, target));
 	if (!sd)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return target;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	i = select_idle_core(p, sd, target);
 	if ((unsigned)i < nr_cpumask_bits)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return i;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	i = select_idle_cpu(p, sd, target);
 	if ((unsigned)i < nr_cpumask_bits)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return i;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	i = select_idle_smt(p, sd, target);
 	if ((unsigned)i < nr_cpumask_bits)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return i;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return target;
 }
 
@@ -5872,6 +6009,7 @@ static int select_idle_sibling(struct task_struct *p, int prev, int target)
  */
 static int cpu_util(int cpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	unsigned long util = cpu_rq(cpu)->cfs.avg.util_avg;
 	unsigned long capacity = capacity_orig_of(cpu);
 
@@ -5880,6 +6018,7 @@ static int cpu_util(int cpu)
 
 static inline int task_util(struct task_struct *p)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return p->se.avg.util_avg;
 }
 
@@ -5917,7 +6056,9 @@ static int wake_cap(struct task_struct *p, int cpu, int prev_cpu)
 
 	/* Minimum capacity is close to max, no need to abort wake_affine */
 	if (max_cap - min_cap < max_cap >> 3)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	/* Bring task utilization in sync with prev_cpu */
 	sync_entity_load_avg(&p->se);
@@ -5952,8 +6093,10 @@ select_task_rq_fair(struct task_struct *p, int prev_cpu, int sd_flag, int wake_f
 			      && cpumask_test_cpu(cpu, &p->cpus_allowed);
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rcu_read_lock();
 	for_each_domain(cpu, tmp) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (!(tmp->flags & SD_LOAD_BALANCE))
 			break;
 
@@ -5963,23 +6106,32 @@ select_task_rq_fair(struct task_struct *p, int prev_cpu, int sd_flag, int wake_f
 		 */
 		if (want_affine && (tmp->flags & SD_WAKE_AFFINE) &&
 		    cpumask_test_cpu(prev_cpu, sched_domain_span(tmp))) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			affine_sd = tmp;
 			break;
 		}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (tmp->flags & sd_flag)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			sd = tmp;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		else if (!want_affine)
 			break;
 	}
 
 	if (affine_sd) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		sd = NULL; /* Prefer wake_affine over balance flags */
 		if (cpu == prev_cpu)
 			goto pick_cpu;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (wake_affine(affine_sd, p, prev_cpu, sync))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			new_cpu = cpu;
+}
 	}
 
 	if (!sd) {
@@ -5987,22 +6139,28 @@ select_task_rq_fair(struct task_struct *p, int prev_cpu, int sd_flag, int wake_f
 		if (sd_flag & SD_BALANCE_WAKE) /* XXX always ? */
 			new_cpu = select_idle_sibling(p, prev_cpu, new_cpu);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	} else while (sd) {
 		struct sched_group *group;
 		int weight;
 
 		if (!(sd->flags & sd_flag)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			sd = sd->child;
 			continue;
 		}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		group = find_idlest_group(sd, p, cpu, sd_flag);
 		if (!group) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			sd = sd->child;
 			continue;
 		}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		new_cpu = find_idlest_cpu(group, p, cpu);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (new_cpu == -1 || new_cpu == cpu) {
 			/* Now try balancing at a lower domain level of cpu */
 			sd = sd->child;
@@ -6013,14 +6171,20 @@ select_task_rq_fair(struct task_struct *p, int prev_cpu, int sd_flag, int wake_f
 		cpu = new_cpu;
 		weight = sd->span_weight;
 		sd = NULL;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		for_each_domain(cpu, tmp) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			if (weight <= tmp->span_weight)
 				break;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			if (tmp->flags & sd_flag)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				sd = tmp;
+}
 		}
 		/* while loop will break here if sd == NULL */
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rcu_read_unlock();
 
 	return new_cpu;
@@ -6122,23 +6286,32 @@ wakeup_preempt_entity(struct sched_entity *curr, struct sched_entity *se)
 	s64 gran, vdiff = curr->vruntime - se->vruntime;
 
 	if (vdiff <= 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -1;
+}
 
 	gran = wakeup_gran(curr, se);
 	if (vdiff > gran)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 1;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
 static void set_last_buddy(struct sched_entity *se)
 {
 	if (entity_is_task(se) && unlikely(task_of(se)->policy == SCHED_IDLE))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	for_each_sched_entity(se) {
 		if (SCHED_WARN_ON(!se->on_rq))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return;
+}
 		cfs_rq_of(se)->last = se;
 	}
 }
@@ -6146,11 +6319,15 @@ static void set_last_buddy(struct sched_entity *se)
 static void set_next_buddy(struct sched_entity *se)
 {
 	if (entity_is_task(se) && unlikely(task_of(se)->policy == SCHED_IDLE))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	for_each_sched_entity(se) {
 		if (SCHED_WARN_ON(!se->on_rq))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return;
+}
 		cfs_rq_of(se)->next = se;
 	}
 }
@@ -6182,9 +6359,12 @@ static void check_preempt_wakeup(struct rq *rq, struct task_struct *p, int wake_
 	 * next-buddy nomination below.
 	 */
 	if (unlikely(throttled_hierarchy(cfs_rq_of(pse))))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	if (sched_feat(NEXT_BUDDY) && scale && !(wake_flags & WF_FORK)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		set_next_buddy(pse);
 		next_buddy_marked = 1;
 	}
@@ -6200,7 +6380,9 @@ static void check_preempt_wakeup(struct rq *rq, struct task_struct *p, int wake_
 	 * below.
 	 */
 	if (test_tsk_need_resched(curr))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	/* Idle tasks are by definition preempted by non-idle tasks. */
 	if (unlikely(curr->policy == SCHED_IDLE) &&
@@ -6212,7 +6394,9 @@ static void check_preempt_wakeup(struct rq *rq, struct task_struct *p, int wake_
 	 * is driven by the tick):
 	 */
 	if (unlikely(p->policy != SCHED_NORMAL) || !sched_feat(WAKEUP_PREEMPTION))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	find_matching_se(&se, &pse);
 	update_curr(cfs_rq_of(se));
@@ -6227,6 +6411,7 @@ static void check_preempt_wakeup(struct rq *rq, struct task_struct *p, int wake_
 		goto preempt;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return;
 
 preempt:
@@ -6241,7 +6426,9 @@ static void check_preempt_wakeup(struct rq *rq, struct task_struct *p, int wake_
 	 * for obvious reasons its a bad idea to schedule back to it.
 	 */
 	if (unlikely(!se->on_rq || curr == rq->idle))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	if (sched_feat(LAST_BUDDY) && scale && entity_is_task(se))
 		set_last_buddy(se);
@@ -6293,6 +6480,7 @@ pick_next_task_fair(struct rq *rq, struct task_struct *prev, struct rq_flags *rf
 			 * be correct.
 			 */
 			if (unlikely(check_cfs_rq_runtime(cfs_rq))) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				cfs_rq = &rq->cfs;
 
 				if (!cfs_rq->nr_running)
@@ -6335,8 +6523,11 @@ pick_next_task_fair(struct rq *rq, struct task_struct *prev, struct rq_flags *rf
 	}
 
 	if (hrtick_enabled(rq))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		hrtick_start_fair(rq, p);
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return p;
 simple:
 #endif
@@ -6352,8 +6543,11 @@ pick_next_task_fair(struct rq *rq, struct task_struct *prev, struct rq_flags *rf
 	p = task_of(se);
 
 	if (hrtick_enabled(rq))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		hrtick_start_fair(rq, p);
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return p;
 
 idle:
@@ -6365,11 +6559,14 @@ pick_next_task_fair(struct rq *rq, struct task_struct *prev, struct rq_flags *rf
 	 * must re-start the pick_next_entity() loop.
 	 */
 	if (new_tasks < 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return RETRY_TASK;
+}
 
 	if (new_tasks > 0)
 		goto again;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return NULL;
 }
 
@@ -6382,6 +6579,7 @@ static void put_prev_task_fair(struct rq *rq, struct task_struct *prev)
 	struct cfs_rq *cfs_rq;
 
 	for_each_sched_entity(se) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		cfs_rq = cfs_rq_of(se);
 		put_prev_entity(cfs_rq, se);
 	}
@@ -6402,7 +6600,9 @@ static void yield_task_fair(struct rq *rq)
 	 * Are we the only task in the tree?
 	 */
 	if (unlikely(rq->nr_running == 1))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	clear_buddies(cfs_rq, se);
 
@@ -6600,6 +6800,7 @@ static int task_hot(struct task_struct *p, struct lb_env *env)
 {
 	s64 delta;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&env->src_rq->lock);
 
 	if (p->sched_class != &fair_sched_class)
@@ -6681,6 +6882,7 @@ static int migrate_degrades_locality(struct task_struct *p, struct lb_env *env)
 static inline int migrate_degrades_locality(struct task_struct *p,
 					     struct lb_env *env)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return -1;
 }
 #endif
@@ -6693,6 +6895,7 @@ int can_migrate_task(struct task_struct *p, struct lb_env *env)
 {
 	int tsk_cache_hot;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&env->src_rq->lock);
 
 	/*
@@ -6771,6 +6974,7 @@ int can_migrate_task(struct task_struct *p, struct lb_env *env)
  */
 static void detach_task(struct task_struct *p, struct lb_env *env)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&env->src_rq->lock);
 
 	p->on_rq = TASK_ON_RQ_MIGRATING;
@@ -6788,6 +6992,7 @@ static struct task_struct *detach_one_task(struct lb_env *env)
 {
 	struct task_struct *p, *n;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&env->src_rq->lock);
 
 	list_for_each_entry_safe(p, n, &env->src_rq->cfs_tasks, se.group_node) {
@@ -6823,6 +7028,7 @@ static int detach_tasks(struct lb_env *env)
 	unsigned long load;
 	int detached = 0;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&env->src_rq->lock);
 
 	if (env->imbalance <= 0)
@@ -6904,6 +7110,7 @@ static int detach_tasks(struct lb_env *env)
  */
 static void attach_task(struct rq *rq, struct task_struct *p)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&rq->lock);
 
 	BUG_ON(task_rq(p) != rq);
@@ -6939,6 +7146,7 @@ static void attach_tasks(struct lb_env *env)
 	rq_lock(env->dst_rq, &rf);
 	update_rq_clock(env->dst_rq);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	while (!list_empty(tasks)) {
 		p = list_first_entry(tasks, struct task_struct, se.group_node);
 		list_del_init(&p->se.group_node);
@@ -6954,16 +7162,24 @@ static void attach_tasks(struct lb_env *env)
 static inline bool cfs_rq_is_decayed(struct cfs_rq *cfs_rq)
 {
 	if (cfs_rq->load.weight)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return false;
+}
 
 	if (cfs_rq->avg.load_sum)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return false;
+}
 
 	if (cfs_rq->avg.util_sum)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return false;
+}
 
 	if (cfs_rq->runnable_load_sum)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return false;
+}
 
 	return true;
 }
@@ -7013,6 +7229,7 @@ static void update_blocked_averages(int cpu)
  */
 static void update_cfs_rq_h_load(struct cfs_rq *cfs_rq)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct rq *rq = rq_of(cfs_rq);
 	struct sched_entity *se = cfs_rq->tg->se[cpu_of(rq)];
 	unsigned long now = jiffies;
@@ -7046,6 +7263,7 @@ static void update_cfs_rq_h_load(struct cfs_rq *cfs_rq)
 
 static unsigned long task_h_load(struct task_struct *p)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cfs_rq *cfs_rq = task_cfs_rq(p);
 
 	update_cfs_rq_h_load(cfs_rq);
@@ -7177,11 +7395,14 @@ static unsigned long scale_rt_capacity(int cpu)
 	 * we read them once before doing sanity checks on them.
 	 */
 	age_stamp = READ_ONCE(rq->age_stamp);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	avg = READ_ONCE(rq->rt_avg);
 	delta = __rq_clock_broken(rq) - age_stamp;
 
 	if (unlikely(delta < 0))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		delta = 0;
+}
 
 	total = sched_avg_period() + delta;
 
@@ -7190,11 +7411,13 @@ static unsigned long scale_rt_capacity(int cpu)
 	if (likely(used < SCHED_CAPACITY_SCALE))
 		return SCHED_CAPACITY_SCALE - used;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 1;
 }
 
 static void update_cpu_capacity(struct sched_domain *sd, int cpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	unsigned long capacity = arch_scale_cpu_capacity(sd, cpu);
 	struct sched_group *sdg = sd->groups;
 
@@ -7204,7 +7427,9 @@ static void update_cpu_capacity(struct sched_domain *sd, int cpu)
 	capacity >>= SCHED_CAPACITY_SHIFT;
 
 	if (!capacity)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		capacity = 1;
+}
 
 	cpu_rq(cpu)->cpu_capacity = capacity;
 	sdg->sgc->capacity = capacity;
@@ -7227,6 +7452,7 @@ void update_group_capacity(struct sched_domain *sd, int cpu)
 		return;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	capacity = 0;
 	min_capacity = ULONG_MAX;
 
@@ -7236,8 +7462,10 @@ void update_group_capacity(struct sched_domain *sd, int cpu)
 		 * span the current group.
 		 */
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		for_each_cpu(cpu, sched_group_span(sdg)) {
 			struct sched_group_capacity *sgc;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			struct rq *rq = cpu_rq(cpu);
 
 			/*
@@ -7252,12 +7480,15 @@ void update_group_capacity(struct sched_domain *sd, int cpu)
 			 * causing divide-by-zero issues on boot.
 			 */
 			if (unlikely(!rq->sd)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				capacity += capacity_of(cpu);
 			} else {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				sgc = rq->sd->groups->sgc;
 				capacity += sgc->capacity;
 			}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			min_capacity = min(capacity, min_capacity);
 		}
 	} else  {
@@ -7266,16 +7497,20 @@ void update_group_capacity(struct sched_domain *sd, int cpu)
 		 * span the current group.
 		 */
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		group = child->groups;
 		do {
 			struct sched_group_capacity *sgc = group->sgc;
 
 			capacity += sgc->capacity;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			min_capacity = min(sgc->min_capacity, min_capacity);
 			group = group->next;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		} while (group != child->groups);
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	sdg->sgc->capacity = capacity;
 	sdg->sgc->min_capacity = min_capacity;
 }
@@ -7288,6 +7523,7 @@ void update_group_capacity(struct sched_domain *sd, int cpu)
 static inline int
 check_cpu_capacity(struct rq *rq, struct sched_domain *sd)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return ((rq->cpu_capacity * sd->imbalance_pct) <
 				(rq->cpu_capacity_orig * 100));
 }
@@ -7323,6 +7559,7 @@ check_cpu_capacity(struct rq *rq, struct sched_domain *sd)
 
 static inline int sg_imbalanced(struct sched_group *group)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return group->sgc->imbalance;
 }
 
@@ -7341,6 +7578,7 @@ static inline int sg_imbalanced(struct sched_group *group)
 static inline bool
 group_has_capacity(struct lb_env *env, struct sg_lb_stats *sgs)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (sgs->sum_nr_running < sgs->group_weight)
 		return true;
 
@@ -7362,6 +7600,7 @@ group_has_capacity(struct lb_env *env, struct sg_lb_stats *sgs)
 static inline bool
 group_is_overloaded(struct lb_env *env, struct sg_lb_stats *sgs)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (sgs->sum_nr_running <= sgs->group_weight)
 		return false;
 
@@ -7379,6 +7618,7 @@ group_is_overloaded(struct lb_env *env, struct sg_lb_stats *sgs)
 static inline bool
 group_smaller_cpu_capacity(struct sched_group *sg, struct sched_group *ref)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return sg->sgc->min_capacity * capacity_margin <
 						ref->sgc->min_capacity * 1024;
 }
@@ -7387,6 +7627,7 @@ static inline enum
 group_type group_classify(struct sched_group *group,
 			  struct sg_lb_stats *sgs)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (sgs->group_no_capacity)
 		return group_overloaded;
 
@@ -7415,6 +7656,7 @@ static inline void update_sg_lb_stats(struct lb_env *env,
 
 	memset(sgs, 0, sizeof(*sgs));
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for_each_cpu_and(i, sched_group_span(group), env->cpus) {
 		struct rq *rq = cpu_rq(i);
 
@@ -7478,7 +7720,9 @@ static bool update_sd_pick_busiest(struct lb_env *env,
 	struct sg_lb_stats *busiest = &sds->busiest_stat;
 
 	if (sgs->group_type > busiest->group_type)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return true;
+}
 
 	if (sgs->group_type < busiest->group_type)
 		return false;
@@ -7547,11 +7791,13 @@ static inline enum fbq_type fbq_classify_rq(struct rq *rq)
 #else
 static inline enum fbq_type fbq_classify_group(struct sg_lb_stats *sgs)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return all;
 }
 
 static inline enum fbq_type fbq_classify_rq(struct rq *rq)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return regular;
 }
 #endif /* CONFIG_NUMA_BALANCING */
@@ -7570,6 +7816,7 @@ static inline void update_sd_lb_stats(struct lb_env *env, struct sd_lb_stats *sd
 	int load_idx, prefer_sibling = 0;
 	bool overload = false;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (child && child->flags & SD_PREFER_SIBLING)
 		prefer_sibling = 1;
 
@@ -7664,7 +7911,9 @@ static int check_asym_packing(struct lb_env *env, struct sd_lb_stats *sds)
 	int busiest_cpu;
 
 	if (!(env->sd->flags & SD_ASYM_PACKING))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	if (env->idle == CPU_NOT_IDLE)
 		return 0;
@@ -7702,7 +7951,9 @@ void fix_small_imbalance(struct lb_env *env, struct sd_lb_stats *sds)
 	busiest = &sds->busiest_stat;
 
 	if (!local->sum_nr_running)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		local->load_per_task = cpu_avg_load_per_task(env->dst_cpu);
+}
 	else if (busiest->load_per_task > local->load_per_task)
 		imbn = 1;
 
@@ -7857,7 +8108,9 @@ static struct sched_group *find_busiest_group(struct lb_env *env)
 
 	/* ASYM feature bypasses nice load balance check */
 	if (check_asym_packing(env, &sds))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return sds.busiest;
+}
 
 	/* There is no busy sibling group to pull tasks from */
 	if (!sds.busiest || busiest->sum_nr_running == 0)
@@ -7935,6 +8188,7 @@ static struct rq *find_busiest_queue(struct lb_env *env,
 	unsigned long busiest_load = 0, busiest_capacity = 1;
 	int i;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for_each_cpu_and(i, sched_group_span(group), env->cpus) {
 		unsigned long capacity, wl;
 		enum fbq_type rt;
@@ -8048,7 +8302,9 @@ static int should_we_balance(struct lb_env *env)
 	 * when the softirq triggers 'during' hotplug.
 	 */
 	if (!cpumask_test_cpu(env->dst_cpu, env->cpus))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	/*
 	 * In the newly idle case, we will allow all the cpu's
@@ -8089,6 +8345,7 @@ static int load_balance(int this_cpu, struct rq *this_rq,
 	struct sched_group *group;
 	struct rq *busiest;
 	struct rq_flags rf;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cpumask *cpus = this_cpu_cpumask_var_ptr(load_balance_mask);
 
 	struct lb_env env = {
@@ -8349,7 +8606,9 @@ get_sd_balance_interval(struct sched_domain *sd, int cpu_busy)
 	unsigned long interval = sd->balance_interval;
 
 	if (cpu_busy)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		interval *= sd->busy_factor;
+}
 
 	/* scale ms to jiffies */
 	interval = msecs_to_jiffies(interval);
@@ -8367,6 +8626,7 @@ update_next_balance(struct sched_domain *sd, unsigned long *next_balance)
 	interval = get_sd_balance_interval(sd, 0);
 	next = sd->last_balance + interval;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (time_after(*next_balance, next))
 		*next_balance = next;
 }
@@ -8393,7 +8653,9 @@ static int idle_balance(struct rq *this_rq, struct rq_flags *rf)
 	 * Do not pull tasks towards !active CPUs...
 	 */
 	if (!cpu_active(this_cpu))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	/*
 	 * This is OK, because current is on_cpu, which avoids it being picked
@@ -8405,15 +8667,20 @@ static int idle_balance(struct rq *this_rq, struct rq_flags *rf)
 
 	if (this_rq->avg_idle < sysctl_sched_migration_cost ||
 	    !this_rq->rd->overload) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		rcu_read_lock();
 		sd = rcu_dereference_check_sched_domain(this_rq->sd);
 		if (sd)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			update_next_balance(sd, &next_balance);
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		rcu_read_unlock();
 
 		goto out;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	raw_spin_unlock(&this_rq->lock);
 
 	update_blocked_averages(this_cpu);
@@ -8425,12 +8692,16 @@ static int idle_balance(struct rq *this_rq, struct rq_flags *rf)
 		if (!(sd->flags & SD_LOAD_BALANCE))
 			continue;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (this_rq->avg_idle < curr_cost + sd->max_newidle_lb_cost) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			update_next_balance(sd, &next_balance);
 			break;
 		}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (sd->flags & SD_BALANCE_NEWIDLE) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			t0 = sched_clock_cpu(this_cpu);
 
 			pulled_task = load_balance(this_cpu, this_rq,
@@ -8439,11 +8710,15 @@ static int idle_balance(struct rq *this_rq, struct rq_flags *rf)
 
 			domain_cost = sched_clock_cpu(this_cpu) - t0;
 			if (domain_cost > sd->max_newidle_lb_cost)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				sd->max_newidle_lb_cost = domain_cost;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			curr_cost += domain_cost;
 		}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		update_next_balance(sd, &next_balance);
 
 		/*
@@ -8453,12 +8728,15 @@ static int idle_balance(struct rq *this_rq, struct rq_flags *rf)
 		if (pulled_task || this_rq->nr_running > 0)
 			break;
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rcu_read_unlock();
 
 	raw_spin_lock(&this_rq->lock);
 
 	if (curr_cost > this_rq->max_idle_balance_cost)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		this_rq->max_idle_balance_cost = curr_cost;
+}
 
 	/*
 	 * While browsing the domains, we released the rq lock, a task could
@@ -8466,20 +8744,29 @@ static int idle_balance(struct rq *this_rq, struct rq_flags *rf)
 	 * pretend we pulled a task.
 	 */
 	if (this_rq->cfs.h_nr_running && !pulled_task)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pulled_task = 1;
+}
 
 out:
 	/* Move the next balance forward */
 	if (time_after(this_rq->next_balance, next_balance))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		this_rq->next_balance = next_balance;
+}
 
 	/* Is there a task of a high priority class? */
 	if (this_rq->nr_running != this_rq->cfs.h_nr_running)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pulled_task = -1;
+}
 
 	if (pulled_task)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		this_rq->idle_stamp = 0;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rq_repin_lock(this_rq, rf);
 
 	return pulled_task;
@@ -8496,6 +8783,7 @@ static int active_load_balance_cpu_stop(void *data)
 	struct rq *busiest_rq = data;
 	int busiest_cpu = cpu_of(busiest_rq);
 	int target_cpu = busiest_rq->push_cpu;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct rq *target_rq = cpu_rq(target_cpu);
 	struct sched_domain *sd;
 	struct task_struct *p = NULL;
diff --git a/kernel/sched/idle.c b/kernel/sched/idle.c
index 257f4f0..7403eee 100644
--- a/kernel/sched/idle.c
+++ b/kernel/sched/idle.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * Generic entry point for the idle threads
  */
@@ -27,6 +29,7 @@ extern char __cpuidle_text_start[], __cpuidle_text_end[];
  */
 void sched_idle_set_state(struct cpuidle_state *idle_state)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	idle_set_state(this_rq(), idle_state);
 }
 
@@ -34,6 +37,7 @@ static int __read_mostly cpu_idle_force_poll;
 
 void cpu_idle_poll_ctrl(bool enable)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (enable) {
 		cpu_idle_force_poll++;
 	} else {
@@ -60,6 +64,7 @@ __setup("hlt", cpu_idle_nopoll_setup);
 
 static noinline int __cpuidle cpu_idle_poll(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rcu_idle_enter();
 	trace_cpu_idle_rcuidle(0, smp_processor_id());
 	local_irq_enable();
@@ -80,6 +85,7 @@ void __weak arch_cpu_idle_exit(void) { }
 void __weak arch_cpu_idle_dead(void) { }
 void __weak arch_cpu_idle(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	cpu_idle_force_poll = 1;
 	local_irq_enable();
 }
@@ -92,10 +98,13 @@ void __weak arch_cpu_idle(void)
 void __cpuidle default_idle_call(void)
 {
 	if (current_clr_polling_and_test()) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		local_irq_enable();
 	} else {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		stop_critical_timings();
 		arch_cpu_idle();
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		start_critical_timings();
 	}
 }
@@ -132,6 +141,7 @@ static int call_cpuidle(struct cpuidle_driver *drv, struct cpuidle_device *dev,
  */
 static void cpuidle_idle_call(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cpuidle_device *dev = cpuidle_get_device();
 	struct cpuidle_driver *drv = cpuidle_get_cpu_driver(dev);
 	int next_state, entered_state;
@@ -167,15 +177,20 @@ static void cpuidle_idle_call(void)
 	 * until a proper wakeup interrupt happens.
 	 */
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (idle_should_enter_s2idle() || dev->use_deepest_state) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (idle_should_enter_s2idle()) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			entered_state = cpuidle_enter_s2idle(drv, dev);
 			if (entered_state > 0) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				local_irq_enable();
 				goto exit_idle;
 			}
 		}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		next_state = cpuidle_find_deepest_state(drv, dev);
 		call_cpuidle(drv, dev, next_state);
 	} else {
@@ -197,7 +212,9 @@ static void cpuidle_idle_call(void)
 	 * It is up to the idle functions to reenable local interrupts
 	 */
 	if (WARN_ON_ONCE(irqs_disabled()))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		local_irq_enable();
+}
 
 	rcu_idle_exit();
 }
@@ -223,10 +240,12 @@ static void do_idle(void)
 	tick_nohz_idle_enter();
 
 	while (!need_resched()) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		check_pgt_cache();
 		rmb();
 
 		if (cpu_is_offline(smp_processor_id())) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			cpuhp_report_idle_dead();
 			arch_cpu_idle_dead();
 		}
@@ -241,7 +260,9 @@ static void do_idle(void)
 		 * idle as we know that the IPI is going to arrive right away.
 		 */
 		if (cpu_idle_force_poll || tick_check_broadcast_expired())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			cpu_idle_poll();
+}
 		else
 			cpuidle_idle_call();
 		arch_cpu_idle_exit();
@@ -269,11 +290,14 @@ static void do_idle(void)
 	schedule_idle();
 
 	if (unlikely(klp_patch_pending(current)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		klp_update_patch_state(current);
 }
+}
 
 bool cpu_in_idle(unsigned long pc)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return pc >= (unsigned long)__cpuidle_text_start &&
 		pc < (unsigned long)__cpuidle_text_end;
 }
@@ -285,6 +309,7 @@ struct idle_timer {
 
 static enum hrtimer_restart idle_inject_timer_fn(struct hrtimer *timer)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct idle_timer *it = container_of(timer, struct idle_timer, timer);
 
 	WRITE_ONCE(it->done, 1);
@@ -347,6 +372,7 @@ void cpu_startup_entry(enum cpuhp_state state)
 #endif
 	arch_cpu_idle_prepare();
 	cpuhp_online_idle(state);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	while (1)
 		do_idle();
 }
diff --git a/kernel/sched/idle_task.c b/kernel/sched/idle_task.c
index d518664..c01c8b0 100644
--- a/kernel/sched/idle_task.c
+++ b/kernel/sched/idle_task.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 #include "sched.h"
 
@@ -12,6 +14,7 @@
 static int
 select_task_rq_idle(struct task_struct *p, int cpu, int sd_flag, int flags)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return task_cpu(p); /* IDLE tasks as never migrated */
 }
 #endif /* CONFIG_SMP */
@@ -21,6 +24,7 @@ select_task_rq_idle(struct task_struct *p, int cpu, int sd_flag, int flags)
  */
 static void check_preempt_curr_idle(struct rq *rq, struct task_struct *p, int flags)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	resched_curr(rq);
 }
 
@@ -29,6 +33,7 @@ pick_next_task_idle(struct rq *rq, struct task_struct *prev, struct rq_flags *rf
 {
 	put_prev_task(rq, prev);
 	update_idle_core(rq);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	schedstat_inc(rq->sched_goidle);
 	return rq->idle;
 }
@@ -40,6 +45,7 @@ pick_next_task_idle(struct rq *rq, struct task_struct *prev, struct rq_flags *rf
 static void
 dequeue_task_idle(struct rq *rq, struct task_struct *p, int flags)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	raw_spin_unlock_irq(&rq->lock);
 	printk(KERN_ERR "bad: scheduling from the idle thread!\n");
 	dump_stack();
@@ -48,6 +54,7 @@ dequeue_task_idle(struct rq *rq, struct task_struct *p, int flags)
 
 static void put_prev_task_idle(struct rq *rq, struct task_struct *prev)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rq_last_tick_reset(rq);
 }
 
@@ -61,17 +68,20 @@ static void set_curr_task_idle(struct rq *rq)
 
 static void switched_to_idle(struct rq *rq, struct task_struct *p)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	BUG();
 }
 
 static void
 prio_changed_idle(struct rq *rq, struct task_struct *p, int oldprio)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	BUG();
 }
 
 static unsigned int get_rr_interval_idle(struct rq *rq, struct task_struct *task)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
diff --git a/kernel/sched/loadavg.c b/kernel/sched/loadavg.c
index 89a989e..553297e 100644
--- a/kernel/sched/loadavg.c
+++ b/kernel/sched/loadavg.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 /*
  * kernel/sched/loadavg.c
@@ -207,7 +209,9 @@ void calc_load_nohz_stop(void)
 	 */
 	this_rq->calc_load_update = READ_ONCE(calc_load_update);
 	if (time_before(jiffies, this_rq->calc_load_update))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	/*
 	 * We woke inside or after the sample window, this means we're already
@@ -220,11 +224,14 @@ void calc_load_nohz_stop(void)
 
 static long calc_load_nohz_fold(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	int idx = calc_load_read_idx();
 	long delta = 0;
 
 	if (atomic_long_read(&calc_load_nohz[idx]))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		delta = atomic_long_xchg(&calc_load_nohz[idx], 0);
+}
 
 	return delta;
 }
@@ -251,6 +258,7 @@ fixed_power_int(unsigned long x, unsigned int frac_bits, unsigned int n)
 
 	if (n) {
 		for (;;) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			if (n & 1) {
 				result *= x;
 				result += 1UL << (frac_bits - 1);
@@ -295,6 +303,7 @@ static unsigned long
 calc_load_n(unsigned long load, unsigned long exp,
 	    unsigned long active, unsigned int n)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return calc_load(load, fixed_power_int(exp, FSHIFT, n), active);
 }
 
@@ -312,6 +321,7 @@ static void calc_global_nohz(void)
 	unsigned long sample_window;
 	long delta, active, n;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	sample_window = READ_ONCE(calc_load_update);
 	if (!time_before(jiffies, sample_window + 10)) {
 		/*
@@ -321,6 +331,7 @@ static void calc_global_nohz(void)
 		n = 1 + (delta / LOAD_FREQ);
 
 		active = atomic_long_read(&calc_load_tasks);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		active = active > 0 ? active * FIXED_1 : 0;
 
 		avenrun[0] = calc_load_n(avenrun[0], EXP_1, active, n);
@@ -358,17 +369,23 @@ void calc_global_load(unsigned long ticks)
 	unsigned long sample_window;
 	long active, delta;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	sample_window = READ_ONCE(calc_load_update);
 	if (time_before(jiffies, sample_window + 10))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	/*
 	 * Fold the 'old' NO_HZ-delta to include all NO_HZ cpus.
 	 */
 	delta = calc_load_nohz_fold();
 	if (delta)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		atomic_long_add(delta, &calc_load_tasks);
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	active = atomic_long_read(&calc_load_tasks);
 	active = active > 0 ? active * FIXED_1 : 0;
 
@@ -394,11 +411,15 @@ void calc_global_load_tick(struct rq *this_rq)
 	long delta;
 
 	if (time_before(jiffies, this_rq->calc_load_update))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	delta  = calc_load_fold_active(this_rq, 0);
 	if (delta)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		atomic_long_add(delta, &calc_load_tasks);
+}
 
 	this_rq->calc_load_update += LOAD_FREQ;
 }
diff --git a/kernel/sched/rt.c b/kernel/sched/rt.c
index 298f62b..13a7561 100644
--- a/kernel/sched/rt.c
+++ b/kernel/sched/rt.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 /*
  * Real-Time Scheduling Class (mapped to the SCHED_FIFO and SCHED_RR
@@ -29,12 +31,14 @@ static enum hrtimer_restart sched_rt_period_timer(struct hrtimer *timer)
 		if (!overrun)
 			break;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		raw_spin_unlock(&rt_b->rt_runtime_lock);
 		idle = do_sched_rt_period_timer(rt_b, overrun);
 		raw_spin_lock(&rt_b->rt_runtime_lock);
 	}
 	if (idle)
 		rt_b->rt_period_active = 0;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	raw_spin_unlock(&rt_b->rt_runtime_lock);
 
 	return idle ? HRTIMER_NORESTART : HRTIMER_RESTART;
@@ -55,7 +59,9 @@ void init_rt_bandwidth(struct rt_bandwidth *rt_b, u64 period, u64 runtime)
 static void start_rt_bandwidth(struct rt_bandwidth *rt_b)
 {
 	if (!rt_bandwidth_enabled() || rt_b->rt_runtime == RUNTIME_INF)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	raw_spin_lock(&rt_b->rt_runtime_lock);
 	if (!rt_b->rt_period_active) {
@@ -71,6 +77,7 @@ static void start_rt_bandwidth(struct rt_bandwidth *rt_b)
 		hrtimer_forward_now(&rt_b->rt_period_timer, ns_to_ktime(0));
 		hrtimer_start_expires(&rt_b->rt_period_timer, HRTIMER_MODE_ABS_PINNED);
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	raw_spin_unlock(&rt_b->rt_runtime_lock);
 }
 
@@ -227,16 +234,19 @@ int alloc_rt_sched_group(struct task_group *tg, struct task_group *parent)
 
 static inline struct task_struct *rt_task_of(struct sched_rt_entity *rt_se)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return container_of(rt_se, struct task_struct, rt);
 }
 
 static inline struct rq *rq_of_rt_rq(struct rt_rq *rt_rq)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return container_of(rt_rq, struct rq, rt);
 }
 
 static inline struct rq *rq_of_rt_se(struct sched_rt_entity *rt_se)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct task_struct *p = rt_task_of(rt_se);
 
 	return task_rq(p);
@@ -244,6 +254,7 @@ static inline struct rq *rq_of_rt_se(struct sched_rt_entity *rt_se)
 
 static inline struct rt_rq *rt_rq_of_se(struct sched_rt_entity *rt_se)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct rq *rq = rq_of_rt_se(rt_se);
 
 	return &rq->rt;
@@ -2592,6 +2603,7 @@ static int sched_rt_global_constraints(void)
 	unsigned long flags;
 	int i;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	raw_spin_lock_irqsave(&def_rt_bandwidth.rt_runtime_lock, flags);
 	for_each_possible_cpu(i) {
 		struct rt_rq *rt_rq = &cpu_rq(i)->rt;
@@ -2608,6 +2620,7 @@ static int sched_rt_global_constraints(void)
 
 static int sched_rt_global_validate(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (sysctl_sched_rt_period <= 0)
 		return -EINVAL;
 
@@ -2620,6 +2633,7 @@ static int sched_rt_global_validate(void)
 
 static void sched_rt_do_global(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	def_rt_bandwidth.rt_runtime = global_rt_runtime();
 	def_rt_bandwidth.rt_period = ns_to_ktime(global_rt_period());
 }
@@ -2638,6 +2652,7 @@ int sched_rt_handler(struct ctl_table *table, int write,
 
 	ret = proc_dointvec(table, write, buffer, lenp, ppos);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!ret && write) {
 		ret = sched_rt_global_validate();
 		if (ret)
diff --git a/kernel/sched/sched.h b/kernel/sched/sched.h
index 307c35d..c572023 100644
--- a/kernel/sched/sched.h
+++ b/kernel/sched/sched.h
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /* SPDX-License-Identifier: GPL-2.0 */
 
 #include <linux/sched.h>
diff --git a/kernel/sched/stats.h b/kernel/sched/stats.h
index baf500d..4d7e415 100644
--- a/kernel/sched/stats.h
+++ b/kernel/sched/stats.h
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /* SPDX-License-Identifier: GPL-2.0 */
 
 #ifdef CONFIG_SCHEDSTATS
diff --git a/kernel/sched/stop_task.c b/kernel/sched/stop_task.c
index 45caf90..74b879e 100644
--- a/kernel/sched/stop_task.c
+++ b/kernel/sched/stop_task.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 #include "sched.h"
 
@@ -14,6 +16,7 @@
 static int
 select_task_rq_stop(struct task_struct *p, int cpu, int sd_flag, int flags)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return task_cpu(p); /* stop tasks as never migrate */
 }
 #endif /* CONFIG_SMP */
@@ -30,7 +33,9 @@ pick_next_task_stop(struct rq *rq, struct task_struct *prev, struct rq_flags *rf
 	struct task_struct *stop = rq->stop;
 
 	if (!stop || !task_on_rq_queued(stop))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 
 	put_prev_task(rq, prev);
 
@@ -48,11 +53,13 @@ enqueue_task_stop(struct rq *rq, struct task_struct *p, int flags)
 static void
 dequeue_task_stop(struct rq *rq, struct task_struct *p, int flags)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	sub_nr_running(rq, 1);
 }
 
 static void yield_task_stop(struct rq *rq)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	BUG(); /* the stop task should never yield, its pointless. */
 }
 
@@ -63,8 +70,11 @@ static void put_prev_task_stop(struct rq *rq, struct task_struct *prev)
 
 	delta_exec = rq_clock_task(rq) - curr->se.exec_start;
 	if (unlikely((s64)delta_exec < 0))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		delta_exec = 0;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	schedstat_set(curr->se.statistics.exec_max,
 			max(curr->se.statistics.exec_max, delta_exec));
 
@@ -88,18 +98,21 @@ static void set_curr_task_stop(struct rq *rq)
 
 static void switched_to_stop(struct rq *rq, struct task_struct *p)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	BUG(); /* its impossible to change to this class */
 }
 
 static void
 prio_changed_stop(struct rq *rq, struct task_struct *p, int oldprio)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	BUG(); /* how!?, what priority? */
 }
 
 static unsigned int
 get_rr_interval_stop(struct rq *rq, struct task_struct *task)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
diff --git a/kernel/sched/swait.c b/kernel/sched/swait.c
index 9ff1555..158f9c4 100644
--- a/kernel/sched/swait.c
+++ b/kernel/sched/swait.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 #include <linux/sched/signal.h>
 #include <linux/swait.h>
@@ -6,6 +8,7 @@ void __init_swait_queue_head(struct swait_queue_head *q, const char *name,
 			     struct lock_class_key *key)
 {
 	raw_spin_lock_init(&q->lock);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_set_class_and_name(&q->lock, key, name);
 	INIT_LIST_HEAD(&q->task_list);
 }
@@ -22,7 +25,9 @@ void swake_up_locked(struct swait_queue_head *q)
 	struct swait_queue *curr;
 
 	if (list_empty(&q->task_list))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	curr = list_first_entry(&q->task_list, typeof(*curr), task_list);
 	wake_up_process(curr->task);
@@ -51,6 +56,7 @@ void swake_up_all(struct swait_queue_head *q)
 
 	raw_spin_lock_irq(&q->lock);
 	list_splice_init(&q->task_list, &tmp);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	while (!list_empty(&tmp)) {
 		curr = list_first_entry(&tmp, typeof(*curr), task_list);
 
@@ -88,7 +94,9 @@ EXPORT_SYMBOL(prepare_to_swait);
 long prepare_to_swait_event(struct swait_queue_head *q, struct swait_queue *wait, int state)
 {
 	if (signal_pending_state(state, current))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ERESTARTSYS;
+}
 
 	prepare_to_swait(q, wait, state);
 
@@ -98,6 +106,7 @@ EXPORT_SYMBOL(prepare_to_swait_event);
 
 void __finish_swait(struct swait_queue_head *q, struct swait_queue *wait)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	__set_current_state(TASK_RUNNING);
 	if (!list_empty(&wait->task_list))
 		list_del_init(&wait->task_list);
diff --git a/kernel/sched/topology.c b/kernel/sched/topology.c
index 659e075..22ec94f 100644
--- a/kernel/sched/topology.c
+++ b/kernel/sched/topology.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 /*
  * Scheduler topology setup/handling methods
@@ -148,6 +150,7 @@ static void sched_domain_debug(struct sched_domain *sd, int cpu)
 # define sched_domain_debug(sd, cpu) do { } while (0)
 static inline bool sched_debug(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return false;
 }
 #endif /* CONFIG_SCHED_DEBUG */
@@ -155,7 +158,9 @@ static inline bool sched_debug(void)
 static int sd_degenerate(struct sched_domain *sd)
 {
 	if (cpumask_weight(sched_domain_span(sd)) == 1)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 1;
+}
 
 	/* Following flags need at least 2 groups */
 	if (sd->flags & (SD_LOAD_BALANCE |
@@ -166,14 +171,20 @@ static int sd_degenerate(struct sched_domain *sd)
 			 SD_ASYM_CPUCAPACITY |
 			 SD_SHARE_PKG_RESOURCES |
 			 SD_SHARE_POWERDOMAIN)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (sd->groups != sd->groups->next)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return 0;
+}
 	}
 
 	/* Following flags don't use groups */
 	if (sd->flags & (SD_WAKE_AFFINE))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 1;
 }
 
@@ -183,7 +194,9 @@ sd_parent_degenerate(struct sched_domain *sd, struct sched_domain *parent)
 	unsigned long cflags = sd->flags, pflags = parent->flags;
 
 	if (sd_degenerate(parent))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 1;
+}
 
 	if (!cpumask_equal(sched_domain_span(sd), sched_domain_span(parent)))
 		return 0;
@@ -210,6 +223,7 @@ sd_parent_degenerate(struct sched_domain *sd, struct sched_domain *parent)
 
 static void free_rootdomain(struct rcu_head *rcu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct root_domain *rd = container_of(rcu, struct root_domain, rcu);
 
 	cpupri_cleanup(&rd->cpupri);
@@ -229,6 +243,7 @@ void rq_attach_root(struct rq *rq, struct root_domain *rd)
 	raw_spin_lock_irqsave(&rq->lock, flags);
 
 	if (rq->rd) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		old_rd = rq->rd;
 
 		if (cpumask_test_cpu(rq->cpu, old_rd->online))
@@ -242,7 +257,9 @@ void rq_attach_root(struct rq *rq, struct root_domain *rd)
 		 * in this function:
 		 */
 		if (!atomic_dec_and_test(&old_rd->refcount))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			old_rd = NULL;
+}
 	}
 
 	atomic_inc(&rd->refcount);
@@ -255,16 +272,20 @@ void rq_attach_root(struct rq *rq, struct root_domain *rd)
 	raw_spin_unlock_irqrestore(&rq->lock, flags);
 
 	if (old_rd)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		call_rcu_sched(&old_rd->rcu, free_rootdomain);
 }
+}
 
 void sched_get_rd(struct root_domain *rd)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	atomic_inc(&rd->refcount);
 }
 
 void sched_put_rd(struct root_domain *rd)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!atomic_dec_and_test(&rd->refcount))
 		return;
 
@@ -285,6 +306,7 @@ static int init_rootdomain(struct root_domain *rd)
 #ifdef HAVE_RT_PUSH_IPI
 	rd->rto_cpu = -1;
 	raw_spin_lock_init(&rd->rto_lock);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	init_irq_work(&rd->rto_push_work, rto_push_irq_work_func);
 #endif
 
@@ -294,6 +316,7 @@ static int init_rootdomain(struct root_domain *rd)
 
 	if (cpupri_init(&rd->cpupri) != 0)
 		goto free_cpudl;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 
 free_cpudl:
@@ -329,13 +352,17 @@ static struct root_domain *alloc_rootdomain(void)
 
 	rd = kzalloc(sizeof(*rd), GFP_KERNEL);
 	if (!rd)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 
 	if (init_rootdomain(rd) != 0) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		kfree(rd);
 		return NULL;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return rd;
 }
 
@@ -344,8 +371,11 @@ static void free_sched_groups(struct sched_group *sg, int free_sgc)
 	struct sched_group *tmp, *first;
 
 	if (!sg)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	first = sg;
 	do {
 		tmp = sg->next;
@@ -355,6 +385,7 @@ static void free_sched_groups(struct sched_group *sg, int free_sgc)
 
 		if (atomic_dec_and_test(&sg->ref))
 			kfree(sg);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		sg = tmp;
 	} while (sg != first);
 }
@@ -375,6 +406,7 @@ static void destroy_sched_domain(struct sched_domain *sd)
 
 static void destroy_sched_domains_rcu(struct rcu_head *rcu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct sched_domain *sd = container_of(rcu, struct sched_domain, rcu);
 
 	while (sd) {
@@ -387,8 +419,10 @@ static void destroy_sched_domains_rcu(struct rcu_head *rcu)
 static void destroy_sched_domains(struct sched_domain *sd)
 {
 	if (sd)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		call_rcu(&sd->rcu, destroy_sched_domains_rcu);
 }
+}
 
 /*
  * Keep a special pointer to the highest sched_domain that has
@@ -415,6 +449,7 @@ static void update_top_cache_domain(int cpu)
 
 	sd = highest_flag_domain(cpu, SD_SHARE_PKG_RESOURCES);
 	if (sd) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		id = cpumask_first(sched_domain_span(sd));
 		size = cpumask_weight(sched_domain_span(sd));
 		sds = sd->shared;
@@ -448,28 +483,40 @@ cpu_attach_domain(struct sched_domain *sd, struct root_domain *rd, int cpu)
 		if (!parent)
 			break;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (sd_parent_degenerate(tmp, parent)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			tmp->parent = parent->parent;
 			if (parent->parent)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				parent->parent->child = tmp;
+}
 			/*
 			 * Transfer SD_PREFER_SIBLING down in case of a
 			 * degenerate parent; the spans match for this
 			 * so the property transfers.
 			 */
 			if (parent->flags & SD_PREFER_SIBLING)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				tmp->flags |= SD_PREFER_SIBLING;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			destroy_sched_domain(parent);
 		} else
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			tmp = tmp->parent;
+}
 	}
 
 	if (sd && sd_degenerate(sd)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		tmp = sd;
 		sd = sd->parent;
 		destroy_sched_domain(tmp);
 		if (sd)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			sd->child = NULL;
+}
 	}
 
 	sched_domain_debug(sd, cpu);
@@ -491,6 +538,7 @@ static int __init isolated_cpu_setup(char *str)
 	alloc_bootmem_cpumask_var(&cpu_isolated_map);
 	ret = cpulist_parse(str, cpu_isolated_map);
 	if (ret) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_err("sched: Error, all isolcpus= values must be between 0 and %u\n", nr_cpu_ids);
 		return 0;
 	}
@@ -633,6 +681,7 @@ int group_balance_cpu(struct sched_group *sg)
 static void
 build_balance_mask(struct sched_domain *sd, struct sched_group *sg, struct cpumask *mask)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	const struct cpumask *sg_span = sched_group_span(sg);
 	struct sd_data *sdd = sd->private;
 	struct sched_domain *sibling;
@@ -677,7 +726,9 @@ build_group_from_child_sched_domain(struct sched_domain *sd, int cpu)
 			GFP_KERNEL, cpu_to_node(cpu));
 
 	if (!sg)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 
 	sg_span = sched_group_span(sg);
 	if (sd->child)
@@ -700,6 +751,7 @@ static void init_overlap_sched_group(struct sched_domain *sd,
 	build_balance_mask(sd, sg, mask);
 	cpu = cpumask_first_and(sched_group_span(sg), mask);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	sg->sgc = *per_cpu_ptr(sdd->sgc, cpu);
 	if (atomic_inc_return(&sg->sgc->ref) == 1)
 		cpumask_copy(group_balance_mask(sg), mask);
@@ -728,6 +780,7 @@ build_overlap_sched_groups(struct sched_domain *sd, int cpu)
 
 	cpumask_clear(covered);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for_each_cpu_wrap(i, span, cpu) {
 		struct cpumask *sg_span;
 
@@ -854,7 +907,9 @@ static struct sched_group *get_group(int cpu, struct sd_data *sdd)
 	struct sched_group *sg;
 
 	if (child)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		cpu = cpumask_first(sched_domain_span(child));
+}
 
 	sg = *per_cpu_ptr(sdd->sg, cpu);
 	sg->sgc = *per_cpu_ptr(sdd->sgc, cpu);
@@ -864,6 +919,7 @@ static struct sched_group *get_group(int cpu, struct sd_data *sdd)
 	atomic_inc(&sg->sgc->ref);
 
 	if (child) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		cpumask_copy(sched_group_span(sg), sched_domain_span(child));
 		cpumask_copy(group_balance_mask(sg), sched_group_span(sg));
 	} else {
@@ -893,7 +949,9 @@ build_sched_groups(struct sched_domain *sd, int cpu)
 	struct cpumask *covered;
 	int i;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&sched_domains_mutex);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	covered = sched_domains_tmpmask;
 
 	cpumask_clear(covered);
@@ -909,9 +967,14 @@ build_sched_groups(struct sched_domain *sd, int cpu)
 		cpumask_or(covered, covered, sched_group_span(sg));
 
 		if (!first)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			first = sg;
+}
 		if (last)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			last->next = sg;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		last = sg;
 	}
 	last->next = first;
@@ -944,12 +1007,20 @@ static void init_sched_groups_capacity(int cpu, struct sched_domain *sd)
 		if (!(sd->flags & SD_ASYM_PACKING))
 			goto next;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		for_each_cpu(cpu, sched_group_span(sg)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			if (max_cpu < 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				max_cpu = cpu;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			else if (sched_asym_prefer(cpu, max_cpu))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				max_cpu = cpu;
+}
 		}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		sg->asym_prefer_cpu = max_cpu;
 
 next:
@@ -957,7 +1028,9 @@ static void init_sched_groups_capacity(int cpu, struct sched_domain *sd)
 	} while (sg != sd->groups);
 
 	if (cpu != group_balance_cpu(sg))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	update_group_capacity(sd, cpu);
 }
@@ -972,6 +1045,7 @@ int sched_domain_level_max;
 
 static int __init setup_relax_domain_level(char *str)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (kstrtoint(str, 0, &default_relax_domain_level))
 		pr_warn("Unable to set relax_domain_level\n");
 
@@ -986,11 +1060,16 @@ static void set_domain_attribute(struct sched_domain *sd,
 
 	if (!attr || attr->relax_domain_level < 0) {
 		if (default_relax_domain_level < 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return;
+}
 		else
 			request = default_relax_domain_level;
 	} else
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		request = attr->relax_domain_level;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (request < sd->level) {
 		/* Turn off idle balance on this domain: */
 		sd->flags &= ~(SD_BALANCE_WAKE|SD_BALANCE_NEWIDLE);
@@ -1009,7 +1088,9 @@ static void __free_domain_allocs(struct s_data *d, enum s_alloc what,
 	switch (what) {
 	case sa_rootdomain:
 		if (!atomic_read(&d->rd->refcount))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			free_rootdomain(&d->rd->rcu);
+}
 		/* Fall through */
 	case sa_sd:
 		free_percpu(d->sd);
@@ -1025,16 +1106,23 @@ static void __free_domain_allocs(struct s_data *d, enum s_alloc what,
 static enum s_alloc
 __visit_domain_allocation_hell(struct s_data *d, const struct cpumask *cpu_map)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	memset(d, 0, sizeof(*d));
 
 	if (__sdt_alloc(cpu_map))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return sa_sd_storage;
+}
 	d->sd = alloc_percpu(struct sched_domain *);
 	if (!d->sd)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return sa_sd_storage;
+}
 	d->rd = alloc_rootdomain();
 	if (!d->rd)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return sa_sd;
+}
 	return sa_rootdomain;
 }
 
@@ -1167,11 +1255,13 @@ sd_init(struct sched_domain_topology_level *tl,
 	if (sd->flags & SD_ASYM_CPUCAPACITY) {
 		struct sched_domain *t = sd;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		for_each_lower_domain(t)
 			t->flags |= SD_BALANCE_WAKE;
 	}
 
 	if (sd->flags & SD_SHARE_CPUCAPACITY) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		sd->flags |= SD_PREFER_SIBLING;
 		sd->imbalance_pct = 110;
 		sd->smt_gain = 1178; /* ~15% */
@@ -1183,12 +1273,14 @@ sd_init(struct sched_domain_topology_level *tl,
 
 #ifdef CONFIG_NUMA
 	} else if (sd->flags & SD_NUMA) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		sd->cache_nice_tries = 2;
 		sd->busy_idx = 3;
 		sd->idle_idx = 2;
 
 		sd->flags |= SD_SERIALIZE;
 		if (sched_domains_numa_distance[tl->numa_level] > RECLAIM_DISTANCE) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			sd->flags &= ~(SD_BALANCE_EXEC |
 				       SD_BALANCE_FORK |
 				       SD_WAKE_AFFINE);
@@ -1196,6 +1288,7 @@ sd_init(struct sched_domain_topology_level *tl,
 
 #endif
 	} else {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		sd->flags |= SD_PREFER_SIBLING;
 		sd->cache_nice_tries = 1;
 		sd->busy_idx = 2;
@@ -1240,7 +1333,9 @@ static struct sched_domain_topology_level *sched_domain_topology =
 void set_sched_topology(struct sched_domain_topology_level *tl)
 {
 	if (WARN_ON_ONCE(sched_smp_initialized))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	sched_domain_topology = tl;
 }
@@ -1249,6 +1344,7 @@ void set_sched_topology(struct sched_domain_topology_level *tl)
 
 static const struct cpumask *sd_numa_mask(int cpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return sched_domains_numa_masks[sched_domains_curr_level][cpu_to_node(cpu)];
 }
 
@@ -1258,7 +1354,9 @@ static void sched_numa_warn(const char *str)
 	int i,j;
 
 	if (done)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	done = true;
 
@@ -1278,7 +1376,9 @@ bool find_numa_distance(int distance)
 	int i;
 
 	if (distance == node_distance(0, 0))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return true;
+}
 
 	for (i = 0; i < sched_domains_numa_levels; i++) {
 		if (sched_domains_numa_distance[i] == distance)
@@ -1314,6 +1414,7 @@ static void init_numa_topology_type(void)
 	n = sched_max_numa_distance;
 
 	if (sched_domains_numa_levels <= 1) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		sched_numa_topology_type = NUMA_DIRECT;
 		return;
 	}
@@ -1349,7 +1450,9 @@ void sched_init_numa(void)
 
 	sched_domains_numa_distance = kzalloc(sizeof(int) * nr_node_ids, GFP_KERNEL);
 	if (!sched_domains_numa_distance)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	/*
 	 * O(nr_nodes^2) deduplicating selection sort -- in order to find the
@@ -1483,6 +1586,7 @@ void sched_init_numa(void)
 
 void sched_domains_numa_masks_set(unsigned int cpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	int node = cpu_to_node(cpu);
 	int i, j;
 
@@ -1498,6 +1602,7 @@ void sched_domains_numa_masks_clear(unsigned int cpu)
 {
 	int i, j;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (i = 0; i < sched_domains_numa_levels; i++) {
 		for (j = 0; j < nr_node_ids; j++)
 			cpumask_clear_cpu(cpu, sched_domains_numa_masks[i][j]);
@@ -1516,19 +1621,27 @@ static int __sdt_alloc(const struct cpumask *cpu_map)
 
 		sdd->sd = alloc_percpu(struct sched_domain *);
 		if (!sdd->sd)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -ENOMEM;
+}
 
 		sdd->sds = alloc_percpu(struct sched_domain_shared *);
 		if (!sdd->sds)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -ENOMEM;
+}
 
 		sdd->sg = alloc_percpu(struct sched_group *);
 		if (!sdd->sg)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -ENOMEM;
+}
 
 		sdd->sgc = alloc_percpu(struct sched_group_capacity *);
 		if (!sdd->sgc)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -ENOMEM;
+}
 
 		for_each_cpu(j, cpu_map) {
 			struct sched_domain *sd;
@@ -1539,21 +1652,27 @@ static int __sdt_alloc(const struct cpumask *cpu_map)
 			sd = kzalloc_node(sizeof(struct sched_domain) + cpumask_size(),
 					GFP_KERNEL, cpu_to_node(j));
 			if (!sd)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				return -ENOMEM;
+}
 
 			*per_cpu_ptr(sdd->sd, j) = sd;
 
 			sds = kzalloc_node(sizeof(struct sched_domain_shared),
 					GFP_KERNEL, cpu_to_node(j));
 			if (!sds)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				return -ENOMEM;
+}
 
 			*per_cpu_ptr(sdd->sds, j) = sds;
 
 			sg = kzalloc_node(sizeof(struct sched_group) + cpumask_size(),
 					GFP_KERNEL, cpu_to_node(j));
 			if (!sg)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				return -ENOMEM;
+}
 
 			sg->next = sg;
 
@@ -1562,7 +1681,9 @@ static int __sdt_alloc(const struct cpumask *cpu_map)
 			sgc = kzalloc_node(sizeof(struct sched_group_capacity) + cpumask_size(),
 					GFP_KERNEL, cpu_to_node(j));
 			if (!sgc)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				return -ENOMEM;
+}
 
 #ifdef CONFIG_SCHED_DEBUG
 			sgc->id = j;
@@ -1572,6 +1693,7 @@ static int __sdt_alloc(const struct cpumask *cpu_map)
 		}
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
@@ -1589,7 +1711,9 @@ static void __sdt_free(const struct cpumask *cpu_map)
 			if (sdd->sd) {
 				sd = *per_cpu_ptr(sdd->sd, j);
 				if (sd && (sd->flags & SD_OVERLAP))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 					free_sched_groups(sd->groups, 0);
+}
 				kfree(*per_cpu_ptr(sdd->sd, j));
 			}
 
@@ -1618,12 +1742,15 @@ static struct sched_domain *build_sched_domain(struct sched_domain_topology_leve
 	struct sched_domain *sd = sd_init(tl, cpu_map, child, cpu);
 
 	if (child) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		sd->level = child->level + 1;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		sched_domain_level_max = max(sched_domain_level_max, sd->level);
 		child->parent = sd;
 
 		if (!cpumask_subset(sched_domain_span(child),
 				    sched_domain_span(sd))) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			pr_err("BUG: arch topology borken\n");
 #ifdef CONFIG_SCHED_DEBUG
 			pr_err("     the %s domain not a subset of the %s domain\n",
@@ -1668,7 +1795,9 @@ build_sched_domains(const struct cpumask *cpu_map, struct sched_domain_attr *att
 			if (tl == sched_domain_topology)
 				*per_cpu_ptr(d.sd, i) = sd;
 			if (tl->flags & SDTL_OVERLAP)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				sd->flags |= SD_OVERLAP;
+}
 			if (cpumask_equal(cpu_map, sched_domain_span(sd)))
 				break;
 		}
@@ -1679,6 +1808,7 @@ build_sched_domains(const struct cpumask *cpu_map, struct sched_domain_attr *att
 		for (sd = *per_cpu_ptr(d.sd, i); sd; sd = sd->parent) {
 			sd->span_weight = cpumask_weight(sched_domain_span(sd));
 			if (sd->flags & SD_OVERLAP) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				if (build_overlap_sched_groups(sd, i))
 					goto error;
 			} else {
@@ -1711,13 +1841,16 @@ build_sched_domains(const struct cpumask *cpu_map, struct sched_domain_attr *att
 
 		cpu_attach_domain(sd, d.rd, i);
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rcu_read_unlock();
 
 	if (rq && sched_debug_enabled) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_info("span: %*pbl (max cpu_capacity = %lu)\n",
 			cpumask_pr_args(cpu_map), rq->rd->max_cpu_capacity);
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	ret = 0;
 error:
 	__free_domain_allocs(&d, alloc_state, cpu_map);
@@ -1747,6 +1880,7 @@ static cpumask_var_t			fallback_doms;
  */
 int __weak arch_update_cpu_topology(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
@@ -1757,21 +1891,30 @@ cpumask_var_t *alloc_sched_domains(unsigned int ndoms)
 
 	doms = kmalloc(sizeof(*doms) * ndoms, GFP_KERNEL);
 	if (!doms)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (i = 0; i < ndoms; i++) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (!alloc_cpumask_var(&doms[i], GFP_KERNEL)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			free_sched_domains(doms, i);
 			return NULL;
 		}
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return doms;
 }
 
 void free_sched_domains(cpumask_var_t doms[], unsigned int ndoms)
 {
 	unsigned int i;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (i = 0; i < ndoms; i++)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		free_cpumask_var(doms[i]);
+}
 	kfree(doms);
 }
 
@@ -1792,7 +1935,9 @@ int sched_init_domains(const struct cpumask *cpu_map)
 	ndoms_cur = 1;
 	doms_cur = alloc_sched_domains(ndoms_cur);
 	if (!doms_cur)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		doms_cur = &fallback_doms;
+}
 	cpumask_andnot(doms_cur[0], cpu_map, cpu_isolated_map);
 	err = build_sched_domains(doms_cur[0], NULL);
 	register_sched_domain_sysctl();
@@ -1809,6 +1954,7 @@ static void detach_destroy_domains(const struct cpumask *cpu_map)
 	int i;
 
 	rcu_read_lock();
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for_each_cpu(i, cpu_map)
 		cpu_attach_domain(NULL, &def_root_domain, i);
 	rcu_read_unlock();
@@ -1822,7 +1968,9 @@ static int dattrs_equal(struct sched_domain_attr *cur, int idx_cur,
 
 	/* Fast path: */
 	if (!new && !cur)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 1;
+}
 
 	tmp = SD_ATTR_INIT;
 	return !memcmp(cur ? (cur + idx_cur) : &tmp,
@@ -1871,19 +2019,23 @@ void partition_sched_domains(int ndoms_new, cpumask_var_t doms_new[],
 	new_topology = arch_update_cpu_topology();
 
 	if (!doms_new) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		WARN_ON_ONCE(dattr_new);
 		n = 0;
 		doms_new = alloc_sched_domains(1);
 		if (doms_new) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			n = 1;
 			cpumask_andnot(doms_new[0], cpu_active_mask, cpu_isolated_map);
 		}
 	} else {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		n = ndoms_new;
 	}
 
 	/* Destroy deleted domains: */
 	for (i = 0; i < ndoms_cur; i++) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		for (j = 0; j < n && !new_topology; j++) {
 			if (cpumask_equal(doms_cur[i], doms_new[j])
 			    && dattrs_equal(dattr_cur, i, dattr_new, j))
@@ -1895,8 +2047,10 @@ void partition_sched_domains(int ndoms_new, cpumask_var_t doms_new[],
 		;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	n = ndoms_cur;
 	if (!doms_new) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		n = 0;
 		doms_new = &fallback_doms;
 		cpumask_andnot(doms_new[0], cpu_active_mask, cpu_isolated_map);
@@ -1904,6 +2058,7 @@ void partition_sched_domains(int ndoms_new, cpumask_var_t doms_new[],
 
 	/* Build new domains: */
 	for (i = 0; i < ndoms_new; i++) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		for (j = 0; j < n && !new_topology; j++) {
 			if (cpumask_equal(doms_new[i], doms_cur[j])
 			    && dattrs_equal(dattr_new, i, dattr_cur, j))
@@ -1917,7 +2072,9 @@ void partition_sched_domains(int ndoms_new, cpumask_var_t doms_new[],
 
 	/* Remember the new sched domains: */
 	if (doms_cur != &fallback_doms)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		free_sched_domains(doms_cur, ndoms_cur);
+}
 
 	kfree(dattr_cur);
 	doms_cur = doms_new;
diff --git a/kernel/sched/wait.c b/kernel/sched/wait.c
index 929ecb7..58a22e9 100644
--- a/kernel/sched/wait.c
+++ b/kernel/sched/wait.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * Generic waiting primitives.
  *
@@ -15,6 +17,7 @@
 void __init_waitqueue_head(struct wait_queue_head *wq_head, const char *name, struct lock_class_key *key)
 {
 	spin_lock_init(&wq_head->lock);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_set_class_and_name(&wq_head->lock, key, name);
 	INIT_LIST_HEAD(&wq_head->head);
 }
@@ -27,6 +30,7 @@ void add_wait_queue(struct wait_queue_head *wq_head, struct wait_queue_entry *wq
 
 	wq_entry->flags &= ~WQ_FLAG_EXCLUSIVE;
 	spin_lock_irqsave(&wq_head->lock, flags);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	__add_wait_queue(wq_head, wq_entry);
 	spin_unlock_irqrestore(&wq_head->lock, flags);
 }
@@ -37,6 +41,7 @@ void add_wait_queue_exclusive(struct wait_queue_head *wq_head, struct wait_queue
 	unsigned long flags;
 
 	wq_entry->flags |= WQ_FLAG_EXCLUSIVE;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_lock_irqsave(&wq_head->lock, flags);
 	__add_wait_queue_entry_tail(wq_head, wq_entry);
 	spin_unlock_irqrestore(&wq_head->lock, flags);
@@ -48,6 +53,7 @@ void remove_wait_queue(struct wait_queue_head *wq_head, struct wait_queue_entry
 	unsigned long flags;
 
 	spin_lock_irqsave(&wq_head->lock, flags);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	__remove_wait_queue(wq_head, wq_entry);
 	spin_unlock_irqrestore(&wq_head->lock, flags);
 }
@@ -77,6 +83,7 @@ static int __wake_up_common(struct wait_queue_head *wq_head, unsigned int mode,
 	int cnt = 0;
 
 	if (bookmark && (bookmark->flags & WQ_FLAG_BOOKMARK)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		curr = list_next_entry(bookmark, entry);
 
 		list_del(&bookmark->entry);
@@ -85,7 +92,9 @@ static int __wake_up_common(struct wait_queue_head *wq_head, unsigned int mode,
 		curr = list_first_entry(&wq_head->head, wait_queue_entry_t, entry);
 
 	if (&curr->entry == &wq_head->head)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return nr_exclusive;
+}
 
 	list_for_each_entry_safe_from(curr, next, &wq_head->head, entry) {
 		unsigned flags = curr->flags;
@@ -102,11 +111,13 @@ static int __wake_up_common(struct wait_queue_head *wq_head, unsigned int mode,
 
 		if (bookmark && (++cnt > WAITQUEUE_WALK_BREAK_CNT) &&
 				(&next->entry != &wq_head->head)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			bookmark->flags = WQ_FLAG_BOOKMARK;
 			list_add_tail(&bookmark->entry, &next->entry);
 			break;
 		}
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return nr_exclusive;
 }
 
@@ -126,7 +137,9 @@ static void __wake_up_common_lock(struct wait_queue_head *wq_head, unsigned int
 	spin_unlock_irqrestore(&wq_head->lock, flags);
 
 	while (bookmark.flags & WQ_FLAG_BOOKMARK) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		spin_lock_irqsave(&wq_head->lock, flags);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		nr_exclusive = __wake_up_common(wq_head, mode, nr_exclusive,
 						wake_flags, key, &bookmark);
 		spin_unlock_irqrestore(&wq_head->lock, flags);
@@ -195,10 +208,14 @@ void __wake_up_sync_key(struct wait_queue_head *wq_head, unsigned int mode,
 	int wake_flags = 1; /* XXX WF_SYNC */
 
 	if (unlikely(!wq_head))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	if (unlikely(nr_exclusive != 1))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		wake_flags = 0;
+}
 
 	__wake_up_common_lock(wq_head, mode, nr_exclusive, wake_flags, key);
 }
@@ -209,6 +226,7 @@ EXPORT_SYMBOL_GPL(__wake_up_sync_key);
  */
 void __wake_up_sync(struct wait_queue_head *wq_head, unsigned int mode, int nr_exclusive)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	__wake_up_sync_key(wq_head, mode, nr_exclusive, NULL);
 }
 EXPORT_SYMBOL_GPL(__wake_up_sync);	/* For internal use only */
@@ -233,8 +251,11 @@ prepare_to_wait(struct wait_queue_head *wq_head, struct wait_queue_entry *wq_ent
 	wq_entry->flags &= ~WQ_FLAG_EXCLUSIVE;
 	spin_lock_irqsave(&wq_head->lock, flags);
 	if (list_empty(&wq_entry->entry))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		__add_wait_queue(wq_head, wq_entry);
+}
 	set_current_state(state);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_unlock_irqrestore(&wq_head->lock, flags);
 }
 EXPORT_SYMBOL(prepare_to_wait);
@@ -247,8 +268,11 @@ prepare_to_wait_exclusive(struct wait_queue_head *wq_head, struct wait_queue_ent
 	wq_entry->flags |= WQ_FLAG_EXCLUSIVE;
 	spin_lock_irqsave(&wq_head->lock, flags);
 	if (list_empty(&wq_entry->entry))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		__add_wait_queue_entry_tail(wq_head, wq_entry);
+}
 	set_current_state(state);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_unlock_irqrestore(&wq_head->lock, flags);
 }
 EXPORT_SYMBOL(prepare_to_wait_exclusive);
@@ -286,12 +310,15 @@ long prepare_to_wait_event(struct wait_queue_head *wq_head, struct wait_queue_en
 	} else {
 		if (list_empty(&wq_entry->entry)) {
 			if (wq_entry->flags & WQ_FLAG_EXCLUSIVE)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				__add_wait_queue_entry_tail(wq_head, wq_entry);
+}
 			else
 				__add_wait_queue(wq_head, wq_entry);
 		}
 		set_current_state(state);
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_unlock_irqrestore(&wq_head->lock, flags);
 
 	return ret;
@@ -307,6 +334,7 @@ EXPORT_SYMBOL(prepare_to_wait_event);
  */
 int do_wait_intr(wait_queue_head_t *wq, wait_queue_entry_t *wait)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (likely(list_empty(&wait->entry)))
 		__add_wait_queue_entry_tail(wq, wait);
 
@@ -324,12 +352,17 @@ EXPORT_SYMBOL(do_wait_intr);
 int do_wait_intr_irq(wait_queue_head_t *wq, wait_queue_entry_t *wait)
 {
 	if (likely(list_empty(&wait->entry)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		__add_wait_queue_entry_tail(wq, wait);
+}
 
 	set_current_state(TASK_INTERRUPTIBLE);
 	if (signal_pending(current))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ERESTARTSYS;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_unlock_irq(&wq->lock);
 	schedule();
 	spin_lock_irq(&wq->lock);
diff --git a/kernel/sched/wait_bit.c b/kernel/sched/wait_bit.c
index f815969..31ff7d3 100644
--- a/kernel/sched/wait_bit.c
+++ b/kernel/sched/wait_bit.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * The implementation of the wait_bit*() and related waiting APIs:
  */
@@ -13,6 +15,7 @@ static wait_queue_head_t bit_wait_table[WAIT_TABLE_SIZE] __cacheline_aligned;
 
 wait_queue_head_t *bit_waitqueue(void *word, int bit)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	const int shift = BITS_PER_LONG == 32 ? 5 : 6;
 	unsigned long val = (unsigned long)word << shift | bit;
 
@@ -23,6 +26,7 @@ EXPORT_SYMBOL(bit_waitqueue);
 int wake_bit_function(struct wait_queue_entry *wq_entry, unsigned mode, int sync, void *arg)
 {
 	struct wait_bit_key *key = arg;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct wait_bit_queue_entry *wait_bit = container_of(wq_entry, struct wait_bit_queue_entry, wq_entry);
 
 	if (wait_bit->key.flags != key->flags ||
@@ -46,6 +50,7 @@ __wait_on_bit(struct wait_queue_head *wq_head, struct wait_bit_queue_entry *wbq_
 	int ret = 0;
 
 	do {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		prepare_to_wait(wq_head, &wbq_entry->wq_entry, mode);
 		if (test_bit(wbq_entry->key.bit_nr, wbq_entry->key.flags))
 			ret = (*action)(&wbq_entry->key, mode);
@@ -58,6 +63,7 @@ EXPORT_SYMBOL(__wait_on_bit);
 int __sched out_of_line_wait_on_bit(void *word, int bit,
 				    wait_bit_action_f *action, unsigned mode)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct wait_queue_head *wq_head = bit_waitqueue(word, bit);
 	DEFINE_WAIT_BIT(wq_entry, word, bit);
 
@@ -69,6 +75,7 @@ int __sched out_of_line_wait_on_bit_timeout(
 	void *word, int bit, wait_bit_action_f *action,
 	unsigned mode, unsigned long timeout)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct wait_queue_head *wq_head = bit_waitqueue(word, bit);
 	DEFINE_WAIT_BIT(wq_entry, word, bit);
 
@@ -84,6 +91,7 @@ __wait_on_bit_lock(struct wait_queue_head *wq_head, struct wait_bit_queue_entry
 	int ret = 0;
 
 	for (;;) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		prepare_to_wait_exclusive(wq_head, &wbq_entry->wq_entry, mode);
 		if (test_bit(wbq_entry->key.bit_nr, wbq_entry->key.flags)) {
 			ret = action(&wbq_entry->key, mode);
@@ -110,6 +118,7 @@ EXPORT_SYMBOL(__wait_on_bit_lock);
 int __sched out_of_line_wait_on_bit_lock(void *word, int bit,
 					 wait_bit_action_f *action, unsigned mode)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct wait_queue_head *wq_head = bit_waitqueue(word, bit);
 	DEFINE_WAIT_BIT(wq_entry, word, bit);
 
@@ -121,8 +130,10 @@ void __wake_up_bit(struct wait_queue_head *wq_head, void *word, int bit)
 {
 	struct wait_bit_key key = __WAIT_BIT_KEY_INITIALIZER(word, bit);
 	if (waitqueue_active(wq_head))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		__wake_up(wq_head, TASK_NORMAL, 1, &key);
 }
+}
 EXPORT_SYMBOL(__wake_up_bit);
 
 /**
@@ -155,6 +166,7 @@ EXPORT_SYMBOL(wake_up_bit);
  */
 static inline wait_queue_head_t *atomic_t_waitqueue(atomic_t *p)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (BITS_PER_LONG == 64) {
 		unsigned long q = (unsigned long)p;
 		return bit_waitqueue((void *)(q & ~1), q & 1);
@@ -166,6 +178,7 @@ static int wake_atomic_t_function(struct wait_queue_entry *wq_entry, unsigned mo
 				  void *arg)
 {
 	struct wait_bit_key *key = arg;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct wait_bit_queue_entry *wait_bit = container_of(wq_entry, struct wait_bit_queue_entry, wq_entry);
 	atomic_t *val = key->flags;
 
@@ -189,6 +202,7 @@ int __wait_on_atomic_t(struct wait_queue_head *wq_head, struct wait_bit_queue_en
 	int ret = 0;
 
 	do {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		prepare_to_wait(wq_head, &wbq_entry->wq_entry, mode);
 		val = wbq_entry->key.flags;
 		if (atomic_read(val) == 0)
diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index 5f0dfb2ab..68e8641 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 /*
  * linux/kernel/seccomp.c
@@ -75,6 +77,7 @@ struct seccomp_filter {
  */
 static void populate_seccomp_data(struct seccomp_data *sd)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct task_struct *task = current;
 	struct pt_regs *regs = task_pt_regs(task);
 	unsigned long args[6];
@@ -106,6 +109,7 @@ static void populate_seccomp_data(struct seccomp_data *sd)
 static int seccomp_check_filter(struct sock_filter *filter, unsigned int flen)
 {
 	int pc;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (pc = 0; pc < flen; pc++) {
 		struct sock_filter *ftest = &filter[pc];
 		u16 code = ftest->code;
@@ -219,6 +223,7 @@ static u32 seccomp_run_filters(const struct seccomp_data *sd,
 
 static inline bool seccomp_may_assign_mode(unsigned long seccomp_mode)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	assert_spin_locked(&current->sighand->siglock);
 
 	if (current->seccomp.mode && current->seccomp.mode != seccomp_mode)
@@ -230,6 +235,7 @@ static inline bool seccomp_may_assign_mode(unsigned long seccomp_mode)
 static inline void seccomp_assign_mode(struct task_struct *task,
 				       unsigned long seccomp_mode)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	assert_spin_locked(&task->sighand->siglock);
 
 	task->seccomp.mode = seccomp_mode;
@@ -268,6 +274,7 @@ static inline pid_t seccomp_can_sync_threads(void)
 {
 	struct task_struct *thread, *caller;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	BUG_ON(!mutex_is_locked(&current->signal->cred_guard_mutex));
 	assert_spin_locked(&current->sighand->siglock);
 
@@ -309,6 +316,7 @@ static inline void seccomp_sync_threads(void)
 {
 	struct task_struct *thread, *caller;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	BUG_ON(!mutex_is_locked(&current->signal->cred_guard_mutex));
 	assert_spin_locked(&current->sighand->siglock);
 
@@ -362,6 +370,7 @@ static struct seccomp_filter *seccomp_prepare_filter(struct sock_fprog *fprog)
 	int ret;
 	const bool save_orig = IS_ENABLED(CONFIG_CHECKPOINT_RESTORE);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (fprog->len == 0 || fprog->len > BPF_MAXINSNS)
 		return ERR_PTR(-EINVAL);
 
@@ -412,6 +421,7 @@ seccomp_prepare_user_filter(const char __user *user_filter)
 		struct compat_sock_fprog fprog32;
 		if (copy_from_user(&fprog32, user_filter, sizeof(fprog32)))
 			goto out;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		fprog.len = fprog32.len;
 		fprog.filter = compat_ptr(fprog32.filter);
 	} else /* falls through to the if below. */
@@ -438,6 +448,7 @@ static long seccomp_attach_filter(unsigned int flags,
 	unsigned long total_insns;
 	struct seccomp_filter *walker;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	assert_spin_locked(&current->sighand->siglock);
 
 	/* Validate resulting filter length. */
@@ -485,12 +496,16 @@ void get_seccomp_filter(struct task_struct *tsk)
 {
 	struct seccomp_filter *orig = tsk->seccomp.filter;
 	if (!orig)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	__get_seccomp_filter(orig);
 }
 
 static inline void seccomp_filter_free(struct seccomp_filter *filter)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (filter) {
 		bpf_prog_destroy(filter->prog);
 		kfree(filter);
@@ -515,6 +530,7 @@ void put_seccomp_filter(struct task_struct *tsk)
 
 static void seccomp_init_siginfo(siginfo_t *info, int syscall, int reason)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	memset(info, 0, sizeof(*info));
 	info->si_signo = SIGSYS;
 	info->si_code = SYS_SECCOMP;
@@ -613,7 +629,9 @@ static void __secure_computing_strict(int this_syscall)
 	const int *syscall_whitelist = mode1_syscalls;
 #ifdef CONFIG_COMPAT
 	if (in_compat_syscall())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		syscall_whitelist = get_compat_mode1_syscalls();
+}
 #endif
 	do {
 		if (*syscall_whitelist == this_syscall)
@@ -771,6 +789,7 @@ static int __seccomp_filter(int this_syscall, const struct seccomp_data *sd,
 
 int __secure_computing(const struct seccomp_data *sd)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	int mode = current->seccomp.mode;
 	int this_syscall;
 
@@ -795,6 +814,7 @@ int __secure_computing(const struct seccomp_data *sd)
 
 long prctl_get_seccomp(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return current->seccomp.mode;
 }
 
@@ -850,7 +870,9 @@ static long seccomp_set_mode_filter(unsigned int flags,
 
 	/* Validate flags. */
 	if (flags & ~SECCOMP_FILTER_FLAG_MASK)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	/* Prepare the new filter before holding any locks. */
 	prepared = seccomp_prepare_user_filter(filter);
@@ -898,7 +920,9 @@ static long seccomp_get_action_avail(const char __user *uaction)
 	u32 action;
 
 	if (copy_from_user(&action, uaction, sizeof(action)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EFAULT;
+}
 
 	switch (action) {
 	case SECCOMP_RET_KILL_PROCESS:
@@ -920,6 +944,7 @@ static long seccomp_get_action_avail(const char __user *uaction)
 static long do_seccomp(unsigned int op, unsigned int flags,
 		       const char __user *uargs)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	switch (op) {
 	case SECCOMP_SET_MODE_STRICT:
 		if (flags != 0 || uargs != NULL)
@@ -940,6 +965,7 @@ static long do_seccomp(unsigned int op, unsigned int flags,
 SYSCALL_DEFINE3(seccomp, unsigned int, op, unsigned int, flags,
 			 const char __user *, uargs)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return do_seccomp(op, flags, uargs);
 }
 
@@ -1092,6 +1118,7 @@ static bool seccomp_names_from_actions_logged(char *names, size_t size,
 	const struct seccomp_log_name *cur;
 	bool append_space = false;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (cur = seccomp_log_names; cur->name && size; cur++) {
 		ssize_t ret;
 
@@ -1124,6 +1151,7 @@ static bool seccomp_action_logged_from_name(u32 *action_logged,
 {
 	const struct seccomp_log_name *cur;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (cur = seccomp_log_names; cur->name; cur++) {
 		if (!strcmp(cur->name, name)) {
 			*action_logged = cur->log;
@@ -1139,6 +1167,7 @@ static bool seccomp_actions_logged_from_names(u32 *actions_logged, char *names)
 	char *name;
 
 	*actions_logged = 0;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	while ((name = strsep(&names, " ")) && *name) {
 		u32 action_logged = 0;
 
@@ -1159,6 +1188,7 @@ static int seccomp_actions_logged_handler(struct ctl_table *ro_table, int write,
 	struct ctl_table table;
 	int ret;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (write && !capable(CAP_SYS_ADMIN))
 		return -EPERM;
 
@@ -1221,7 +1251,9 @@ static int __init seccomp_sysctl_init(void)
 
 	hdr = register_sysctl_paths(seccomp_sysctl_path, seccomp_sysctl_table);
 	if (!hdr)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_warn("seccomp: sysctl registration failed\n");
+}
 	else
 		kmemleak_not_leak(hdr);
 
diff --git a/kernel/signal.c b/kernel/signal.c
index 6895f6bb..316e3c2 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  *  linux/kernel/signal.c
  *
@@ -92,7 +94,9 @@ static int sig_ignored(struct task_struct *t, int sig, bool force)
 	 * unblocked.
 	 */
 	if (sigismember(&t->blocked, sig) || sigismember(&t->real_blocked, sig))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	/*
 	 * Tracers may want to know about even ignored signal unless it
@@ -100,7 +104,9 @@ static int sig_ignored(struct task_struct *t, int sig, bool force)
 	 * by SIGNAL_UNKILLABLE task.
 	 */
 	if (t->ptrace && sig != SIGKILL)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	return sig_task_ignored(t, sig, force);
 }
@@ -117,21 +123,26 @@ static inline int has_pending_signals(sigset_t *signal, sigset_t *blocked)
 	switch (_NSIG_WORDS) {
 	default:
 		for (i = _NSIG_WORDS, ready = 0; --i >= 0 ;)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			ready |= signal->sig[i] &~ blocked->sig[i];
+}
 		break;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	case 4: ready  = signal->sig[3] &~ blocked->sig[3];
 		ready |= signal->sig[2] &~ blocked->sig[2];
 		ready |= signal->sig[1] &~ blocked->sig[1];
 		ready |= signal->sig[0] &~ blocked->sig[0];
 		break;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	case 2: ready  = signal->sig[1] &~ blocked->sig[1];
 		ready |= signal->sig[0] &~ blocked->sig[0];
 		break;
 
 	case 1: ready  = signal->sig[0] &~ blocked->sig[0];
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return ready !=	0;
 }
 
@@ -142,6 +153,7 @@ static int recalc_sigpending_tsk(struct task_struct *t)
 	if ((t->jobctl & JOBCTL_PENDING_MASK) ||
 	    PENDING(&t->pending, &t->blocked) ||
 	    PENDING(&t->signal->shared_pending, &t->blocked)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		set_tsk_thread_flag(t, TIF_SIGPENDING);
 		return 1;
 	}
@@ -159,6 +171,7 @@ static int recalc_sigpending_tsk(struct task_struct *t)
  */
 void recalc_sigpending_and_wake(struct task_struct *t)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (recalc_sigpending_tsk(t))
 		signal_wake_up(t, 0);
 }
@@ -191,17 +204,22 @@ int next_signal(struct sigpending *pending, sigset_t *mask)
 	x = *s &~ *m;
 	if (x) {
 		if (x & SYNCHRONOUS_MASK)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			x &= SYNCHRONOUS_MASK;
+}
 		sig = ffz(~x) + 1;
 		return sig;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	switch (_NSIG_WORDS) {
 	default:
 		for (i = 1; i < _NSIG_WORDS; ++i) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			x = *++s &~ *++m;
 			if (!x)
 				continue;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			sig = ffz(~x) + i*_NSIG_BPW + 1;
 			break;
 		}
@@ -211,6 +229,7 @@ int next_signal(struct sigpending *pending, sigset_t *mask)
 		x = s[1] &~ m[1];
 		if (!x)
 			break;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		sig = ffz(~x) + _NSIG_BPW + 1;
 		break;
 
@@ -219,6 +238,7 @@ int next_signal(struct sigpending *pending, sigset_t *mask)
 		break;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return sig;
 }
 
@@ -227,7 +247,9 @@ static inline void print_dropped_signal(int sig)
 	static DEFINE_RATELIMIT_STATE(ratelimit_state, 5 * HZ, 10);
 
 	if (!print_fatal_signals)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	if (!__ratelimit(&ratelimit_state))
 		return;
@@ -260,7 +282,9 @@ bool task_set_jobctl_pending(struct task_struct *task, unsigned long mask)
 	BUG_ON((mask & JOBCTL_TRAPPING) && !(mask & JOBCTL_PENDING_MASK));
 
 	if (unlikely(fatal_signal_pending(task) || (task->flags & PF_EXITING)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return false;
+}
 
 	if (mask & JOBCTL_STOP_SIGMASK)
 		task->jobctl &= ~JOBCTL_STOP_SIGMASK;
@@ -284,6 +308,7 @@ bool task_set_jobctl_pending(struct task_struct *task, unsigned long mask)
 void task_clear_jobctl_trapping(struct task_struct *task)
 {
 	if (unlikely(task->jobctl & JOBCTL_TRAPPING)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		task->jobctl &= ~JOBCTL_TRAPPING;
 		smp_mb();	/* advised by wake_up_bit() */
 		wake_up_bit(&task->jobctl, JOBCTL_TRAPPING_BIT);
@@ -344,7 +369,9 @@ static bool task_participate_group_stop(struct task_struct *task)
 	task_clear_jobctl_pending(task, JOBCTL_STOP_PENDING);
 
 	if (!consume)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return false;
+}
 
 	if (!WARN_ON_ONCE(sig->group_stop_count == 0))
 		sig->group_stop_count--;
@@ -357,6 +384,7 @@ static bool task_participate_group_stop(struct task_struct *task)
 		signal_set_stop_flags(sig, SIGNAL_STOP_STOPPED);
 		return true;
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return false;
 }
 
@@ -385,10 +413,12 @@ __sigqueue_alloc(int sig, struct task_struct *t, gfp_t flags, int override_rlimi
 			task_rlimit(t, RLIMIT_SIGPENDING)) {
 		q = kmem_cache_alloc(sigqueue_cachep, flags);
 	} else {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		print_dropped_signal(sig);
 	}
 
 	if (unlikely(q == NULL)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		atomic_dec(&user->sigpending);
 		free_uid(user);
 	} else {
@@ -403,7 +433,9 @@ __sigqueue_alloc(int sig, struct task_struct *t, gfp_t flags, int override_rlimi
 static void __sigqueue_free(struct sigqueue *q)
 {
 	if (q->flags & SIGQUEUE_PREALLOC)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 	atomic_dec(&q->user->sigpending);
 	free_uid(q->user);
 	kmem_cache_free(sigqueue_cachep, q);
@@ -429,6 +461,7 @@ void flush_signals(struct task_struct *t)
 	unsigned long flags;
 
 	spin_lock_irqsave(&t->sighand->siglock, flags);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	clear_tsk_thread_flag(t, TIF_SIGPENDING);
 	flush_sigqueue(&t->pending);
 	flush_sigqueue(&t->signal->shared_pending);
@@ -448,19 +481,23 @@ static void __flush_itimer_signals(struct sigpending *pending)
 		int sig = q->info.si_signo;
 
 		if (likely(q->info.si_code != SI_TIMER)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			sigaddset(&retain, sig);
 		} else {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			sigdelset(&signal, sig);
 			list_del_init(&q->list);
 			__sigqueue_free(q);
 		}
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	sigorsets(&pending->signal, &signal, &retain);
 }
 
 void flush_itimer_signals(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct task_struct *tsk = current;
 	unsigned long flags;
 
@@ -506,9 +543,13 @@ int unhandled_signal(struct task_struct *tsk, int sig)
 {
 	void __user *handler = tsk->sighand->action[sig-1].sa.sa_handler;
 	if (is_global_init(tsk))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 1;
+}
 	if (handler != SIG_IGN && handler != SIG_DFL)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 	/* if ptraced, let the tracer determine */
 	return !tsk->ptrace;
 }
@@ -526,6 +567,7 @@ static void collect_signal(int sig, struct sigpending *list, siginfo_t *info,
 		if (q->info.si_signo == sig) {
 			if (first)
 				goto still_pending;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			first = q;
 		}
 	}
@@ -614,7 +656,9 @@ int dequeue_signal(struct task_struct *tsk, sigset_t *mask, siginfo_t *info)
 
 	recalc_sigpending();
 	if (!signr)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	if (unlikely(sig_kernel_stop(signr))) {
 		/*
@@ -660,6 +704,7 @@ int dequeue_signal(struct task_struct *tsk, sigset_t *mask, siginfo_t *info)
  */
 void signal_wake_up_state(struct task_struct *t, unsigned int state)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	set_tsk_thread_flag(t, TIF_SIGPENDING);
 	/*
 	 * TASK_WAKEKILL also means wake it up in the stopped/traced/killable
@@ -685,20 +730,28 @@ static int flush_sigqueue_mask(sigset_t *mask, struct sigpending *s)
 
 	sigandsets(&m, mask, &s->signal);
 	if (sigisemptyset(&m))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	sigandnsets(&s->signal, &s->signal, mask);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry_safe(q, n, &s->list, list) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (sigismember(mask, q->info.si_signo)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			list_del_init(&q->list);
 			__sigqueue_free(q);
 		}
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 1;
 }
 
 static inline int is_si_special(const struct siginfo *info)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return info <= SEND_SIG_FORCED;
 }
 
@@ -723,8 +776,11 @@ static int kill_ok_by_cred(struct task_struct *t)
 		return 1;
 
 	if (ns_capable(tcred->user_ns, CAP_KILL))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 1;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
@@ -739,17 +795,24 @@ static int check_kill_permission(int sig, struct siginfo *info,
 	int error;
 
 	if (!valid_signal(sig))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	if (!si_fromuser(info))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	error = audit_signal_info(sig, t); /* Let audit system see the signal */
 	if (error)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return error;
+}
 
 	if (!same_thread_group(current, t) &&
 	    !kill_ok_by_cred(t)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		switch (sig) {
 		case SIGCONT:
 			sid = task_session(t);
@@ -786,6 +849,7 @@ static int check_kill_permission(int sig, struct siginfo *info,
  */
 static void ptrace_trap_notify(struct task_struct *t)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WARN_ON_ONCE(!(t->ptrace & PT_SEIZED));
 	assert_spin_locked(&t->sighand->siglock);
 
@@ -811,7 +875,9 @@ static bool prepare_signal(int sig, struct task_struct *p, bool force)
 
 	if (signal->flags & (SIGNAL_GROUP_EXIT | SIGNAL_GROUP_COREDUMP)) {
 		if (!(signal->flags & SIGNAL_GROUP_EXIT))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return sig == SIGKILL;
+}
 		/*
 		 * The process is in the middle of dying, nothing to do.
 		 */
@@ -849,9 +915,14 @@ static bool prepare_signal(int sig, struct task_struct *p, bool force)
 		 */
 		why = 0;
 		if (signal->flags & SIGNAL_STOP_STOPPED)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			why |= SIGNAL_CLD_CONTINUED;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		else if (signal->group_stop_count)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			why |= SIGNAL_CLD_STOPPED;
+}
 
 		if (why) {
 			/*
@@ -879,13 +950,21 @@ static bool prepare_signal(int sig, struct task_struct *p, bool force)
 static inline int wants_signal(int sig, struct task_struct *p)
 {
 	if (sigismember(&p->blocked, sig))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 	if (p->flags & PF_EXITING)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 	if (sig == SIGKILL)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 1;
+}
 	if (task_is_stopped_or_traced(p))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 	return task_curr(p) || !signal_pending(p);
 }
 
@@ -901,7 +980,9 @@ static void complete_signal(int sig, struct task_struct *p, int group)
 	 * Probably the least surprising to the average bear.
 	 */
 	if (wants_signal(sig, p))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		t = p;
+}
 	else if (!group || thread_group_empty(p))
 		/*
 		 * There is just one thread and it does not need to be woken.
@@ -914,6 +995,7 @@ static void complete_signal(int sig, struct task_struct *p, int group)
 		 */
 		t = signal->curr_target;
 		while (!wants_signal(sig, t)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			t = next_thread(t);
 			if (t == signal->curr_target)
 				/*
@@ -953,6 +1035,7 @@ static void complete_signal(int sig, struct task_struct *p, int group)
 				sigaddset(&t->pending.signal, SIGKILL);
 				signal_wake_up(t, 1);
 			} while_each_thread(p, t);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return;
 		}
 	}
@@ -987,6 +1070,7 @@ static inline void userns_fixup_signal_uid(struct siginfo *info, struct task_str
 #else
 static inline void userns_fixup_signal_uid(struct siginfo *info, struct task_struct *t)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return;
 }
 #endif
@@ -1001,6 +1085,7 @@ static int __send_signal(int sig, struct siginfo *info, struct task_struct *t,
 
 	assert_spin_locked(&t->sighand->siglock);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	result = TRACE_SIGNAL_IGNORED;
 	if (!prepare_signal(sig, t,
 			from_ancestor_ns || (info == SEND_SIG_FORCED)))
@@ -1016,6 +1101,7 @@ static int __send_signal(int sig, struct siginfo *info, struct task_struct *t,
 	if (legacy_queue(pending, sig))
 		goto ret;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	result = TRACE_SIGNAL_DELIVERED;
 	/*
 	 * fast-pathed signals for kernel-internal things like SIGSTOP
@@ -1067,6 +1153,7 @@ static int __send_signal(int sig, struct siginfo *info, struct task_struct *t,
 		userns_fixup_signal_uid(&q->info, t);
 
 	} else if (!is_si_special(info)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (sig >= SIGRTMIN && info->si_code != SI_USER) {
 			/*
 			 * Queue overflow, abort.  We may abort if the
@@ -1109,6 +1196,7 @@ static int send_signal(int sig, struct siginfo *info, struct task_struct *t,
 
 static void print_fatal_signal(int signr)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct pt_regs *regs = signal_pt_regs();
 	pr_info("potentially unexpected fatal signal %d.\n", signr);
 
@@ -1133,6 +1221,7 @@ static void print_fatal_signal(int signr)
 
 static int __init setup_print_fatal_signals(char *str)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	get_option (&str, &print_fatal_signals);
 
 	return 1;
@@ -1189,8 +1278,10 @@ force_sig_info(int sig, struct siginfo *info, struct task_struct *t)
 	ignored = action->sa.sa_handler == SIG_IGN;
 	blocked = sigismember(&t->blocked, sig);
 	if (blocked || ignored) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		action->sa.sa_handler = SIG_DFL;
 		if (blocked) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			sigdelset(&t->blocked, sig);
 			recalc_sigpending_and_wake(t);
 		}
@@ -1224,6 +1315,7 @@ int zap_other_threads(struct task_struct *p)
 		/* Don't bother with already dead threads */
 		if (t->exit_state)
 			continue;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		sigaddset(&t->pending.signal, SIGKILL);
 		signal_wake_up(t, 1);
 	}
@@ -1242,10 +1334,13 @@ struct sighand_struct *__lock_task_sighand(struct task_struct *tsk,
 		 * See rcu_read_unlock() comment header for details.
 		 */
 		local_irq_save(*flags);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		rcu_read_lock();
 		sighand = rcu_dereference(tsk->sighand);
 		if (unlikely(sighand == NULL)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			rcu_read_unlock();
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			local_irq_restore(*flags);
 			break;
 		}
@@ -1262,11 +1357,14 @@ struct sighand_struct *__lock_task_sighand(struct task_struct *tsk,
 		 */
 		spin_lock(&sighand->siglock);
 		if (likely(sighand == tsk->sighand)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			rcu_read_unlock();
 			break;
 		}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		spin_unlock(&sighand->siglock);
 		rcu_read_unlock();
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		local_irq_restore(*flags);
 	}
 
@@ -1306,6 +1404,7 @@ int __kill_pgrp_info(int sig, struct siginfo *info, struct pid *pgrp)
 		int err = group_send_sig_info(sig, info, p);
 		success |= !err;
 		retval = err;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	} while_each_pid_task(pgrp, PIDTYPE_PGID, p);
 	return success ? 0 : retval;
 }
@@ -1316,10 +1415,12 @@ int kill_pid_info(int sig, struct siginfo *info, struct pid *pid)
 	struct task_struct *p;
 
 	for (;;) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		rcu_read_lock();
 		p = pid_task(pid, PIDTYPE_PID);
 		if (p)
 			error = group_send_sig_info(sig, info, p);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		rcu_read_unlock();
 		if (likely(!p || error != -ESRCH))
 			return error;
@@ -1344,6 +1445,7 @@ static int kill_proc_info(int sig, struct siginfo *info, pid_t pid)
 static int kill_as_cred_perm(const struct cred *cred,
 			     struct task_struct *target)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	const struct cred *pcred = __task_cred(target);
 	if (!uid_eq(cred->euid, pcred->suid) && !uid_eq(cred->euid, pcred->uid) &&
 	    !uid_eq(cred->uid,  pcred->suid) && !uid_eq(cred->uid,  pcred->uid))
@@ -1360,7 +1462,9 @@ int kill_pid_info_as_cred(int sig, struct siginfo *info, struct pid *pid,
 	unsigned long flags;
 
 	if (!valid_signal(sig))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ret;
+}
 
 	rcu_read_lock();
 	p = pid_task(pid, PIDTYPE_PID);
@@ -1401,6 +1505,7 @@ static int kill_something_info(int sig, struct siginfo *info, pid_t pid)
 	int ret;
 
 	if (pid > 0) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		rcu_read_lock();
 		ret = kill_pid_info(sig, info, find_vpid(pid));
 		rcu_read_unlock();
@@ -1409,8 +1514,11 @@ static int kill_something_info(int sig, struct siginfo *info, pid_t pid)
 
 	/* -INT_MIN is undefined.  Exclude this case to avoid a UBSAN warning */
 	if (pid == INT_MIN)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ESRCH;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	read_lock(&tasklist_lock);
 	if (pid != -1) {
 		ret = __kill_pgrp_info(sig, info,
@@ -1419,17 +1527,24 @@ static int kill_something_info(int sig, struct siginfo *info, pid_t pid)
 		int retval = 0, count = 0;
 		struct task_struct * p;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		for_each_process(p) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			if (task_pid_vnr(p) > 1 &&
 					!same_thread_group(p, current)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				int err = group_send_sig_info(sig, info, p);
 				++count;
 				if (err != -EPERM)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 					retval = err;
+}
 			}
 		}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ret = count ? retval : -ESRCH;
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	read_unlock(&tasklist_lock);
 
 	return ret;
@@ -1446,7 +1561,9 @@ int send_sig_info(int sig, struct siginfo *info, struct task_struct *p)
 	 * (normal paths check this in check_kill_permission).
 	 */
 	if (!valid_signal(sig))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	return do_send_sig_info(sig, info, p, false);
 }
@@ -1463,6 +1580,7 @@ send_sig(int sig, struct task_struct *p, int priv)
 void
 force_sig(int sig, struct task_struct *p)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	force_sig_info(sig, SEND_SIG_PRIV, p);
 }
 
@@ -1475,6 +1593,7 @@ force_sig(int sig, struct task_struct *p)
 int
 force_sigsegv(int sig, struct task_struct *p)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (sig == SIGSEGV) {
 		unsigned long flags;
 		spin_lock_irqsave(&p->sighand->siglock, flags);
@@ -1499,6 +1618,7 @@ EXPORT_SYMBOL(kill_pgrp);
 
 int kill_pid(struct pid *pid, int sig, int priv)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return kill_pid_info(sig, __si_special(priv), pid);
 }
 EXPORT_SYMBOL(kill_pid);
@@ -1540,7 +1660,10 @@ void sigqueue_free(struct sigqueue *q)
 	 * like the "regular" sigqueue.
 	 */
 	if (!list_empty(&q->list))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		q = NULL;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_unlock_irqrestore(lock, flags);
 
 	if (q)
@@ -1554,6 +1677,7 @@ int send_sigqueue(struct sigqueue *q, struct task_struct *t, int group)
 	unsigned long flags;
 	int ret, result;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	BUG_ON(!(q->flags & SIGQUEUE_PREALLOC));
 
 	ret = -1;
@@ -1620,7 +1744,9 @@ bool do_notify_parent(struct task_struct *tsk, int sig)
 		 * Check if it has changed security domain.
 		 */
 		if (tsk->parent_exec_id != tsk->parent->self_exec_id)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			sig = SIGCHLD;
+}
 	}
 
 	info.si_signo = sig;
@@ -1648,7 +1774,9 @@ bool do_notify_parent(struct task_struct *tsk, int sig)
 
 	info.si_status = tsk->exit_code & 0x7f;
 	if (tsk->exit_code & 0x80)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		info.si_code = CLD_DUMPED;
+}
 	else if (tsk->exit_code & 0x7f)
 		info.si_code = CLD_KILLED;
 	else {
@@ -1678,7 +1806,9 @@ bool do_notify_parent(struct task_struct *tsk, int sig)
 		 */
 		autoreap = true;
 		if (psig->action[SIGCHLD-1].sa.sa_handler == SIG_IGN)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			sig = 0;
+}
 	}
 	if (valid_signal(sig) && sig)
 		__group_send_sig_info(sig, &info, tsk->parent);
@@ -1761,7 +1891,9 @@ static void do_notify_parent_cldstop(struct task_struct *tsk,
 static inline int may_ptrace_stop(void)
 {
 	if (!likely(current->ptrace))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 	/*
 	 * Are we in the middle of do_coredump?
 	 * If so and our tracer is also part of the coredump stopping
@@ -1779,6 +1911,7 @@ static inline int may_ptrace_stop(void)
 	    unlikely(current->mm == current->parent->mm))
 		return 0;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 1;
 }
 
@@ -1788,6 +1921,7 @@ static inline int may_ptrace_stop(void)
  */
 static int sigkill_pending(struct task_struct *tsk)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return	sigismember(&tsk->pending.signal, SIGKILL) ||
 		sigismember(&tsk->signal->shared_pending.signal, SIGKILL);
 }
@@ -1822,10 +1956,14 @@ static void ptrace_stop(int exit_code, int why, int clear_code, siginfo_t *info)
 		 * So after regaining the lock, we must check for SIGKILL.
 		 */
 		spin_unlock_irq(&current->sighand->siglock);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		arch_ptrace_stop(exit_code, info);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		spin_lock_irq(&current->sighand->siglock);
 		if (sigkill_pending(current))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return;
+}
 	}
 
 	/*
@@ -1848,12 +1986,16 @@ static void ptrace_stop(int exit_code, int why, int clear_code, siginfo_t *info)
 	 * TASK_TRACED is entered - ignore it.
 	 */
 	if (why == CLD_STOPPED && (current->jobctl & JOBCTL_STOP_PENDING))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		gstop_done = task_participate_group_stop(current);
+}
 
 	/* any trap clears pending STOP trap, STOP trap clears NOTIFY */
 	task_clear_jobctl_pending(current, JOBCTL_TRAP_STOP);
 	if (info && info->si_code >> 8 == PTRACE_EVENT_STOP)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		task_clear_jobctl_pending(current, JOBCTL_TRAP_NOTIFY);
+}
 
 	/* entering a trap, clear TRAPPING */
 	task_clear_jobctl_trapping(current);
@@ -1873,7 +2015,9 @@ static void ptrace_stop(int exit_code, int why, int clear_code, siginfo_t *info)
 		 */
 		do_notify_parent_cldstop(current, true, why);
 		if (gstop_done && ptrace_reparented(current))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			do_notify_parent_cldstop(current, false, why);
+}
 
 		/*
 		 * Don't want to allow preemption here, because
@@ -1897,12 +2041,18 @@ static void ptrace_stop(int exit_code, int why, int clear_code, siginfo_t *info)
 		 * the real parent of the group stop completion is enough.
 		 */
 		if (gstop_done)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			do_notify_parent_cldstop(current, false, why);
+}
 
 		/* tasklist protects us from ptrace_freeze_traced() */
 		__set_current_state(TASK_RUNNING);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (clear_code)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			current->exit_code = 0;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		read_unlock(&tasklist_lock);
 	}
 
@@ -2014,6 +2164,7 @@ static bool do_signal_stop(int signr)
 		if (task_set_jobctl_pending(current, signr | gstop))
 			sig->group_stop_count++;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		t = current;
 		while_each_thread(current, t) {
 			/*
@@ -2023,9 +2174,12 @@ static bool do_signal_stop(int signr)
 			 */
 			if (!task_is_stopped(t) &&
 			    task_set_jobctl_pending(t, signr | gstop)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				sig->group_stop_count++;
 				if (likely(!(t->ptrace & PT_SEIZED)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 					signal_wake_up(t, 0);
+}
 				else
 					ptrace_trap_notify(t);
 			}
@@ -2041,7 +2195,9 @@ static bool do_signal_stop(int signr)
 		 * report to the parent.
 		 */
 		if (task_participate_group_stop(current))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			notify = CLD_STOPPED;
+}
 
 		__set_current_state(TASK_STOPPED);
 		spin_unlock_irq(&current->sighand->siglock);
@@ -2091,6 +2247,7 @@ static bool do_signal_stop(int signr)
  */
 static void do_jobctl_trap(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct signal_struct *signal = current->signal;
 	int signr = current->jobctl & JOBCTL_STOP_SIGMASK;
 
@@ -2125,8 +2282,11 @@ static int ptrace_signal(int signr, siginfo_t *info)
 	/* We're back.  Did the debugger cancel the sig?  */
 	signr = current->exit_code;
 	if (signr == 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return signr;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	current->exit_code = 0;
 
 	/*
@@ -2136,6 +2296,7 @@ static int ptrace_signal(int signr, siginfo_t *info)
 	 * have updated *info via PTRACE_SETSIGINFO.
 	 */
 	if (signr != info->si_signo) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		info->si_signo = signr;
 		info->si_errno = 0;
 		info->si_code = SI_USER;
@@ -2148,10 +2309,12 @@ static int ptrace_signal(int signr, siginfo_t *info)
 
 	/* If the (new) signal is now blocked, requeue it.  */
 	if (sigismember(&current->blocked, signr)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		specific_send_sig_info(signr, info, current);
 		signr = 0;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return signr;
 }
 
@@ -2165,7 +2328,9 @@ int get_signal(struct ksignal *ksig)
 		task_work_run();
 
 	if (unlikely(uprobe_deny_signal()))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	/*
 	 * Do this once, we can't return to user-mode if freezing() == T.
@@ -2185,7 +2350,9 @@ int get_signal(struct ksignal *ksig)
 		int why;
 
 		if (signal->flags & SIGNAL_CLD_CONTINUED)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			why = CLD_CONTINUED;
+}
 		else
 			why = CLD_STOPPED;
 
@@ -2205,8 +2372,10 @@ int get_signal(struct ksignal *ksig)
 		do_notify_parent_cldstop(current, false, why);
 
 		if (ptrace_reparented(current->group_leader))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			do_notify_parent_cldstop(current->group_leader,
 						true, why);
+}
 		read_unlock(&tasklist_lock);
 
 		goto relock;
@@ -2220,6 +2389,7 @@ int get_signal(struct ksignal *ksig)
 			goto relock;
 
 		if (unlikely(current->jobctl & JOBCTL_TRAP_MASK)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			do_jobctl_trap();
 			spin_unlock_irq(&sighand->siglock);
 			goto relock;
@@ -2248,7 +2418,9 @@ int get_signal(struct ksignal *ksig)
 			ksig->ka = *ka;
 
 			if (ka->sa.sa_flags & SA_ONESHOT)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				ka->sa.sa_handler = SIG_DFL;
+}
 
 			break; /* will return non-zero "signr" value */
 		}
@@ -2285,6 +2457,7 @@ int get_signal(struct ksignal *ksig)
 			 * We need to check for that and bail out if necessary.
 			 */
 			if (signr != SIGSTOP) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				spin_unlock_irq(&sighand->siglock);
 
 				/* signals can be posted during this window */
@@ -2292,6 +2465,7 @@ int get_signal(struct ksignal *ksig)
 				if (is_current_pgrp_orphaned())
 					goto relock;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				spin_lock_irq(&sighand->siglock);
 			}
 
@@ -2307,6 +2481,7 @@ int get_signal(struct ksignal *ksig)
 			continue;
 		}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		spin_unlock_irq(&sighand->siglock);
 
 		/*
@@ -2316,7 +2491,9 @@ int get_signal(struct ksignal *ksig)
 
 		if (sig_kernel_coredump(signr)) {
 			if (print_fatal_signals)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				print_fatal_signal(ksig->info.si_signo);
+}
 			proc_coredump_connector(current);
 			/*
 			 * If it was able to dump core, this kills all
@@ -2335,6 +2512,7 @@ int get_signal(struct ksignal *ksig)
 		do_group_exit(ksig->info.si_signo);
 		/* NOTREACHED */
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_unlock_irq(&sighand->siglock);
 
 	ksig->sig = signr;
@@ -2371,7 +2549,9 @@ static void signal_delivered(struct ksignal *ksig, int stepping)
 void signal_setup_done(int failed, struct ksignal *ksig, int stepping)
 {
 	if (failed)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		force_sigsegv(ksig->sig, current);
+}
 	else
 		signal_delivered(ksig, stepping);
 }
@@ -2388,8 +2568,11 @@ static void retarget_shared_pending(struct task_struct *tsk, sigset_t *which)
 
 	sigandsets(&retarget, &tsk->signal->shared_pending.signal, which);
 	if (sigisemptyset(&retarget))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	t = tsk;
 	while_each_thread(tsk, t) {
 		if (t->flags & PF_EXITING)
@@ -2401,7 +2584,9 @@ static void retarget_shared_pending(struct task_struct *tsk, sigset_t *which)
 		sigandsets(&retarget, &retarget, &t->blocked);
 
 		if (!signal_pending(t))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			signal_wake_up(t, 0);
+}
 
 		if (sigisemptyset(&retarget))
 			break;
@@ -2437,6 +2622,7 @@ void exit_signals(struct task_struct *tsk)
 	if (!signal_pending(tsk))
 		goto out;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	unblocked = tsk->blocked;
 	signotset(&unblocked);
 	retarget_shared_pending(tsk, &unblocked);
@@ -2452,6 +2638,7 @@ void exit_signals(struct task_struct *tsk)
 	 * should always go to the real parent of the group leader.
 	 */
 	if (unlikely(group_stop)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		read_lock(&tasklist_lock);
 		do_notify_parent_cldstop(tsk, false, group_stop);
 		read_unlock(&tasklist_lock);
@@ -2481,6 +2668,7 @@ SYSCALL_DEFINE0(restart_syscall)
 
 long do_no_restart_syscall(struct restart_block *param)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return -EINTR;
 }
 
@@ -2505,12 +2693,14 @@ static void __set_task_blocked(struct task_struct *tsk, const sigset_t *newset)
  */
 void set_current_blocked(sigset_t *newset)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	sigdelsetmask(newset, sigmask(SIGKILL) | sigmask(SIGSTOP));
 	__set_current_blocked(newset);
 }
 
 void __set_current_blocked(const sigset_t *newset)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct task_struct *tsk = current;
 
 	/*
@@ -2518,7 +2708,9 @@ void __set_current_blocked(const sigset_t *newset)
 	 * to do. The current->blocked shouldn't be modified by other task.
 	 */
 	if (sigequalsets(&tsk->blocked, newset))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	spin_lock_irq(&tsk->sighand->siglock);
 	__set_task_blocked(tsk, newset);
@@ -2535,12 +2727,15 @@ void __set_current_blocked(const sigset_t *newset)
  */
 int sigprocmask(int how, sigset_t *set, sigset_t *oldset)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct task_struct *tsk = current;
 	sigset_t newset;
 
 	/* Lockless, only current can change ->blocked, never from irq */
 	if (oldset)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		*oldset = tsk->blocked;
+}
 
 	switch (how) {
 	case SIG_BLOCK:
@@ -2575,25 +2770,35 @@ SYSCALL_DEFINE4(rt_sigprocmask, int, how, sigset_t __user *, nset,
 
 	/* XXX: Don't preclude handling different sized sigset_t's.  */
 	if (sigsetsize != sizeof(sigset_t))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	old_set = current->blocked;
 
 	if (nset) {
 		if (copy_from_user(&new_set, nset, sizeof(sigset_t)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -EFAULT;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		sigdelsetmask(&new_set, sigmask(SIGKILL)|sigmask(SIGSTOP));
 
 		error = sigprocmask(how, &new_set, NULL);
 		if (error)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return error;
+}
 	}
 
 	if (oset) {
 		if (copy_to_user(oset, &old_set, sizeof(sigset_t)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -EFAULT;
+}
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
@@ -2638,6 +2843,7 @@ COMPAT_SYSCALL_DEFINE4(rt_sigprocmask, int, how, compat_sigset_t __user *, nset,
 
 static int do_sigpending(void *set, unsigned long sigsetsize)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (sigsetsize > sizeof(sigset_t))
 		return -EINVAL;
 
@@ -2661,6 +2867,7 @@ SYSCALL_DEFINE2(rt_sigpending, sigset_t __user *, uset, size_t, sigsetsize)
 {
 	sigset_t set;
 	int err = do_sigpending(&set, sigsetsize);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!err && copy_to_user(uset, &set, sigsetsize))
 		err = -EFAULT;
 	return err;
@@ -2710,15 +2917,24 @@ enum siginfo_layout siginfo_layout(int sig, int si_code)
 		};
 		if ((sig < ARRAY_SIZE(filter)) && (si_code <= filter[sig].limit))
 			layout = filter[sig].layout;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		else if (si_code <= NSIGPOLL)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			layout = SIL_POLL;
+}
 	} else {
 		if (si_code == SI_TIMER)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			layout = SIL_TIMER;
+}
 		else if (si_code == SI_SIGIO)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			layout = SIL_POLL;
+}
 		else if (si_code < 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			layout = SIL_RT;
+}
 		/* Tests to support buggy kernel ABIs */
 #ifdef TRAP_FIXME
 		if ((sig == SIGTRAP) && (si_code == TRAP_FIXME))
@@ -2739,10 +2955,14 @@ int copy_siginfo_to_user(siginfo_t __user *to, const siginfo_t *from)
 	int err;
 
 	if (!access_ok (VERIFY_WRITE, to, sizeof(siginfo_t)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EFAULT;
+}
 	if (from->si_code < 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return __copy_to_user(to, from, sizeof(siginfo_t))
 			? -EFAULT : 0;
+}
 	/*
 	 * If you change siginfo_t structure, please be sure
 	 * this code is fixed accordingly.
@@ -2765,6 +2985,7 @@ int copy_siginfo_to_user(siginfo_t __user *to, const siginfo_t *from)
 		break;
 	case SIL_POLL:
 		err |= __put_user(from->si_band, &to->si_band);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		err |= __put_user(from->si_fd, &to->si_fd);
 		break;
 	case SIL_FAULT:
@@ -2783,13 +3004,17 @@ int copy_siginfo_to_user(siginfo_t __user *to, const siginfo_t *from)
 #endif
 #ifdef SEGV_BNDERR
 		if (from->si_signo == SIGSEGV && from->si_code == SEGV_BNDERR) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			err |= __put_user(from->si_lower, &to->si_lower);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			err |= __put_user(from->si_upper, &to->si_upper);
 		}
 #endif
 #ifdef SEGV_PKUERR
 		if (from->si_signo == SIGSEGV && from->si_code == SEGV_PKUERR)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			err |= __put_user(from->si_pkey, &to->si_pkey);
+}
 #endif
 		break;
 	case SIL_CHLD:
@@ -2801,17 +3026,22 @@ int copy_siginfo_to_user(siginfo_t __user *to, const siginfo_t *from)
 		break;
 	case SIL_RT:
 		err |= __put_user(from->si_pid, &to->si_pid);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		err |= __put_user(from->si_uid, &to->si_uid);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		err |= __put_user(from->si_ptr, &to->si_ptr);
 		break;
 #ifdef __ARCH_SIGSYS
 	case SIL_SYS:
 		err |= __put_user(from->si_call_addr, &to->si_call_addr);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		err |= __put_user(from->si_syscall, &to->si_syscall);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		err |= __put_user(from->si_arch, &to->si_arch);
 		break;
 #endif
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return err;
 }
 
@@ -2833,7 +3063,9 @@ static int do_sigtimedwait(const sigset_t *which, siginfo_t *info,
 
 	if (ts) {
 		if (!timespec_valid(ts))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -EINVAL;
+}
 		timeout = timespec_to_ktime(*ts);
 		to = &timeout;
 	}
@@ -2869,7 +3101,9 @@ static int do_sigtimedwait(const sigset_t *which, siginfo_t *info,
 	spin_unlock_irq(&tsk->sighand->siglock);
 
 	if (sig)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return sig;
+}
 	return ret ? -EINTR : -EAGAIN;
 }
 
@@ -2892,21 +3126,29 @@ SYSCALL_DEFINE4(rt_sigtimedwait, const sigset_t __user *, uthese,
 
 	/* XXX: Don't preclude handling different sized sigset_t's.  */
 	if (sigsetsize != sizeof(sigset_t))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	if (copy_from_user(&these, uthese, sizeof(these)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EFAULT;
+}
 
 	if (uts) {
 		if (copy_from_user(&ts, uts, sizeof(ts)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -EFAULT;
+}
 	}
 
 	ret = do_sigtimedwait(&these, &info, uts ? &ts : NULL);
 
 	if (ret > 0 && uinfo) {
 		if (copy_siginfo_to_user(uinfo, &info))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			ret = -EFAULT;
+}
 	}
 
 	return ret;
@@ -2924,7 +3166,9 @@ COMPAT_SYSCALL_DEFINE4(rt_sigtimedwait, compat_sigset_t __user *, uthese,
 	long ret;
 
 	if (sigsetsize != sizeof(sigset_t))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	if (copy_from_user(&s32, uthese, sizeof(compat_sigset_t)))
 		return -EFAULT;
@@ -2986,9 +3230,12 @@ do_send_specific(pid_t tgid, pid_t pid, int sig, struct siginfo *info)
 			 * and the signal is private anyway.
 			 */
 			if (unlikely(error == -ESRCH))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				error = 0;
+}
 		}
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rcu_read_unlock();
 
 	return error;
@@ -3021,7 +3268,9 @@ SYSCALL_DEFINE3(tgkill, pid_t, tgid, pid_t, pid, int, sig)
 {
 	/* This is only valid for single tasks */
 	if (pid <= 0 || tgid <= 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	return do_tkill(tgid, pid, sig);
 }
@@ -3037,7 +3286,9 @@ SYSCALL_DEFINE2(tkill, pid_t, pid, int, sig)
 {
 	/* This is only valid for single tasks */
 	if (pid <= 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	return do_tkill(0, pid, sig);
 }
@@ -3068,7 +3319,9 @@ SYSCALL_DEFINE3(rt_sigqueueinfo, pid_t, pid, int, sig,
 {
 	siginfo_t info;
 	if (copy_from_user(&info, uinfo, sizeof(siginfo_t)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EFAULT;
+}
 	return do_rt_sigqueueinfo(pid, sig, &info);
 }
 
@@ -3081,7 +3334,9 @@ COMPAT_SYSCALL_DEFINE3(rt_sigqueueinfo,
 	siginfo_t info = {};
 	int ret = copy_siginfo_from_user32(&info, uinfo);
 	if (unlikely(ret))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ret;
+}
 	return do_rt_sigqueueinfo(pid, sig, &info);
 }
 #endif
@@ -3110,7 +3365,9 @@ SYSCALL_DEFINE4(rt_tgsigqueueinfo, pid_t, tgid, pid_t, pid, int, sig,
 	siginfo_t info;
 
 	if (copy_from_user(&info, uinfo, sizeof(siginfo_t)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EFAULT;
+}
 
 	return do_rt_tgsigqueueinfo(tgid, pid, sig, &info);
 }
@@ -3125,7 +3382,9 @@ COMPAT_SYSCALL_DEFINE4(rt_tgsigqueueinfo,
 	siginfo_t info = {};
 
 	if (copy_siginfo_from_user32(&info, uinfo))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EFAULT;
+}
 	return do_rt_tgsigqueueinfo(tgid, pid, sig, &info);
 }
 #endif
@@ -3158,12 +3417,15 @@ void __weak sigaction_compat_abi(struct k_sigaction *act,
 
 int do_sigaction(int sig, struct k_sigaction *act, struct k_sigaction *oact)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct task_struct *p = current, *t;
 	struct k_sigaction *k;
 	sigset_t mask;
 
 	if (!valid_signal(sig) || sig < 1 || (act && sig_kernel_only(sig)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	k = &p->sighand->action[sig-1];
 
@@ -3174,6 +3436,7 @@ int do_sigaction(int sig, struct k_sigaction *act, struct k_sigaction *oact)
 	sigaction_compat_abi(act, oact);
 
 	if (act) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		sigdelsetmask(&act->sa.sa_mask,
 			      sigmask(SIGKILL) | sigmask(SIGSTOP));
 		*k = *act;
@@ -3189,6 +3452,7 @@ int do_sigaction(int sig, struct k_sigaction *act, struct k_sigaction *oact)
 		 *   be discarded, whether or not it is blocked"
 		 */
 		if (sig_handler_ignored(sig_handler(p, sig), sig)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			sigemptyset(&mask);
 			sigaddset(&mask, sig);
 			flush_sigqueue_mask(&mask, &p->signal->shared_pending);
@@ -3204,9 +3468,11 @@ int do_sigaction(int sig, struct k_sigaction *act, struct k_sigaction *oact)
 static int
 do_sigaltstack (const stack_t *ss, stack_t *oss, unsigned long sp)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct task_struct *t = current;
 
 	if (oss) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		memset(oss, 0, sizeof(stack_t));
 		oss->ss_sp = (void __user *) t->sas_ss_sp;
 		oss->ss_size = t->sas_ss_size;
@@ -3221,7 +3487,9 @@ do_sigaltstack (const stack_t *ss, stack_t *oss, unsigned long sp)
 		int ss_mode;
 
 		if (unlikely(on_sig_stack(sp)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -EPERM;
+}
 
 		ss_mode = ss_flags & ~SS_FLAG_BITS;
 		if (unlikely(ss_mode != SS_DISABLE && ss_mode != SS_ONSTACK &&
@@ -3229,17 +3497,21 @@ do_sigaltstack (const stack_t *ss, stack_t *oss, unsigned long sp)
 			return -EINVAL;
 
 		if (ss_mode == SS_DISABLE) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			ss_size = 0;
 			ss_sp = NULL;
 		} else {
 			if (unlikely(ss_size < MINSIGSTKSZ))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				return -ENOMEM;
+}
 		}
 
 		t->sas_ss_sp = (unsigned long) ss_sp;
 		t->sas_ss_size = ss_size;
 		t->sas_ss_flags = ss_flags;
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
@@ -3248,11 +3520,15 @@ SYSCALL_DEFINE2(sigaltstack,const stack_t __user *,uss, stack_t __user *,uoss)
 	stack_t new, old;
 	int err;
 	if (uss && copy_from_user(&new, uss, sizeof(stack_t)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EFAULT;
+}
 	err = do_sigaltstack(uss ? &new : NULL, uoss ? &old : NULL,
 			      current_user_stack_pointer());
 	if (!err && uoss && copy_to_user(uoss, &old, sizeof(stack_t)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		err = -EFAULT;
+}
 	return err;
 }
 
@@ -3260,7 +3536,9 @@ int restore_altstack(const stack_t __user *uss)
 {
 	stack_t new;
 	if (copy_from_user(&new, uss, sizeof(stack_t)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EFAULT;
+}
 	(void)do_sigaltstack(&new, NULL, current_user_stack_pointer());
 	/* squash all but EFAULT for now */
 	return 0;
@@ -3268,6 +3546,7 @@ int restore_altstack(const stack_t __user *uss)
 
 int __save_altstack(stack_t __user *uss, unsigned long sp)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct task_struct *t = current;
 	int err = __put_user((void __user *)t->sas_ss_sp, &uss->ss_sp) |
 		__put_user(t->sas_ss_flags, &uss->ss_flags) |
@@ -3290,7 +3569,9 @@ COMPAT_SYSCALL_DEFINE2(sigaltstack,
 	if (uss_ptr) {
 		compat_stack_t uss32;
 		if (copy_from_user(&uss32, uss_ptr, sizeof(compat_stack_t)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -EFAULT;
+}
 		uss.ss_sp = compat_ptr(uss32.ss_sp);
 		uss.ss_flags = uss32.ss_flags;
 		uss.ss_size = uss32.ss_size;
@@ -3311,6 +3592,7 @@ COMPAT_SYSCALL_DEFINE2(sigaltstack,
 
 int compat_restore_altstack(const compat_stack_t __user *uss)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	int err = compat_sys_sigaltstack(uss, NULL);
 	/* squash all but -EFAULT for now */
 	return err == -EFAULT ? err : 0;
@@ -3320,6 +3602,7 @@ int __compat_save_altstack(compat_stack_t __user *uss, unsigned long sp)
 {
 	int err;
 	struct task_struct *t = current;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	err = __put_user(ptr_to_compat((void __user *)t->sas_ss_sp),
 			 &uss->ss_sp) |
 		__put_user(t->sas_ss_flags, &uss->ss_flags) |
@@ -3340,6 +3623,7 @@ int __compat_save_altstack(compat_stack_t __user *uss, unsigned long sp)
  */
 SYSCALL_DEFINE1(sigpending, old_sigset_t __user *, set)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return sys_rt_sigpending((sigset_t __user *)set, sizeof(old_sigset_t)); 
 }
 
@@ -3380,6 +3664,7 @@ SYSCALL_DEFINE3(sigprocmask, int, how, old_sigset_t __user *, nset,
 	old_set = current->blocked.sig[0];
 
 	if (nset) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (copy_from_user(&new_set, nset, sizeof(*nset)))
 			return -EFAULT;
 
@@ -3433,14 +3718,18 @@ SYSCALL_DEFINE4(rt_sigaction, int, sig,
 
 	if (act) {
 		if (copy_from_user(&new_sa.sa, act, sizeof(new_sa.sa)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -EFAULT;
+}
 	}
 
 	ret = do_sigaction(sig, act ? &new_sa : NULL, oact ? &old_sa : NULL);
 
 	if (!ret && oact) {
 		if (copy_to_user(oact, &old_sa.sa, sizeof(old_sa.sa)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -EFAULT;
+}
 	}
 out:
 	return ret;
@@ -3460,7 +3749,9 @@ COMPAT_SYSCALL_DEFINE4(rt_sigaction, int, sig,
 
 	/* XXX: Don't preclude handling different sized sigset_t's.  */
 	if (sigsetsize != sizeof(compat_sigset_t))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	if (act) {
 		compat_uptr_t handler;
@@ -3610,6 +3901,7 @@ SYSCALL_DEFINE2(signal, int, sig, __sighandler_t, handler)
 
 	ret = do_sigaction(sig, &new_sa, &old_sa);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return ret ? ret : (unsigned long)old_sa.sa.sa_handler;
 }
 #endif /* __ARCH_WANT_SYS_SIGNAL */
@@ -3620,6 +3912,7 @@ SYSCALL_DEFINE0(pause)
 {
 	while (!signal_pending(current)) {
 		__set_current_state(TASK_INTERRUPTIBLE);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		schedule();
 	}
 	return -ERESTARTNOHAND;
@@ -3652,10 +3945,14 @@ SYSCALL_DEFINE2(rt_sigsuspend, sigset_t __user *, unewset, size_t, sigsetsize)
 
 	/* XXX: Don't preclude handling different sized sigset_t's.  */
 	if (sigsetsize != sizeof(sigset_t))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	if (copy_from_user(&newset, unewset, sizeof(newset)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EFAULT;
+}
 	return sigsuspend(&newset);
 }
  
@@ -3700,6 +3997,7 @@ SYSCALL_DEFINE3(sigsuspend, int, unused1, int, unused2, old_sigset_t, mask)
 
 __weak const char *arch_vma_name(struct vm_area_struct *vma)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return NULL;
 }
 
diff --git a/kernel/smp.c b/kernel/smp.c
index c94dd85..4872aab 100644
--- a/kernel/smp.c
+++ b/kernel/smp.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * Generic helpers for smp ipi calls
  *
@@ -48,21 +50,25 @@ int smpcfd_prepare_cpu(unsigned int cpu)
 		return -ENOMEM;
 	if (!zalloc_cpumask_var_node(&cfd->cpumask_ipi, GFP_KERNEL,
 				     cpu_to_node(cpu))) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		free_cpumask_var(cfd->cpumask);
 		return -ENOMEM;
 	}
 	cfd->csd = alloc_percpu(call_single_data_t);
 	if (!cfd->csd) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		free_cpumask_var(cfd->cpumask);
 		free_cpumask_var(cfd->cpumask_ipi);
 		return -ENOMEM;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
 int smpcfd_dead_cpu(unsigned int cpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct call_function_data *cfd = &per_cpu(cfd_data, cpu);
 
 	free_cpumask_var(cfd->cpumask);
@@ -110,6 +116,7 @@ static __always_inline void csd_lock_wait(call_single_data_t *csd)
 
 static __always_inline void csd_lock(call_single_data_t *csd)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	csd_lock_wait(csd);
 	csd->flags |= CSD_FLAG_LOCK;
 
@@ -156,11 +163,14 @@ static int generic_exec_single(int cpu, call_single_data_t *csd,
 	}
 
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if ((unsigned)cpu >= nr_cpu_ids || !cpu_online(cpu)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		csd_unlock(csd);
 		return -ENXIO;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	csd->func = func;
 	csd->info = info;
 
@@ -176,8 +186,11 @@ static int generic_exec_single(int cpu, call_single_data_t *csd,
 	 * equipped to do the right thing...
 	 */
 	if (llist_add(&csd->llist, &per_cpu(call_single_queue, cpu)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		arch_send_call_function_single_ipi(cpu);
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
@@ -189,6 +202,7 @@ static int generic_exec_single(int cpu, call_single_data_t *csd,
  */
 void generic_smp_call_function_single_interrupt(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	flush_smp_call_function_queue(true);
 }
 
@@ -213,6 +227,7 @@ static void flush_smp_call_function_queue(bool warn_cpu_offline)
 	call_single_data_t *csd, *csd_next;
 	static bool warned;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WARN_ON(!irqs_disabled());
 
 	head = this_cpu_ptr(&call_single_queue);
@@ -292,6 +307,7 @@ int smp_call_function_single(int cpu, smp_call_func_t func, void *info,
 
 	csd = &csd_stack;
 	if (!wait) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		csd = this_cpu_ptr(&csd_data);
 		csd_lock(csd);
 	}
@@ -299,7 +315,9 @@ int smp_call_function_single(int cpu, smp_call_func_t func, void *info,
 	err = generic_exec_single(cpu, csd, func, info);
 
 	if (wait)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		csd_lock_wait(csd);
+}
 
 	put_cpu();
 
@@ -422,19 +440,25 @@ void smp_call_function_many(const struct cpumask *mask,
 
 	/* No online cpus?  We're done. */
 	if (cpu >= nr_cpu_ids)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	/* Do we have another CPU which isn't us? */
 	next_cpu = cpumask_next_and(cpu, mask, cpu_online_mask);
 	if (next_cpu == this_cpu)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		next_cpu = cpumask_next_and(next_cpu, mask, cpu_online_mask);
+}
 
 	/* Fastpath: do that cpu by itself. */
 	if (next_cpu >= nr_cpu_ids) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		smp_call_function_single(cpu, func, info, wait);
 		return;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	cfd = this_cpu_ptr(&cfd_data);
 
 	cpumask_and(cfd->cpumask, mask, cpu_online_mask);
@@ -442,28 +466,41 @@ void smp_call_function_many(const struct cpumask *mask,
 
 	/* Some callers race with other cpus changing the passed mask */
 	if (unlikely(!cpumask_weight(cfd->cpumask)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	cpumask_clear(cfd->cpumask_ipi);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for_each_cpu(cpu, cfd->cpumask) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		call_single_data_t *csd = per_cpu_ptr(cfd->csd, cpu);
 
 		csd_lock(csd);
 		if (wait)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			csd->flags |= CSD_FLAG_SYNCHRONOUS;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		csd->func = func;
 		csd->info = info;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (llist_add(&csd->llist, &per_cpu(call_single_queue, cpu)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			__cpumask_set_cpu(cpu, cfd->cpumask_ipi);
+}
 	}
 
 	/* Send a message to all CPUs in the map */
 	arch_send_call_function_ipi_mask(cfd->cpumask_ipi);
 
 	if (wait) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		for_each_cpu(cpu, cfd->cpumask) {
 			call_single_data_t *csd;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			csd = per_cpu_ptr(cfd->csd, cpu);
 			csd_lock_wait(csd);
 		}
@@ -516,6 +553,7 @@ void __weak arch_disable_smp_support(void) { }
 
 static int __init nosmp(char *str)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	setup_max_cpus = 0;
 	arch_disable_smp_support();
 
@@ -530,6 +568,7 @@ static int __init nrcpus(char *str)
 	int nr_cpus;
 
 	get_option(&str, &nr_cpus);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (nr_cpus > 0 && nr_cpus < nr_cpu_ids)
 		nr_cpu_ids = nr_cpus;
 
@@ -540,6 +579,7 @@ early_param("nr_cpus", nrcpus);
 
 static int __init maxcpus(char *str)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	get_option(&str, &setup_max_cpus);
 	if (setup_max_cpus == 0)
 		arch_disable_smp_support();
@@ -575,9 +615,12 @@ void __init smp_init(void)
 		if (num_online_cpus() >= setup_max_cpus)
 			break;
 		if (!cpu_online(cpu))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			cpu_up(cpu);
+}
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	num_nodes = num_online_nodes();
 	num_cpus  = num_online_cpus();
 	pr_info("Brought up %d node%s, %d CPU%s\n",
@@ -632,8 +675,11 @@ void on_each_cpu_mask(const struct cpumask *mask, smp_call_func_t func,
 	smp_call_function_many(mask, func, info, wait);
 	if (cpumask_test_cpu(cpu, mask)) {
 		unsigned long flags;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		local_irq_save(flags);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		func(info);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		local_irq_restore(flags);
 	}
 	put_cpu();
@@ -676,11 +722,14 @@ void on_each_cpu_cond(bool (*cond_func)(int cpu, void *info),
 
 	might_sleep_if(gfpflags_allow_blocking(gfp_flags));
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (likely(zalloc_cpumask_var(&cpus, (gfp_flags|__GFP_NOWARN)))) {
 		preempt_disable();
 		for_each_online_cpu(cpu)
 			if (cond_func(cpu, info))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				cpumask_set_cpu(cpu, cpus);
+}
 		on_each_cpu_mask(cpus, func, info, wait);
 		preempt_enable();
 		free_cpumask_var(cpus);
@@ -690,12 +739,16 @@ void on_each_cpu_cond(bool (*cond_func)(int cpu, void *info),
 		 * just have to IPI them one by one.
 		 */
 		preempt_disable();
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		for_each_online_cpu(cpu)
 			if (cond_func(cpu, info)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				ret = smp_call_function_single(cpu, func,
 								info, wait);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				WARN_ON_ONCE(ret);
 			}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		preempt_enable();
 	}
 }
@@ -735,6 +788,7 @@ void wake_up_all_idle_cpus(void)
 	int cpu;
 
 	preempt_disable();
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for_each_online_cpu(cpu) {
 		if (cpu == smp_processor_id())
 			continue;
@@ -765,6 +819,7 @@ static void smp_call_on_cpu_callback(struct work_struct *work)
 {
 	struct smp_call_on_cpu_struct *sscs;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	sscs = container_of(work, struct smp_call_on_cpu_struct, work);
 	if (sscs->cpu >= 0)
 		hypervisor_pin_vcpu(sscs->cpu);
diff --git a/kernel/smpboot.c b/kernel/smpboot.c
index 5043e74..9758096 100644
--- a/kernel/smpboot.c
+++ b/kernel/smpboot.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * Common SMP CPU bringup/teardown functions
  */
@@ -28,6 +30,7 @@ static DEFINE_PER_CPU(struct task_struct *, idle_threads);
 
 struct task_struct *idle_thread_get(unsigned int cpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct task_struct *tsk = per_cpu(idle_threads, cpu);
 
 	if (!tsk)
@@ -49,6 +52,7 @@ void __init idle_thread_set_boot_cpu(void)
  */
 static inline void idle_init(unsigned int cpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct task_struct *tsk = per_cpu(idle_threads, cpu);
 
 	if (!tsk) {
@@ -71,7 +75,9 @@ void __init idle_threads_init(void)
 
 	for_each_possible_cpu(cpu) {
 		if (cpu != boot_cpu)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			idle_init(cpu);
+}
 	}
 }
 #endif
@@ -108,27 +114,39 @@ static int smpboot_thread_fn(void *data)
 	struct smpboot_thread_data *td = data;
 	struct smp_hotplug_thread *ht = td->ht;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	while (1) {
 		set_current_state(TASK_INTERRUPTIBLE);
 		preempt_disable();
 		if (kthread_should_stop()) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			__set_current_state(TASK_RUNNING);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			preempt_enable();
 			/* cleanup must mirror setup */
 			if (ht->cleanup && td->status != HP_THREAD_NONE)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				ht->cleanup(td->cpu, cpu_online(td->cpu));
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			kfree(td);
 			return 0;
 		}
 
 		if (kthread_should_park()) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			__set_current_state(TASK_RUNNING);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			preempt_enable();
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			if (ht->park && td->status == HP_THREAD_ACTIVE) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				BUG_ON(td->cpu != smp_processor_id());
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				ht->park(td->cpu);
 				td->status = HP_THREAD_PARKED;
 			}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			kthread_parkme();
 			/* We might have been woken for stop */
 			continue;
@@ -148,9 +166,13 @@ static int smpboot_thread_fn(void *data)
 
 		case HP_THREAD_PARKED:
 			__set_current_state(TASK_RUNNING);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			preempt_enable();
 			if (ht->unpark)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				ht->unpark(td->cpu);
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			td->status = HP_THREAD_ACTIVE;
 			continue;
 		}
@@ -173,17 +195,22 @@ __smpboot_create_thread(struct smp_hotplug_thread *ht, unsigned int cpu)
 	struct smpboot_thread_data *td;
 
 	if (tsk)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	td = kzalloc_node(sizeof(*td), GFP_KERNEL, cpu_to_node(cpu));
 	if (!td)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 	td->cpu = cpu;
 	td->ht = ht;
 
 	tsk = kthread_create_on_cpu(smpboot_thread_fn, td, cpu,
 				    ht->thread_comm);
 	if (IS_ERR(tsk)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		kfree(td);
 		return PTR_ERR(tsk);
 	}
@@ -202,10 +229,13 @@ __smpboot_create_thread(struct smp_hotplug_thread *ht, unsigned int cpu)
 		 * requires that the task is off the runqueue.
 		 */
 		if (!wait_task_inactive(tsk, TASK_PARKED))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			WARN_ON(1);
+}
 		else
 			ht->create(cpu);
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
@@ -215,6 +245,7 @@ int smpboot_create_threads(unsigned int cpu)
 	int ret = 0;
 
 	mutex_lock(&smpboot_threads_lock);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry(cur, &hotplug_threads, list) {
 		ret = __smpboot_create_thread(cur, cpu);
 		if (ret)
@@ -237,6 +268,7 @@ int smpboot_unpark_threads(unsigned int cpu)
 	struct smp_hotplug_thread *cur;
 
 	mutex_lock(&smpboot_threads_lock);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry(cur, &hotplug_threads, list)
 		if (cpumask_test_cpu(cpu, cur->cpumask))
 			smpboot_unpark_thread(cur, cpu);
@@ -246,6 +278,7 @@ int smpboot_unpark_threads(unsigned int cpu)
 
 static void smpboot_park_thread(struct smp_hotplug_thread *ht, unsigned int cpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct task_struct *tsk = *per_cpu_ptr(ht->store, cpu);
 
 	if (tsk && !ht->selfparking)
@@ -257,6 +290,7 @@ int smpboot_park_threads(unsigned int cpu)
 	struct smp_hotplug_thread *cur;
 
 	mutex_lock(&smpboot_threads_lock);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry_reverse(cur, &hotplug_threads, list)
 		smpboot_park_thread(cur, cpu);
 	mutex_unlock(&smpboot_threads_lock);
@@ -294,7 +328,9 @@ int smpboot_register_percpu_thread_cpumask(struct smp_hotplug_thread *plug_threa
 	int ret = 0;
 
 	if (!alloc_cpumask_var(&plug_thread->cpumask, GFP_KERNEL))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 	cpumask_copy(plug_thread->cpumask, cpumask);
 
 	get_online_cpus();
@@ -302,6 +338,7 @@ int smpboot_register_percpu_thread_cpumask(struct smp_hotplug_thread *plug_threa
 	for_each_online_cpu(cpu) {
 		ret = __smpboot_create_thread(plug_thread, cpu);
 		if (ret) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			smpboot_destroy_threads(plug_thread);
 			free_cpumask_var(plug_thread->cpumask);
 			goto out;
@@ -325,6 +362,7 @@ EXPORT_SYMBOL_GPL(smpboot_register_percpu_thread_cpumask);
  */
 void smpboot_unregister_percpu_thread(struct smp_hotplug_thread *plug_thread)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	get_online_cpus();
 	mutex_lock(&smpboot_threads_lock);
 	list_del(&plug_thread->list);
@@ -377,6 +415,7 @@ static DEFINE_PER_CPU(atomic_t, cpu_hotplug_state) = ATOMIC_INIT(CPU_POST_DEAD);
  */
 int cpu_report_state(int cpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return atomic_read(&per_cpu(cpu_hotplug_state, cpu));
 }
 
@@ -394,6 +433,7 @@ int cpu_report_state(int cpu)
  */
 int cpu_check_up_prepare(int cpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!IS_ENABLED(CONFIG_HOTPLUG_CPU)) {
 		atomic_set(&per_cpu(cpu_hotplug_state, cpu), CPU_UP_PREPARE);
 		return 0;
@@ -465,6 +505,7 @@ bool cpu_wait_death(unsigned int cpu, int seconds)
 	bool ret = true;
 	int sleep_jf = 1;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	might_sleep();
 
 	/* The outgoing CPU will normally get done quite quickly. */
@@ -509,6 +550,7 @@ bool cpu_report_death(void)
 {
 	int oldstate;
 	int newstate;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	int cpu = smp_processor_id();
 
 	do {
diff --git a/kernel/softirq.c b/kernel/softirq.c
index e89c3b0..657703c 100644
--- a/kernel/softirq.c
+++ b/kernel/softirq.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  *	linux/kernel/softirq.c
  *
@@ -140,7 +142,9 @@ static void __local_bh_enable(unsigned int cnt)
 	WARN_ON_ONCE(!irqs_disabled());
 
 	if (softirq_count() == (cnt & SOFTIRQ_MASK))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		trace_softirqs_on(_RET_IP_);
+}
 	preempt_count_sub(cnt);
 }
 
@@ -166,7 +170,9 @@ void __local_bh_enable_ip(unsigned long ip, unsigned int cnt)
 	 * Are softirqs going to be turned on now:
 	 */
 	if (softirq_count() == SOFTIRQ_DISABLE_OFFSET)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		trace_softirqs_on(ip);
+}
 	/*
 	 * Keep preemption disabled until we are done with
 	 * softirq processing:
@@ -181,6 +187,7 @@ void __local_bh_enable_ip(unsigned long ip, unsigned int cnt)
 		do_softirq();
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	preempt_count_dec();
 #ifdef CONFIG_TRACE_IRQFLAGS
 	local_irq_enable();
@@ -267,6 +274,7 @@ asmlinkage __visible void __softirq_entry __do_softirq(void)
 
 	local_irq_enable();
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	h = softirq_vec;
 
 	while ((softirq_bit = ffs(pending))) {
@@ -284,6 +292,7 @@ asmlinkage __visible void __softirq_entry __do_softirq(void)
 		h->action(h);
 		trace_softirq_exit(vec_nr);
 		if (unlikely(prev_count != preempt_count())) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			pr_err("huh, entered softirq %u %s %p with preempt_count %08x, exited with %08x?\n",
 			       vec_nr, softirq_to_name[vec_nr], h->action,
 			       prev_count, preempt_count());
@@ -305,6 +314,7 @@ asmlinkage __visible void __softirq_entry __do_softirq(void)
 		wakeup_softirqd();
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_softirq_end(in_hardirq);
 	account_irq_exit_time(current);
 	__local_bh_enable(SOFTIRQ_OFFSET);
@@ -318,7 +328,9 @@ asmlinkage __visible void do_softirq(void)
 	unsigned long flags;
 
 	if (in_interrupt())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	local_irq_save(flags);
 
@@ -346,13 +358,16 @@ void irq_enter(void)
 		_local_bh_enable();
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	__irq_enter();
 }
 
 static inline void invoke_softirq(void)
 {
 	if (ksoftirqd_running())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	if (!force_irqthreads) {
 #ifdef CONFIG_HAVE_IRQ_EXIT_ON_IRQ_STACK
@@ -371,6 +386,7 @@ static inline void invoke_softirq(void)
 		do_softirq_own_stack();
 #endif
 	} else {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		wakeup_softirqd();
 	}
 }
@@ -399,6 +415,7 @@ void irq_exit(void)
 	WARN_ON_ONCE(!irqs_disabled());
 #endif
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	account_irq_exit_time(current);
 	preempt_count_sub(HARDIRQ_OFFSET);
 	if (!in_interrupt() && local_softirq_pending())
@@ -406,6 +423,7 @@ void irq_exit(void)
 
 	tick_irq_exit();
 	rcu_irq_exit();
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	trace_hardirq_exit(); /* must be last! */
 }
 
@@ -477,6 +495,7 @@ void __tasklet_hi_schedule(struct tasklet_struct *t)
 {
 	unsigned long flags;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	local_irq_save(flags);
 	t->next = NULL;
 	*__this_cpu_read(tasklet_hi_vec.tail) = t;
@@ -510,14 +529,20 @@ static __latent_entropy void tasklet_action(struct softirq_action *a)
 				tasklet_unlock(t);
 				continue;
 			}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			tasklet_unlock(t);
 		}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		local_irq_disable();
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		t->next = NULL;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		*__this_cpu_read(tasklet_vec.tail) = t;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		__this_cpu_write(tasklet_vec.tail, &(t->next));
 		__raise_softirq_irqoff(TASKLET_SOFTIRQ);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		local_irq_enable();
 	}
 }
@@ -526,6 +551,7 @@ static __latent_entropy void tasklet_hi_action(struct softirq_action *a)
 {
 	struct tasklet_struct *list;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	local_irq_disable();
 	list = __this_cpu_read(tasklet_hi_vec.head);
 	__this_cpu_write(tasklet_hi_vec.head, NULL);
@@ -571,6 +597,7 @@ EXPORT_SYMBOL(tasklet_init);
 
 void tasklet_kill(struct tasklet_struct *t)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (in_interrupt())
 		pr_notice("Attempt to kill tasklet from interrupt\n");
 
@@ -613,8 +640,10 @@ static void __tasklet_hrtimer_trampoline(unsigned long data)
 
 	restart = ttimer->function(&ttimer->timer);
 	if (restart != HRTIMER_NORESTART)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		hrtimer_restart(&ttimer->timer);
 }
+}
 
 /**
  * tasklet_hrtimer_init - Init a tasklet/hrtimer combo for softirq callbacks
@@ -627,6 +656,7 @@ void tasklet_hrtimer_init(struct tasklet_hrtimer *ttimer,
 			  enum hrtimer_restart (*function)(struct hrtimer *),
 			  clockid_t which_clock, enum hrtimer_mode mode)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	hrtimer_init(&ttimer->timer, which_clock, mode);
 	ttimer->timer.function = __hrtimer_tasklet_trampoline;
 	tasklet_init(&ttimer->tasklet, __tasklet_hrtimer_trampoline,
@@ -646,6 +676,7 @@ void __init softirq_init(void)
 			&per_cpu(tasklet_hi_vec, cpu).head;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	open_softirq(TASKLET_SOFTIRQ, tasklet_action);
 	open_softirq(HI_SOFTIRQ, tasklet_hi_action);
 }
@@ -666,6 +697,7 @@ static void run_ksoftirqd(unsigned int cpu)
 		__do_softirq();
 		local_irq_enable();
 		cond_resched_rcu_qs();
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
 	}
 	local_irq_enable();
@@ -685,6 +717,7 @@ void tasklet_kill_immediate(struct tasklet_struct *t, unsigned int cpu)
 {
 	struct tasklet_struct **i;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	BUG_ON(cpu_online(cpu));
 	BUG_ON(test_bit(TASKLET_STATE_RUN, &t->state));
 
@@ -757,20 +790,24 @@ early_initcall(spawn_ksoftirqd);
 
 int __init __weak early_irq_init(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
 int __init __weak arch_probe_nr_irqs(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return NR_IRQS_LEGACY;
 }
 
 int __init __weak arch_early_irq_init(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
 unsigned int __weak arch_dynirq_lower_bound(unsigned int from)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return from;
 }
diff --git a/kernel/stop_machine.c b/kernel/stop_machine.c
index b759126..3529a2c 100644
--- a/kernel/stop_machine.c
+++ b/kernel/stop_machine.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * kernel/stop_machine.c
  *
@@ -52,6 +54,7 @@ static bool stop_cpus_in_progress;
 
 static void cpu_stop_init_done(struct cpu_stop_done *done, unsigned int nr_todo)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	memset(done, 0, sizeof(*done));
 	atomic_set(&done->nr_todo, nr_todo);
 	init_completion(&done->completion);
@@ -82,8 +85,12 @@ static bool cpu_stop_queue_work(unsigned int cpu, struct cpu_stop_work *work)
 	enabled = stopper->enabled;
 	if (enabled)
 		__cpu_stop_queue_work(stopper, work);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	else if (work->done)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		cpu_stop_signal_done(work->done);
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_unlock_irqrestore(&stopper->lock, flags);
 
 	return enabled;
@@ -120,7 +127,9 @@ int stop_one_cpu(unsigned int cpu, cpu_stop_fn_t fn, void *arg)
 
 	cpu_stop_init_done(&done, 1);
 	if (!cpu_stop_queue_work(cpu, &work))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOENT;
+}
 	/*
 	 * In case @cpu == smp_proccessor_id() we can avoid a sleep+wakeup
 	 * cycle by doing a preemption:
@@ -196,10 +205,12 @@ static int multi_cpu_stop(void *data)
 		/* Chill out and ensure we re-read multi_stop_state. */
 		cpu_relax_yield();
 		if (msdata->state != curstate) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			curstate = msdata->state;
 			switch (curstate) {
 			case MULTI_STOP_DISABLE_IRQ:
 				local_irq_disable();
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				hard_irq_disable();
 				break;
 			case MULTI_STOP_RUN:
@@ -227,6 +238,7 @@ static int multi_cpu_stop(void *data)
 static int cpu_stop_queue_two_works(int cpu1, struct cpu_stop_work *work1,
 				    int cpu2, struct cpu_stop_work *work2)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cpu_stopper *stopper1 = per_cpu_ptr(&cpu_stopper, cpu1);
 	struct cpu_stopper *stopper2 = per_cpu_ptr(&cpu_stopper, cpu2);
 	int err;
@@ -299,7 +311,9 @@ int stop_two_cpus(unsigned int cpu1, unsigned int cpu2, cpu_stop_fn_t fn, void *
 	set_state(&msdata, MULTI_STOP_PREPARE);
 
 	if (cpu1 > cpu2)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		swap(cpu1, cpu2);
+}
 	if (cpu_stop_queue_two_works(cpu1, &work1, cpu2, &work2))
 		return -ENOENT;
 
@@ -353,7 +367,9 @@ static bool queue_stop_cpus_work(const struct cpumask *cpumask,
 		work->arg = arg;
 		work->done = done;
 		if (cpu_stop_queue_work(cpu, work))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			queued = true;
+}
 	}
 	stop_cpus_in_progress = false;
 	preempt_enable();
@@ -368,7 +384,9 @@ static int __stop_cpus(const struct cpumask *cpumask,
 
 	cpu_stop_init_done(&done, cpumask_weight(cpumask));
 	if (!queue_stop_cpus_work(cpumask, fn, arg, &done))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOENT;
+}
 	wait_for_completion(&done.completion);
 	return done.ret;
 }
@@ -436,7 +454,9 @@ int try_stop_cpus(const struct cpumask *cpumask, cpu_stop_fn_t fn, void *arg)
 
 	/* static works are used, process one request at a time */
 	if (!mutex_trylock(&stop_cpus_mutex))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EAGAIN;
+}
 	ret = __stop_cpus(cpumask, fn, arg);
 	mutex_unlock(&stop_cpus_mutex);
 	return ret;
@@ -467,6 +487,7 @@ static void cpu_stopper_thread(unsigned int cpu)
 					struct cpu_stop_work, list);
 		list_del_init(&work->list);
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_unlock_irq(&stopper->lock);
 
 	if (work) {
@@ -480,9 +501,12 @@ static void cpu_stopper_thread(unsigned int cpu)
 		ret = fn(arg);
 		if (done) {
 			if (ret)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				done->ret = ret;
+}
 			cpu_stop_signal_done(done);
 		}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		preempt_count_dec();
 		WARN_ONCE(preempt_count(),
 			  "cpu_stop: %pf(%p) leaked preempt count\n", fn, arg);
@@ -492,6 +516,7 @@ static void cpu_stopper_thread(unsigned int cpu)
 
 void stop_machine_park(int cpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cpu_stopper *stopper = &per_cpu(cpu_stopper, cpu);
 	/*
 	 * Lockless. cpu_stopper_thread() will take stopper->lock and flush
@@ -511,6 +536,7 @@ static void cpu_stop_create(unsigned int cpu)
 
 static void cpu_stop_park(unsigned int cpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cpu_stopper *stopper = &per_cpu(cpu_stopper, cpu);
 
 	WARN_ON(!list_empty(&stopper->works));
@@ -573,13 +599,19 @@ int stop_machine_cpuslocked(cpu_stop_fn_t fn, void *data,
 		unsigned long flags;
 		int ret;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		WARN_ON_ONCE(msdata.num_threads != 1);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		local_irq_save(flags);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		hard_irq_disable();
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ret = (*fn)(data);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		local_irq_restore(flags);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ret;
 	}
 
diff --git a/kernel/sys.c b/kernel/sys.c
index 524a4cb..41d26ae 100644
--- a/kernel/sys.c
+++ b/kernel/sys.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 /*
  *  linux/kernel/sys.c
@@ -147,8 +149,12 @@ static bool set_one_prio_perm(struct task_struct *p)
 	if (uid_eq(pcred->uid,  cred->euid) ||
 	    uid_eq(pcred->euid, cred->euid))
 		return true;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (ns_capable(pcred->user_ns, CAP_SYS_NICE))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return true;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return false;
 }
 
@@ -161,20 +167,25 @@ static int set_one_prio(struct task_struct *p, int niceval, int error)
 	int no_nice;
 
 	if (!set_one_prio_perm(p)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		error = -EPERM;
 		goto out;
 	}
 	if (niceval < task_nice(p) && !can_nice(p, niceval)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		error = -EACCES;
 		goto out;
 	}
 	no_nice = security_task_setnice(p, niceval);
 	if (no_nice) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		error = no_nice;
 		goto out;
 	}
 	if (error == -ESRCH)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		error = 0;
+}
 	set_user_nice(p, niceval);
 out:
 	return error;
@@ -195,10 +206,15 @@ SYSCALL_DEFINE3(setpriority, int, which, int, who, int, niceval)
 	/* normalize: avoid signed division (rounding problems) */
 	error = -ESRCH;
 	if (niceval < MIN_NICE)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		niceval = MIN_NICE;
+}
 	if (niceval > MAX_NICE)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		niceval = MAX_NICE;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rcu_read_lock();
 	read_lock(&tasklist_lock);
 	switch (which) {
@@ -212,29 +228,44 @@ SYSCALL_DEFINE3(setpriority, int, which, int, who, int, niceval)
 		break;
 	case PRIO_PGRP:
 		if (who)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			pgrp = find_vpid(who);
+}
 		else
 			pgrp = task_pgrp(current);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		do_each_pid_thread(pgrp, PIDTYPE_PGID, p) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			error = set_one_prio(p, niceval, error);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		} while_each_pid_thread(pgrp, PIDTYPE_PGID, p);
 		break;
 	case PRIO_USER:
 		uid = make_kuid(cred->user_ns, who);
 		user = cred->user;
 		if (!who)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			uid = cred->uid;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		else if (!uid_eq(uid, cred->uid)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			user = find_user(uid);
 			if (!user)
 				goto out_unlock;	/* No processes for this user */
 		}
 		do_each_thread(g, p) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			if (uid_eq(task_uid(p), uid) && task_pid_vnr(p))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				error = set_one_prio(p, niceval, error);
+}
 		} while_each_thread(g, p);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (!uid_eq(uid, cred->uid))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			free_uid(user);		/* For find_user() */
+}
 		break;
 	}
 out_unlock:
@@ -260,8 +291,11 @@ SYSCALL_DEFINE2(getpriority, int, which, int, who)
 	kuid_t uid;
 
 	if (which > PRIO_USER || which < PRIO_PROCESS)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rcu_read_lock();
 	read_lock(&tasklist_lock);
 	switch (which) {
@@ -273,39 +307,57 @@ SYSCALL_DEFINE2(getpriority, int, which, int, who)
 		if (p) {
 			niceval = nice_to_rlimit(task_nice(p));
 			if (niceval > retval)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				retval = niceval;
+}
 		}
 		break;
 	case PRIO_PGRP:
 		if (who)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			pgrp = find_vpid(who);
+}
 		else
 			pgrp = task_pgrp(current);
 		do_each_pid_thread(pgrp, PIDTYPE_PGID, p) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			niceval = nice_to_rlimit(task_nice(p));
 			if (niceval > retval)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				retval = niceval;
+}
 		} while_each_pid_thread(pgrp, PIDTYPE_PGID, p);
 		break;
 	case PRIO_USER:
 		uid = make_kuid(cred->user_ns, who);
 		user = cred->user;
 		if (!who)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			uid = cred->uid;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		else if (!uid_eq(uid, cred->uid)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			user = find_user(uid);
 			if (!user)
 				goto out_unlock;	/* No processes for this user */
 		}
 		do_each_thread(g, p) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			if (uid_eq(task_uid(p), uid) && task_pid_vnr(p)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				niceval = nice_to_rlimit(task_nice(p));
 				if (niceval > retval)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 					retval = niceval;
+}
 			}
 		} while_each_thread(g, p);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (!uid_eq(uid, cred->uid))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			free_uid(user);		/* for find_user() */
+}
 		break;
 	}
 out_unlock:
@@ -336,6 +388,7 @@ SYSCALL_DEFINE2(getpriority, int, which, int, who)
 #ifdef CONFIG_MULTIUSER
 SYSCALL_DEFINE2(setregid, gid_t, rgid, gid_t, egid)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct user_namespace *ns = current_user_ns();
 	const struct cred *old;
 	struct cred *new;
@@ -401,11 +454,15 @@ SYSCALL_DEFINE1(setgid, gid_t, gid)
 
 	kgid = make_kgid(ns, gid);
 	if (!gid_valid(kgid))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	new = prepare_creds();
 	if (!new)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 	old = current_cred();
 
 	retval = -EPERM;
@@ -432,7 +489,9 @@ static int set_user(struct cred *new)
 
 	new_user = alloc_uid(new->uid);
 	if (!new_user)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EAGAIN;
+}
 
 	/*
 	 * We don't fail in case of NPROC limit excess here because too many
@@ -469,6 +528,7 @@ static int set_user(struct cred *new)
  */
 SYSCALL_DEFINE2(setreuid, uid_t, ruid, uid_t, euid)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct user_namespace *ns = current_user_ns();
 	const struct cred *old;
 	struct cred *new;
@@ -548,11 +608,15 @@ SYSCALL_DEFINE1(setuid, uid_t, uid)
 
 	kuid = make_kuid(ns, uid);
 	if (!uid_valid(kuid))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	new = prepare_creds();
 	if (!new)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 	old = current_cred();
 
 	retval = -EPERM;
@@ -598,17 +662,25 @@ SYSCALL_DEFINE3(setresuid, uid_t, ruid, uid_t, euid, uid_t, suid)
 	ksuid = make_kuid(ns, suid);
 
 	if ((ruid != (uid_t) -1) && !uid_valid(kruid))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	if ((euid != (uid_t) -1) && !uid_valid(keuid))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	if ((suid != (uid_t) -1) && !uid_valid(ksuid))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	new = prepare_creds();
 	if (!new)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 
 	old = current_cred();
 
@@ -626,8 +698,10 @@ SYSCALL_DEFINE3(setresuid, uid_t, ruid, uid_t, euid, uid_t, suid)
 	}
 
 	if (ruid != (uid_t) -1) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		new->uid = kruid;
 		if (!uid_eq(kruid, old->uid)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			retval = set_user(new);
 			if (retval < 0)
 				goto error;
@@ -636,7 +710,9 @@ SYSCALL_DEFINE3(setresuid, uid_t, ruid, uid_t, euid, uid_t, suid)
 	if (euid != (uid_t) -1)
 		new->euid = keuid;
 	if (suid != (uid_t) -1)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		new->suid = ksuid;
+}
 	new->fsuid = new->euid;
 
 	retval = security_task_fix_setuid(new, old, LSM_SETID_RES);
@@ -666,6 +742,7 @@ SYSCALL_DEFINE3(getresuid, uid_t __user *, ruidp, uid_t __user *, euidp, uid_t _
 		if (!retval)
 			return put_user(suid, suidp);
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return retval;
 }
 
@@ -685,36 +762,51 @@ SYSCALL_DEFINE3(setresgid, gid_t, rgid, gid_t, egid, gid_t, sgid)
 	ksgid = make_kgid(ns, sgid);
 
 	if ((rgid != (gid_t) -1) && !gid_valid(krgid))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 	if ((egid != (gid_t) -1) && !gid_valid(kegid))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 	if ((sgid != (gid_t) -1) && !gid_valid(ksgid))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	new = prepare_creds();
 	if (!new)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 	old = current_cred();
 
 	retval = -EPERM;
 	if (!ns_capable(old->user_ns, CAP_SETGID)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (rgid != (gid_t) -1        && !gid_eq(krgid, old->gid) &&
 		    !gid_eq(krgid, old->egid) && !gid_eq(krgid, old->sgid))
 			goto error;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (egid != (gid_t) -1        && !gid_eq(kegid, old->gid) &&
 		    !gid_eq(kegid, old->egid) && !gid_eq(kegid, old->sgid))
 			goto error;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (sgid != (gid_t) -1        && !gid_eq(ksgid, old->gid) &&
 		    !gid_eq(ksgid, old->egid) && !gid_eq(ksgid, old->sgid))
 			goto error;
 	}
 
 	if (rgid != (gid_t) -1)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		new->gid = krgid;
+}
 	if (egid != (gid_t) -1)
 		new->egid = kegid;
 	if (sgid != (gid_t) -1)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		new->sgid = ksgid;
+}
 	new->fsgid = new->egid;
 
 	return commit_creds(new);
@@ -763,7 +855,9 @@ SYSCALL_DEFINE1(setfsuid, uid_t, uid)
 
 	kuid = make_kuid(old->user_ns, uid);
 	if (!uid_valid(kuid))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return old_fsuid;
+}
 
 	new = prepare_creds();
 	if (!new)
@@ -802,7 +896,9 @@ SYSCALL_DEFINE1(setfsgid, gid_t, gid)
 
 	kgid = make_kgid(old->user_ns, gid);
 	if (!gid_valid(kgid))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return old_fsgid;
+}
 
 	new = prepare_creds();
 	if (!new)
@@ -907,7 +1003,9 @@ SYSCALL_DEFINE1(times, struct tms __user *, tbuf)
 
 		do_sys_times(&tmp);
 		if (copy_to_user(tbuf, &tmp, sizeof(struct tms)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -EFAULT;
+}
 	}
 	force_successful_syscall_return();
 	return (long) jiffies_64_to_clock_t(get_jiffies_64());
@@ -916,11 +1014,13 @@ SYSCALL_DEFINE1(times, struct tms __user *, tbuf)
 #ifdef CONFIG_COMPAT
 static compat_clock_t clock_t_to_compat_clock_t(clock_t x)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return compat_jiffies_to_clock_t(clock_t_to_jiffies(x));
 }
 
 COMPAT_SYSCALL_DEFINE1(times, struct compat_tms __user *, tbuf)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (tbuf) {
 		struct tms tms;
 		struct compat_tms tmp;
@@ -960,9 +1060,14 @@ SYSCALL_DEFINE2(setpgid, pid_t, pid, pid_t, pgid)
 	if (!pid)
 		pid = task_pid_vnr(group_leader);
 	if (!pgid)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pgid = pid;
+}
 	if (pgid < 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rcu_read_lock();
 
 	/* From this point forward we keep holding onto the tasklist lock
@@ -975,27 +1080,33 @@ SYSCALL_DEFINE2(setpgid, pid_t, pid, pid_t, pgid)
 	if (!p)
 		goto out;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	err = -EINVAL;
 	if (!thread_group_leader(p))
 		goto out;
 
 	if (same_thread_group(p->real_parent, group_leader)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		err = -EPERM;
 		if (task_session(p) != task_session(group_leader))
 			goto out;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		err = -EACCES;
 		if (!(p->flags & PF_FORKNOEXEC))
 			goto out;
 	} else {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		err = -ESRCH;
 		if (p != group_leader)
 			goto out;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	err = -EPERM;
 	if (p->signal->leader)
 		goto out;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pgrp = task_pid(p);
 	if (pgid != pid) {
 		struct task_struct *g;
@@ -1013,6 +1124,7 @@ SYSCALL_DEFINE2(setpgid, pid_t, pid, pid_t, pgid)
 	if (task_pgrp(p) != pgrp)
 		change_pid(p, PIDTYPE_PGID, pgrp);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	err = 0;
 out:
 	/* All paths lead to here, thus we are safe. -DaveM */
@@ -1031,14 +1143,17 @@ SYSCALL_DEFINE1(getpgid, pid_t, pid)
 	if (!pid)
 		grp = task_pgrp(current);
 	else {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		retval = -ESRCH;
 		p = find_task_by_vpid(pid);
 		if (!p)
 			goto out;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		grp = task_pgrp(p);
 		if (!grp)
 			goto out;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		retval = security_task_getpgid(p);
 		if (retval)
 			goto out;
@@ -1068,14 +1183,17 @@ SYSCALL_DEFINE1(getsid, pid_t, pid)
 	if (!pid)
 		sid = task_session(current);
 	else {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		retval = -ESRCH;
 		p = find_task_by_vpid(pid);
 		if (!p)
 			goto out;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		sid = task_session(p);
 		if (!sid)
 			goto out;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		retval = security_task_getsid(p);
 		if (retval)
 			goto out;
@@ -1157,14 +1275,20 @@ static int override_release(char __user *release, size_t len)
 		unsigned v;
 		size_t copy;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		while (*rest) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			if (*rest == '.' && ++ndots >= 3)
 				break;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			if (!isdigit(*rest) && *rest != '.')
 				break;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			rest++;
 		}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		v = ((LINUX_VERSION_CODE >> 8) & 0xff) + 60;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		copy = clamp_t(size_t, len, 1, sizeof(buf));
 		copy = scnprintf(buf, copy, "2.6.%u%s", v, rest);
 		ret = copy_to_user(release, buf, copy + 1);
@@ -1178,13 +1302,19 @@ SYSCALL_DEFINE1(newuname, struct new_utsname __user *, name)
 
 	down_read(&uts_sem);
 	if (copy_to_user(name, utsname(), sizeof *name))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		errno = -EFAULT;
+}
 	up_read(&uts_sem);
 
 	if (!errno && override_release(name->release, sizeof(name->release)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		errno = -EFAULT;
+}
 	if (!errno && override_architecture(name))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		errno = -EFAULT;
+}
 	return errno;
 }
 
@@ -1197,7 +1327,9 @@ SYSCALL_DEFINE1(uname, struct old_utsname __user *, name)
 	int error = 0;
 
 	if (!name)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EFAULT;
+}
 
 	down_read(&uts_sem);
 	if (copy_to_user(name, utsname(), sizeof(*name)))
@@ -1216,7 +1348,9 @@ SYSCALL_DEFINE1(olduname, struct oldold_utsname __user *, name)
 	int error;
 
 	if (!name)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EFAULT;
+}
 	if (!access_ok(VERIFY_WRITE, name, sizeof(struct oldold_utsname)))
 		return -EFAULT;
 
@@ -1252,10 +1386,14 @@ SYSCALL_DEFINE2(sethostname, char __user *, name, int, len)
 	char tmp[__NEW_UTS_LEN];
 
 	if (!ns_capable(current->nsproxy->uts_ns->user_ns, CAP_SYS_ADMIN))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EPERM;
+}
 
 	if (len < 0 || len > __NEW_UTS_LEN)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 	down_write(&uts_sem);
 	errno = -EFAULT;
 	if (!copy_from_user(tmp, name, len)) {
@@ -1278,7 +1416,9 @@ SYSCALL_DEFINE2(gethostname, char __user *, name, int, len)
 	struct new_utsname *u;
 
 	if (len < 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 	down_read(&uts_sem);
 	u = utsname();
 	i = 1 + strlen(u->nodename);
@@ -1303,7 +1443,9 @@ SYSCALL_DEFINE2(setdomainname, char __user *, name, int, len)
 	char tmp[__NEW_UTS_LEN];
 
 	if (!ns_capable(current->nsproxy->uts_ns->user_ns, CAP_SYS_ADMIN))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EPERM;
+}
 	if (len < 0 || len > __NEW_UTS_LEN)
 		return -EINVAL;
 
@@ -1342,7 +1484,9 @@ COMPAT_SYSCALL_DEFINE2(setrlimit, unsigned int, resource,
 	struct compat_rlimit r32;
 
 	if (copy_from_user(&r32, rlim, sizeof(struct compat_rlimit)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EFAULT;
+}
 
 	if (r32.rlim_cur == COMPAT_RLIM_INFINITY)
 		r.rlim_cur = RLIM_INFINITY;
@@ -1365,7 +1509,9 @@ COMPAT_SYSCALL_DEFINE2(getrlimit, unsigned int, resource,
 	if (!ret) {
 		struct compat_rlimit r32;
 		if (r.rlim_cur > COMPAT_RLIM_INFINITY)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			r32.rlim_cur = COMPAT_RLIM_INFINITY;
+}
 		else
 			r32.rlim_cur = r.rlim_cur;
 		if (r.rlim_max > COMPAT_RLIM_INFINITY)
@@ -1391,7 +1537,9 @@ SYSCALL_DEFINE2(old_getrlimit, unsigned int, resource,
 {
 	struct rlimit x;
 	if (resource >= RLIM_NLIMITS)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	task_lock(current->group_leader);
 	x = current->signal->rlim[resource];
@@ -1410,7 +1558,9 @@ COMPAT_SYSCALL_DEFINE2(old_getrlimit, unsigned int, resource,
 	struct rlimit r;
 
 	if (resource >= RLIM_NLIMITS)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	task_lock(current->group_leader);
 	r = current->signal->rlim[resource];
@@ -1453,11 +1603,15 @@ static void rlim_to_rlim64(const struct rlimit *rlim, struct rlimit64 *rlim64)
 static void rlim64_to_rlim(const struct rlimit64 *rlim64, struct rlimit *rlim)
 {
 	if (rlim64_is_infinity(rlim64->rlim_cur))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		rlim->rlim_cur = RLIM_INFINITY;
+}
 	else
 		rlim->rlim_cur = (unsigned long)rlim64->rlim_cur;
 	if (rlim64_is_infinity(rlim64->rlim_max))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		rlim->rlim_max = RLIM_INFINITY;
+}
 	else
 		rlim->rlim_max = (unsigned long)rlim64->rlim_max;
 }
@@ -1470,10 +1624,14 @@ int do_prlimit(struct task_struct *tsk, unsigned int resource,
 	int retval = 0;
 
 	if (resource >= RLIM_NLIMITS)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 	if (new_rlim) {
 		if (new_rlim->rlim_cur > new_rlim->rlim_max)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -EINVAL;
+}
 		if (resource == RLIMIT_NOFILE &&
 				new_rlim->rlim_max > sysctl_nr_open)
 			return -EPERM;
@@ -1482,6 +1640,7 @@ int do_prlimit(struct task_struct *tsk, unsigned int resource,
 	/* protect tsk->signal and tsk->sighand from disappearing */
 	read_lock(&tasklist_lock);
 	if (!tsk->sighand) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		retval = -ESRCH;
 		goto out;
 	}
@@ -1537,18 +1696,26 @@ static int check_prlimit_permission(struct task_struct *task,
 	bool id_match;
 
 	if (current == task)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	tcred = __task_cred(task);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	id_match = (uid_eq(cred->uid, tcred->euid) &&
 		    uid_eq(cred->uid, tcred->suid) &&
 		    uid_eq(cred->uid, tcred->uid)  &&
 		    gid_eq(cred->gid, tcred->egid) &&
 		    gid_eq(cred->gid, tcred->sgid) &&
 		    gid_eq(cred->gid, tcred->gid));
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!id_match && !ns_capable(tcred->user_ns, CAP_SYS_RESOURCE))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EPERM;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return security_task_prlimit(cred, tcred, flags);
 }
 
@@ -1563,27 +1730,35 @@ SYSCALL_DEFINE4(prlimit64, pid_t, pid, unsigned int, resource,
 	int ret;
 
 	if (old_rlim)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		checkflags |= LSM_PRLIMIT_READ;
+}
 
 	if (new_rlim) {
 		if (copy_from_user(&new64, new_rlim, sizeof(new64)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -EFAULT;
+}
 		rlim64_to_rlim(&new64, &new);
 		checkflags |= LSM_PRLIMIT_WRITE;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rcu_read_lock();
 	tsk = pid ? find_task_by_vpid(pid) : current;
 	if (!tsk) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		rcu_read_unlock();
 		return -ESRCH;
 	}
 	ret = check_prlimit_permission(tsk, checkflags);
 	if (ret) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		rcu_read_unlock();
 		return ret;
 	}
 	get_task_struct(tsk);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rcu_read_unlock();
 
 	ret = do_prlimit(tsk, resource, new_rlim ? &new : NULL,
@@ -1592,7 +1767,9 @@ SYSCALL_DEFINE4(prlimit64, pid_t, pid, unsigned int, resource,
 	if (!ret && old_rlim) {
 		rlim_to_rlim64(&old, &old64);
 		if (copy_to_user(old_rlim, &old64, sizeof(old64)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			ret = -EFAULT;
+}
 	}
 
 	put_task_struct(tsk);
@@ -1604,7 +1781,9 @@ SYSCALL_DEFINE2(setrlimit, unsigned int, resource, struct rlimit __user *, rlim)
 	struct rlimit new_rlim;
 
 	if (copy_from_user(&new_rlim, rlim, sizeof(*rlim)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EFAULT;
+}
 	return do_prlimit(current, resource, &new_rlim, NULL);
 }
 
@@ -1669,7 +1848,9 @@ void getrusage(struct task_struct *p, int who, struct rusage *r)
 	}
 
 	if (!lock_task_sighand(p, &flags))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	switch (who) {
 	case RUSAGE_BOTH:
@@ -1699,6 +1880,7 @@ void getrusage(struct task_struct *p, int who, struct rusage *r)
 		r->ru_oublock += p->signal->oublock;
 		if (maxrss < p->signal->maxrss)
 			maxrss = p->signal->maxrss;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		t = p;
 		do {
 			accumulate_thread_rusage(t, r);
@@ -1742,6 +1924,7 @@ COMPAT_SYSCALL_DEFINE2(getrusage, int, who, struct compat_rusage __user *, ru)
 {
 	struct rusage r;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (who != RUSAGE_SELF && who != RUSAGE_CHILDREN &&
 	    who != RUSAGE_THREAD)
 		return -EINVAL;
@@ -1766,7 +1949,9 @@ static int prctl_set_mm_exe_file(struct mm_struct *mm, unsigned int fd)
 
 	exe = fdget(fd);
 	if (!exe.file)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EBADF;
+}
 
 	inode = file_inode(exe.file);
 
@@ -1825,6 +2010,7 @@ static int prctl_set_mm_exe_file(struct mm_struct *mm, unsigned int fd)
  */
 static int validate_prctl_map(struct prctl_mm_map *prctl_map)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	unsigned long mmap_max_addr = TASK_SIZE;
 	struct mm_struct *mm = current->mm;
 	int error = -EINVAL, i;
@@ -2007,7 +2193,9 @@ static int prctl_set_auxv(struct mm_struct *mm, unsigned long addr,
 	unsigned long user_auxv[AT_VECTOR_SIZE];
 
 	if (len > sizeof(user_auxv))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	if (copy_from_user(user_auxv, (const void __user *)addr, len))
 		return -EFAULT;
@@ -2028,6 +2216,7 @@ static int prctl_set_auxv(struct mm_struct *mm, unsigned long addr,
 static int prctl_set_mm(int opt, unsigned long addr,
 			unsigned long arg4, unsigned long arg5)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct mm_struct *mm = current->mm;
 	struct prctl_mm_map prctl_map;
 	struct vm_area_struct *vma;
@@ -2162,6 +2351,7 @@ static int prctl_get_tid_address(struct task_struct *me, int __user **tid_addr)
 #else
 static int prctl_get_tid_address(struct task_struct *me, int __user **tid_addr)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return -EINVAL;
 }
 #endif
@@ -2193,12 +2383,16 @@ SYSCALL_DEFINE5(prctl, int, option, unsigned long, arg2, unsigned long, arg3,
 
 	error = security_task_prctl(option, arg2, arg3, arg4, arg5);
 	if (error != -ENOSYS)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return error;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	error = 0;
 	switch (option) {
 	case PR_SET_PDEATHSIG:
 		if (!valid_signal(arg2)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			error = -EINVAL;
 			break;
 		}
@@ -2212,6 +2406,7 @@ SYSCALL_DEFINE5(prctl, int, option, unsigned long, arg2, unsigned long, arg3,
 		break;
 	case PR_SET_DUMPABLE:
 		if (arg2 != SUID_DUMP_DISABLE && arg2 != SUID_DUMP_USER) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			error = -EINVAL;
 			break;
 		}
@@ -2241,7 +2436,9 @@ SYSCALL_DEFINE5(prctl, int, option, unsigned long, arg2, unsigned long, arg3,
 		break;
 	case PR_SET_TIMING:
 		if (arg2 != PR_TIMING_STATISTICAL)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			error = -EINVAL;
+}
 		break;
 	case PR_SET_NAME:
 		comm[sizeof(me->comm) - 1] = 0;
@@ -2254,7 +2451,9 @@ SYSCALL_DEFINE5(prctl, int, option, unsigned long, arg2, unsigned long, arg3,
 	case PR_GET_NAME:
 		get_task_comm(comm, me);
 		if (copy_to_user((char __user *)arg2, comm, sizeof(comm)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -EFAULT;
+}
 		break;
 	case PR_GET_ENDIAN:
 		error = GET_ENDIAN(me, arg2);
@@ -2282,7 +2481,9 @@ SYSCALL_DEFINE5(prctl, int, option, unsigned long, arg2, unsigned long, arg3,
 		break;
 	case PR_GET_TIMERSLACK:
 		if (current->timer_slack_ns > ULONG_MAX)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			error = ULONG_MAX;
+}
 		else
 			error = current->timer_slack_ns;
 		break;
@@ -2295,19 +2496,26 @@ SYSCALL_DEFINE5(prctl, int, option, unsigned long, arg2, unsigned long, arg3,
 		break;
 	case PR_MCE_KILL:
 		if (arg4 | arg5)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -EINVAL;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		switch (arg2) {
 		case PR_MCE_KILL_CLEAR:
 			if (arg3 != 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				return -EINVAL;
+}
 			current->flags &= ~PF_MCE_PROCESS;
 			break;
 		case PR_MCE_KILL_SET:
 			current->flags |= PF_MCE_PROCESS;
 			if (arg3 == PR_MCE_KILL_EARLY)
 				current->flags |= PF_MCE_EARLY;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			else if (arg3 == PR_MCE_KILL_LATE)
 				current->flags &= ~PF_MCE_EARLY;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			else if (arg3 == PR_MCE_KILL_DEFAULT)
 				current->flags &=
 						~(PF_MCE_EARLY|PF_MCE_PROCESS);
@@ -2320,10 +2528,14 @@ SYSCALL_DEFINE5(prctl, int, option, unsigned long, arg2, unsigned long, arg3,
 		break;
 	case PR_MCE_KILL_GET:
 		if (arg2 | arg3 | arg4 | arg5)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -EINVAL;
+}
 		if (current->flags & PF_MCE_PROCESS)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			error = (current->flags & PF_MCE_EARLY) ?
 				PR_MCE_KILL_EARLY : PR_MCE_KILL_LATE;
+}
 		else
 			error = PR_MCE_KILL_DEFAULT;
 		break;
@@ -2346,24 +2558,35 @@ SYSCALL_DEFINE5(prctl, int, option, unsigned long, arg2, unsigned long, arg3,
 		break;
 	case PR_SET_NO_NEW_PRIVS:
 		if (arg2 != 1 || arg3 || arg4 || arg5)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -EINVAL;
+}
 
 		task_set_no_new_privs(current);
 		break;
 	case PR_GET_NO_NEW_PRIVS:
 		if (arg2 || arg3 || arg4 || arg5)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -EINVAL;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return task_no_new_privs(current) ? 1 : 0;
 	case PR_GET_THP_DISABLE:
 		if (arg2 || arg3 || arg4 || arg5)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -EINVAL;
+}
 		error = !!test_bit(MMF_DISABLE_THP, &me->mm->flags);
 		break;
 	case PR_SET_THP_DISABLE:
 		if (arg3 || arg4 || arg5)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -EINVAL;
+}
 		if (down_write_killable(&me->mm->mmap_sem))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -EINTR;
+}
 		if (arg2)
 			set_bit(MMF_DISABLE_THP, &me->mm->flags);
 		else
@@ -2372,12 +2595,16 @@ SYSCALL_DEFINE5(prctl, int, option, unsigned long, arg2, unsigned long, arg3,
 		break;
 	case PR_MPX_ENABLE_MANAGEMENT:
 		if (arg2 || arg3 || arg4 || arg5)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -EINVAL;
+}
 		error = MPX_ENABLE_MANAGEMENT();
 		break;
 	case PR_MPX_DISABLE_MANAGEMENT:
 		if (arg2 || arg3 || arg4 || arg5)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -EINVAL;
+}
 		error = MPX_DISABLE_MANAGEMENT();
 		break;
 	case PR_SET_FP_MODE:
@@ -2390,6 +2617,7 @@ SYSCALL_DEFINE5(prctl, int, option, unsigned long, arg2, unsigned long, arg3,
 		error = -EINVAL;
 		break;
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return error;
 }
 
@@ -2401,6 +2629,7 @@ SYSCALL_DEFINE3(getcpu, unsigned __user *, cpup, unsigned __user *, nodep,
 
 	if (cpup)
 		err |= put_user(cpu, cpup);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (nodep)
 		err |= put_user(cpu_to_node(cpu), nodep);
 	return err ? -EFAULT : 0;
@@ -2440,6 +2669,7 @@ static int do_sysinfo(struct sysinfo *info)
 	mem_total = info->totalram + info->totalswap;
 	if (mem_total < info->totalram || mem_total < info->totalswap)
 		goto out;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	bitcount = 0;
 	mem_unit = info->mem_unit;
 	while (mem_unit > 1) {
@@ -2479,7 +2709,9 @@ SYSCALL_DEFINE1(sysinfo, struct sysinfo __user *, info)
 	do_sysinfo(&val);
 
 	if (copy_to_user(info, &val, sizeof(struct sysinfo)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EFAULT;
+}
 
 	return 0;
 }
@@ -2514,6 +2746,7 @@ COMPAT_SYSCALL_DEFINE1(sysinfo, struct compat_sysinfo __user *, info)
 	if (upper_32_bits(s.totalram) || upper_32_bits(s.totalswap)) {
 		int bitcount = 0;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		while (s.mem_unit < PAGE_SIZE) {
 			s.mem_unit <<= 1;
 			bitcount++;
diff --git a/kernel/sys_ni.c b/kernel/sys_ni.c
index b518976..55924f2 100644
--- a/kernel/sys_ni.c
+++ b/kernel/sys_ni.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 
 #include <linux/linkage.h>
diff --git a/kernel/sysctl.c b/kernel/sysctl.c
index 0695505..e0d1671 100644
--- a/kernel/sysctl.c
+++ b/kernel/sysctl.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * sysctl.c: General linux system control interface
  *
@@ -230,11 +232,14 @@ static int sysrq_sysctl_handler(struct ctl_table *table, int write,
 
 	error = proc_dointvec(table, write, buffer, lenp, ppos);
 	if (error)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return error;
+}
 
 	if (write)
 		sysrq_toggle_support(__sysrq_enabled);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
@@ -1905,10 +1910,15 @@ static int _proc_do_string(char *data, int maxlen, int write,
 			/* Only continue writes not past the end of buffer. */
 			len = strlen(data);
 			if (len > maxlen - 1)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				len = maxlen - 1;
+}
 
 			if (*ppos > len)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				return 0;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			len = *ppos;
 		} else {
 			/* Start writing from beginning of buffer. */
@@ -1919,18 +1929,24 @@ static int _proc_do_string(char *data, int maxlen, int write,
 		p = buffer;
 		while ((p - buffer) < *lenp && len < maxlen - 1) {
 			if (get_user(c, p++))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				return -EFAULT;
+}
 			if (c == 0 || c == '\n')
 				break;
 			data[len++] = c;
 		}
 		data[len] = 0;
 	} else {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		len = strlen(data);
 		if (len > maxlen)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			len = maxlen;
+}
 
 		if (*ppos > len) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			*lenp = 0;
 			return 0;
 		}
@@ -1939,23 +1955,31 @@ static int _proc_do_string(char *data, int maxlen, int write,
 		len  -= *ppos;
 
 		if (len > *lenp)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			len = *lenp;
+}
 		if (len)
 			if (copy_to_user(buffer, data, len))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				return -EFAULT;
+}
 		if (len < *lenp) {
 			if (put_user('\n', buffer + len))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				return -EFAULT;
+}
 			len++;
 		}
 		*lenp = len;
 		*ppos += len;
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
 static void warn_sysctl_write(struct ctl_table *table)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pr_warn_once("%s wrote to %s when file position was not 0!\n"
 		"This will not be supported in the future. To silence this\n"
 		"warning, set kernel.sysctl_writes_strict = -1\n",
@@ -1975,8 +1999,11 @@ static bool proc_first_pos_non_zero_ignore(loff_t *ppos,
 					   struct ctl_table *table)
 {
 	if (!*ppos)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return false;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	switch (sysctl_writes_strict) {
 	case SYSCTL_WRITES_STRICT:
 		return true;
@@ -2026,6 +2053,7 @@ static size_t proc_skip_spaces(char **buf)
 
 static void proc_skip_char(char **buf, size_t *size, const char v)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	while (*size) {
 		if (**buf != v)
 			break;
@@ -2059,23 +2087,30 @@ static int proc_get_long(char **buf, size_t *size,
 	char *p, tmp[TMPBUFLEN];
 
 	if (!*size)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	len = *size;
 	if (len > TMPBUFLEN - 1)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		len = TMPBUFLEN - 1;
+}
 
 	memcpy(tmp, *buf, len);
 
 	tmp[len] = 0;
 	p = tmp;
 	if (*p == '-' && *size > 1) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		*neg = true;
 		p++;
 	} else
 		*neg = false;
 	if (!isdigit(*p))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	*val = simple_strtoul(p, &p, 0);
 
@@ -2085,13 +2120,19 @@ static int proc_get_long(char **buf, size_t *size,
 	 * invalid integers (e.g. 1234...a) or two integers instead of one
 	 * (e.g. 123...1). So lets not allow such large numbers. */
 	if (len == TMPBUFLEN - 1)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	if (len < *size && perm_tr_len && !memchr(perm_tr, *p, perm_tr_len))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	if (tr && (len < *size))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		*tr = *p;
+}
 
 	*buf += len;
 	*size -= len;
@@ -2119,9 +2160,13 @@ static int proc_put_long(void __user **buf, size_t *size, unsigned long val,
 	sprintf(p, "%s%lu", neg ? "-" : "", val);
 	len = strlen(tmp);
 	if (len > *size)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		len = *size;
+}
 	if (copy_to_user(*buf, tmp, len))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EFAULT;
+}
 	*size -= len;
 	*buf += len;
 	return 0;
@@ -2133,10 +2178,13 @@ static int proc_put_char(void __user **buf, size_t *size, char c)
 	if (*size) {
 		char __user **buffer = (char __user **)buf;
 		if (put_user(c, *buffer))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -EFAULT;
+}
 		(*size)--, (*buffer)++;
 		*buf = *buffer;
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
@@ -2146,17 +2194,24 @@ static int do_proc_dointvec_conv(bool *negp, unsigned long *lvalp,
 {
 	if (write) {
 		if (*negp) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			if (*lvalp > (unsigned long) INT_MAX + 1)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				return -EINVAL;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			*valp = -*lvalp;
 		} else {
 			if (*lvalp > (unsigned long) INT_MAX)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				return -EINVAL;
+}
 			*valp = *lvalp;
 		}
 	} else {
 		int val = *valp;
 		if (val < 0) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			*negp = true;
 			*lvalp = -(unsigned long)val;
 		} else {
@@ -2164,6 +2219,7 @@ static int do_proc_dointvec_conv(bool *negp, unsigned long *lvalp,
 			*lvalp = (unsigned long)val;
 		}
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
@@ -2171,6 +2227,7 @@ static int do_proc_douintvec_conv(unsigned long *lvalp,
 				  unsigned int *valp,
 				  int write, void *data)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (write) {
 		if (*lvalp > UINT_MAX)
 			return -EINVAL;
@@ -2205,17 +2262,23 @@ static int __do_proc_dointvec(void *tbl_data, struct ctl_table *table,
 	left = *lenp;
 
 	if (!conv)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		conv = do_proc_dointvec_conv;
+}
 
 	if (write) {
 		if (proc_first_pos_non_zero_ignore(ppos, table))
 			goto out;
 
 		if (left > PAGE_SIZE - 1)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			left = PAGE_SIZE - 1;
+}
 		p = kbuf = memdup_user_nul(buffer, left);
 		if (IS_ERR(kbuf))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return PTR_ERR(kbuf);
+}
 	}
 
 	for (; left && vleft--; i++, first=0) {
@@ -2233,16 +2296,20 @@ static int __do_proc_dointvec(void *tbl_data, struct ctl_table *table,
 			if (err)
 				break;
 			if (conv(&neg, &lval, i, 1, data)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				err = -EINVAL;
 				break;
 			}
 		} else {
 			if (conv(&neg, &lval, i, 0, data)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				err = -EINVAL;
 				break;
 			}
 			if (!first)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				err = proc_put_char(&buffer, &left, '\t');
+}
 			if (err)
 				break;
 			err = proc_put_long(&buffer, &left, lval, neg);
@@ -2258,7 +2325,9 @@ static int __do_proc_dointvec(void *tbl_data, struct ctl_table *table,
 	if (write) {
 		kfree(kbuf);
 		if (first)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return err ? : -EINVAL;
+}
 	}
 	*lenp -= left;
 out:
@@ -2296,6 +2365,7 @@ static int do_proc_douintvec_w(unsigned int *tbl_data,
 	if (proc_first_pos_non_zero_ignore(ppos, table))
 		goto bail_early;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (left > PAGE_SIZE - 1)
 		left = PAGE_SIZE - 1;
 
@@ -2352,6 +2422,7 @@ static int do_proc_douintvec_r(unsigned int *tbl_data, void __user *buffer,
 	left = *lenp;
 
 	if (conv(&lval, tbl_data, 0, data)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		err = -EINVAL;
 		goto out;
 	}
@@ -2379,6 +2450,7 @@ static int __do_proc_douintvec(void *tbl_data, struct ctl_table *table,
 {
 	unsigned int *i, vleft;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!tbl_data || !table->maxlen || !*lenp || (*ppos && !write)) {
 		*lenp = 0;
 		return 0;
@@ -2412,6 +2484,7 @@ static int do_proc_douintvec(struct ctl_table *table, int write,
 					 int write, void *data),
 			     void *data)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return __do_proc_douintvec(table->data, table, write,
 				   buffer, lenp, ppos, conv, data);
 }
@@ -2451,6 +2524,7 @@ int proc_dointvec(struct ctl_table *table, int write,
 int proc_douintvec(struct ctl_table *table, int write,
 		     void __user *buffer, size_t *lenp, loff_t *ppos)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return do_proc_douintvec(table, write, buffer, lenp, ppos,
 				 do_proc_douintvec_conv, NULL);
 }
@@ -2466,6 +2540,7 @@ static int proc_taint(struct ctl_table *table, int write,
 	unsigned long tmptaint = get_taint();
 	int err;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (write && !capable(CAP_SYS_ADMIN))
 		return -EPERM;
 
@@ -2495,7 +2570,9 @@ static int proc_dointvec_minmax_sysadmin(struct ctl_table *table, int write,
 				void __user *buffer, size_t *lenp, loff_t *ppos)
 {
 	if (write && !capable(CAP_SYS_ADMIN))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EPERM;
+}
 
 	return proc_dointvec_minmax(table, write, buffer, lenp, ppos);
 }
@@ -2520,6 +2597,7 @@ static int do_proc_dointvec_minmax_conv(bool *negp, unsigned long *lvalp,
 	} else {
 		int val = *valp;
 		if (val < 0) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			*negp = true;
 			*lvalp = -(unsigned long)val;
 		} else {
@@ -2527,6 +2605,7 @@ static int do_proc_dointvec_minmax_conv(bool *negp, unsigned long *lvalp,
 			*lvalp = (unsigned long)val;
 		}
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
@@ -2571,6 +2650,7 @@ static int do_proc_douintvec_minmax_conv(unsigned long *lvalp,
 	if (write) {
 		unsigned int val = *lvalp;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if ((param->min && *param->min > val) ||
 		    (param->max && *param->max < val))
 			return -ERANGE;
@@ -2621,6 +2701,7 @@ static void validate_coredump_safety(void)
 #ifdef CONFIG_COREDUMP
 	if (suid_dumpable == SUID_DUMP_ROOT &&
 	    core_pattern[0] != '/' && core_pattern[0] != '|') {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		printk(KERN_WARNING
 "Unsafe core_pattern used with fs.suid_dumpable=2.\n"
 "Pipe handler or fully qualified core dump path required.\n"
@@ -2633,6 +2714,7 @@ static void validate_coredump_safety(void)
 static int proc_dointvec_minmax_coredump(struct ctl_table *table, int write,
 		void __user *buffer, size_t *lenp, loff_t *ppos)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	int error = proc_dointvec_minmax(table, write, buffer, lenp, ppos);
 	if (!error)
 		validate_coredump_safety();
@@ -2662,10 +2744,12 @@ static int __do_proc_doulongvec_minmax(void *data, struct ctl_table *table, int
 	char *kbuf = NULL, *p;
 
 	if (!data || !table->maxlen || !*lenp || (*ppos && !write)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		*lenp = 0;
 		return 0;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	i = (unsigned long *) data;
 	min = (unsigned long *) table->extra1;
 	max = (unsigned long *) table->extra2;
@@ -2677,10 +2761,14 @@ static int __do_proc_doulongvec_minmax(void *data, struct ctl_table *table, int
 			goto out;
 
 		if (left > PAGE_SIZE - 1)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			left = PAGE_SIZE - 1;
+}
 		p = kbuf = memdup_user_nul(buffer, left);
 		if (IS_ERR(kbuf))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return PTR_ERR(kbuf);
+}
 	}
 
 	for (; left && vleft--; i++, first = 0) {
@@ -2703,12 +2791,15 @@ static int __do_proc_doulongvec_minmax(void *data, struct ctl_table *table, int
 				continue;
 			*i = val;
 		} else {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			val = convdiv * (*i) / convmul;
 			if (!first) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				err = proc_put_char(&buffer, &left, '\t');
 				if (err)
 					break;
 			}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			err = proc_put_long(&buffer, &left, val, false);
 			if (err)
 				break;
@@ -2716,13 +2807,17 @@ static int __do_proc_doulongvec_minmax(void *data, struct ctl_table *table, int
 	}
 
 	if (!write && !first && left && !err)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		err = proc_put_char(&buffer, &left, '\n');
+}
 	if (write && !err)
 		left -= proc_skip_spaces(&p);
 	if (write) {
 		kfree(kbuf);
 		if (first)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return err ? : -EINVAL;
+}
 	}
 	*lenp -= left;
 out:
@@ -2783,6 +2878,7 @@ int proc_doulongvec_ms_jiffies_minmax(struct ctl_table *table, int write,
 				      void __user *buffer,
 				      size_t *lenp, loff_t *ppos)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
     return do_proc_doulongvec_minmax(table, write, buffer,
 				     lenp, ppos, HZ, 1000l);
 }
@@ -2792,6 +2888,7 @@ static int do_proc_dointvec_jiffies_conv(bool *negp, unsigned long *lvalp,
 					 int *valp,
 					 int write, void *data)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (write) {
 		if (*lvalp > INT_MAX / HZ)
 			return 1;
@@ -2815,6 +2912,7 @@ static int do_proc_dointvec_userhz_jiffies_conv(bool *negp, unsigned long *lvalp
 						int *valp,
 						int write, void *data)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (write) {
 		if (USER_HZ < HZ && *lvalp > (LONG_MAX / HZ) * USER_HZ)
 			return 1;
@@ -2838,6 +2936,7 @@ static int do_proc_dointvec_ms_jiffies_conv(bool *negp, unsigned long *lvalp,
 					    int *valp,
 					    int write, void *data)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (write) {
 		unsigned long jif = msecs_to_jiffies(*negp ? -*lvalp : *lvalp);
 
@@ -2877,6 +2976,7 @@ static int do_proc_dointvec_ms_jiffies_conv(bool *negp, unsigned long *lvalp,
 int proc_dointvec_jiffies(struct ctl_table *table, int write,
 			  void __user *buffer, size_t *lenp, loff_t *ppos)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
     return do_proc_dointvec(table,write,buffer,lenp,ppos,
 		    	    do_proc_dointvec_jiffies_conv,NULL);
 }
@@ -2899,6 +2999,7 @@ int proc_dointvec_jiffies(struct ctl_table *table, int write,
 int proc_dointvec_userhz_jiffies(struct ctl_table *table, int write,
 				 void __user *buffer, size_t *lenp, loff_t *ppos)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
     return do_proc_dointvec(table,write,buffer,lenp,ppos,
 		    	    do_proc_dointvec_userhz_jiffies_conv,NULL);
 }
@@ -2922,6 +3023,7 @@ int proc_dointvec_userhz_jiffies(struct ctl_table *table, int write,
 int proc_dointvec_ms_jiffies(struct ctl_table *table, int write,
 			     void __user *buffer, size_t *lenp, loff_t *ppos)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return do_proc_dointvec(table, write, buffer, lenp, ppos,
 				do_proc_dointvec_ms_jiffies_conv, NULL);
 }
@@ -2937,6 +3039,7 @@ static int proc_do_cad_pid(struct ctl_table *table, int write,
 
 	r = __do_proc_dointvec(&tmp, table, write, buffer,
 			       lenp, ppos, NULL, NULL);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (r || !write)
 		return r;
 
@@ -2976,6 +3079,7 @@ int proc_do_large_bitmap(struct ctl_table *table, int write,
 	unsigned long *tmp_bitmap = NULL;
 	char tr_a[] = { '-', ',', '\n' }, tr_b[] = { ',', '\n', 0 }, c;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!bitmap || !bitmap_len || !left || (*ppos && !write)) {
 		*lenp = 0;
 		return 0;
diff --git a/kernel/task_work.c b/kernel/task_work.c
index 0fef395..dfd21d1 100644
--- a/kernel/task_work.c
+++ b/kernel/task_work.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 #include <linux/spinlock.h>
 #include <linux/task_work.h>
@@ -32,12 +34,15 @@ task_work_add(struct task_struct *task, struct callback_head *work, bool notify)
 	do {
 		head = READ_ONCE(task->task_works);
 		if (unlikely(head == &work_exited))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -ESRCH;
+}
 		work->next = head;
 	} while (cmpxchg(&task->task_works, head, work) != head);
 
 	if (notify)
 		set_notify_resume(task);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
@@ -60,7 +65,9 @@ task_work_cancel(struct task_struct *task, task_work_func_t func)
 	unsigned long flags;
 
 	if (likely(!task->task_works))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 	/*
 	 * If cmpxchg() fails we continue without updating pprev.
 	 * Either we raced with task_work_add() which added the
@@ -89,6 +96,7 @@ task_work_cancel(struct task_struct *task, task_work_func_t func)
  */
 void task_work_run(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct task_struct *task = current;
 	struct callback_head *work, *head, *next;
 
diff --git a/kernel/taskstats.c b/kernel/taskstats.c
index 4559e91..5fc80cd 100644
--- a/kernel/taskstats.c
+++ b/kernel/taskstats.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * taskstats.c - Export per-task statistics to userland
  *
@@ -87,7 +89,9 @@ static int prepare_reply(struct genl_info *info, u8 cmd, struct sk_buff **skbp,
 	 */
 	skb = genlmsg_new(size, GFP_KERNEL);
 	if (!skb)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 
 	if (!info) {
 		int seq = this_cpu_inc_return(taskstats_seqnum) - 1;
@@ -109,6 +113,7 @@ static int prepare_reply(struct genl_info *info, u8 cmd, struct sk_buff **skbp,
  */
 static int send_reply(struct sk_buff *skb, struct genl_info *info)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct genlmsghdr *genlhdr = nlmsg_data(nlmsg_hdr(skb));
 	void *reply = genlmsg_data(genlhdr);
 
@@ -123,6 +128,7 @@ static int send_reply(struct sk_buff *skb, struct genl_info *info)
 static void send_cpu_listeners(struct sk_buff *skb,
 					struct listener_list *listeners)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct genlmsghdr *genlhdr = nlmsg_data(nlmsg_hdr(skb));
 	struct listener *s, *tmp;
 	struct sk_buff *skb_next, *skb_cur = skb;
@@ -170,6 +176,7 @@ static void fill_stats(struct user_namespace *user_ns,
 		       struct pid_namespace *pid_ns,
 		       struct task_struct *tsk, struct taskstats *stats)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	memset(stats, 0, sizeof(*stats));
 	/*
 	 * Each accounting subsystem adds calls to its functions to
@@ -197,7 +204,9 @@ static int fill_stats_for_pid(pid_t pid, struct taskstats *stats)
 	rcu_read_lock();
 	tsk = find_task_by_vpid(pid);
 	if (tsk)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		get_task_struct(tsk);
+}
 	rcu_read_unlock();
 	if (!tsk)
 		return -ESRCH;
@@ -221,6 +230,7 @@ static int fill_stats_for_tgid(pid_t tgid, struct taskstats *stats)
 	rcu_read_lock();
 	first = find_task_by_vpid(tgid);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!first || !lock_task_sighand(first, &flags))
 		goto out;
 
@@ -297,7 +307,9 @@ static int add_del_listener(pid_t pid, const struct cpumask *mask, int isadd)
 	int ret = 0;
 
 	if (!cpumask_subset(mask, cpu_possible_mask))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	if (current_user_ns() != &init_user_ns)
 		return -EINVAL;
@@ -355,7 +367,9 @@ static int parse(struct nlattr *na, struct cpumask *mask)
 	int ret;
 
 	if (na == NULL)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 1;
+}
 	len = nla_len(na);
 	if (len > TASKSTATS_CPUMASK_MAXLEN)
 		return -E2BIG;
@@ -375,6 +389,7 @@ static struct taskstats *mk_reply(struct sk_buff *skb, int type, u32 pid)
 	struct nlattr *na, *ret;
 	int aggr;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	aggr = (type == TASKSTATS_TYPE_PID)
 			? TASKSTATS_TYPE_AGGR_PID
 			: TASKSTATS_TYPE_AGGR_TGID;
@@ -412,7 +427,9 @@ static int cgroupstats_user_cmd(struct sk_buff *skb, struct genl_info *info)
 
 	na = info->attrs[CGROUPSTATS_CMD_ATTR_FD];
 	if (!na)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	fd = nla_get_u32(info->attrs[CGROUPSTATS_CMD_ATTR_FD]);
 	f = fdget(fd);
@@ -456,7 +473,9 @@ static int cmd_attr_register_cpumask(struct genl_info *info)
 	int rc;
 
 	if (!alloc_cpumask_var(&mask, GFP_KERNEL))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 	rc = parse(info->attrs[TASKSTATS_CMD_ATTR_REGISTER_CPUMASK], mask);
 	if (rc < 0)
 		goto out;
@@ -472,7 +491,9 @@ static int cmd_attr_deregister_cpumask(struct genl_info *info)
 	int rc;
 
 	if (!alloc_cpumask_var(&mask, GFP_KERNEL))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 	rc = parse(info->attrs[TASKSTATS_CMD_ATTR_DEREGISTER_CPUMASK], mask);
 	if (rc < 0)
 		goto out;
@@ -505,7 +526,9 @@ static int cmd_attr_pid(struct genl_info *info)
 
 	rc = prepare_reply(info, TASKSTATS_CMD_NEW, &rep_skb, size);
 	if (rc < 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return rc;
+}
 
 	rc = -EINVAL;
 	pid = nla_get_u32(info->attrs[TASKSTATS_CMD_ATTR_PID]);
@@ -534,7 +557,9 @@ static int cmd_attr_tgid(struct genl_info *info)
 
 	rc = prepare_reply(info, TASKSTATS_CMD_NEW, &rep_skb, size);
 	if (rc < 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return rc;
+}
 
 	rc = -EINVAL;
 	tgid = nla_get_u32(info->attrs[TASKSTATS_CMD_ATTR_TGID]);
@@ -553,6 +578,7 @@ static int cmd_attr_tgid(struct genl_info *info)
 
 static int taskstats_user_cmd(struct sk_buff *skb, struct genl_info *info)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (info->attrs[TASKSTATS_CMD_ATTR_REGISTER_CPUMASK])
 		return cmd_attr_register_cpumask(info);
 	else if (info->attrs[TASKSTATS_CMD_ATTR_DEREGISTER_CPUMASK])
@@ -617,17 +643,23 @@ void taskstats_exit(struct task_struct *tsk, int group_dead)
 
 	listeners = raw_cpu_ptr(&listener_array);
 	if (list_empty(&listeners->list))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rc = prepare_reply(NULL, TASKSTATS_CMD_NEW, &rep_skb, size);
 	if (rc < 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	stats = mk_reply(rep_skb, TASKSTATS_TYPE_PID,
 			 task_pid_nr_ns(tsk, &init_pid_ns));
 	if (!stats)
 		goto err;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	fill_stats(&init_user_ns, &init_pid_ns, tsk, stats);
 
 	/*
@@ -641,6 +673,7 @@ void taskstats_exit(struct task_struct *tsk, int group_dead)
 	if (!stats)
 		goto err;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	memcpy(stats, tsk->signal->stats, sizeof(*stats));
 
 send:
@@ -691,7 +724,9 @@ static int __init taskstats_init(void)
 
 	rc = genl_register_family(&family);
 	if (rc)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return rc;
+}
 
 	family_registered = 1;
 	pr_info("registered taskstats version %d\n", TASKSTATS_GENL_VERSION);
diff --git a/kernel/time/alarmtimer.c b/kernel/time/alarmtimer.c
index ec09ce9..5c45e301 100644
--- a/kernel/time/alarmtimer.c
+++ b/kernel/time/alarmtimer.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * Alarmtimer interface
  *
@@ -138,6 +140,7 @@ static int alarmtimer_rtc_interface_setup(void)
 }
 static void alarmtimer_rtc_interface_remove(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	class_interface_unregister(&alarmtimer_rtc_interface);
 }
 #else
@@ -162,6 +165,7 @@ static inline void alarmtimer_rtc_timer_init(void) { }
  */
 static void alarmtimer_enqueue(struct alarm_base *base, struct alarm *alarm)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (alarm->state & ALARMTIMER_STATE_ENQUEUED)
 		timerqueue_del(&base->timerqueue, &alarm->node);
 
@@ -180,6 +184,7 @@ static void alarmtimer_enqueue(struct alarm_base *base, struct alarm *alarm)
  */
 static void alarmtimer_dequeue(struct alarm_base *base, struct alarm *alarm)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!(alarm->state & ALARMTIMER_STATE_ENQUEUED))
 		return;
 
@@ -199,6 +204,7 @@ static void alarmtimer_dequeue(struct alarm_base *base, struct alarm *alarm)
  */
 static enum hrtimer_restart alarmtimer_fired(struct hrtimer *timer)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct alarm *alarm = container_of(timer, struct alarm, timer);
 	struct alarm_base *base = &alarm_bases[alarm->type];
 	unsigned long flags;
@@ -251,6 +257,7 @@ static int alarmtimer_suspend(struct device *dev)
 	unsigned long flags;
 	struct rtc_time tm;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_lock_irqsave(&freezer_delta_lock, flags);
 	min = freezer_delta;
 	expires = freezer_expires;
@@ -310,7 +317,9 @@ static int alarmtimer_resume(struct device *dev)
 
 	rtc = alarmtimer_get_rtcdev();
 	if (rtc)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		rtc_timer_cancel(rtc, &rtctimer);
+}
 	return 0;
 }
 
@@ -335,6 +344,7 @@ static int alarmtimer_resume(struct device *dev)
 void alarm_init(struct alarm *alarm, enum alarmtimer_type type,
 		enum alarmtimer_restart (*function)(struct alarm *, ktime_t))
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	timerqueue_init(&alarm->node);
 	hrtimer_init(&alarm->timer, alarm_bases[type].base_clockid,
 			HRTIMER_MODE_ABS);
@@ -355,6 +365,7 @@ void alarm_start(struct alarm *alarm, ktime_t start)
 	struct alarm_base *base = &alarm_bases[alarm->type];
 	unsigned long flags;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_lock_irqsave(&base->lock, flags);
 	alarm->node.expires = start;
 	alarmtimer_enqueue(base, alarm);
@@ -384,6 +395,7 @@ void alarm_restart(struct alarm *alarm)
 	struct alarm_base *base = &alarm_bases[alarm->type];
 	unsigned long flags;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_lock_irqsave(&base->lock, flags);
 	hrtimer_set_expires(&alarm->timer, alarm->node.expires);
 	hrtimer_restart(&alarm->timer);
@@ -405,6 +417,7 @@ int alarm_try_to_cancel(struct alarm *alarm)
 	unsigned long flags;
 	int ret;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_lock_irqsave(&base->lock, flags);
 	ret = hrtimer_try_to_cancel(&alarm->timer);
 	if (ret >= 0)
@@ -426,6 +439,7 @@ EXPORT_SYMBOL_GPL(alarm_try_to_cancel);
 int alarm_cancel(struct alarm *alarm)
 {
 	for (;;) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		int ret = alarm_try_to_cancel(alarm);
 		if (ret >= 0)
 			return ret;
@@ -443,7 +457,9 @@ u64 alarm_forward(struct alarm *alarm, ktime_t now, ktime_t interval)
 	delta = ktime_sub(now, alarm->node.expires);
 
 	if (delta < 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	if (unlikely(delta >= interval)) {
 		s64 incr = ktime_to_ns(interval);
@@ -514,6 +530,7 @@ static void alarmtimer_freezerset(ktime_t absexp, enum alarmtimer_type type)
  */
 static enum alarmtimer_type clock2alarm(clockid_t clockid)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (clockid == CLOCK_REALTIME_ALARM)
 		return ALARM_REALTIME;
 	if (clockid == CLOCK_BOOTTIME_ALARM)
@@ -530,6 +547,7 @@ static enum alarmtimer_type clock2alarm(clockid_t clockid)
 static enum alarmtimer_restart alarm_handle_timer(struct alarm *alarm,
 							ktime_t now)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct k_itimer *ptr = container_of(alarm, struct k_itimer,
 					    it.alarm.alarmtimer);
 	enum alarmtimer_restart result = ALARMTIMER_NORESTART;
@@ -599,6 +617,7 @@ static ktime_t alarm_timer_remaining(struct k_itimer *timr, ktime_t now)
  */
 static int alarm_timer_try_to_cancel(struct k_itimer *timr)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return alarm_try_to_cancel(&timr->it.alarm.alarmtimer);
 }
 
@@ -616,7 +635,9 @@ static void alarm_timer_arm(struct k_itimer *timr, ktime_t expires,
 	struct alarm_base *base = &alarm_bases[alarm->type];
 
 	if (!absolute)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		expires = ktime_add_safe(expires, base->gettime());
+}
 	if (sigev_none)
 		alarm->node.expires = expires;
 	else
@@ -632,6 +653,7 @@ static void alarm_timer_arm(struct k_itimer *timr, ktime_t expires,
  */
 static int alarm_clock_getres(const clockid_t which_clock, struct timespec64 *tp)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!alarmtimer_get_rtcdev())
 		return -EINVAL;
 
@@ -649,6 +671,7 @@ static int alarm_clock_getres(const clockid_t which_clock, struct timespec64 *tp
  */
 static int alarm_clock_get(clockid_t which_clock, struct timespec64 *tp)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct alarm_base *base = &alarm_bases[clock2alarm(which_clock)];
 
 	if (!alarmtimer_get_rtcdev())
@@ -669,7 +692,9 @@ static int alarm_timer_create(struct k_itimer *new_timer)
 	enum  alarmtimer_type type;
 
 	if (!alarmtimer_get_rtcdev())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOTSUPP;
+}
 
 	if (!capable(CAP_WAKE_ALARM))
 		return -EPERM;
@@ -692,7 +717,9 @@ static enum alarmtimer_restart alarmtimer_nsleep_wakeup(struct alarm *alarm,
 
 	alarm->data = NULL;
 	if (task)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		wake_up_process(task);
+}
 	return ALARMTIMER_NORESTART;
 }
 
@@ -709,6 +736,7 @@ static int alarmtimer_do_nsleep(struct alarm *alarm, ktime_t absexp,
 	struct restart_block *restart;
 	alarm->data = (void *)current;
 	do {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		set_current_state(TASK_INTERRUPTIBLE);
 		alarm_start(alarm, absexp);
 		if (likely(alarm->data))
@@ -769,6 +797,7 @@ static long __sched alarm_timer_nsleep_restart(struct restart_block *restart)
 static int alarm_timer_nsleep(const clockid_t which_clock, int flags,
 			      const struct timespec64 *tsreq)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	enum  alarmtimer_type type = clock2alarm(which_clock);
 	struct restart_block *restart = &current->restart_block;
 	struct alarm alarm;
@@ -857,13 +886,16 @@ static int __init alarmtimer_init(void)
 	alarm_bases[ALARM_BOOTTIME].base_clockid = CLOCK_BOOTTIME;
 	alarm_bases[ALARM_BOOTTIME].gettime = &ktime_get_boottime;
 	for (i = 0; i < ALARM_NUMTYPE; i++) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		timerqueue_init_head(&alarm_bases[i].timerqueue);
 		spin_lock_init(&alarm_bases[i].lock);
 	}
 
 	error = alarmtimer_rtc_interface_setup();
 	if (error)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return error;
+}
 
 	error = platform_driver_register(&alarmtimer_driver);
 	if (error)
@@ -871,9 +903,11 @@ static int __init alarmtimer_init(void)
 
 	pdev = platform_device_register_simple("alarmtimer", -1, NULL, 0);
 	if (IS_ERR(pdev)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		error = PTR_ERR(pdev);
 		goto out_drv;
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 
 out_drv:
diff --git a/kernel/time/clockevents.c b/kernel/time/clockevents.c
index 4237e07..6e5ea64 100644
--- a/kernel/time/clockevents.c
+++ b/kernel/time/clockevents.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * linux/kernel/time/clockevents.c
  *
@@ -40,7 +42,9 @@ static u64 cev_delta2ns(unsigned long latch, struct clock_event_device *evt,
 	u64 rnd;
 
 	if (unlikely(!evt->mult)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		evt->mult = 1;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		WARN_ON(1);
 	}
 	rnd = (u64) evt->mult - 1;
@@ -50,7 +54,9 @@ static u64 cev_delta2ns(unsigned long latch, struct clock_event_device *evt,
 	 * not equal latch, we know that the above shift overflowed.
 	 */
 	if ((clc >> evt->shift) != (u64)latch)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		clc = ~0ULL;
+}
 
 	/*
 	 * Scaled math oddities:
@@ -98,7 +104,9 @@ static int __clockevents_switch_state(struct clock_event_device *dev,
 				      enum clock_event_state state)
 {
 	if (dev->features & CLOCK_EVT_FEAT_DUMMY)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	/* Transition with new state-specific callbacks */
 	switch (state) {
@@ -108,22 +116,29 @@ static int __clockevents_switch_state(struct clock_event_device *dev,
 	case CLOCK_EVT_STATE_SHUTDOWN:
 		if (dev->set_state_shutdown)
 			return dev->set_state_shutdown(dev);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
 
 	case CLOCK_EVT_STATE_PERIODIC:
 		/* Core internal bug */
 		if (!(dev->features & CLOCK_EVT_FEAT_PERIODIC))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -ENOSYS;
+}
 		if (dev->set_state_periodic)
 			return dev->set_state_periodic(dev);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
 
 	case CLOCK_EVT_STATE_ONESHOT:
 		/* Core internal bug */
 		if (!(dev->features & CLOCK_EVT_FEAT_ONESHOT))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -ENOSYS;
+}
 		if (dev->set_state_oneshot)
 			return dev->set_state_oneshot(dev);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
 
 	case CLOCK_EVT_STATE_ONESHOT_STOPPED:
@@ -133,8 +148,11 @@ static int __clockevents_switch_state(struct clock_event_device *dev,
 			      clockevent_get_state(dev)))
 			return -EINVAL;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (dev->set_state_oneshot_stopped)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return dev->set_state_oneshot_stopped(dev);
+}
 		else
 			return -ENOSYS;
 
@@ -155,8 +173,11 @@ void clockevents_switch_state(struct clock_event_device *dev,
 {
 	if (clockevent_get_state(dev) != state) {
 		if (__clockevents_switch_state(dev, state))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		clockevent_set_state(dev, state);
 
 		/*
@@ -165,7 +186,9 @@ void clockevents_switch_state(struct clock_event_device *dev,
 		 */
 		if (clockevent_state_oneshot(dev)) {
 			if (unlikely(!dev->mult)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				dev->mult = 1;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				WARN_ON(1);
 			}
 		}
@@ -191,7 +214,9 @@ int clockevents_tick_resume(struct clock_event_device *dev)
 	int ret = 0;
 
 	if (dev->tick_resume)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ret = dev->tick_resume(dev);
+}
 
 	return ret;
 }
@@ -249,13 +274,18 @@ static int clockevents_program_min_delta(struct clock_event_device *dev)
 		dev->next_event = ktime_add_ns(ktime_get(), delta);
 
 		if (clockevent_state_shutdown(dev))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return 0;
+}
 
 		dev->retries++;
 		clc = ((unsigned long long) delta * dev->mult) >> dev->shift;
 		if (dev->set_next_event((unsigned long) clc, dev) == 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return 0;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (++i > 2) {
 			/*
 			 * We tried 3 times to program the device with the
@@ -263,7 +293,10 @@ static int clockevents_program_min_delta(struct clock_event_device *dev)
 			 * delta, if that fails as well get out of here.
 			 */
 			if (clockevents_increase_min_delta(dev))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				return -ETIME;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			i = 0;
 		}
 	}
@@ -311,6 +344,7 @@ int clockevents_program_event(struct clock_event_device *dev, ktime_t expires,
 	int rc;
 
 	if (unlikely(expires < 0)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		WARN_ON_ONCE(1);
 		return -ETIME;
 	}
@@ -318,7 +352,9 @@ int clockevents_program_event(struct clock_event_device *dev, ktime_t expires,
 	dev->next_event = expires;
 
 	if (clockevent_state_shutdown(dev))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	/* We must be in ONESHOT state here */
 	WARN_ONCE(!clockevent_state_oneshot(dev), "Current state: %d\n",
@@ -326,7 +362,9 @@ int clockevents_program_event(struct clock_event_device *dev, ktime_t expires,
 
 	/* Shortcut for clockevent devices that can deal with ktime. */
 	if (dev->features & CLOCK_EVT_FEAT_KTIME)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return dev->set_next_ktime(expires, dev);
+}
 
 	delta = ktime_to_ns(ktime_sub(expires, ktime_get()));
 	if (delta <= 0)
@@ -365,6 +403,7 @@ static int clockevents_replace(struct clock_event_device *ced)
 {
 	struct clock_event_device *dev, *newdev = NULL;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry(dev, &clockevent_devices, list) {
 		if (dev == ced || !clockevent_state_detached(dev))
 			continue;
@@ -409,6 +448,7 @@ static void __clockevents_unbind(void *arg)
 	int res;
 
 	raw_spin_lock(&clockevents_lock);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	res = __clockevents_try_unbind(cu->ce, smp_processor_id());
 	if (res == -EAGAIN)
 		res = clockevents_replace(cu->ce);
@@ -454,7 +494,9 @@ void clockevents_register_device(struct clock_event_device *dev)
 	clockevent_set_state(dev, CLOCK_EVT_STATE_DETACHED);
 
 	if (!dev->cpumask) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		WARN_ON(num_possible_cpus() > 1);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		dev->cpumask = cpumask_of(smp_processor_id());
 	}
 
@@ -473,7 +515,9 @@ static void clockevents_config(struct clock_event_device *dev, u32 freq)
 	u64 sec;
 
 	if (!(dev->features & CLOCK_EVT_FEAT_ONESHOT))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	/*
 	 * Calculate the maximum number of seconds we can sleep. Limit
@@ -483,9 +527,13 @@ static void clockevents_config(struct clock_event_device *dev, u32 freq)
 	sec = dev->max_delta_ticks;
 	do_div(sec, freq);
 	if (!sec)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		sec = 1;
+}
 	else if (sec > 600 && dev->max_delta_ticks > UINT_MAX)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		sec = 600;
+}
 
 	clockevents_calc_mult_shift(dev, freq, sec);
 	dev->min_delta_ns = cev_delta2ns(dev->min_delta_ticks, dev, false);
@@ -514,6 +562,7 @@ EXPORT_SYMBOL_GPL(clockevents_config_and_register);
 
 int __clockevents_update_freq(struct clock_event_device *dev, u32 freq)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	clockevents_config(dev, freq);
 
 	if (clockevent_state_oneshot(dev))
@@ -542,6 +591,7 @@ int clockevents_update_freq(struct clock_event_device *dev, u32 freq)
 	unsigned long flags;
 	int ret;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	local_irq_save(flags);
 	ret = tick_broadcast_update_freq(dev, freq);
 	if (ret == -ENODEV)
@@ -592,6 +642,7 @@ void clockevents_suspend(void)
 {
 	struct clock_event_device *dev;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry_reverse(dev, &clockevent_devices, list)
 		if (dev->suspend && !clockevent_state_detached(dev))
 			dev->suspend(dev);
@@ -604,6 +655,7 @@ void clockevents_resume(void)
 {
 	struct clock_event_device *dev;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry(dev, &clockevent_devices, list)
 		if (dev->resume && !clockevent_state_detached(dev))
 			dev->resume(dev);
@@ -618,6 +670,7 @@ void tick_cleanup_dead_cpu(int cpu)
 	struct clock_event_device *dev, *tmp;
 	unsigned long flags;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	raw_spin_lock_irqsave(&clockevents_lock, flags);
 
 	tick_shutdown_broadcast_oneshot(cpu);
@@ -662,6 +715,7 @@ static ssize_t sysfs_show_current_tick_dev(struct device *dev,
 
 	raw_spin_lock_irq(&clockevents_lock);
 	td = tick_get_tick_dev(dev);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (td && td->evtdev)
 		count = snprintf(buf, PAGE_SIZE, "%s\n", td->evtdev->name);
 	raw_spin_unlock_irq(&clockevents_lock);
@@ -679,7 +733,9 @@ static ssize_t sysfs_unbind_tick_dev(struct device *dev,
 	struct clock_event_device *ce;
 
 	if (ret < 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ret;
+}
 
 	ret = -ENODEV;
 	mutex_lock(&clockevents_mutex);
@@ -710,6 +766,7 @@ static struct device tick_bc_dev = {
 
 static struct tick_device *tick_get_tick_dev(struct device *dev)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return dev == &tick_bc_dev ? tick_get_broadcast_device() :
 		&per_cpu(tick_cpu_device, dev->id);
 }
@@ -746,7 +803,9 @@ static int __init tick_init_sysfs(void)
 		if (!err)
 			err = device_create_file(dev, &dev_attr_unbind_device);
 		if (err)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return err;
+}
 	}
 	return tick_broadcast_init_sysfs();
 }
diff --git a/kernel/time/clocksource.c b/kernel/time/clocksource.c
index 03918a1..2a5282c 100644
--- a/kernel/time/clocksource.c
+++ b/kernel/time/clocksource.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * linux/kernel/time/clocksource.c
  *
@@ -139,6 +141,7 @@ static void clocksource_watchdog_work(struct work_struct *work)
 
 static void __clocksource_unstable(struct clocksource *cs)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	cs->flags &= ~(CLOCK_SOURCE_VALID_FOR_HRES | CLOCK_SOURCE_WATCHDOG);
 	cs->flags |= CLOCK_SOURCE_UNSTABLE;
 
@@ -162,6 +165,7 @@ void clocksource_mark_unstable(struct clocksource *cs)
 {
 	unsigned long flags;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_lock_irqsave(&watchdog_lock, flags);
 	if (!(cs->flags & CLOCK_SOURCE_UNSTABLE)) {
 		if (list_empty(&cs->wd_list))
@@ -182,14 +186,18 @@ static void clocksource_watchdog(unsigned long data)
 	if (!watchdog_running)
 		goto out;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	reset_pending = atomic_read(&watchdog_reset_pending);
 
 	list_for_each_entry(cs, &watchdog_list, wd_list) {
 
 		/* Clocksource already marked unstable? */
 		if (cs->flags & CLOCK_SOURCE_UNSTABLE) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			if (finished_booting)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				schedule_work(&watchdog_work);
+}
 			continue;
 		}
 
@@ -223,6 +231,7 @@ static void clocksource_watchdog(unsigned long data)
 
 		/* Check the deviation from the watchdog clocksource. */
 		if (abs(cs_nsec - wd_nsec) > WATCHDOG_THRESHOLD) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			pr_warn("timekeeping watchdog on CPU%d: Marking clocksource '%s' as unstable because the skew is too large:\n",
 				smp_processor_id(), cs->name);
 			pr_warn("                      '%s' wd_now: %llx wd_last: %llx mask: %llx\n",
@@ -261,6 +270,7 @@ static void clocksource_watchdog(unsigned long data)
 				cs->flags |= CLOCK_SOURCE_RESELECT;
 				schedule_work(&watchdog_work);
 			} else {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				tick_clock_notify();
 			}
 		}
@@ -271,7 +281,9 @@ static void clocksource_watchdog(unsigned long data)
 	 * full cycle through all clocksources.
 	 */
 	if (reset_pending)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		atomic_dec(&watchdog_reset_pending);
+}
 
 	/*
 	 * Cycle through CPUs to check if the CPUs stay synchronized
@@ -289,7 +301,9 @@ static void clocksource_watchdog(unsigned long data)
 static inline void clocksource_start_watchdog(void)
 {
 	if (watchdog_running || !watchdog || list_empty(&watchdog_list))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 	init_timer(&watchdog_timer);
 	watchdog_timer.function = clocksource_watchdog;
 	watchdog_timer.expires = jiffies + WATCHDOG_INTERVAL;
@@ -300,7 +314,10 @@ static inline void clocksource_start_watchdog(void)
 static inline void clocksource_stop_watchdog(void)
 {
 	if (!watchdog_running || (watchdog && !list_empty(&watchdog_list)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	del_timer(&watchdog_timer);
 	watchdog_running = 0;
 }
@@ -315,6 +332,7 @@ static inline void clocksource_reset_watchdog(void)
 
 static void clocksource_resume_watchdog(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	atomic_inc(&watchdog_reset_pending);
 }
 
@@ -332,6 +350,7 @@ static void clocksource_enqueue_watchdog(struct clocksource *cs)
 		if (cs->flags & CLOCK_SOURCE_IS_CONTINUOUS)
 			cs->flags |= CLOCK_SOURCE_VALID_FOR_HRES;
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_unlock_irqrestore(&watchdog_lock, flags);
 }
 
@@ -344,7 +363,9 @@ static void clocksource_select_watchdog(bool fallback)
 	/* save current watchdog */
 	old_wd = watchdog;
 	if (fallback)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		watchdog = NULL;
+}
 
 	list_for_each_entry(cs, &clocksource_list, list) {
 		/* cs is a clocksource to be watched. */
@@ -361,7 +382,9 @@ static void clocksource_select_watchdog(bool fallback)
 	}
 	/* If we failed to find a fallback restore the old one. */
 	if (!watchdog)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		watchdog = old_wd;
+}
 
 	/* If we changed the watchdog we need to reset cycles. */
 	if (watchdog != old_wd)
@@ -376,6 +399,7 @@ static void clocksource_dequeue_watchdog(struct clocksource *cs)
 {
 	unsigned long flags;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_lock_irqsave(&watchdog_lock, flags);
 	if (cs != watchdog) {
 		if (cs->flags & CLOCK_SOURCE_MUST_VERIFY) {
@@ -398,6 +422,7 @@ static int __clocksource_watchdog_kthread(void)
 	spin_lock_irqsave(&watchdog_lock, flags);
 	list_for_each_entry_safe(cs, tmp, &watchdog_list, wd_list) {
 		if (cs->flags & CLOCK_SOURCE_UNSTABLE) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			list_del_init(&cs->wd_list);
 			list_add(&cs->wd_list, &unstable);
 			select = 1;
@@ -413,6 +438,7 @@ static int __clocksource_watchdog_kthread(void)
 
 	/* Needs to be done outside of watchdog lock */
 	list_for_each_entry_safe(cs, tmp, &unstable, wd_list) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		list_del_init(&cs->wd_list);
 		__clocksource_change_rating(cs, 0);
 	}
@@ -430,6 +456,7 @@ static int clocksource_watchdog_kthread(void *data)
 
 static bool clocksource_is_watchdog(struct clocksource *cs)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return cs == watchdog;
 }
 
@@ -1041,6 +1068,7 @@ device_initcall(init_clocksource_sysfs);
  */
 static int __init boot_override_clocksource(char* str)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	mutex_lock(&clocksource_mutex);
 	if (str)
 		strlcpy(override_name, str, sizeof(override_name));
@@ -1059,6 +1087,7 @@ __setup("clocksource=", boot_override_clocksource);
  */
 static int __init boot_override_clock(char* str)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!strcmp(str, "pmtmr")) {
 		pr_warn("clock=pmtmr is deprecated - use clocksource=acpi_pm\n");
 		return boot_override_clocksource("acpi_pm");
diff --git a/kernel/time/hrtimer.c b/kernel/time/hrtimer.c
index d00e85a..b9a9709 100644
--- a/kernel/time/hrtimer.c
+++ b/kernel/time/hrtimer.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  *  linux/kernel/hrtimer.c
  *
@@ -151,6 +153,7 @@ struct hrtimer_clock_base *lock_hrtimer_base(const struct hrtimer *timer,
 			/* The timer has migrated to another CPU: */
 			raw_spin_unlock_irqrestore(&base->cpu_base->lock, *flags);
 		}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		cpu_relax();
 	}
 }
@@ -169,7 +172,9 @@ hrtimer_check_target(struct hrtimer *timer, struct hrtimer_clock_base *new_base)
 	ktime_t expires;
 
 	if (!new_base->cpu_base->hres_active)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	expires = ktime_sub(hrtimer_get_expires(timer), new_base->offset);
 	return expires <= new_base->cpu_base->expires_next;
@@ -184,7 +189,9 @@ struct hrtimer_cpu_base *get_target_base(struct hrtimer_cpu_base *base,
 					 int pinned)
 {
 	if (pinned || !base->migration_enabled)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return base;
+}
 	return &per_cpu(hrtimer_bases, get_nohz_timer_target());
 }
 #else
@@ -232,7 +239,9 @@ switch_hrtimer_base(struct hrtimer *timer, struct hrtimer_clock_base *base,
 		 * the timer is enqueued.
 		 */
 		if (unlikely(hrtimer_callback_running(timer)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return base;
+}
 
 		/* See the comment in lock_hrtimer_base() */
 		timer->base = &migration_base;
@@ -241,20 +250,24 @@ switch_hrtimer_base(struct hrtimer *timer, struct hrtimer_clock_base *base,
 
 		if (new_cpu_base != this_cpu_base &&
 		    hrtimer_check_target(timer, new_base)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			raw_spin_unlock(&new_base->cpu_base->lock);
 			raw_spin_lock(&base->cpu_base->lock);
 			new_cpu_base = this_cpu_base;
 			timer->base = base;
 			goto again;
 		}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		timer->base = new_base;
 	} else {
 		if (new_cpu_base != this_cpu_base &&
 		    hrtimer_check_target(timer, new_base)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			new_cpu_base = this_cpu_base;
 			goto again;
 		}
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return new_base;
 }
 
@@ -315,7 +328,9 @@ ktime_t ktime_add_safe(const ktime_t lhs, const ktime_t rhs)
 	 * return to user space in a timespec:
 	 */
 	if (res < 0 || res < lhs || res < rhs)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		res = ktime_set(KTIME_SEC_MAX, 0);
+}
 
 	return res;
 }
diff --git a/kernel/time/itimer.c b/kernel/time/itimer.c
index f26acef..353aa12 100644
--- a/kernel/time/itimer.c
+++ b/kernel/time/itimer.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 /*
  * linux/kernel/itimer.c
@@ -39,9 +41,13 @@ static struct timeval itimer_get_remtime(struct hrtimer *timer)
 	 */
 	if (hrtimer_active(timer)) {
 		if (rem <= 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			rem = NSEC_PER_USEC;
+}
 	} else
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		rem = 0;
+}
 
 	return ktime_to_timeval(rem);
 }
@@ -62,7 +68,9 @@ static void get_cpu_itimer(struct task_struct *tsk, unsigned int clock_id,
 
 		thread_group_cputimer(tsk, &cputime);
 		if (clock_id == CPUCLOCK_PROF)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			t = cputime.utime + cputime.stime;
+}
 		else
 			/* CPUCLOCK_VIRT */
 			t = cputime.utime;
@@ -82,6 +90,7 @@ static void get_cpu_itimer(struct task_struct *tsk, unsigned int clock_id,
 
 int do_getitimer(int which, struct itimerval *value)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct task_struct *tsk = current;
 
 	switch (which) {
@@ -105,11 +114,12 @@ int do_getitimer(int which, struct itimerval *value)
 }
 
 SYSCALL_DEFINE2(getitimer, int, which, struct itimerval __user *, value)
-{
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	int error = -EFAULT;
 	struct itimerval get_buffer;
 
 	if (value) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		error = do_getitimer(which, &get_buffer);
 		if (!error &&
 		    copy_to_user(value, &get_buffer, sizeof(get_buffer)))
@@ -125,6 +135,7 @@ COMPAT_SYSCALL_DEFINE2(getitimer, int, which,
 	struct itimerval kit;
 	int error = do_getitimer(which, &kit);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!error && put_compat_itimerval(it, &kit))
 		error = -EFAULT;
 	return error;
@@ -164,6 +175,7 @@ static void set_cpu_itimer(struct task_struct *tsk, unsigned int clock_id,
 
 	oval = it->expires;
 	ointerval = it->incr;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (oval || nval) {
 		if (nval > 0)
 			nval += TICK_NSEC;
@@ -190,6 +202,7 @@ static void set_cpu_itimer(struct task_struct *tsk, unsigned int clock_id,
 
 int do_setitimer(int which, struct itimerval *value, struct itimerval *ovalue)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct task_struct *tsk = current;
 	struct hrtimer *timer;
 	ktime_t expires;
@@ -213,6 +226,7 @@ int do_setitimer(int which, struct itimerval *value, struct itimerval *ovalue)
 		}
 		/* We are sharing ->siglock with it_real_fn() */
 		if (hrtimer_try_to_cancel(timer) < 0) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			spin_unlock_irq(&tsk->sighand->siglock);
 			goto again;
 		}
@@ -236,6 +250,7 @@ int do_setitimer(int which, struct itimerval *value, struct itimerval *ovalue)
 	default:
 		return -EINVAL;
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
@@ -299,6 +314,7 @@ SYSCALL_DEFINE3(setitimer, int, which, struct itimerval __user *, value,
 		if(copy_from_user(&set_buffer, value, sizeof(set_buffer)))
 			return -EFAULT;
 	} else {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		memset(&set_buffer, 0, sizeof(set_buffer));
 		printk_once(KERN_WARNING "%s calls setitimer() with new_value NULL pointer."
 			    " Misfeature support will be removed\n",
@@ -307,10 +323,14 @@ SYSCALL_DEFINE3(setitimer, int, which, struct itimerval __user *, value,
 
 	error = do_setitimer(which, &set_buffer, ovalue ? &get_buffer : NULL);
 	if (error || !ovalue)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return error;
+}
 
 	if (copy_to_user(ovalue, &get_buffer, sizeof(get_buffer)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EFAULT;
+}
 	return 0;
 }
 
@@ -323,6 +343,7 @@ COMPAT_SYSCALL_DEFINE3(setitimer, int, which,
 	int error;
 
 	if (in) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (get_compat_itimerval(&kin, in))
 			return -EFAULT;
 	} else {
diff --git a/kernel/time/jiffies.c b/kernel/time/jiffies.c
index 4977191..2a2b745 100644
--- a/kernel/time/jiffies.c
+++ b/kernel/time/jiffies.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /***********************************************************************
 * linux/kernel/time/jiffies.c
 *
diff --git a/kernel/time/ntp.c b/kernel/time/ntp.c
index 99e03be..dc50a94 100644
--- a/kernel/time/ntp.c
+++ b/kernel/time/ntp.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 /*
  * NTP state machine interfaces and logic.
@@ -218,6 +220,7 @@ static inline void pps_set_freq(s64 freq) {}
 
 static inline int is_error_status(int status)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return status & (STA_UNSYNC|STA_CLOCKERR);
 }
 
@@ -243,6 +246,7 @@ static inline void pps_fill_timex(struct timex *txc)
  */
 static inline int ntp_synced(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return !(time_status & STA_UNSYNC);
 }
 
@@ -279,6 +283,7 @@ static void ntp_update_frequency(void)
 
 static inline s64 ntp_update_offset_fll(s64 offset64, long secs)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	time_status &= ~STA_MODE;
 
 	if (secs < MINSEC)
@@ -299,7 +304,9 @@ static void ntp_update_offset(long offset)
 	long secs;
 
 	if (!(time_status & STA_PLL))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	if (!(time_status & STA_NANO)) {
 		/* Make sure the multiplication below won't overflow */
@@ -381,7 +388,10 @@ ktime_t ntp_get_next_leap(void)
 	ktime_t ret;
 
 	if ((time_state == TIME_INS) && (time_status & STA_INS))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ktime_set(ntp_next_leap_sec, 0);
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	ret = KTIME_MAX;
 	return ret;
 }
@@ -410,10 +420,12 @@ int second_overflow(time64_t secs)
 	switch (time_state) {
 	case TIME_OK:
 		if (time_status & STA_INS) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			time_state = TIME_INS;
 			div_s64_rem(secs, SECS_PER_DAY, &rem);
 			ntp_next_leap_sec = secs + SECS_PER_DAY - rem;
 		} else if (time_status & STA_DEL) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			time_state = TIME_DEL;
 			div_s64_rem(secs + 1, SECS_PER_DAY, &rem);
 			ntp_next_leap_sec = secs + SECS_PER_DAY - rem;
@@ -421,9 +433,11 @@ int second_overflow(time64_t secs)
 		break;
 	case TIME_INS:
 		if (!(time_status & STA_INS)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			ntp_next_leap_sec = TIME64_MAX;
 			time_state = TIME_OK;
 		} else if (secs == ntp_next_leap_sec) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			leap = -1;
 			time_state = TIME_OOP;
 			printk(KERN_NOTICE
@@ -432,9 +446,11 @@ int second_overflow(time64_t secs)
 		break;
 	case TIME_DEL:
 		if (!(time_status & STA_DEL)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			ntp_next_leap_sec = TIME64_MAX;
 			time_state = TIME_OK;
 		} else if (secs == ntp_next_leap_sec) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			leap = 1;
 			ntp_next_leap_sec = TIME64_MAX;
 			time_state = TIME_WAIT;
@@ -448,7 +464,9 @@ int second_overflow(time64_t secs)
 		break;
 	case TIME_WAIT:
 		if (!(time_status & (STA_INS | STA_DEL)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			time_state = TIME_OK;
+}
 		break;
 	}
 
@@ -473,18 +491,23 @@ int second_overflow(time64_t secs)
 	if (!time_adjust)
 		goto out;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (time_adjust > MAX_TICKADJ) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		time_adjust -= MAX_TICKADJ;
 		tick_length += MAX_TICKADJ_SCALED;
 		goto out;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (time_adjust < -MAX_TICKADJ) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		time_adjust += MAX_TICKADJ;
 		tick_length -= MAX_TICKADJ_SCALED;
 		goto out;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	tick_length += (s64)(time_adjust * NSEC_PER_USEC / NTP_INTERVAL_FREQ)
 							 << NTP_SCALE_SHIFT;
 	time_adjust = 0;
@@ -496,6 +519,7 @@ int second_overflow(time64_t secs)
 #ifdef CONFIG_GENERIC_CMOS_UPDATE
 int __weak update_persistent_clock(struct timespec now)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return -ENODEV;
 }
 
@@ -571,6 +595,7 @@ static void sync_cmos_clock(struct work_struct *work)
 
 void ntp_notify_cmos_timer(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	queue_delayed_work(system_power_efficient_wq, &sync_cmos_work, 0);
 }
 
@@ -584,6 +609,7 @@ void ntp_notify_cmos_timer(void) { }
  */
 static inline void process_adj_status(struct timex *txc, struct timespec64 *ts)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if ((time_status & STA_PLL) && !(txc->status & STA_PLL)) {
 		time_state = TIME_OK;
 		time_status = STA_UNSYNC;
@@ -609,6 +635,7 @@ static inline void process_adjtimex_modes(struct timex *txc,
 						struct timespec64 *ts,
 						s32 *time_tai)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (txc->modes & ADJ_STATUS)
 		process_adj_status(txc, ts);
 
@@ -660,6 +687,7 @@ static inline void process_adjtimex_modes(struct timex *txc,
  */
 int ntp_validate_timex(struct timex *txc)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (txc->modes & ADJ_ADJTIME) {
 		/* singleshot must not be used with any other mode bits */
 		if (!(txc->modes & ADJ_OFFSET_SINGLESHOT))
@@ -1023,6 +1051,7 @@ void __hardpps(const struct timespec64 *phase_ts, const struct timespec64 *raw_t
 
 static int __init ntp_tick_adj_setup(char *str)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	int rc = kstrtol(str, 0, (long *)&ntp_tick_adj);
 
 	if (rc)
diff --git a/kernel/time/posix-cpu-timers.c b/kernel/time/posix-cpu-timers.c
index 5b11711..416dc70 100644
--- a/kernel/time/posix-cpu-timers.c
+++ b/kernel/time/posix-cpu-timers.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 /*
  * Implement CPU time clocks for the POSIX clock interface.
@@ -41,17 +43,24 @@ static int check_clock(const clockid_t which_clock)
 	const pid_t pid = CPUCLOCK_PID(which_clock);
 
 	if (CPUCLOCK_WHICH(which_clock) >= CPUCLOCK_MAX)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	if (pid == 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rcu_read_lock();
 	p = find_task_by_vpid(pid);
 	if (!p || !(CPUCLOCK_PERTHREAD(which_clock) ?
 		   same_thread_group(p, current) : has_group_leader_pid(p))) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		error = -EINVAL;
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rcu_read_unlock();
 
 	return error;
@@ -67,7 +76,9 @@ static void bump_cpu_timer(struct k_itimer *timer, u64 now)
 	u64 delta, incr;
 
 	if (timer->it.cpu.incr == 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	if (now < timer->it.cpu.expires)
 		return;
@@ -100,7 +111,10 @@ static void bump_cpu_timer(struct k_itimer *timer, u64 now)
 static inline int task_cputime_zero(const struct task_cputime *cputime)
 {
 	if (!cputime->utime && !cputime->stime && !cputime->sum_exec_runtime)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 1;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
@@ -174,6 +188,7 @@ static int cpu_clock_sample(const clockid_t which_clock,
 		*sample = task_sched_runtime(p);
 		break;
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
@@ -194,6 +209,7 @@ static inline void __update_gt_cputime(atomic64_t *cputime, u64 sum_cputime)
 
 static void update_gt_cputime(struct task_cputime_atomic *cputime_atomic, struct task_cputime *sum)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	__update_gt_cputime(&cputime_atomic->utime, sum->utime);
 	__update_gt_cputime(&cputime_atomic->stime, sum->stime);
 	__update_gt_cputime(&cputime_atomic->sum_exec_runtime, sum->sum_exec_runtime);
@@ -203,6 +219,7 @@ static void update_gt_cputime(struct task_cputime_atomic *cputime_atomic, struct
 static inline void sample_cputime_atomic(struct task_cputime *times,
 					 struct task_cputime_atomic *atomic_times)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	times->utime = atomic64_read(&atomic_times->utime);
 	times->stime = atomic64_read(&atomic_times->stime);
 	times->sum_exec_runtime = atomic64_read(&atomic_times->sum_exec_runtime);
@@ -262,6 +279,7 @@ static int cpu_clock_sample_group(const clockid_t which_clock,
 		*sample = cputime.sum_exec_runtime;
 		break;
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
@@ -308,6 +326,7 @@ static int posix_cpu_clock_get(const clockid_t which_clock, struct timespec64 *t
 		p = find_task_by_vpid(pid);
 		if (p)
 			err = posix_cpu_clock_get_task(p, which_clock, tp);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		rcu_read_unlock();
 	}
 
@@ -326,7 +345,9 @@ static int posix_cpu_timer_create(struct k_itimer *new_timer)
 	struct task_struct *p;
 
 	if (CPUCLOCK_WHICH(new_timer->it_clock) >= CPUCLOCK_MAX)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	new_timer->kclock = &clock_posix_cpu;
 
@@ -374,6 +395,7 @@ static int posix_cpu_timer_del(struct k_itimer *timer)
 	struct sighand_struct *sighand;
 	struct task_struct *p = timer->it.cpu.task;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WARN_ON_ONCE(p == NULL);
 
 	/*
@@ -439,6 +461,7 @@ void posix_cpu_timers_exit_group(struct task_struct *tsk)
 
 static inline int expires_gt(u64 expires, u64 new_exp)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return expires == 0 || expires > new_exp;
 }
 
@@ -455,6 +478,7 @@ static void arm_timer(struct k_itimer *timer)
 	struct cpu_timer_list *next;
 
 	if (CPUCLOCK_PERTHREAD(timer->it_clock)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		head = p->cpu_timers;
 		cputime_expires = &p->cputime_expires;
 	} else {
@@ -507,6 +531,7 @@ static void arm_timer(struct k_itimer *timer)
  */
 static void cpu_timer_fire(struct k_itimer *timer)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if ((timer->it_sigev_notify & ~SIGEV_THREAD_ID) == SIGEV_NONE) {
 		/*
 		 * User don't want any signal.
@@ -579,6 +604,7 @@ static int posix_cpu_timer_set(struct k_itimer *timer, int timer_flags,
 	u64 old_expires, new_expires, old_incr, val;
 	int ret;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WARN_ON_ONCE(p == NULL);
 
 	/*
@@ -718,6 +744,7 @@ static void posix_cpu_timer_get(struct k_itimer *timer, struct itimerspec64 *itp
 	u64 now;
 	struct task_struct *p = timer->it.cpu.task;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WARN_ON_ONCE(p == NULL);
 
 	/*
@@ -776,6 +803,7 @@ check_timers_list(struct list_head *timers,
 {
 	int maxfire = 20;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	while (!list_empty(timers)) {
 		struct cpu_timer_list *t;
 
@@ -809,7 +837,9 @@ static void check_thread_timers(struct task_struct *tsk,
 	 * per thread CPU timers.
 	 */
 	if (task_cputime_zero(&tsk->cputime_expires))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	expires = check_timers_list(timers, firing, prof_ticks(tsk));
 	tsk_expires->prof_exp = expires;
@@ -872,6 +902,7 @@ static inline void stop_process_timers(struct signal_struct *sig)
 static void check_cpu_itimer(struct task_struct *tsk, struct cpu_itimer *it,
 			     u64 *expires, u64 cur_time, int signo)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!it->expires)
 		return;
 
@@ -994,6 +1025,7 @@ static void posix_cpu_timer_rearm(struct k_itimer *timer)
 	struct task_struct *p = timer->it.cpu.task;
 	u64 now;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WARN_ON_ONCE(p == NULL);
 
 	/*
@@ -1053,6 +1085,7 @@ static void posix_cpu_timer_rearm(struct k_itimer *timer)
 static inline int task_cputime_expired(const struct task_cputime *sample,
 					const struct task_cputime *expires)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (expires->utime && sample->utime >= expires->utime)
 		return 1;
 	if (expires->stime && sample->utime + sample->stime >= expires->stime)
@@ -1083,7 +1116,9 @@ static inline int fastpath_timer_check(struct task_struct *tsk)
 		task_cputime(tsk, &task_sample.utime, &task_sample.stime);
 		task_sample.sum_exec_runtime = tsk->se.sum_exec_runtime;
 		if (task_cputime_expired(&task_sample, &tsk->cputime_expires))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return 1;
+}
 	}
 
 	sig = tsk->signal;
@@ -1108,9 +1143,12 @@ static inline int fastpath_timer_check(struct task_struct *tsk)
 		sample_cputime_atomic(&group_sample, &sig->cputimer.cputime_atomic);
 
 		if (task_cputime_expired(&group_sample, &sig->cputime_expires))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return 1;
+}
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
@@ -1134,8 +1172,11 @@ void run_posix_cpu_timers(struct task_struct *tsk)
 	if (!fastpath_timer_check(tsk))
 		return;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!lock_task_sighand(tsk, &flags))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 	/*
 	 * Here we take off tsk->signal->cpu_timers[N] and
 	 * tsk->cpu_timers[N] all the timers that are firing, and
@@ -1174,7 +1215,10 @@ void run_posix_cpu_timers(struct task_struct *tsk)
 		 * almost-firing as an overrun.  So don't generate an event.
 		 */
 		if (likely(cpu_firing >= 0))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			cpu_timer_fire(timer);
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		spin_unlock(&timer->it_lock);
 	}
 }
@@ -1188,6 +1232,7 @@ void set_process_cpu_timer(struct task_struct *tsk, unsigned int clock_idx,
 {
 	u64 now;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WARN_ON_ONCE(clock_idx == CPUCLOCK_SCHED);
 	cpu_timer_sample_group(clock_idx, tsk, &now);
 
@@ -1241,6 +1286,7 @@ static int do_cpu_nanosleep(const clockid_t which_clock, int flags,
 	 * Set up a temporary timer and then wait for it to go off.
 	 */
 	memset(&timer, 0, sizeof timer);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_lock_init(&timer.it_lock);
 	timer.it_clock = which_clock;
 	timer.it_overrun = -1;
@@ -1329,6 +1375,7 @@ static long posix_cpu_nsleep_restart(struct restart_block *restart_block);
 static int posix_cpu_nsleep(const clockid_t which_clock, int flags,
 			    const struct timespec64 *rqtp)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct restart_block *restart_block = &current->restart_block;
 	int error;
 
@@ -1369,6 +1416,7 @@ static long posix_cpu_nsleep_restart(struct restart_block *restart_block)
 static int process_cpu_clock_getres(const clockid_t which_clock,
 				    struct timespec64 *tp)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return posix_cpu_clock_getres(PROCESS_CLOCK, tp);
 }
 static int process_cpu_clock_get(const clockid_t which_clock,
@@ -1378,17 +1426,20 @@ static int process_cpu_clock_get(const clockid_t which_clock,
 }
 static int process_cpu_timer_create(struct k_itimer *timer)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	timer->it_clock = PROCESS_CLOCK;
 	return posix_cpu_timer_create(timer);
 }
 static int process_cpu_nsleep(const clockid_t which_clock, int flags,
 			      const struct timespec64 *rqtp)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return posix_cpu_nsleep(PROCESS_CLOCK, flags, rqtp);
 }
 static int thread_cpu_clock_getres(const clockid_t which_clock,
 				   struct timespec64 *tp)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return posix_cpu_clock_getres(THREAD_CLOCK, tp);
 }
 static int thread_cpu_clock_get(const clockid_t which_clock,
@@ -1398,6 +1449,7 @@ static int thread_cpu_clock_get(const clockid_t which_clock,
 }
 static int thread_cpu_timer_create(struct k_itimer *timer)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	timer->it_clock = THREAD_CLOCK;
 	return posix_cpu_timer_create(timer);
 }
diff --git a/kernel/time/posix-timers.c b/kernel/time/posix-timers.c
index ec999f3..44dca4a 100644
--- a/kernel/time/posix-timers.c
+++ b/kernel/time/posix-timers.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * linux/kernel/posix-timers.c
  *
@@ -1351,6 +1353,8 @@ static const struct k_clock *clockid_to_kclock(const clockid_t id)
 			&clock_posix_dynamic : &clock_posix_cpu;
 
 	if (id >= ARRAY_SIZE(posix_clocks) || !posix_clocks[id])
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 	return posix_clocks[id];
 }
diff --git a/kernel/time/tick-broadcast.c b/kernel/time/tick-broadcast.c
index b398c2e..dcac9d7 100644
--- a/kernel/time/tick-broadcast.c
+++ b/kernel/time/tick-broadcast.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * linux/kernel/time/tick-broadcast.c
  *
diff --git a/kernel/time/tick-common.c b/kernel/time/tick-common.c
index 49edc1c..3d9c6d2 100644
--- a/kernel/time/tick-common.c
+++ b/kernel/time/tick-common.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * linux/kernel/time/tick-common.c
  *
@@ -56,6 +58,7 @@ int tick_do_timer_cpu __read_mostly = TICK_DO_TIMER_BOOT;
  */
 struct tick_device *tick_get_device(int cpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return &per_cpu(tick_cpu_device, cpu);
 }
 
@@ -67,9 +70,13 @@ int tick_is_oneshot_available(void)
 	struct clock_event_device *dev = __this_cpu_read(tick_cpu_device.evtdev);
 
 	if (!dev || !(dev->features & CLOCK_EVT_FEAT_ONESHOT))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 	if (!(dev->features & CLOCK_EVT_FEAT_C3STOP))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 1;
+}
 	return tick_broadcast_oneshot_available();
 }
 
@@ -110,11 +117,15 @@ void tick_handle_periodic(struct clock_event_device *dev)
 	 * hrtimer_run_queues().
 	 */
 	if (dev->event_handler != tick_handle_periodic)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 #endif
 
 	if (!clockevent_state_oneshot(dev))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 	for (;;) {
 		/*
 		 * Setup the next period for devices, which do not have
@@ -123,7 +134,9 @@ void tick_handle_periodic(struct clock_event_device *dev)
 		next = ktime_add(next, tick_period);
 
 		if (!clockevents_program_event(dev, next, false))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return;
+}
 		/*
 		 * Have to be careful here. If we're in oneshot mode,
 		 * before we call tick_periodic() in a loop, we need
@@ -134,7 +147,9 @@ void tick_handle_periodic(struct clock_event_device *dev)
 		 * the loop to trigger again and again.
 		 */
 		if (timekeeping_valid_for_hres())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			tick_periodic(cpu);
+}
 	}
 }
 
@@ -147,7 +162,9 @@ void tick_setup_periodic(struct clock_event_device *dev, int broadcast)
 
 	/* Broadcast setup ? */
 	if (!tick_device_is_functional(dev))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	if ((dev->features & CLOCK_EVT_FEAT_PERIODIC) &&
 	    !tick_broadcast_oneshot_active()) {
@@ -157,15 +174,22 @@ void tick_setup_periodic(struct clock_event_device *dev, int broadcast)
 		ktime_t next;
 
 		do {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			seq = read_seqbegin(&jiffies_lock);
 			next = tick_next_period;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		} while (read_seqretry(&jiffies_lock, seq));
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		clockevents_switch_state(dev, CLOCK_EVT_STATE_ONESHOT);
 
 		for (;;) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			if (!clockevents_program_event(dev, next, false))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				return;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			next = ktime_add(next, tick_period);
 		}
 	}
@@ -190,6 +214,7 @@ static void tick_setup_device(struct tick_device *td,
 		 * this cpu:
 		 */
 		if (tick_do_timer_cpu == TICK_DO_TIMER_BOOT) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			if (!tick_nohz_full_cpu(cpu))
 				tick_do_timer_cpu = cpu;
 			else
@@ -215,7 +240,9 @@ static void tick_setup_device(struct tick_device *td,
 	 * current cpu:
 	 */
 	if (!cpumask_equal(newdev->cpumask, cpumask))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		irq_set_affinity(newdev->irq, cpumask);
+}
 
 	/*
 	 * When global broadcasting is active, check if the current
@@ -225,7 +252,9 @@ static void tick_setup_device(struct tick_device *td,
 	 * current active broadcast state for this CPU.
 	 */
 	if (tick_device_uses_broadcast(newdev, cpu))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	if (td->mode == TICKDEV_MODE_PERIODIC)
 		tick_setup_periodic(newdev, 0);
@@ -235,6 +264,7 @@ static void tick_setup_device(struct tick_device *td,
 
 void tick_install_replacement(struct clock_event_device *newdev)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct tick_device *td = this_cpu_ptr(&tick_cpu_device);
 	int cpu = smp_processor_id();
 
@@ -248,15 +278,24 @@ static bool tick_check_percpu(struct clock_event_device *curdev,
 			      struct clock_event_device *newdev, int cpu)
 {
 	if (!cpumask_test_cpu(cpu, newdev->cpumask))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return false;
+}
 	if (cpumask_equal(newdev->cpumask, cpumask_of(cpu)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return true;
+}
 	/* Check if irq affinity can be set */
 	if (newdev->irq >= 0 && !irq_can_set_affinity(newdev->irq))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return false;
+}
 	/* Prefer an existing cpu local device */
 	if (curdev && cpumask_equal(curdev->cpumask, cpumask_of(cpu)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return false;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return true;
 }
 
@@ -265,10 +304,16 @@ static bool tick_check_preferred(struct clock_event_device *curdev,
 {
 	/* Prefer oneshot capable device */
 	if (!(newdev->features & CLOCK_EVT_FEAT_ONESHOT)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (curdev && (curdev->features & CLOCK_EVT_FEAT_ONESHOT))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return false;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (tick_oneshot_mode_active())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return false;
+}
 	}
 
 	/*
@@ -287,6 +332,7 @@ static bool tick_check_preferred(struct clock_event_device *curdev,
 bool tick_check_replacement(struct clock_event_device *curdev,
 			    struct clock_event_device *newdev)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!tick_check_percpu(curdev, newdev, smp_processor_id()))
 		return false;
 
@@ -316,7 +362,9 @@ void tick_check_new_device(struct clock_event_device *newdev)
 		goto out_bc;
 
 	if (!try_module_get(newdev->owner))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	/*
 	 * Replace the eventually existing device by the new
@@ -324,6 +372,7 @@ void tick_check_new_device(struct clock_event_device *newdev)
 	 * not give it back to the clockevents layer !
 	 */
 	if (tick_is_broadcast_device(curdev)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		clockevents_shutdown(curdev);
 		curdev = NULL;
 	}
@@ -331,6 +380,7 @@ void tick_check_new_device(struct clock_event_device *newdev)
 	tick_setup_device(td, newdev, cpu, cpumask_of(cpu));
 	if (newdev->features & CLOCK_EVT_FEAT_ONESHOT)
 		tick_oneshot_notify();
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return;
 
 out_bc:
@@ -353,6 +403,7 @@ void tick_check_new_device(struct clock_event_device *newdev)
  */
 int tick_broadcast_oneshot_control(enum tick_broadcast_state state)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct tick_device *td = this_cpu_ptr(&tick_cpu_device);
 
 	if (!(td->evtdev->features & CLOCK_EVT_FEAT_C3STOP))
@@ -371,6 +422,7 @@ EXPORT_SYMBOL_GPL(tick_broadcast_oneshot_control);
  */
 void tick_handover_do_timer(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (tick_do_timer_cpu == smp_processor_id()) {
 		int cpu = cpumask_first(cpu_online_mask);
 
@@ -388,6 +440,7 @@ void tick_handover_do_timer(void)
  */
 void tick_shutdown(unsigned int cpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct tick_device *td = &per_cpu(tick_cpu_device, cpu);
 	struct clock_event_device *dev = td->evtdev;
 
@@ -414,6 +467,7 @@ void tick_shutdown(unsigned int cpu)
  */
 void tick_suspend_local(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct tick_device *td = this_cpu_ptr(&tick_cpu_device);
 
 	clockevents_shutdown(td->evtdev);
@@ -428,6 +482,7 @@ void tick_suspend_local(void)
  */
 void tick_resume_local(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct tick_device *td = this_cpu_ptr(&tick_cpu_device);
 	bool broadcast = tick_resume_check_broadcast();
 
@@ -451,6 +506,7 @@ void tick_resume_local(void)
  */
 void tick_suspend(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	tick_suspend_local();
 	tick_suspend_broadcast();
 }
@@ -465,6 +521,7 @@ void tick_suspend(void)
  */
 void tick_resume(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	tick_resume_broadcast();
 	tick_resume_local();
 }
@@ -484,6 +541,7 @@ static unsigned int tick_freeze_depth;
  */
 void tick_freeze(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	raw_spin_lock(&tick_freeze_lock);
 
 	tick_freeze_depth++;
@@ -509,6 +567,7 @@ void tick_freeze(void)
  */
 void tick_unfreeze(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	raw_spin_lock(&tick_freeze_lock);
 
 	if (tick_freeze_depth == num_online_cpus()) {
diff --git a/kernel/time/tick-internal.h b/kernel/time/tick-internal.h
index f8e1845..7bdf2c3 100644
--- a/kernel/time/tick-internal.h
+++ b/kernel/time/tick-internal.h
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /* SPDX-License-Identifier: GPL-2.0 */
 /*
  * tick internal variable and functions used by low/high res code
diff --git a/kernel/time/tick-oneshot.c b/kernel/time/tick-oneshot.c
index 6b009c2..ea94951 100644
--- a/kernel/time/tick-oneshot.c
+++ b/kernel/time/tick-oneshot.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * linux/kernel/time/tick-oneshot.c
  *
@@ -52,6 +54,7 @@ int tick_program_event(ktime_t expires, int force)
  */
 void tick_resume_oneshot(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct clock_event_device *dev = __this_cpu_read(tick_cpu_device.evtdev);
 
 	clockevents_switch_state(dev, CLOCK_EVT_STATE_ONESHOT);
@@ -65,6 +68,7 @@ void tick_setup_oneshot(struct clock_event_device *newdev,
 			void (*handler)(struct clock_event_device *),
 			ktime_t next_event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	newdev->event_handler = handler;
 	clockevents_switch_state(newdev, CLOCK_EVT_STATE_ONESHOT);
 	clockevents_program_event(newdev, next_event, true);
@@ -81,17 +85,23 @@ int tick_switch_to_oneshot(void (*handler)(struct clock_event_device *))
 	if (!dev || !(dev->features & CLOCK_EVT_FEAT_ONESHOT) ||
 		    !tick_device_is_functional(dev)) {
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		printk(KERN_INFO "Clockevents: "
 		       "could not switch to one-shot mode:");
 		if (!dev) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			printk(" no tick device\n");
 		} else {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			if (!tick_device_is_functional(dev))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				printk(" %s is not functional.\n", dev->name);
+}
 			else
 				printk(" %s does not support one-shot mode.\n",
 				       dev->name);
 		}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
 	}
 
diff --git a/kernel/time/tick-sched.c b/kernel/time/tick-sched.c
index dfa4a11..4d77d2e 100644
--- a/kernel/time/tick-sched.c
+++ b/kernel/time/tick-sched.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  *  linux/kernel/time/tick-sched.c
  *
@@ -41,6 +43,7 @@ static DEFINE_PER_CPU(struct tick_sched, tick_cpu_sched);
 
 struct tick_sched *tick_get_tick_sched(int cpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return &per_cpu(tick_cpu_sched, cpu);
 }
 
@@ -63,7 +66,9 @@ static void tick_do_update_jiffies64(ktime_t now)
 	 */
 	delta = ktime_sub(now, last_jiffies_update);
 	if (delta < tick_period)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	/* Reevaluate with jiffies_lock held */
 	write_seqlock(&jiffies_lock);
@@ -89,6 +94,7 @@ static void tick_do_update_jiffies64(ktime_t now)
 		/* Keep the tick_next_period variable up to date */
 		tick_next_period = ktime_add(last_jiffies_update, tick_period);
 	} else {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		write_sequnlock(&jiffies_lock);
 		return;
 	}
@@ -500,6 +506,7 @@ unsigned long tick_nohz_active  __read_mostly;
  */
 static int __init setup_tick_nohz(char *str)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return (kstrtobool(str, &tick_nohz_enabled) == 0);
 }
 
@@ -551,7 +558,9 @@ update_ts_time_stats(int cpu, struct tick_sched *ts, ktime_t now, u64 *last_upda
 	}
 
 	if (last_update_time)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		*last_update_time = ktime_to_us(now);
+}
 
 }
 
@@ -593,10 +602,13 @@ u64 get_cpu_idle_time_us(int cpu, u64 *last_update_time)
 	ktime_t now, idle;
 
 	if (!tick_nohz_active)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -1;
+}
 
 	now = ktime_get();
 	if (last_update_time) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		update_ts_time_stats(cpu, ts, now, last_update_time);
 		idle = ts->idle_sleeptime;
 	} else {
@@ -634,10 +646,13 @@ u64 get_cpu_iowait_time_us(int cpu, u64 *last_update_time)
 	ktime_t now, iowait;
 
 	if (!tick_nohz_active)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -1;
+}
 
 	now = ktime_get();
 	if (last_update_time) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		update_ts_time_stats(cpu, ts, now, last_update_time);
 		iowait = ts->iowait_sleeptime;
 	} else {
@@ -689,6 +704,7 @@ static ktime_t tick_nohz_stop_sched_tick(struct tick_sched *ts,
 
 	/* Read jiffies and the time when jiffies were updated last */
 	do {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		seq = read_seqbegin(&jiffies_lock);
 		basemono = last_jiffies_update;
 		basejiff = jiffies;
@@ -738,6 +754,7 @@ static ktime_t tick_nohz_stop_sched_tick(struct tick_sched *ts,
 		 * next period, so no point in stopping it either, bail.
 		 */
 		if (!ts->tick_stopped) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			tick = 0;
 			goto out;
 		}
@@ -759,9 +776,11 @@ static ktime_t tick_nohz_stop_sched_tick(struct tick_sched *ts,
 		tick_do_timer_cpu = TICK_DO_TIMER_NONE;
 		ts->do_timer_last = 1;
 	} else if (tick_do_timer_cpu != TICK_DO_TIMER_NONE) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		delta = KTIME_MAX;
 		ts->do_timer_last = 0;
 	} else if (!ts->do_timer_last) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		delta = KTIME_MAX;
 	}
 
@@ -786,7 +805,9 @@ static ktime_t tick_nohz_stop_sched_tick(struct tick_sched *ts,
 		if (tick == KTIME_MAX || ts->next_tick == hrtimer_get_expires(&ts->sched_timer))
 			goto out;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		WARN_ON_ONCE(1);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		printk_once("basemono: %llu ts->next_tick: %llu dev->next_event: %llu timer->active: %d timer->expires: %llu\n",
 			    basemono, ts->next_tick, dev->next_event,
 			    hrtimer_active(&ts->sched_timer), hrtimer_get_expires(&ts->sched_timer));
@@ -815,8 +836,11 @@ static ktime_t tick_nohz_stop_sched_tick(struct tick_sched *ts,
 	 * the tick timer.
 	 */
 	if (unlikely(expires == KTIME_MAX)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (ts->nohz_mode == NOHZ_MODE_HIGHRES)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			hrtimer_cancel(&ts->sched_timer);
+}
 		goto out;
 	}
 
@@ -886,8 +910,11 @@ static bool can_stop_idle_tick(int cpu, struct tick_sched *ts)
 	 * invoked.
 	 */
 	if (unlikely(!cpu_online(cpu))) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (cpu == tick_do_timer_cpu)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			tick_do_timer_cpu = TICK_DO_TIMER_NONE;
+}
 		/*
 		 * Make sure the CPU doesn't get fooled by obsolete tick
 		 * deadline if it comes back online later.
@@ -897,40 +924,51 @@ static bool can_stop_idle_tick(int cpu, struct tick_sched *ts)
 	}
 
 	if (unlikely(ts->nohz_mode == NOHZ_MODE_INACTIVE)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ts->sleep_length = NSEC_PER_SEC / HZ;
 		return false;
 	}
 
 	if (need_resched())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return false;
+}
 
 	if (unlikely(local_softirq_pending() && cpu_online(cpu))) {
 		static int ratelimit;
 
 		if (ratelimit < 10 &&
 		    (local_softirq_pending() & SOFTIRQ_STOP_IDLE_MASK)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			pr_warn("NOHZ: local_softirq_pending %02x\n",
 				(unsigned int) local_softirq_pending());
 			ratelimit++;
 		}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return false;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (tick_nohz_full_enabled()) {
 		/*
 		 * Keep the tick alive to guarantee timekeeping progression
 		 * if there are full dynticks CPUs around
 		 */
 		if (tick_do_timer_cpu == cpu)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return false;
+}
 		/*
 		 * Boot safety: make sure the timekeeping duty has been
 		 * assigned before entering dyntick-idle mode,
 		 */
 		if (tick_do_timer_cpu == TICK_DO_TIMER_NONE)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return false;
+}
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return true;
 }
 
@@ -1019,6 +1057,7 @@ void tick_nohz_irq_exit(void)
  */
 ktime_t tick_nohz_get_sleep_length(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct tick_sched *ts = this_cpu_ptr(&tick_cpu_sched);
 
 	return ts->sleep_length;
@@ -1032,6 +1071,7 @@ ktime_t tick_nohz_get_sleep_length(void)
  */
 unsigned long tick_nohz_get_idle_calls_cpu(int cpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct tick_sched *ts = tick_get_tick_sched(cpu);
 
 	return ts->idle_calls;
@@ -1044,6 +1084,7 @@ unsigned long tick_nohz_get_idle_calls_cpu(int cpu)
  */
 unsigned long tick_nohz_get_idle_calls(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct tick_sched *ts = this_cpu_ptr(&tick_cpu_sched);
 
 	return ts->idle_calls;
@@ -1055,7 +1096,9 @@ static void tick_nohz_account_idle_ticks(struct tick_sched *ts)
 	unsigned long ticks;
 
 	if (vtime_accounting_cpu_enabled())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 	/*
 	 * We stopped the tick in idle. Update process times would miss the
 	 * time we slept as update_process_times does only a 1 tick
@@ -1107,6 +1150,7 @@ void tick_nohz_idle_exit(void)
  */
 static void tick_nohz_handler(struct clock_event_device *dev)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct tick_sched *ts = this_cpu_ptr(&tick_cpu_sched);
 	struct pt_regs *regs = get_irq_regs();
 	ktime_t now = ktime_get();
@@ -1127,7 +1171,9 @@ static void tick_nohz_handler(struct clock_event_device *dev)
 static inline void tick_nohz_activate(struct tick_sched *ts, int mode)
 {
 	if (!tick_nohz_enabled)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 	ts->nohz_mode = mode;
 	/* One update is enough */
 	if (!test_and_set_bit(0, &tick_nohz_active))
@@ -1139,6 +1185,7 @@ static inline void tick_nohz_activate(struct tick_sched *ts, int mode)
  */
 static void tick_nohz_switch_to_nohz(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct tick_sched *ts = this_cpu_ptr(&tick_cpu_sched);
 	ktime_t next;
 
@@ -1168,7 +1215,9 @@ static inline void tick_nohz_irq_enter(void)
 	ktime_t now;
 
 	if (!ts->idle_active && !ts->tick_stopped)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 	now = ktime_get();
 	if (ts->idle_active)
 		tick_nohz_stop_idle(ts, now);
diff --git a/kernel/time/time.c b/kernel/time/time.c
index 44a8c14..34c1bb3 100644
--- a/kernel/time/time.c
+++ b/kernel/time/time.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  *  linux/kernel/time.c
  *
@@ -67,9 +69,13 @@ SYSCALL_DEFINE1(time, time_t __user *, tloc)
 
 	if (tloc) {
 		if (put_user(i,tloc))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -EFAULT;
+}
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	force_successful_syscall_return();
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return i;
 }
 
@@ -81,12 +87,14 @@ SYSCALL_DEFINE1(time, time_t __user *, tloc)
  */
 
 SYSCALL_DEFINE1(stime, time_t __user *, tptr)
-{
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct timespec tv;
 	int err;
 
 	if (get_user(tv.tv_sec, tptr))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EFAULT;
+}
 
 	tv.tv_nsec = 0;
 
@@ -114,7 +122,9 @@ COMPAT_SYSCALL_DEFINE1(time, compat_time_t __user *, tloc)
 
 	if (tloc) {
 		if (put_user(i,tloc))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -EFAULT;
+}
 	}
 	force_successful_syscall_return();
 	return i;
@@ -126,7 +136,9 @@ COMPAT_SYSCALL_DEFINE1(stime, compat_time_t __user *, tptr)
 	int err;
 
 	if (get_user(tv.tv_sec, tptr))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EFAULT;
+}
 
 	tv.tv_nsec = 0;
 
@@ -143,17 +155,25 @@ COMPAT_SYSCALL_DEFINE1(stime, compat_time_t __user *, tptr)
 
 SYSCALL_DEFINE2(gettimeofday, struct timeval __user *, tv,
 		struct timezone __user *, tz)
-{
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (likely(tv != NULL)) {
 		struct timeval ktv;
 		do_gettimeofday(&ktv);
 		if (copy_to_user(tv, &ktv, sizeof(ktv)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -EFAULT;
+}
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (unlikely(tz != NULL)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (copy_to_user(tz, &sys_tz, sizeof(sys_tz)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -EFAULT;
+}
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
@@ -181,6 +201,7 @@ int persistent_clock_is_local;
  */
 static inline void warp_clock(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (sys_tz.tz_minuteswest != 0) {
 		struct timespec adjust;
 
@@ -208,27 +229,38 @@ int do_sys_settimeofday64(const struct timespec64 *tv, const struct timezone *tz
 	int error = 0;
 
 	if (tv && !timespec64_valid(tv))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	error = security_settime64(tv, tz);
 	if (error)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return error;
+}
 
 	if (tz) {
 		/* Verify we're witin the +-15 hrs range */
 		if (tz->tz_minuteswest > 15*60 || tz->tz_minuteswest < -15*60)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -EINVAL;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		sys_tz = *tz;
 		update_vsyscall_tz();
 		if (firsttime) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			firsttime = 0;
 			if (!tv)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				warp_clock();
+}
 		}
 	}
 	if (tv)
 		return do_settimeofday64(tv);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
@@ -241,17 +273,24 @@ SYSCALL_DEFINE2(settimeofday, struct timeval __user *, tv,
 
 	if (tv) {
 		if (copy_from_user(&user_tv, tv, sizeof(*tv)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -EFAULT;
+}
 
 		if (!timeval_valid(&user_tv))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -EINVAL;
+}
 
 		new_ts.tv_sec = user_tv.tv_sec;
 		new_ts.tv_nsec = user_tv.tv_usec * NSEC_PER_USEC;
 	}
 	if (tz) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (copy_from_user(&new_tz, tz, sizeof(*tz)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -EFAULT;
+}
 	}
 
 	return do_sys_settimeofday64(tv ? &new_ts : NULL, tz ? &new_tz : NULL);
@@ -261,6 +300,7 @@ SYSCALL_DEFINE2(settimeofday, struct timeval __user *, tv,
 COMPAT_SYSCALL_DEFINE2(gettimeofday, struct compat_timeval __user *, tv,
 		       struct timezone __user *, tz)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (tv) {
 		struct timeval ktv;
 
@@ -284,6 +324,7 @@ COMPAT_SYSCALL_DEFINE2(settimeofday, struct compat_timeval __user *, tv,
 	struct timezone new_tz;
 
 	if (tv) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (compat_get_timeval(&user_tv, tv))
 			return -EFAULT;
 		new_ts.tv_sec = user_tv.tv_sec;
@@ -308,7 +349,9 @@ SYSCALL_DEFINE1(adjtimex, struct timex __user *, txc_p)
 	 * may change
 	 */
 	if (copy_from_user(&txc, txc_p, sizeof(struct timex)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EFAULT;
+}
 	ret = do_adjtimex(&txc);
 	return copy_to_user(txc_p, &txc, sizeof(struct timex)) ? -EFAULT : ret;
 }
@@ -322,7 +365,9 @@ COMPAT_SYSCALL_DEFINE1(adjtimex, struct compat_timex __user *, utp)
 
 	err = compat_get_timex(&txc, utp);
 	if (err)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return err;
+}
 
 	ret = do_adjtimex(&txc);
 
@@ -390,10 +435,13 @@ struct timespec timespec_trunc(struct timespec t, unsigned gran)
 	if (gran == 1) {
 		/* nothing */
 	} else if (gran == NSEC_PER_SEC) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		t.tv_nsec = 0;
 	} else if (gran > 1 && gran < NSEC_PER_SEC) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		t.tv_nsec -= t.tv_nsec % gran;
 	} else {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		WARN(1, "illegal file time granularity: %u", gran);
 	}
 	return t;
@@ -491,8 +539,10 @@ struct timespec ns_to_timespec(const s64 nsec)
 	if (!nsec)
 		return (struct timespec) {0, 0};
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	ts.tv_sec = div_s64_rem(nsec, NSEC_PER_SEC, &rem);
 	if (unlikely(rem < 0)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ts.tv_sec--;
 		rem += NSEC_PER_SEC;
 	}
@@ -612,7 +662,9 @@ unsigned long __msecs_to_jiffies(const unsigned int m)
 	 * Negative value, means infinite timeout:
 	 */
 	if ((int)m < 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return MAX_JIFFY_OFFSET;
+}
 	return _msecs_to_jiffies(m);
 }
 EXPORT_SYMBOL(__msecs_to_jiffies);
@@ -620,7 +672,9 @@ EXPORT_SYMBOL(__msecs_to_jiffies);
 unsigned long __usecs_to_jiffies(const unsigned int u)
 {
 	if (u > jiffies_to_usecs(MAX_JIFFY_OFFSET))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return MAX_JIFFY_OFFSET;
+}
 	return _usecs_to_jiffies(u);
 }
 EXPORT_SYMBOL(__usecs_to_jiffies);
@@ -643,6 +697,7 @@ EXPORT_SYMBOL(__usecs_to_jiffies);
 static unsigned long
 __timespec64_to_jiffies(u64 sec, long nsec)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	nsec = nsec + TICK_NSEC - 1;
 
 	if (sec >= MAX_SEC_IN_JIFFIES){
@@ -658,12 +713,14 @@ __timespec64_to_jiffies(u64 sec, long nsec)
 static unsigned long
 __timespec_to_jiffies(unsigned long sec, long nsec)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return __timespec64_to_jiffies((u64)sec, nsec);
 }
 
 unsigned long
 timespec64_to_jiffies(const struct timespec64 *value)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return __timespec64_to_jiffies(value->tv_sec, value->tv_nsec);
 }
 EXPORT_SYMBOL(timespec64_to_jiffies);
@@ -701,6 +758,7 @@ EXPORT_SYMBOL(jiffies_to_timespec64);
 unsigned long
 timeval_to_jiffies(const struct timeval *value)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return __timespec_to_jiffies(value->tv_sec,
 				     value->tv_usec * NSEC_PER_USEC);
 }
@@ -740,8 +798,10 @@ EXPORT_SYMBOL(jiffies_to_clock_t);
 unsigned long clock_t_to_jiffies(unsigned long x)
 {
 #if (HZ % USER_HZ)==0
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (x >= ~0UL / (HZ / USER_HZ))
 		return ~0UL;
+}
 	return x * (HZ / USER_HZ);
 #else
 	/* Don't worry about loss of precision here .. */
@@ -848,6 +908,7 @@ EXPORT_SYMBOL(nsecs_to_jiffies64);
  */
 unsigned long nsecs_to_jiffies(u64 n)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return (unsigned long)nsecs_to_jiffies64(n);
 }
 EXPORT_SYMBOL_GPL(nsecs_to_jiffies);
@@ -864,6 +925,7 @@ struct timespec timespec_add_safe(const struct timespec lhs,
 	set_normalized_timespec(&res, lhs.tv_sec + rhs.tv_sec,
 				lhs.tv_nsec + rhs.tv_nsec);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (res.tv_sec < lhs.tv_sec || res.tv_sec < rhs.tv_sec)
 		res.tv_sec = TIME_T_MAX;
 
@@ -884,6 +946,7 @@ struct timespec64 timespec64_add_safe(const struct timespec64 lhs,
 			lhs.tv_nsec + rhs.tv_nsec);
 
 	if (unlikely(res.tv_sec < lhs.tv_sec || res.tv_sec < rhs.tv_sec)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		res.tv_sec = TIME64_MAX;
 		res.tv_nsec = 0;
 	}
@@ -899,7 +962,9 @@ int get_timespec64(struct timespec64 *ts,
 
 	ret = copy_from_user(&kts, uts, sizeof(kts));
 	if (ret)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EFAULT;
+}
 
 	ts->tv_sec = kts.tv_sec;
 	ts->tv_nsec = kts.tv_nsec;
@@ -926,7 +991,9 @@ int get_itimerspec64(struct itimerspec64 *it,
 
 	ret = get_timespec64(&it->it_interval, &uit->it_interval);
 	if (ret)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ret;
+}
 
 	ret = get_timespec64(&it->it_value, &uit->it_value);
 
@@ -941,7 +1008,9 @@ int put_itimerspec64(const struct itimerspec64 *it,
 
 	ret = put_timespec64(&it->it_interval, &uit->it_interval);
 	if (ret)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ret;
+}
 
 	ret = put_timespec64(&it->it_value, &uit->it_value);
 
diff --git a/kernel/time/timekeeping.c b/kernel/time/timekeeping.c
index 2cafb49..749319e 100644
--- a/kernel/time/timekeeping.c
+++ b/kernel/time/timekeeping.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  *  linux/kernel/time/timekeeping.c
  *
@@ -95,6 +97,7 @@ static void tk_set_xtime(struct timekeeper *tk, const struct timespec64 *ts)
 
 static void tk_xtime_add(struct timekeeper *tk, const struct timespec64 *ts)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	tk->xtime_sec += ts->tv_sec;
 	tk->tkr_mono.xtime_nsec += (u64)ts->tv_nsec << tk->tkr_mono.shift;
 	tk_normalize_xtime(tk);
@@ -119,6 +122,7 @@ static void tk_set_wall_to_mono(struct timekeeper *tk, struct timespec64 wtm)
 
 static inline void tk_update_sleep_time(struct timekeeper *tk, ktime_t delta)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	tk->offs_boot = ktime_add(tk->offs_boot, delta);
 }
 
@@ -276,8 +280,11 @@ static void tk_setup_internals(struct timekeeper *tk, struct clocksource *clock)
 	tmp += clock->mult/2;
 	do_div(tmp, clock->mult);
 	if (tmp == 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		tmp = 1;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	interval = (u64) tmp;
 	tk->cycle_interval = interval;
 
@@ -422,6 +429,7 @@ static __always_inline u64 __ktime_get_fast_ns(struct tk_fast *tkf)
 	u64 now;
 
 	do {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		seq = raw_read_seqcount_latch(&tkf->seq);
 		tkr = tkf->base + (seq & 0x01);
 		now = ktime_to_ns(tkr->base);
@@ -433,6 +441,7 @@ static __always_inline u64 __ktime_get_fast_ns(struct tk_fast *tkf)
 					tkr->mask));
 	} while (read_seqcount_retry(&tkf->seq, seq));
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return now;
 }
 
@@ -444,6 +453,7 @@ EXPORT_SYMBOL_GPL(ktime_get_mono_fast_ns);
 
 u64 ktime_get_raw_fast_ns(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return __ktime_get_fast_ns(&tk_fast_raw);
 }
 EXPORT_SYMBOL_GPL(ktime_get_raw_fast_ns);
@@ -482,6 +492,7 @@ static u64 cycles_at_suspend;
 
 static u64 dummy_clock_read(struct clocksource *cs)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return cycles_at_suspend;
 }
 
@@ -504,6 +515,7 @@ static void halt_fast_timekeeper(struct timekeeper *tk)
 	static struct tk_read_base tkr_dummy;
 	struct tk_read_base *tkr = &tk->tkr_mono;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	memcpy(&tkr_dummy, tkr, sizeof(tkr_dummy));
 	cycles_at_suspend = tk_clock_read(tkr);
 	tkr_dummy.clock = &dummy_clock;
@@ -570,6 +582,7 @@ int pvclock_gtod_register_notifier(struct notifier_block *nb)
 	unsigned long flags;
 	int ret;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	raw_spin_lock_irqsave(&timekeeper_lock, flags);
 	ret = raw_notifier_chain_register(&pvclock_gtod_chain, nb);
 	update_pvclock_gtod(tk, true);
@@ -588,6 +601,7 @@ int pvclock_gtod_unregister_notifier(struct notifier_block *nb)
 	unsigned long flags;
 	int ret;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	raw_spin_lock_irqsave(&timekeeper_lock, flags);
 	ret = raw_notifier_chain_unregister(&pvclock_gtod_chain, nb);
 	raw_spin_unlock_irqrestore(&timekeeper_lock, flags);
@@ -665,9 +679,11 @@ static void timekeeping_update(struct timekeeper *tk, unsigned int action)
 	 * timekeeper structure on the next update with stale data
 	 */
 	if (action & TK_MIRROR)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		memcpy(&shadow_timekeeper, &tk_core.timekeeper,
 		       sizeof(tk_core.timekeeper));
 }
+}
 
 /**
  * timekeeping_forward_now - update clock to the current time
@@ -713,6 +729,7 @@ int __getnstimeofday64(struct timespec64 *ts)
 	u64 nsecs;
 
 	do {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		seq = read_seqcount_begin(&tk_core.seq);
 
 		ts->tv_sec = tk->xtime_sec;
@@ -720,6 +737,7 @@ int __getnstimeofday64(struct timespec64 *ts)
 
 	} while (read_seqcount_retry(&tk_core.seq, seq));
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	ts->tv_nsec = 0;
 	timespec64_add_ns(ts, nsecs);
 
@@ -728,7 +746,9 @@ int __getnstimeofday64(struct timespec64 *ts)
 	 * the value, even in the face of the WARN_ON.
 	 */
 	if (unlikely(timekeeping_suspended))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EAGAIN;
+}
 	return 0;
 }
 EXPORT_SYMBOL(__getnstimeofday64);
@@ -755,6 +775,7 @@ ktime_t ktime_get(void)
 	WARN_ON(timekeeping_suspended);
 
 	do {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		seq = read_seqcount_begin(&tk_core.seq);
 		base = tk->tkr_mono.base;
 		nsecs = timekeeping_get_ns(&tk->tkr_mono);
@@ -771,6 +792,7 @@ u32 ktime_get_resolution_ns(void)
 	unsigned int seq;
 	u32 nsecs;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WARN_ON(timekeeping_suspended);
 
 	do {
@@ -798,6 +820,7 @@ ktime_t ktime_get_with_offset(enum tk_offsets offs)
 	WARN_ON(timekeeping_suspended);
 
 	do {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		seq = read_seqcount_begin(&tk_core.seq);
 		base = ktime_add(tk->tkr_mono.base, *offset);
 		nsecs = timekeeping_get_ns(&tk->tkr_mono);
@@ -821,6 +844,7 @@ ktime_t ktime_mono_to_any(ktime_t tmono, enum tk_offsets offs)
 	ktime_t tconv;
 
 	do {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		seq = read_seqcount_begin(&tk_core.seq);
 		tconv = ktime_add(tmono, *offset);
 	} while (read_seqcount_retry(&tk_core.seq, seq));
@@ -840,6 +864,7 @@ ktime_t ktime_get_raw(void)
 	u64 nsecs;
 
 	do {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		seq = read_seqcount_begin(&tk_core.seq);
 		base = tk->tkr_raw.base;
 		nsecs = timekeeping_get_ns(&tk->tkr_raw);
@@ -868,6 +893,7 @@ void ktime_get_ts64(struct timespec64 *ts)
 	WARN_ON(timekeeping_suspended);
 
 	do {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		seq = read_seqcount_begin(&tk_core.seq);
 		ts->tv_sec = tk->xtime_sec;
 		nsec = timekeeping_get_ns(&tk->tkr_mono);
@@ -894,6 +920,7 @@ time64_t ktime_get_seconds(void)
 {
 	struct timekeeper *tk = &tk_core.timekeeper;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WARN_ON(timekeeping_suspended);
 	return tk->ktime_sec;
 }
@@ -920,11 +947,14 @@ time64_t ktime_get_real_seconds(void)
 		return tk->xtime_sec;
 
 	do {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		seq = read_seqcount_begin(&tk_core.seq);
 		seconds = tk->xtime_sec;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	} while (read_seqcount_retry(&tk_core.seq, seq));
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return seconds;
 }
 EXPORT_SYMBOL_GPL(ktime_get_real_seconds);
@@ -955,6 +985,7 @@ void ktime_get_snapshot(struct system_time_snapshot *systime_snapshot)
 	u64 nsec_real;
 	u64 now;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WARN_ON_ONCE(timekeeping_suspended);
 
 	do {
@@ -1021,6 +1052,7 @@ static int adjust_historical_crosststamp(struct system_time_snapshot *history,
 	bool interp_forward;
 	int ret;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (total_history_cycles == 0 || partial_history_cycles == 0)
 		return 0;
 
@@ -1077,6 +1109,7 @@ static int adjust_historical_crosststamp(struct system_time_snapshot *history,
  */
 static bool cycle_between(u64 before, u64 test, u64 after)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (test > before && test < after)
 		return true;
 	if (test < before && before > after)
@@ -1115,6 +1148,7 @@ int get_device_system_crosststamp(int (*get_time_fn)
 	int ret;
 
 	do {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		seq = read_seqcount_begin(&tk_core.seq);
 		/*
 		 * Try to synchronously capture device time and a system
@@ -1226,9 +1260,12 @@ int do_settimeofday64(const struct timespec64 *ts)
 	int ret = 0;
 
 	if (!timespec64_valid_strict(ts))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	raw_spin_lock_irqsave(&timekeeper_lock, flags);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	write_seqcount_begin(&tk_core.seq);
 
 	timekeeping_forward_now(tk);
@@ -1238,6 +1275,7 @@ int do_settimeofday64(const struct timespec64 *ts)
 	ts_delta.tv_nsec = ts->tv_nsec - xt.tv_nsec;
 
 	if (timespec64_compare(&tk->wall_to_monotonic, &ts_delta) > 0) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ret = -EINVAL;
 		goto out;
 	}
@@ -1272,7 +1310,9 @@ int timekeeping_inject_offset(struct timespec *ts)
 	int ret = 0;
 
 	if (!timespec_inject_offset_valid(ts))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	ts64 = timespec_to_timespec64(*ts);
 
@@ -1311,6 +1351,7 @@ EXPORT_SYMBOL(timekeeping_inject_offset);
  */
 static void __timekeeping_set_tai_offset(struct timekeeper *tk, s32 tai_offset)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	tk->tai_offset = tai_offset;
 	tk->offs_tai = ktime_add(tk->offs_real, ktime_set(tai_offset, 0));
 }
@@ -1329,6 +1370,7 @@ static int change_clocksource(void *data)
 	new = (struct clocksource *) data;
 
 	raw_spin_lock_irqsave(&timekeeper_lock, flags);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	write_seqcount_begin(&tk_core.seq);
 
 	timekeeping_forward_now(tk);
@@ -1341,9 +1383,12 @@ static int change_clocksource(void *data)
 			old = tk->tkr_mono.clock;
 			tk_setup_internals(tk, new);
 			if (old->disable)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				old->disable(old);
+}
 			module_put(old->owner);
 		} else {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			module_put(new->owner);
 		}
 	}
@@ -1367,7 +1412,9 @@ int timekeeping_notify(struct clocksource *clock)
 	struct timekeeper *tk = &tk_core.timekeeper;
 
 	if (tk->tkr_mono.clock == clock)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 	stop_machine(change_clocksource, clock, NULL);
 	tick_clock_notify();
 	return tk->tkr_mono.clock == clock ? 0 : -1;
@@ -1386,6 +1433,7 @@ void getrawmonotonic64(struct timespec64 *ts)
 	u64 nsecs;
 
 	do {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		seq = read_seqcount_begin(&tk_core.seq);
 		ts->tv_sec = tk->raw_sec;
 		nsecs = timekeeping_get_ns(&tk->tkr_raw);
@@ -1408,6 +1456,7 @@ int timekeeping_valid_for_hres(void)
 	int ret;
 
 	do {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		seq = read_seqcount_begin(&tk_core.seq);
 
 		ret = tk->tkr_mono.clock->flags & CLOCK_SOURCE_VALID_FOR_HRES;
@@ -1427,6 +1476,7 @@ u64 timekeeping_max_deferment(void)
 	u64 ret;
 
 	do {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		seq = read_seqcount_begin(&tk_core.seq);
 
 		ret = tk->tkr_mono.clock->max_idle_ns;
@@ -1447,6 +1497,7 @@ u64 timekeeping_max_deferment(void)
  */
 void __weak read_persistent_clock(struct timespec *ts)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	ts->tv_sec = 0;
 	ts->tv_nsec = 0;
 }
@@ -1492,6 +1543,7 @@ void __init timekeeping_init(void)
 
 	read_persistent_clock64(&now);
 	if (!timespec64_valid_strict(&now)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_warn("WARNING: Persistent clock returned invalid value!\n"
 			"         Check your CMOS/BIOS settings.\n");
 		now.tv_sec = 0;
@@ -1501,6 +1553,7 @@ void __init timekeeping_init(void)
 
 	read_boot_clock64(&boot);
 	if (!timespec64_valid_strict(&boot)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_warn("WARNING: Boot clock returned invalid value!\n"
 			"         Check your CMOS/BIOS settings.\n");
 		boot.tv_sec = 0;
@@ -1508,12 +1561,15 @@ void __init timekeeping_init(void)
 	}
 
 	raw_spin_lock_irqsave(&timekeeper_lock, flags);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	write_seqcount_begin(&tk_core.seq);
 	ntp_init();
 
 	clock = clocksource_default_clock();
 	if (clock->enable)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		clock->enable(clock);
+}
 	tk_setup_internals(tk, clock);
 
 	tk_set_xtime(tk, &now);
@@ -1543,6 +1599,7 @@ static struct timespec64 timekeeping_suspend_time;
 static void __timekeeping_inject_sleeptime(struct timekeeper *tk,
 					   struct timespec64 *delta)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!timespec64_valid_strict(delta)) {
 		printk_deferred(KERN_WARNING
 				"__timekeeping_inject_sleeptime: Invalid "
@@ -1641,6 +1698,7 @@ void timekeeping_resume(void)
 	clockevents_resume();
 	clocksource_resume();
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	raw_spin_lock_irqsave(&timekeeper_lock, flags);
 	write_seqcount_begin(&tk_core.seq);
 
@@ -1771,6 +1829,7 @@ static __always_inline void timekeeping_apply_adjustment(struct timekeeper *tk,
 	s32 mult_adj = 1;
 
 	if (negative) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		mult_adj = -mult_adj;
 		interval = -interval;
 		offset  = -offset;
@@ -1858,7 +1917,9 @@ static __always_inline void timekeeping_freqadjust(struct timekeeper *tk,
 
 	/* Remove any current error adj from freq calculation */
 	if (tk->ntp_err_mult)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		xinterval -= tk->cycle_interval;
+}
 
 	tk->ntp_tick = ntp_tick_length();
 
@@ -1868,32 +1929,43 @@ static __always_inline void timekeeping_freqadjust(struct timekeeper *tk,
 
 	/* Don't worry about correcting it if its small */
 	if (likely((tick_error >= 0) && (tick_error <= interval)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	/* preserve the direction of correction */
 	negative = (tick_error < 0);
 
 	/* If any adjustment would pass the max, just return */
 	if (negative && (cur_adj - 1) <= (base - max))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!negative && (cur_adj + 1) >= (base + max))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 	/*
 	 * Sort out the magnitude of the correction, but
 	 * avoid making so large a correction that we go
 	 * over the max adjustment.
 	 */
 	adj_scale = 0;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	tick_error = abs(tick_error);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	while (tick_error > interval) {
 		u32 adj = 1 << (adj_scale + 1);
 
 		/* Check if adjustment gets us within 1 unit from the max */
 		if (negative && (cur_adj - adj) <= (base - max))
 			break;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (!negative && (cur_adj + adj) >= (base + max))
 			break;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		adj_scale++;
 		tick_error >>= 1;
 	}
@@ -1913,6 +1985,7 @@ static void timekeeping_adjust(struct timekeeper *tk, s64 offset)
 
 	/* Next make a small adjustment to fix any cumulative error */
 	if (!tk->ntp_err_mult && (tk->ntp_error > 0)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		tk->ntp_err_mult = 1;
 		timekeeping_apply_adjustment(tk, offset, 0, 0);
 	} else if (tk->ntp_err_mult && (tk->ntp_error <= 0)) {
@@ -1924,6 +1997,7 @@ static void timekeeping_adjust(struct timekeeper *tk, s64 offset)
 	if (unlikely(tk->tkr_mono.clock->maxadj &&
 		(abs(tk->tkr_mono.mult - tk->tkr_mono.clock->mult)
 			> tk->tkr_mono.clock->maxadj))) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		printk_once(KERN_WARNING
 			"Adjusting %s more than 11%% (%ld vs %ld)\n",
 			tk->tkr_mono.clock->name, (long)tk->tkr_mono.mult,
@@ -2007,7 +2081,9 @@ static u64 logarithmic_accumulation(struct timekeeper *tk, u64 offset,
 
 	/* If the offset is smaller than a shifted interval, do nothing */
 	if (offset < interval)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return offset;
+}
 
 	/* Accumulate one shifted interval */
 	offset -= interval;
@@ -2113,6 +2189,7 @@ void update_wall_time(void)
 	 * updating.
 	 */
 	timekeeping_update(tk, clock_set);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	memcpy(real_tk, tk, sizeof(*tk));
 	/* The memcpy must come last. Do not put anything here! */
 	write_seqcount_end(&tk_core.seq);
@@ -2165,6 +2242,7 @@ struct timespec64 current_kernel_time64(void)
 	unsigned long seq;
 
 	do {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		seq = read_seqcount_begin(&tk_core.seq);
 
 		now = tk_xtime(tk);
@@ -2181,6 +2259,7 @@ struct timespec64 get_monotonic_coarse64(void)
 	unsigned long seq;
 
 	do {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		seq = read_seqcount_begin(&tk_core.seq);
 
 		now = tk_xtime(tk);
@@ -2225,6 +2304,7 @@ ktime_t ktime_get_update_offsets_now(unsigned int *cwsseq, ktime_t *offs_real,
 	u64 nsecs;
 
 	do {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		seq = read_seqcount_begin(&tk_core.seq);
 
 		base = tk->tkr_mono.base;
@@ -2240,7 +2320,9 @@ ktime_t ktime_get_update_offsets_now(unsigned int *cwsseq, ktime_t *offs_real,
 
 		/* Handle leapsecond insertion adjustments */
 		if (unlikely(base >= tk->next_leap_ktime))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			*offs_real = ktime_sub(tk->offs_real, ktime_set(1, 0));
+}
 
 	} while (read_seqcount_retry(&tk_core.seq, seq));
 
@@ -2261,7 +2343,9 @@ int do_adjtimex(struct timex *txc)
 	/* Validate the data before disabling interrupts */
 	ret = ntp_validate_timex(txc);
 	if (ret)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ret;
+}
 
 	if (txc->modes & ADJ_SETOFFSET) {
 		struct timespec delta;
@@ -2326,6 +2410,7 @@ EXPORT_SYMBOL(hardpps);
  */
 void xtime_update(unsigned long ticks)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	write_seqlock(&jiffies_lock);
 	do_timer(ticks);
 	write_sequnlock(&jiffies_lock);
diff --git a/kernel/time/timekeeping_debug.c b/kernel/time/timekeeping_debug.c
index 0754cad..1b4d81c 100644
--- a/kernel/time/timekeeping_debug.c
+++ b/kernel/time/timekeeping_debug.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * debugfs file to track time spent in suspend
  *
@@ -33,6 +35,7 @@ static int tk_debug_show_sleep_time(struct seq_file *s, void *data)
 	unsigned int bin;
 	seq_puts(s, "      time (secs)        count\n");
 	seq_puts(s, "------------------------------\n");
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (bin = 0; bin < 32; bin++) {
 		if (sleep_time_bin[bin] == 0)
 			continue;
@@ -45,6 +48,7 @@ static int tk_debug_show_sleep_time(struct seq_file *s, void *data)
 
 static int tk_debug_sleep_time_open(struct inode *inode, struct file *file)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return single_open(file, tk_debug_show_sleep_time, NULL);
 }
 
@@ -62,10 +66,12 @@ static int __init tk_debug_sleep_time_init(void)
 	d = debugfs_create_file("sleep_time", 0444, NULL, NULL,
 		&tk_debug_sleep_time_fops);
 	if (!d) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_err("Failed to create sleep_time debug file\n");
 		return -ENOMEM;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 late_initcall(tk_debug_sleep_time_init);
diff --git a/kernel/time/timekeeping_internal.h b/kernel/time/timekeeping_internal.h
index fdbeeb0..eb3bbec 100644
--- a/kernel/time/timekeeping_internal.h
+++ b/kernel/time/timekeeping_internal.h
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /* SPDX-License-Identifier: GPL-2.0 */
 #ifndef _TIMEKEEPING_INTERNAL_H
 #define _TIMEKEEPING_INTERNAL_H
diff --git a/kernel/time/timer.c b/kernel/time/timer.c
index db5e6da..e1d02c0 100644
--- a/kernel/time/timer.c
+++ b/kernel/time/timer.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  *  linux/kernel/timer.c
  *
diff --git a/kernel/time/timer_list.c b/kernel/time/timer_list.c
index 0e7f542..af77e90 100644
--- a/kernel/time/timer_list.c
+++ b/kernel/time/timer_list.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * kernel/time/timer_list.c
  *
@@ -42,7 +44,9 @@ static void SEQ_printf(struct seq_file *m, const char *fmt, ...)
 	va_start(args, fmt);
 
 	if (m)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		seq_vprintf(m, fmt, args);
+}
 	else
 		vprintk(fmt, args);
 
@@ -54,7 +58,9 @@ static void print_name_offset(struct seq_file *m, void *sym)
 	char symname[KSYM_NAME_LEN];
 
 	if (lookup_symbol_name((unsigned long)sym, symname) < 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		SEQ_printf(m, "<%pK>", sym);
+}
 	else
 		SEQ_printf(m, "%s", symname);
 }
@@ -63,6 +69,7 @@ static void
 print_timer(struct seq_file *m, struct hrtimer *taddr, struct hrtimer *timer,
 	    int idx, u64 now)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	SEQ_printf(m, " #%d: ", idx);
 	print_name_offset(m, taddr);
 	SEQ_printf(m, ", ");
@@ -118,6 +125,7 @@ print_active_timers(struct seq_file *m, struct hrtimer_clock_base *base,
 static void
 print_base(struct seq_file *m, struct hrtimer_clock_base *base, u64 now)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	SEQ_printf(m, "  .base:       %pK\n", base);
 	SEQ_printf(m, "  .index:      %d\n", base->index);
 
@@ -136,6 +144,7 @@ print_base(struct seq_file *m, struct hrtimer_clock_base *base, u64 now)
 
 static void print_cpu(struct seq_file *m, int cpu, u64 now)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct hrtimer_cpu_base *cpu_base = &per_cpu(hrtimer_bases, cpu);
 	int i;
 
@@ -205,7 +214,9 @@ print_tickdevice(struct seq_file *m, struct tick_device *td, int cpu)
 
 	SEQ_printf(m, "Tick Device: mode:     %d\n", td->mode);
 	if (cpu < 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		SEQ_printf(m, "Broadcast device\n");
+}
 	else
 		SEQ_printf(m, "Per CPU device: %d\n", cpu);
 
@@ -283,6 +294,7 @@ static void timer_list_show_tickdevices_header(struct seq_file *m)
 
 static inline void timer_list_header(struct seq_file *m, u64 now)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	SEQ_printf(m, "Timer List Version: v0.8\n");
 	SEQ_printf(m, "HRTIMER_MAX_CLOCK_BASES: %d\n", HRTIMER_MAX_CLOCK_BASES);
 	SEQ_printf(m, "now at %Ld nsecs\n", (unsigned long long)now);
@@ -293,6 +305,7 @@ static int timer_list_show(struct seq_file *m, void *v)
 {
 	struct timer_list_iter *iter = v;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (iter->cpu == -1 && !iter->second_pass)
 		timer_list_header(m, iter->now);
 	else if (!iter->second_pass)
@@ -308,6 +321,7 @@ static int timer_list_show(struct seq_file *m, void *v)
 
 void sysrq_timer_list_show(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	u64 now = ktime_to_ns(ktime_get());
 	int cpu;
 
@@ -326,6 +340,7 @@ void sysrq_timer_list_show(void)
 
 static void *move_iter(struct timer_list_iter *iter, loff_t offset)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (; offset; offset--) {
 		iter->cpu = cpumask_next(iter->cpu, cpu_online_mask);
 		if (iter->cpu >= nr_cpu_ids) {
@@ -348,7 +363,9 @@ static void *timer_list_start(struct seq_file *file, loff_t *offset)
 	struct timer_list_iter *iter = file->private;
 
 	if (!*offset)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		iter->now = ktime_to_ns(ktime_get());
+}
 	iter->cpu = -1;
 	iter->second_pass = false;
 	return move_iter(iter, *offset);
@@ -374,6 +391,7 @@ static const struct seq_operations timer_list_sops = {
 
 static int timer_list_open(struct inode *inode, struct file *filp)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return seq_open_private(filp, &timer_list_sops,
 			sizeof(struct timer_list_iter));
 }
@@ -391,7 +409,9 @@ static int __init init_timer_list_procfs(void)
 
 	pe = proc_create("timer_list", 0444, NULL, &timer_list_fops);
 	if (!pe)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 	return 0;
 }
 __initcall(init_timer_list_procfs);
diff --git a/kernel/trace/blktrace.c b/kernel/trace/blktrace.c
index e73dcab..0cdad74 100644
--- a/kernel/trace/blktrace.c
+++ b/kernel/trace/blktrace.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * Copyright (C) 2006 Jens Axboe <axboe@kernel.dk>
  *
@@ -83,6 +85,7 @@ static void trace_note(struct blk_trace *bt, pid_t pid, int action,
 	struct ring_buffer_event *event = NULL;
 	struct ring_buffer *buffer = NULL;
 	int pc = 0;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	int cpu = smp_processor_id();
 	bool blk_tracer = blk_tracer_enabled;
 	ssize_t cgid_len = cgid ? sizeof(*cgid) : 0;
@@ -131,6 +134,7 @@ static void trace_note_tsk(struct task_struct *tsk)
 	struct blk_trace *bt;
 
 	tsk->btrace_seq = blktrace_seq;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_lock_irqsave(&running_trace_lock, flags);
 	list_for_each_entry(bt, &running_trace_list, running_list) {
 		trace_note(bt, tsk->pid, BLK_TN_PROCESS, tsk->comm,
@@ -150,6 +154,7 @@ static void trace_note_time(struct blk_trace *bt)
 	words[0] = (u32)now.tv_sec;
 	words[1] = now.tv_nsec;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	local_irq_save(flags);
 	trace_note(bt, 0, BLK_TN_TIMESTAMP, words, sizeof(words), NULL);
 	local_irq_restore(flags);
@@ -163,6 +168,7 @@ void __trace_note_message(struct blk_trace *bt, struct blkcg *blkcg,
 	unsigned long flags;
 	char *buf;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (unlikely(bt->trace_state != Blktrace_running &&
 		     !blk_tracer_enabled))
 		return;
@@ -195,6 +201,7 @@ EXPORT_SYMBOL_GPL(__trace_note_message);
 static int act_log_check(struct blk_trace *bt, u32 what, sector_t sector,
 			 pid_t pid)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (((bt->act_mask << BLK_TC_SHIFT) & what) == 0)
 		return 1;
 	if (sector && (sector < bt->start_lba || sector > bt->end_lba))
@@ -226,6 +233,7 @@ static void __blk_add_trace(struct blk_trace *bt, sector_t sector, int bytes,
 		     int op, int op_flags, u32 what, int error, int pdu_len,
 		     void *pdu_data, union kernfs_node_id *cgid)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct task_struct *tsk = current;
 	struct ring_buffer_event *event = NULL;
 	struct ring_buffer *buffer = NULL;
@@ -321,6 +329,7 @@ static void __blk_add_trace(struct blk_trace *bt, sector_t sector, int bytes,
 
 static void blk_trace_free(struct blk_trace *bt)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	debugfs_remove(bt->msg_file);
 	debugfs_remove(bt->dropped_file);
 	relay_close(bt->rchan);
@@ -332,6 +341,7 @@ static void blk_trace_free(struct blk_trace *bt)
 
 static void get_probe_ref(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	mutex_lock(&blk_probe_mutex);
 	if (++blk_probes_ref == 1)
 		blk_register_tracepoints();
@@ -340,6 +350,7 @@ static void get_probe_ref(void)
 
 static void put_probe_ref(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	mutex_lock(&blk_probe_mutex);
 	if (!--blk_probes_ref)
 		blk_unregister_tracepoints();
@@ -348,6 +359,7 @@ static void put_probe_ref(void)
 
 static void blk_trace_cleanup(struct blk_trace *bt)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	blk_trace_free(bt);
 	put_probe_ref();
 }
@@ -356,6 +368,7 @@ int blk_trace_remove(struct request_queue *q)
 {
 	struct blk_trace *bt;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	bt = xchg(&q->blk_trace, NULL);
 	if (!bt)
 		return -EINVAL;
@@ -392,7 +405,9 @@ static ssize_t blk_msg_write(struct file *filp, const char __user *buffer,
 	struct blk_trace *bt;
 
 	if (count >= BLK_TN_MAX_MSG)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	msg = memdup_user_nul(buffer, count);
 	if (IS_ERR(msg))
@@ -422,7 +437,9 @@ static int blk_subbuf_start_callback(struct rchan_buf *buf, void *subbuf,
 	struct blk_trace *bt;
 
 	if (!relay_buf_full(buf))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 1;
+}
 
 	bt = buf->chan->private_data;
 	atomic_inc(&bt->dropped);
@@ -431,6 +448,7 @@ static int blk_subbuf_start_callback(struct rchan_buf *buf, void *subbuf,
 
 static int blk_remove_buf_file_callback(struct dentry *dentry)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	debugfs_remove(dentry);
 
 	return 0;
@@ -442,6 +460,7 @@ static struct dentry *blk_create_buf_file_callback(const char *filename,
 						   struct rchan_buf *buf,
 						   int *is_global)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return debugfs_create_file(filename, mode, parent, buf,
 					&relay_file_operations);
 }
@@ -458,7 +477,9 @@ static void blk_trace_setup_lba(struct blk_trace *bt,
 	struct hd_struct *part = NULL;
 
 	if (bdev)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		part = bdev->bd_part;
+}
 
 	if (part) {
 		bt->start_lba = part->start_sect;
@@ -480,6 +501,7 @@ static int do_blk_trace_setup(struct request_queue *q, char *name, dev_t dev,
 	struct dentry *dir = NULL;
 	int ret;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!buts->buf_size || !buts->buf_nr)
 		return -EINVAL;
 
@@ -574,7 +596,9 @@ int blk_trace_setup(struct request_queue *q, char *name, dev_t dev,
 
 	ret = copy_from_user(&buts, arg, sizeof(buts));
 	if (ret)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EFAULT;
+}
 
 	ret = do_blk_trace_setup(q, name, dev, bdev, &buts);
 	if (ret)
@@ -598,7 +622,9 @@ static int compat_blk_trace_setup(struct request_queue *q, char *name,
 	int ret;
 
 	if (copy_from_user(&cbuts, arg, sizeof(cbuts)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EFAULT;
+}
 
 	buts = (struct blk_user_trace_setup) {
 		.act_mask = cbuts.act_mask,
@@ -628,7 +654,9 @@ int blk_trace_startstop(struct request_queue *q, int start)
 	struct blk_trace *bt = q->blk_trace;
 
 	if (bt == NULL)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	/*
 	 * For starting a trace, we can transition from a setup or stopped
@@ -684,7 +712,9 @@ int blk_trace_ioctl(struct block_device *bdev, unsigned cmd, char __user *arg)
 
 	q = bdev_get_queue(bdev);
 	if (!q)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENXIO;
+}
 
 	mutex_lock(&q->blk_trace_mutex);
 
@@ -723,6 +753,7 @@ int blk_trace_ioctl(struct block_device *bdev, unsigned cmd, char __user *arg)
  **/
 void blk_trace_shutdown(struct request_queue *q)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (q->blk_trace) {
 		blk_trace_startstop(q, 0);
 		blk_trace_remove(q);
@@ -746,6 +777,7 @@ blk_trace_bio_get_cgid(struct request_queue *q, struct bio *bio)
 static union kernfs_node_id *
 blk_trace_bio_get_cgid(struct request_queue *q, struct bio *bio)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return NULL;
 }
 #endif
@@ -753,6 +785,7 @@ blk_trace_bio_get_cgid(struct request_queue *q, struct bio *bio)
 static union kernfs_node_id *
 blk_trace_request_get_cgid(struct request_queue *q, struct request *rq)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!rq->bio)
 		return NULL;
 	/* Use the first bio */
@@ -782,7 +815,9 @@ static void blk_add_trace_rq(struct request *rq, int error,
 	struct blk_trace *bt = rq->q->blk_trace;
 
 	if (likely(!bt))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	if (blk_rq_is_passthrough(rq))
 		what |= BLK_TC_ACT(BLK_TC_PC);
@@ -796,6 +831,7 @@ static void blk_add_trace_rq(struct request *rq, int error,
 static void blk_add_trace_rq_insert(void *ignore,
 				    struct request_queue *q, struct request *rq)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	blk_add_trace_rq(rq, 0, blk_rq_bytes(rq), BLK_TA_INSERT,
 			 blk_trace_request_get_cgid(q, rq));
 }
@@ -803,6 +839,7 @@ static void blk_add_trace_rq_insert(void *ignore,
 static void blk_add_trace_rq_issue(void *ignore,
 				   struct request_queue *q, struct request *rq)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	blk_add_trace_rq(rq, 0, blk_rq_bytes(rq), BLK_TA_ISSUE,
 			 blk_trace_request_get_cgid(q, rq));
 }
@@ -811,6 +848,7 @@ static void blk_add_trace_rq_requeue(void *ignore,
 				     struct request_queue *q,
 				     struct request *rq)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	blk_add_trace_rq(rq, 0, blk_rq_bytes(rq), BLK_TA_REQUEUE,
 			 blk_trace_request_get_cgid(q, rq));
 }
@@ -839,7 +877,9 @@ static void blk_add_trace_bio(struct request_queue *q, struct bio *bio,
 	struct blk_trace *bt = q->blk_trace;
 
 	if (likely(!bt))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	__blk_add_trace(bt, bio->bi_iter.bi_sector, bio->bi_iter.bi_size,
 			bio_op(bio), bio->bi_opf, what, error, 0, NULL, cgid);
@@ -889,6 +929,7 @@ static void blk_add_trace_getrq(void *ignore,
 				struct request_queue *q,
 				struct bio *bio, int rw)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (bio)
 		blk_add_trace_bio(q, bio, BLK_TA_GETRQ, 0,
 				  blk_trace_bio_get_cgid(q, bio));
@@ -906,6 +947,7 @@ static void blk_add_trace_sleeprq(void *ignore,
 				  struct request_queue *q,
 				  struct bio *bio, int rw)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (bio)
 		blk_add_trace_bio(q, bio, BLK_TA_SLEEPRQ, 0,
 				  blk_trace_bio_get_cgid(q, bio));
@@ -923,8 +965,10 @@ static void blk_add_trace_plug(void *ignore, struct request_queue *q)
 	struct blk_trace *bt = q->blk_trace;
 
 	if (bt)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		__blk_add_trace(bt, 0, 0, 0, 0, BLK_TA_PLUG, 0, 0, NULL, NULL);
 }
+}
 
 static void blk_add_trace_unplug(void *ignore, struct request_queue *q,
 				    unsigned int depth, bool explicit)
@@ -932,6 +976,7 @@ static void blk_add_trace_unplug(void *ignore, struct request_queue *q,
 	struct blk_trace *bt = q->blk_trace;
 
 	if (bt) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		__be64 rpdu = cpu_to_be64(depth);
 		u32 what;
 
@@ -951,6 +996,7 @@ static void blk_add_trace_split(void *ignore,
 	struct blk_trace *bt = q->blk_trace;
 
 	if (bt) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		__be64 rpdu = cpu_to_be64(pdu);
 
 		__blk_add_trace(bt, bio->bi_iter.bi_sector,
@@ -981,7 +1027,9 @@ static void blk_add_trace_bio_remap(void *ignore,
 	struct blk_io_trace_remap r;
 
 	if (likely(!bt))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	r.device_from = cpu_to_be32(dev);
 	r.device_to   = cpu_to_be32(bio_dev(bio));
@@ -1014,7 +1062,9 @@ static void blk_add_trace_rq_remap(void *ignore,
 	struct blk_io_trace_remap r;
 
 	if (likely(!bt))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	r.device_from = cpu_to_be32(dev);
 	r.device_to   = cpu_to_be32(disk_devt(rq->rq_disk));
@@ -1043,7 +1093,9 @@ void blk_add_driver_data(struct request_queue *q,
 	struct blk_trace *bt = q->blk_trace;
 
 	if (likely(!bt))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	__blk_add_trace(bt, blk_rq_trace_sector(rq), blk_rq_bytes(rq), 0, 0,
 				BLK_TA_DRV_DATA, 0, len, data,
@@ -1056,6 +1108,7 @@ static void blk_register_tracepoints(void)
 	int ret;
 
 	ret = register_trace_block_rq_insert(blk_add_trace_rq_insert, NULL);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WARN_ON(ret);
 	ret = register_trace_block_rq_issue(blk_add_trace_rq_issue, NULL);
 	WARN_ON(ret);
@@ -1091,6 +1144,7 @@ static void blk_register_tracepoints(void)
 
 static void blk_unregister_tracepoints(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	unregister_trace_block_rq_remap(blk_add_trace_rq_remap, NULL);
 	unregister_trace_block_bio_remap(blk_add_trace_bio_remap, NULL);
 	unregister_trace_block_split(blk_add_trace_split, NULL);
@@ -1121,6 +1175,7 @@ static void fill_rwbs(char *rwbs, const struct blk_io_trace *t)
 	int tc = t->action >> BLK_TC_SHIFT;
 
 	if ((t->action & ~__BLK_TN_CGROUP) == BLK_TN_MESSAGE) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		rwbs[i++] = 'N';
 		goto out;
 	}
@@ -1152,53 +1207,63 @@ static void fill_rwbs(char *rwbs, const struct blk_io_trace *t)
 static inline
 const struct blk_io_trace *te_blk_io_trace(const struct trace_entry *ent)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return (const struct blk_io_trace *)ent;
 }
 
 static inline const void *pdu_start(const struct trace_entry *ent, bool has_cg)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return (void *)(te_blk_io_trace(ent) + 1) +
 		(has_cg ? sizeof(union kernfs_node_id) : 0);
 }
 
 static inline const void *cgid_start(const struct trace_entry *ent)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return (void *)(te_blk_io_trace(ent) + 1);
 }
 
 static inline int pdu_real_len(const struct trace_entry *ent, bool has_cg)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return te_blk_io_trace(ent)->pdu_len -
 			(has_cg ? sizeof(union kernfs_node_id) : 0);
 }
 
 static inline u32 t_action(const struct trace_entry *ent)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return te_blk_io_trace(ent)->action;
 }
 
 static inline u32 t_bytes(const struct trace_entry *ent)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return te_blk_io_trace(ent)->bytes;
 }
 
 static inline u32 t_sec(const struct trace_entry *ent)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return te_blk_io_trace(ent)->bytes >> 9;
 }
 
 static inline unsigned long long t_sector(const struct trace_entry *ent)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return te_blk_io_trace(ent)->sector;
 }
 
 static inline __u16 t_error(const struct trace_entry *ent)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return te_blk_io_trace(ent)->error;
 }
 
 static __u64 get_pdu_int(const struct trace_entry *ent, bool has_cg)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	const __u64 *val = pdu_start(ent, has_cg);
 	return be64_to_cpu(*val);
 }
@@ -1206,6 +1271,7 @@ static __u64 get_pdu_int(const struct trace_entry *ent, bool has_cg)
 static void get_pdu_remap(const struct trace_entry *ent,
 			  struct blk_io_trace_remap *r, bool has_cg)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	const struct blk_io_trace_remap *__r = pdu_start(ent, has_cg);
 	__u64 sector_from = __r->sector_from;
 
@@ -1242,6 +1308,7 @@ static void blk_log_action(struct trace_iterator *iter, const char *act,
 
 	fill_rwbs(rwbs, t);
 	if (has_cg) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		const union kernfs_node_id *id = cgid_start(iter->ent);
 
 		if (blk_tracer_flags.val & TRACE_BLK_OPT_CGNAME) {
@@ -1273,7 +1340,9 @@ static void blk_log_dump_pdu(struct trace_seq *s,
 	pdu_len = pdu_real_len(ent, has_cg);
 
 	if (!pdu_len)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	/* find the last zero that needs to be printed */
 	for (end = pdu_len - 1; end >= 0; end--)
@@ -1308,6 +1377,7 @@ static void blk_log_generic(struct trace_seq *s, const struct trace_entry *ent,
 	trace_find_cmdline(ent->pid, cmd);
 
 	if (t_action(ent) & BLK_TC_ACT(BLK_TC_PC)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		trace_seq_printf(s, "%u ", t_bytes(ent));
 		blk_log_dump_pdu(s, ent, has_cg);
 		trace_seq_printf(s, "[%s]\n", cmd);
@@ -1323,6 +1393,7 @@ static void blk_log_generic(struct trace_seq *s, const struct trace_entry *ent,
 static void blk_log_with_error(struct trace_seq *s,
 			      const struct trace_entry *ent, bool has_cg)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (t_action(ent) & BLK_TC_ACT(BLK_TC_PC)) {
 		blk_log_dump_pdu(s, ent, has_cg);
 		trace_seq_printf(s, "[%d]\n", t_error(ent));
@@ -1380,6 +1451,7 @@ static void blk_log_msg(struct trace_seq *s, const struct trace_entry *ent,
 			bool has_cg)
 {
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	trace_seq_putmem(s, pdu_start(ent, has_cg),
 		pdu_real_len(ent, has_cg));
 	trace_seq_putc(s, '\n');
@@ -1391,6 +1463,7 @@ static void blk_log_msg(struct trace_seq *s, const struct trace_entry *ent,
 
 static void blk_tracer_print_header(struct seq_file *m)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!(blk_tracer_flags.val & TRACE_BLK_OPT_CLASSIC))
 		return;
 	seq_puts(m, "# DEV   CPU TIMESTAMP     PID ACT FLG\n"
@@ -1399,11 +1472,13 @@ static void blk_tracer_print_header(struct seq_file *m)
 
 static void blk_tracer_start(struct trace_array *tr)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	blk_tracer_enabled = true;
 }
 
 static int blk_tracer_init(struct trace_array *tr)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	blk_tr = tr;
 	blk_tracer_start(tr);
 	return 0;
@@ -1411,11 +1486,13 @@ static int blk_tracer_init(struct trace_array *tr)
 
 static void blk_tracer_stop(struct trace_array *tr)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	blk_tracer_enabled = false;
 }
 
 static void blk_tracer_reset(struct trace_array *tr)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	blk_tracer_stop(tr);
 }
 
@@ -1455,6 +1532,7 @@ static enum print_line_t print_one_line(struct trace_iterator *iter,
 	t	   = te_blk_io_trace(iter->ent);
 	what	   = (t->action & ((1 << BLK_TC_SHIFT) - 1)) & ~__BLK_TA_CGROUP;
 	long_act   = !!(tr->trace_flags & TRACE_ITER_VERBOSE);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	log_action = classic ? &blk_log_action_classic : &blk_log_action;
 	has_cg	   = t->action & __BLK_TA_CGROUP;
 
@@ -1477,6 +1555,7 @@ static enum print_line_t print_one_line(struct trace_iterator *iter,
 static enum print_line_t blk_trace_event_print(struct trace_iterator *iter,
 					       int flags, struct trace_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return print_one_line(iter, false);
 }
 
@@ -1499,6 +1578,7 @@ static enum print_line_t
 blk_trace_event_print_binary(struct trace_iterator *iter, int flags,
 			     struct trace_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	blk_trace_synthesize_old_trace(iter);
 
 	return trace_handle_return(&iter->seq);
@@ -1506,6 +1586,7 @@ blk_trace_event_print_binary(struct trace_iterator *iter, int flags,
 
 static enum print_line_t blk_tracer_print_line(struct trace_iterator *iter)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!(blk_tracer_flags.val & TRACE_BLK_OPT_CLASSIC))
 		return TRACE_TYPE_UNHANDLED;
 
@@ -1550,16 +1631,19 @@ static struct trace_event trace_blk_event = {
 static int __init init_blk_tracer(void)
 {
 	if (!register_trace_event(&trace_blk_event)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_warn("Warning: could not register block events\n");
 		return 1;
 	}
 
 	if (register_tracer(&blk_tracer) != 0) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_warn("Warning: could not register the block tracer\n");
 		unregister_trace_event(&trace_blk_event);
 		return 1;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
@@ -1569,6 +1653,7 @@ static int blk_trace_remove_queue(struct request_queue *q)
 {
 	struct blk_trace *bt;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	bt = xchg(&q->blk_trace, NULL);
 	if (bt == NULL)
 		return -EINVAL;
@@ -1589,7 +1674,9 @@ static int blk_trace_setup_queue(struct request_queue *q,
 
 	bt = kzalloc(sizeof(*bt), GFP_KERNEL);
 	if (!bt)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 
 	bt->msg_data = __alloc_percpu(BLK_TN_MAX_MSG, __alignof__(char));
 	if (!bt->msg_data)
@@ -1677,7 +1764,9 @@ static int blk_trace_str2mask(const char *str)
 
 	buf = kstrdup(str, GFP_KERNEL);
 	if (buf == NULL)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 	s = strstrip(buf);
 
 	while (1) {
@@ -1709,6 +1798,7 @@ static ssize_t blk_trace_mask2str(char *buf, int mask)
 	int i;
 	char *p = buf;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (i = 0; i < ARRAY_SIZE(mask_maps); i++) {
 		if (mask & mask_maps[i].mask) {
 			p += sprintf(p, "%s%s",
@@ -1722,6 +1812,7 @@ static ssize_t blk_trace_mask2str(char *buf, int mask)
 
 static struct request_queue *blk_trace_get_queue(struct block_device *bdev)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (bdev->bd_disk == NULL)
 		return NULL;
 
@@ -1732,6 +1823,7 @@ static ssize_t sysfs_blk_trace_attr_show(struct device *dev,
 					 struct device_attribute *attr,
 					 char *buf)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct hd_struct *p = dev_to_part(dev);
 	struct request_queue *q;
 	struct block_device *bdev;
@@ -1784,6 +1876,7 @@ static ssize_t sysfs_blk_trace_attr_store(struct device *dev,
 	if (count == 0)
 		goto out;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (attr == &dev_attr_act_mask) {
 		if (kstrtoull(buf, 0, &value)) {
 			/* Assume it is a list of trace category names */
@@ -1846,6 +1939,7 @@ int blk_trace_init_sysfs(struct device *dev)
 
 void blk_trace_remove_sysfs(struct device *dev)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	sysfs_remove_group(&dev->kobj, &blk_trace_attr_group);
 }
 
@@ -1858,7 +1952,9 @@ void blk_fill_rwbs(char *rwbs, unsigned int op, int bytes)
 	int i = 0;
 
 	if (op & REQ_PREFLUSH)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		rwbs[i++] = 'F';
+}
 
 	switch (op & REQ_OP_MASK) {
 	case REQ_OP_WRITE:
diff --git a/kernel/trace/ftrace.c b/kernel/trace/ftrace.c
index 7379bcf..bde54e5 100644
--- a/kernel/trace/ftrace.c
+++ b/kernel/trace/ftrace.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * Infrastructure for profiling code inserted by 'gcc -pg'.
  *
diff --git a/kernel/trace/ring_buffer.c b/kernel/trace/ring_buffer.c
index 39c2214..ff61b09 100644
--- a/kernel/trace/ring_buffer.c
+++ b/kernel/trace/ring_buffer.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * Generic ring buffer
  *
@@ -32,6 +34,7 @@ static void update_pages_handler(struct work_struct *work);
  */
 int ring_buffer_print_entry_header(struct trace_seq *s)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	trace_seq_puts(s, "# compressed entry header\n");
 	trace_seq_puts(s, "\ttype_len    :    5 bits\n");
 	trace_seq_puts(s, "\ttime_delta  :   27 bits\n");
@@ -148,6 +151,7 @@ enum {
 
 static inline int rb_null_event(struct ring_buffer_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return event->type_len == RINGBUF_TYPE_PADDING && !event->time_delta;
 }
 
@@ -164,7 +168,9 @@ rb_event_data_length(struct ring_buffer_event *event)
 	unsigned length;
 
 	if (event->type_len)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		length = event->type_len * RB_ALIGNMENT;
+}
 	else
 		length = event->array[0];
 	return length + RB_EVNT_HDR_SIZE;
@@ -178,6 +184,7 @@ rb_event_data_length(struct ring_buffer_event *event)
 static inline unsigned
 rb_event_length(struct ring_buffer_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	switch (event->type_len) {
 	case RINGBUF_TYPE_PADDING:
 		if (rb_null_event(event))
@@ -232,7 +239,9 @@ unsigned ring_buffer_event_length(struct ring_buffer_event *event)
 	unsigned length;
 
 	if (event->type_len == RINGBUF_TYPE_TIME_EXTEND)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		event = skip_time_extend(event);
+}
 
 	length = rb_event_length(event);
 	if (event->type_len > RINGBUF_TYPE_DATA_TYPE_LEN_MAX)
@@ -248,6 +257,7 @@ EXPORT_SYMBOL_GPL(ring_buffer_event_length);
 static __always_inline void *
 rb_event_data(struct ring_buffer_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (event->type_len == RINGBUF_TYPE_TIME_EXTEND)
 		event = skip_time_extend(event);
 	BUG_ON(event->type_len > RINGBUF_TYPE_DATA_TYPE_LEN_MAX);
@@ -264,6 +274,7 @@ rb_event_data(struct ring_buffer_event *event)
  */
 void *ring_buffer_event_data(struct ring_buffer_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return rb_event_data(event);
 }
 EXPORT_SYMBOL_GPL(ring_buffer_event_data);
@@ -322,6 +333,7 @@ struct buffer_page {
 
 static void rb_init_page(struct buffer_data_page *bpage)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	local_set(&bpage->commit, 0);
 }
 
@@ -345,6 +357,7 @@ size_t ring_buffer_page_len(void *page)
  */
 static void free_buffer_page(struct buffer_page *bpage)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	free_page((unsigned long)bpage->page);
 	kfree(bpage);
 }
@@ -354,6 +367,7 @@ static void free_buffer_page(struct buffer_page *bpage)
  */
 static inline int test_time_stamp(u64 delta)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (delta & TS_DELTA_TEST)
 		return 1;
 	return 0;
@@ -507,6 +521,7 @@ struct ring_buffer_iter {
  */
 static void rb_wake_up_waiters(struct irq_work *work)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct rb_irq_work *rbwork = container_of(work, struct rb_irq_work, work);
 
 	wake_up_all(&rbwork->waiters);
@@ -539,6 +554,7 @@ int ring_buffer_wait(struct ring_buffer *buffer, int cpu, bool full)
 	 * caller on the appropriate wait queue.
 	 */
 	if (cpu == RING_BUFFER_ALL_CPUS) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		work = &buffer->irq_work;
 		/* Full only makes sense on per cpu reads */
 		full = false;
@@ -637,7 +653,9 @@ int ring_buffer_poll_wait(struct ring_buffer *buffer, int cpu,
 	struct rb_irq_work *work;
 
 	if (cpu == RING_BUFFER_ALL_CPUS)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		work = &buffer->irq_work;
+}
 	else {
 		if (!cpumask_test_cpu(cpu, buffer->cpumask))
 			return -EINVAL;
diff --git a/kernel/trace/trace.c b/kernel/trace/trace.c
index 76bcc80..d167490 100644
--- a/kernel/trace/trace.c
+++ b/kernel/trace/trace.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * ring buffer based function tracer
  *
@@ -79,6 +81,7 @@ static struct tracer_opt dummy_tracer_opt[] = {
 static int
 dummy_set_flag(struct trace_array *tr, u32 old_flags, u32 bit, int set)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
@@ -166,6 +169,7 @@ static bool allocate_snapshot;
 
 static int __init set_cmdline_ftrace(char *str)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	strlcpy(bootup_tracer_buf, str, MAX_TRACER_SIZE);
 	default_bootup_tracer = bootup_tracer_buf;
 	/* We are using ftrace early, expand it */
@@ -176,6 +180,7 @@ __setup("ftrace=", set_cmdline_ftrace);
 
 static int __init set_ftrace_dump_on_oops(char *str)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (*str++ != '=' || !*str) {
 		ftrace_dump_on_oops = DUMP_ALL;
 		return 1;
@@ -192,6 +197,7 @@ __setup("ftrace_dump_on_oops", set_ftrace_dump_on_oops);
 
 static int __init stop_trace_on_warning(char *str)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if ((strcmp(str, "=0") != 0 && strcmp(str, "=off") != 0))
 		__disable_trace_on_warning = 1;
 	return 1;
@@ -200,6 +206,7 @@ __setup("traceoff_on_warning", stop_trace_on_warning);
 
 static int __init boot_alloc_snapshot(char *str)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	allocate_snapshot = true;
 	/* We also need the main ring buffer expanded */
 	ring_buffer_expanded = true;
@@ -212,6 +219,7 @@ static char trace_boot_options_buf[MAX_TRACER_SIZE] __initdata;
 
 static int __init set_trace_boot_options(char *str)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	strlcpy(trace_boot_options_buf, str, MAX_TRACER_SIZE);
 	return 0;
 }
@@ -222,6 +230,7 @@ static char *trace_boot_clock __initdata;
 
 static int __init set_trace_boot_clock(char *str)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	strlcpy(trace_boot_clock_buf, str, MAX_TRACER_SIZE);
 	trace_boot_clock = trace_boot_clock_buf;
 	return 0;
@@ -230,6 +239,7 @@ __setup("trace_clock=", set_trace_boot_clock);
 
 static int __init set_tracepoint_printk(char *str)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if ((strcmp(str, "=0") != 0 && strcmp(str, "=off") != 0))
 		tracepoint_printk = 1;
 	return 1;
@@ -238,6 +248,7 @@ __setup("tp_printk", set_tracepoint_printk);
 
 unsigned long long ns2usecs(u64 nsec)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	nsec += 500;
 	do_div(nsec, 1000);
 	return nsec;
@@ -275,6 +286,7 @@ int trace_array_get(struct trace_array *this_tr)
 	int ret = -ENODEV;
 
 	mutex_lock(&trace_types_lock);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry(tr, &ftrace_trace_arrays, list) {
 		if (tr == this_tr) {
 			tr->ref++;
@@ -289,12 +301,14 @@ int trace_array_get(struct trace_array *this_tr)
 
 static void __trace_array_put(struct trace_array *this_tr)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WARN_ON(!this_tr->ref);
 	this_tr->ref--;
 }
 
 void trace_array_put(struct trace_array *this_tr)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	mutex_lock(&trace_types_lock);
 	__trace_array_put(this_tr);
 	mutex_unlock(&trace_types_lock);
@@ -304,6 +318,7 @@ int call_filter_check_discard(struct trace_event_call *call, void *rec,
 			      struct ring_buffer *buffer,
 			      struct ring_buffer_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (unlikely(call->flags & TRACE_EVENT_FL_FILTERED) &&
 	    !filter_match_preds(call->filter, rec)) {
 		__trace_event_discard_commit(buffer, event);
@@ -315,6 +330,7 @@ int call_filter_check_discard(struct trace_event_call *call, void *rec,
 
 void trace_free_pid_list(struct trace_pid_list *pid_list)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	vfree(pid_list->pids);
 	kfree(pid_list);
 }
@@ -377,6 +393,7 @@ void trace_filter_add_remove_task(struct trace_pid_list *pid_list,
 				  struct task_struct *self,
 				  struct task_struct *task)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!pid_list)
 		return;
 
@@ -420,7 +437,9 @@ void *trace_pid_next(struct trace_pid_list *pid_list, void *v, loff_t *pos)
 
 	/* Return pid + 1 to allow zero to be represented */
 	if (pid < pid_list->pid_max)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return (void *)(pid + 1);
+}
 
 	return NULL;
 }
@@ -443,7 +462,9 @@ void *trace_pid_start(struct trace_pid_list *pid_list, loff_t *pos)
 
 	pid = find_first_bit(pid_list->pids, pid_list->pid_max);
 	if (pid >= pid_list->pid_max)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 
 	/* Return pid + 1 so that zero can be the exit value */
 	for (pid++; pid && l < *pos;
@@ -485,7 +506,9 @@ int trace_pid_write(struct trace_pid_list *filtered_pids,
 	pid_t pid;
 
 	if (trace_parser_get_init(&parser, PID_BUF_SIZE + 1))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 
 	/*
 	 * Always recreate a new array. The write is an all or nothing
@@ -573,6 +596,7 @@ static u64 buffer_ftrace_now(struct trace_buffer *buf, int cpu)
 	if (!buf->buffer)
 		return trace_clock_local();
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	ts = ring_buffer_time_stamp(buf->buffer, cpu);
 	ring_buffer_normalize_time_stamp(buf->buffer, cpu, &ts);
 
@@ -654,6 +678,7 @@ static DEFINE_PER_CPU(struct mutex, cpu_access_lock);
 
 static inline void trace_access_lock(int cpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (cpu == RING_BUFFER_ALL_CPUS) {
 		/* gain it for accessing the whole ring buffer. */
 		down_write(&all_cpu_access_lock);
@@ -670,6 +695,7 @@ static inline void trace_access_lock(int cpu)
 
 static inline void trace_access_unlock(int cpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (cpu == RING_BUFFER_ALL_CPUS) {
 		up_write(&all_cpu_access_lock);
 	} else {
@@ -736,6 +762,7 @@ static __always_inline void
 trace_event_setup(struct ring_buffer_event *event,
 		  int type, unsigned long flags, int pc)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct trace_entry *ent = ring_buffer_event_data(event);
 
 	tracing_generic_entry_update(ent, flags, pc);
@@ -752,13 +779,16 @@ __trace_buffer_lock_reserve(struct ring_buffer *buffer,
 
 	event = ring_buffer_lock_reserve(buffer, len);
 	if (event != NULL)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		trace_event_setup(event, type, flags, pc);
+}
 
 	return event;
 }
 
 void tracer_tracing_on(struct trace_array *tr)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (tr->trace_buffer.buffer)
 		ring_buffer_record_on(tr->trace_buffer.buffer);
 	/*
@@ -782,6 +812,7 @@ void tracer_tracing_on(struct trace_array *tr)
  */
 void tracing_on(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	tracer_tracing_on(&global_trace);
 }
 EXPORT_SYMBOL_GPL(tracing_on);
@@ -790,6 +821,7 @@ EXPORT_SYMBOL_GPL(tracing_on);
 static __always_inline void
 __buffer_unlock_commit(struct ring_buffer *buffer, struct ring_buffer_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	__this_cpu_write(trace_taskinfo_save, true);
 
 	/* If this is the temp buffer, we need to commit fully */
@@ -818,7 +850,9 @@ int __trace_puts(unsigned long ip, const char *str, int size)
 	int pc;
 
 	if (!(global_trace.trace_flags & TRACE_ITER_PRINTK))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	pc = preempt_count();
 
@@ -868,7 +902,9 @@ int __trace_bputs(unsigned long ip, const char *str)
 	int pc;
 
 	if (!(global_trace.trace_flags & TRACE_ITER_PRINTK))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	pc = preempt_count();
 
@@ -1028,11 +1064,13 @@ EXPORT_SYMBOL_GPL(tracing_snapshot_alloc);
 #else
 void tracing_snapshot(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WARN_ONCE(1, "Snapshot feature not enabled, but internal snapshot used");
 }
 EXPORT_SYMBOL_GPL(tracing_snapshot);
 int tracing_alloc_snapshot(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WARN_ONCE(1, "Snapshot feature not enabled, but snapshot allocation used");
 	return -ENODEV;
 }
@@ -1047,6 +1085,7 @@ EXPORT_SYMBOL_GPL(tracing_snapshot_alloc);
 
 void tracer_tracing_off(struct trace_array *tr)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (tr->trace_buffer.buffer)
 		ring_buffer_record_off(tr->trace_buffer.buffer);
 	/*
@@ -1072,12 +1111,14 @@ void tracer_tracing_off(struct trace_array *tr)
  */
 void tracing_off(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	tracer_tracing_off(&global_trace);
 }
 EXPORT_SYMBOL_GPL(tracing_off);
 
 void disable_trace_on_warning(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (__disable_trace_on_warning)
 		tracing_off();
 }
@@ -1090,6 +1131,7 @@ void disable_trace_on_warning(void)
  */
 int tracer_tracing_is_on(struct trace_array *tr)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (tr->trace_buffer.buffer)
 		return ring_buffer_record_is_on(tr->trace_buffer.buffer);
 	return !tr->buffer_disabled;
@@ -1100,6 +1142,7 @@ int tracer_tracing_is_on(struct trace_array *tr)
  */
 int tracing_is_on(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return tracer_tracing_is_on(&global_trace);
 }
 EXPORT_SYMBOL_GPL(tracing_is_on);
@@ -1109,7 +1152,9 @@ static int __init set_buf_size(char *str)
 	unsigned long buf_size;
 
 	if (!str)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 	buf_size = memparse(str, &str);
 	/* nr_entries can not be zero */
 	if (buf_size == 0)
@@ -1125,7 +1170,9 @@ static int __init set_tracing_thresh(char *str)
 	int ret;
 
 	if (!str)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 	ret = kstrtoul(str, 0, &threshold);
 	if (ret < 0)
 		return 0;
@@ -1136,6 +1183,7 @@ __setup("tracing_thresh=", set_tracing_thresh);
 
 unsigned long nsecs_to_usecs(unsigned long nsecs)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return nsecs / 1000;
 }
 
@@ -1175,6 +1223,7 @@ static struct {
  */
 int trace_parser_get_init(struct trace_parser *parser, int size)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	memset(parser, 0, sizeof(*parser));
 
 	parser->buffer = kmalloc(size, GFP_KERNEL);
@@ -1190,6 +1239,7 @@ int trace_parser_get_init(struct trace_parser *parser, int size)
  */
 void trace_parser_put(struct trace_parser *parser)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	kfree(parser->buffer);
 	parser->buffer = NULL;
 }
@@ -1213,7 +1263,9 @@ int trace_get_user(struct trace_parser *parser, const char __user *ubuf,
 	ssize_t ret;
 
 	if (!*ppos)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		trace_parser_clear(parser);
+}
 
 	ret = get_user(ch, ubuf++);
 	if (ret)
@@ -1286,7 +1338,9 @@ static ssize_t trace_seq_to_buffer(struct trace_seq *s, void *buf, size_t cnt)
 	int len;
 
 	if (trace_seq_used(s) <= s->seq.readpos)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EBUSY;
+}
 
 	len = trace_seq_used(s) - s->seq.readpos;
 	if (cnt > len)
@@ -1562,6 +1616,7 @@ core_initcall(init_trace_selftests);
 #else
 static inline int run_tracer_selftest(struct tracer *type)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 #endif /* CONFIG_FTRACE_STARTUP_TEST */
@@ -1582,11 +1637,13 @@ int __init register_tracer(struct tracer *type)
 	int ret = 0;
 
 	if (!type->name) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_info("Tracer must have a name\n");
 		return -1;
 	}
 
 	if (strlen(type->name) >= MAX_TRACER_SIZE) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_info("Tracer has a name longer than %d\n", MAX_TRACER_SIZE);
 		return -1;
 	}
@@ -1611,6 +1668,7 @@ int __init register_tracer(struct tracer *type)
 		/*allocate a dummy tracer_flags*/
 		type->flags = kmalloc(sizeof(*type->flags), GFP_KERNEL);
 		if (!type->flags) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			ret = -ENOMEM;
 			goto out;
 		}
@@ -1618,7 +1676,9 @@ int __init register_tracer(struct tracer *type)
 		type->flags->opts = dummy_tracer_opt;
 	} else
 		if (!type->flags->opts)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			type->flags->opts = dummy_tracer_opt;
+}
 
 	/* store the tracer for __set_tracer_option */
 	type->flags->trace = type;
@@ -1638,9 +1698,11 @@ int __init register_tracer(struct tracer *type)
 	if (ret || !default_bootup_tracer)
 		goto out_unlock;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (strncmp(default_bootup_tracer, type->name, MAX_TRACER_SIZE))
 		goto out_unlock;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	printk(KERN_INFO "Starting tracer '%s'\n", type->name);
 	/* Do we want this tracer to start on bootup? */
 	tracing_set_tracer(&global_trace, type->name);
@@ -1664,7 +1726,9 @@ void tracing_reset(struct trace_buffer *buf, int cpu)
 	struct ring_buffer *buffer = buf->buffer;
 
 	if (!buffer)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	ring_buffer_record_disable(buffer);
 
@@ -1681,7 +1745,9 @@ void tracing_reset_online_cpus(struct trace_buffer *buf)
 	int cpu;
 
 	if (!buffer)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	ring_buffer_record_disable(buffer);
 
@@ -1701,6 +1767,7 @@ void tracing_reset_all_online_cpus(void)
 {
 	struct trace_array *tr;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry(tr, &ftrace_trace_arrays, list) {
 		if (!tr->clear_trace)
 			continue;
@@ -1731,11 +1798,13 @@ static atomic_t trace_record_taskinfo_disabled __read_mostly;
 
 static inline char *get_saved_cmdlines(int idx)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return &savedcmd->saved_cmdlines[idx * TASK_COMM_LEN];
 }
 
 static inline void set_cmdline(int idx, const char *cmdline)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	memcpy(get_saved_cmdlines(idx), cmdline, TASK_COMM_LEN);
 }
 
@@ -1745,10 +1814,13 @@ static int allocate_cmdlines_buffer(unsigned int val,
 	s->map_cmdline_to_pid = kmalloc(val * sizeof(*s->map_cmdline_to_pid),
 					GFP_KERNEL);
 	if (!s->map_cmdline_to_pid)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 
 	s->saved_cmdlines = kmalloc(val * TASK_COMM_LEN, GFP_KERNEL);
 	if (!s->saved_cmdlines) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		kfree(s->map_cmdline_to_pid);
 		return -ENOMEM;
 	}
@@ -1769,20 +1841,25 @@ static int trace_create_savedcmd(void)
 
 	savedcmd = kmalloc(sizeof(*savedcmd), GFP_KERNEL);
 	if (!savedcmd)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 
 	ret = allocate_cmdlines_buffer(SAVED_CMDLINES_DEFAULT, savedcmd);
 	if (ret < 0) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		kfree(savedcmd);
 		savedcmd = NULL;
 		return -ENOMEM;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
 int is_tracing_stopped(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return global_trace.stop_count;
 }
 
@@ -1798,7 +1875,9 @@ void tracing_start(void)
 	unsigned long flags;
 
 	if (tracing_disabled)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	raw_spin_lock_irqsave(&global_trace.start_lock, flags);
 	if (--global_trace.stop_count) {
@@ -1835,7 +1914,9 @@ static void tracing_start_tr(struct trace_array *tr)
 	unsigned long flags;
 
 	if (tracing_disabled)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	/* If global, we need to also start the max tracer */
 	if (tr->flags & TRACE_ARRAY_FL_GLOBAL)
@@ -1871,6 +1952,7 @@ void tracing_stop(void)
 	struct ring_buffer *buffer;
 	unsigned long flags;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	raw_spin_lock_irqsave(&global_trace.start_lock, flags);
 	if (global_trace.stop_count++)
 		goto out;
@@ -1901,7 +1983,9 @@ static void tracing_stop_tr(struct trace_array *tr)
 
 	/* If global, we need to also stop the max tracer */
 	if (tr->flags & TRACE_ARRAY_FL_GLOBAL)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return tracing_stop();
+}
 
 	raw_spin_lock_irqsave(&tr->start_lock, flags);
 	if (tr->stop_count++)
@@ -1921,7 +2005,9 @@ static int trace_save_cmdline(struct task_struct *tsk)
 
 	/* treat recording of idle task as a success */
 	if (!tsk->pid)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 1;
+}
 
 	if (unlikely(tsk->pid > PID_MAX_DEFAULT))
 		return 0;
@@ -1967,6 +2053,7 @@ static void __trace_find_cmdline(int pid, char comm[])
 	unsigned map;
 
 	if (!pid) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		strcpy(comm, "<idle>");
 		return;
 	}
@@ -1990,6 +2077,7 @@ static void __trace_find_cmdline(int pid, char comm[])
 
 void trace_find_cmdline(int pid, char comm[])
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	preempt_disable();
 	arch_spin_lock(&trace_cmdline_lock);
 
@@ -2001,6 +2089,7 @@ void trace_find_cmdline(int pid, char comm[])
 
 int trace_find_tgid(int pid)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (unlikely(!tgid_map || !pid || pid > PID_MAX_DEFAULT))
 		return 0;
 
@@ -2022,6 +2111,7 @@ static int trace_save_tgid(struct task_struct *tsk)
 
 static bool tracing_record_taskinfo_skip(int flags)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (unlikely(!(flags & (TRACE_RECORD_CMDLINE | TRACE_RECORD_TGID))))
 		return true;
 	if (atomic_read(&trace_record_taskinfo_disabled) || !tracing_is_on())
@@ -2043,7 +2133,9 @@ void tracing_record_taskinfo(struct task_struct *task, int flags)
 	bool done;
 
 	if (tracing_record_taskinfo_skip(flags))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	/*
 	 * Record as much task information as possible. If some fail, continue
@@ -2073,7 +2165,9 @@ void tracing_record_taskinfo_sched_switch(struct task_struct *prev,
 	bool done;
 
 	if (tracing_record_taskinfo_skip(flags))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	/*
 	 * Record as much task information as possible. If some fail, continue
@@ -2094,11 +2188,13 @@ void tracing_record_taskinfo_sched_switch(struct task_struct *prev,
 /* Helpers to record a specific task information */
 void tracing_record_cmdline(struct task_struct *task)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	tracing_record_taskinfo(task, TRACE_RECORD_CMDLINE);
 }
 
 void tracing_record_tgid(struct task_struct *task)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	tracing_record_taskinfo(task, TRACE_RECORD_TGID);
 }
 
@@ -2109,6 +2205,7 @@ void tracing_record_tgid(struct task_struct *task)
  */
 enum print_line_t trace_handle_return(struct trace_seq *s)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return trace_seq_has_overflowed(s) ?
 		TRACE_TYPE_PARTIAL_LINE : TRACE_TYPE_HANDLED;
 }
@@ -2118,6 +2215,7 @@ void
 tracing_generic_entry_update(struct trace_entry *entry, unsigned long flags,
 			     int pc)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct task_struct *tsk = current;
 
 	entry->preempt_count		= pc & 0xff;
@@ -2142,6 +2240,7 @@ trace_buffer_lock_reserve(struct ring_buffer *buffer,
 			  unsigned long len,
 			  unsigned long flags, int pc)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return __trace_buffer_lock_reserve(buffer, type, len, flags, pc);
 }
 
@@ -2169,6 +2268,7 @@ void trace_buffered_event_enable(void)
 	struct page *page;
 	int cpu;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WARN_ON_ONCE(!mutex_is_locked(&event_mutex));
 
 	if (trace_buffered_event_ref++)
@@ -2207,6 +2307,7 @@ static void enable_trace_buffered_event(void *data)
 
 static void disable_trace_buffered_event(void *data)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	this_cpu_inc(trace_buffered_event_cnt);
 }
 
@@ -2222,6 +2323,7 @@ void trace_buffered_event_disable(void)
 {
 	int cpu;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WARN_ON_ONCE(!mutex_is_locked(&event_mutex));
 
 	if (WARN_ON_ONCE(!trace_buffered_event_ref))
@@ -2347,7 +2449,9 @@ int tracepoint_printk_sysctl(struct ctl_table *table, int write,
 	 * is always zero when tracepoint_printk_iter is not allocated
 	 */
 	if (!tracepoint_print_iter)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		tracepoint_printk = 0;
+}
 
 	if (save_tracepoint_printk == tracepoint_printk)
 		goto out;
@@ -2365,6 +2469,7 @@ int tracepoint_printk_sysctl(struct ctl_table *table, int write,
 
 void trace_event_buffer_commit(struct trace_event_buffer *fbuffer)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (static_key_false(&tracepoint_printk_key.key))
 		output_printk(fbuffer);
 
@@ -2380,6 +2485,7 @@ void trace_buffer_unlock_commit_regs(struct trace_array *tr,
 				     unsigned long flags, int pc,
 				     struct pt_regs *regs)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	__buffer_unlock_commit(buffer, event);
 
 	/*
@@ -2403,6 +2509,7 @@ void
 trace_buffer_unlock_commit_nostack(struct ring_buffer *buffer,
 				   struct ring_buffer_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	__buffer_unlock_commit(buffer, event);
 }
 
@@ -2426,11 +2533,13 @@ static DEFINE_STATIC_KEY_FALSE(ftrace_exports_enabled);
 
 static inline void ftrace_exports_enable(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	static_branch_enable(&ftrace_exports_enabled);
 }
 
 static inline void ftrace_exports_disable(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	static_branch_disable(&ftrace_exports_enabled);
 }
 
@@ -2440,6 +2549,7 @@ void ftrace_exports(struct ring_buffer_event *event)
 
 	preempt_disable_notrace();
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	export = rcu_dereference_raw_notrace(ftrace_exports_list);
 	while (export) {
 		trace_process_export(export, event);
@@ -2452,6 +2562,7 @@ void ftrace_exports(struct ring_buffer_event *event)
 static inline void
 add_trace_export(struct trace_export **list, struct trace_export *export)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rcu_assign_pointer(export->next, *list);
 	/*
 	 * We are entering export into the list but another
@@ -2467,6 +2578,7 @@ rm_trace_export(struct trace_export **list, struct trace_export *export)
 {
 	struct trace_export **p;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (p = list; *p != NULL; p = &(*p)->next)
 		if (*p == export)
 			break;
@@ -2482,6 +2594,7 @@ rm_trace_export(struct trace_export **list, struct trace_export *export)
 static inline void
 add_ftrace_export(struct trace_export **list, struct trace_export *export)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (*list == NULL)
 		ftrace_exports_enable();
 
@@ -2495,13 +2608,16 @@ rm_ftrace_export(struct trace_export **list, struct trace_export *export)
 
 	ret = rm_trace_export(list, export);
 	if (*list == NULL)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ftrace_exports_disable();
+}
 
 	return ret;
 }
 
 int register_ftrace_export(struct trace_export *export)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (WARN_ON_ONCE(!export->write))
 		return -1;
 
@@ -2542,7 +2658,9 @@ trace_function(struct trace_array *tr,
 	event = __trace_buffer_lock_reserve(buffer, TRACE_FN, sizeof(*entry),
 					    flags, pc);
 	if (!event)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 	entry	= ring_buffer_event_data(event);
 	entry->ip			= ip;
 	entry->parent_ip		= parent_ip;
@@ -2583,7 +2701,9 @@ static void __ftrace_trace_stack(struct ring_buffer *buffer,
 	 * If regs is set, then these functions will not be in the way.
 	 */
 	if (!regs)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		trace.skip += 2;
+}
 
 	/*
 	 * Since events can happen in NMIs there's no safe way to
@@ -2657,6 +2777,7 @@ static inline void ftrace_trace_stack(struct trace_array *tr,
 				      unsigned long flags,
 				      int skip, int pc, struct pt_regs *regs)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!(tr->trace_flags & TRACE_ITER_STACKTRACE))
 		return;
 
@@ -2669,6 +2790,7 @@ void __trace_stack(struct trace_array *tr, unsigned long flags, int skip,
 	struct ring_buffer *buffer = tr->trace_buffer.buffer;
 
 	if (rcu_is_watching()) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		__ftrace_trace_stack(buffer, flags, skip, pc, NULL);
 		return;
 	}
@@ -2706,6 +2828,7 @@ void trace_dump_stack(int skip)
 {
 	unsigned long flags;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (tracing_disabled || tracing_selftest_running)
 		return;
 
@@ -2731,7 +2854,9 @@ ftrace_trace_userstack(struct ring_buffer *buffer, unsigned long flags, int pc)
 	struct stack_trace trace;
 
 	if (!(global_trace.trace_flags & TRACE_ITER_USERSTACKTRACE))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	/*
 	 * NMIs can not handle page faults, even with fix ups.
@@ -2797,6 +2922,7 @@ static struct trace_buffer_struct *trace_percpu_buffer;
  */
 static char *get_trace_buf(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct trace_buffer_struct *buffer = this_cpu_ptr(trace_percpu_buffer);
 
 	if (!buffer || buffer->nesting >= 4)
@@ -2821,6 +2947,7 @@ static int alloc_percpu_trace_buffer(void)
 	struct trace_buffer_struct *buffers;
 
 	buffers = alloc_percpu(struct trace_buffer_struct);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (WARN(!buffers, "Could not allocate percpu trace_printk buffer"))
 		return -ENOMEM;
 
@@ -2832,6 +2959,7 @@ static int buffers_allocated;
 
 void trace_printk_init_buffers(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (buffers_allocated)
 		return;
 
@@ -2874,12 +3002,16 @@ void trace_printk_start_comm(void)
 {
 	/* Start tracing comms if trace printk is set */
 	if (!buffers_allocated)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	tracing_start_cmdline_record();
 }
 
 static void trace_printk_start_stop_comm(int enabled)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!buffers_allocated)
 		return;
 
@@ -2904,6 +3036,7 @@ int trace_vbprintk(unsigned long ip, const char *fmt, va_list args)
 	char *tbuffer;
 	int len = 0, size, pc;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (unlikely(tracing_selftest_running || tracing_disabled))
 		return 0;
 
@@ -2963,6 +3096,7 @@ __trace_array_vprintk(struct ring_buffer *buffer,
 	unsigned long flags;
 	char *tbuffer;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (tracing_disabled || tracing_selftest_running)
 		return 0;
 
@@ -3009,6 +3143,7 @@ __trace_array_vprintk(struct ring_buffer *buffer,
 int trace_array_vprintk(struct trace_array *tr,
 			unsigned long ip, const char *fmt, va_list args)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return __trace_array_vprintk(tr->trace_buffer.buffer, ip, fmt, args);
 }
 
@@ -3019,7 +3154,9 @@ int trace_array_printk(struct trace_array *tr,
 	va_list ap;
 
 	if (!(global_trace.trace_flags & TRACE_ITER_PRINTK))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	va_start(ap, fmt);
 	ret = trace_array_vprintk(tr, ip, fmt, ap);
@@ -3034,7 +3171,9 @@ int trace_array_printk_buf(struct ring_buffer *buffer,
 	va_list ap;
 
 	if (!(global_trace.trace_flags & TRACE_ITER_PRINTK))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	va_start(ap, fmt);
 	ret = __trace_array_vprintk(buffer, ip, fmt, ap);
@@ -3044,12 +3183,14 @@ int trace_array_printk_buf(struct ring_buffer *buffer,
 
 int trace_vprintk(unsigned long ip, const char *fmt, va_list args)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return trace_array_vprintk(&global_trace, ip, fmt, args);
 }
 EXPORT_SYMBOL_GPL(trace_vprintk);
 
 static void trace_iterator_increment(struct trace_iterator *iter)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct ring_buffer_iter *buf_iter = trace_buffer_iter(iter, iter->cpu);
 
 	iter->idx++;
@@ -3065,7 +3206,9 @@ peek_next_entry(struct trace_iterator *iter, int cpu, u64 *ts,
 	struct ring_buffer_iter *buf_iter = trace_buffer_iter(iter, cpu);
 
 	if (buf_iter)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		event = ring_buffer_iter_peek(buf_iter, ts);
+}
 	else
 		event = ring_buffer_peek(iter->trace_buffer->buffer, cpu, ts,
 					 lost_events);
@@ -3096,6 +3239,7 @@ __find_next_entry(struct trace_iterator *iter, int *ent_cpu,
 	 * all cpu and peek directly.
 	 */
 	if (cpu_file > RING_BUFFER_ALL_CPUS) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (ring_buffer_empty_cpu(buffer, cpu_file))
 			return NULL;
 		ent = peek_next_entry(iter, cpu_file, ent_ts, missing_events);
@@ -3142,12 +3286,14 @@ __find_next_entry(struct trace_iterator *iter, int *ent_cpu,
 struct trace_entry *trace_find_next_entry(struct trace_iterator *iter,
 					  int *ent_cpu, u64 *ent_ts)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return __find_next_entry(iter, ent_cpu, NULL, ent_ts);
 }
 
 /* Find the next real entry, and increment the iterator to the next entry */
 void *trace_find_next_entry_inc(struct trace_iterator *iter)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	iter->ent = __find_next_entry(iter, &iter->cpu,
 				      &iter->lost_events, &iter->ts);
 
@@ -3159,6 +3305,7 @@ void *trace_find_next_entry_inc(struct trace_iterator *iter)
 
 static void trace_consume(struct trace_iterator *iter)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	ring_buffer_consume(iter->trace_buffer->buffer, iter->cpu, &iter->ts,
 			    &iter->lost_events);
 }
@@ -3169,6 +3316,7 @@ static void *s_next(struct seq_file *m, void *v, loff_t *pos)
 	int i = (int)*pos;
 	void *ent;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WARN_ON_ONCE(iter->leftover);
 
 	(*pos)++;
@@ -3197,6 +3345,7 @@ void tracing_iter_reset(struct trace_iterator *iter, int cpu)
 	unsigned long entries = 0;
 	u64 ts;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	per_cpu_ptr(iter->trace_buffer->data, cpu)->skipped_entries = 0;
 
 	buf_iter = trace_buffer_iter(iter, cpu);
@@ -3240,6 +3389,7 @@ static void *s_start(struct seq_file *m, loff_t *pos)
 	 * will point to the same string as current_trace->name.
 	 */
 	mutex_lock(&trace_types_lock);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (unlikely(tr->current_trace && iter->trace->name != tr->current_trace->name))
 		*iter->trace = *tr->current_trace;
 	mutex_unlock(&trace_types_lock);
@@ -3295,7 +3445,9 @@ static void s_stop(struct seq_file *m, void *p)
 #endif
 
 	if (!iter->snapshot)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		atomic_dec(&trace_record_taskinfo_disabled);
+}
 
 	trace_access_unlock(iter->cpu_file);
 	trace_event_read_unlock();
@@ -3311,6 +3463,7 @@ get_total_entries(struct trace_buffer *buf,
 	*total = 0;
 	*entries = 0;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for_each_tracing_cpu(cpu) {
 		count = ring_buffer_entries_cpu(buf->buffer, cpu);
 		/*
@@ -3331,6 +3484,7 @@ get_total_entries(struct trace_buffer *buf,
 
 static void print_lat_help_header(struct seq_file *m)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	seq_puts(m, "#                  _------=> CPU#            \n"
 		    "#                 / _-----=> irqs-off        \n"
 		    "#                | / _----=> need-resched    \n"
@@ -3359,6 +3513,7 @@ static void print_func_help_header(struct trace_buffer *buf, struct seq_file *m,
 
 	print_event_info(buf, m);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	seq_printf(m, "#           TASK-PID   CPU#   %s  TIMESTAMP  FUNCTION\n", tgid ? "TGID     " : "");
 	seq_printf(m, "#              | |       |    %s     |         |\n",	 tgid ? "  |      " : "");
 }
@@ -3391,6 +3546,7 @@ print_trace_header(struct seq_file *m, struct trace_iterator *iter)
 {
 	unsigned long sym_flags = (global_trace.trace_flags & TRACE_ITER_SYM_MASK);
 	struct trace_buffer *buf = iter->trace_buffer;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct trace_array_cpu *data = per_cpu_ptr(buf->data, buf->cpu);
 	struct tracer *type = iter->trace;
 	unsigned long entries;
@@ -3454,7 +3610,9 @@ static void test_cpu_buff_start(struct trace_iterator *iter)
 	struct trace_array *tr = iter->tr;
 
 	if (!(tr->trace_flags & TRACE_ITER_ANNOTATE))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	if (!(iter->iter_flags & TRACE_FILE_ANNOTATE))
 		return;
@@ -3490,6 +3648,7 @@ static enum print_line_t print_trace_fmt(struct trace_iterator *iter)
 	event = ftrace_find_event(entry->type);
 
 	if (tr->trace_flags & TRACE_ITER_CONTEXT_INFO) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (iter->iter_flags & TRACE_FILE_LAT_FMT)
 			trace_print_lat_context(iter);
 		else
@@ -3517,8 +3676,10 @@ static enum print_line_t print_raw_fmt(struct trace_iterator *iter)
 	entry = iter->ent;
 
 	if (tr->trace_flags & TRACE_ITER_CONTEXT_INFO)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		trace_seq_printf(s, "%d %d %llu ",
 				 entry->pid, iter->cpu, iter->ts);
+}
 
 	if (trace_seq_has_overflowed(s))
 		return TRACE_TYPE_PARTIAL_LINE;
@@ -3543,6 +3704,7 @@ static enum print_line_t print_hex_fmt(struct trace_iterator *iter)
 	entry = iter->ent;
 
 	if (tr->trace_flags & TRACE_ITER_CONTEXT_INFO) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		SEQ_PUT_HEX_FIELD(s, entry->pid);
 		SEQ_PUT_HEX_FIELD(s, iter->cpu);
 		SEQ_PUT_HEX_FIELD(s, iter->ts);
@@ -3572,6 +3734,7 @@ static enum print_line_t print_bin_fmt(struct trace_iterator *iter)
 	entry = iter->ent;
 
 	if (tr->trace_flags & TRACE_ITER_CONTEXT_INFO) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		SEQ_PUT_FIELD(s, entry->pid);
 		SEQ_PUT_FIELD(s, iter->cpu);
 		SEQ_PUT_FIELD(s, iter->ts);
@@ -3591,6 +3754,7 @@ int trace_empty(struct trace_iterator *iter)
 
 	/* If we are looking at one CPU buffer, only check that one */
 	if (iter->cpu_file != RING_BUFFER_ALL_CPUS) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		cpu = iter->cpu_file;
 		buf_iter = trace_buffer_iter(iter, cpu);
 		if (buf_iter) {
@@ -3625,6 +3789,7 @@ enum print_line_t print_trace_line(struct trace_iterator *iter)
 	enum print_line_t ret;
 
 	if (iter->lost_events) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		trace_seq_printf(&iter->seq, "CPU:%d [LOST %lu EVENTS]\n",
 				 iter->cpu, iter->lost_events);
 		if (trace_seq_has_overflowed(&iter->seq))
@@ -3671,7 +3836,9 @@ void trace_latency_header(struct seq_file *m)
 
 	/* print nothing if the buffers are empty */
 	if (trace_empty(iter))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	if (iter->iter_flags & TRACE_FILE_LAT_FMT)
 		print_trace_header(m, iter);
@@ -3687,7 +3854,9 @@ void trace_default_header(struct seq_file *m)
 	unsigned long trace_flags = tr->trace_flags;
 
 	if (!(trace_flags & TRACE_ITER_CONTEXT_INFO))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	if (iter->iter_flags & TRACE_FILE_LAT_FMT) {
 		/* print nothing if the buffers are empty */
@@ -3710,6 +3879,7 @@ void trace_default_header(struct seq_file *m)
 
 static void test_ftrace_alive(struct seq_file *m)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!ftrace_is_dead())
 		return;
 	seq_puts(m, "# WARNING: FUNCTION TRACING IS CORRUPTED\n"
@@ -3830,7 +4000,9 @@ __tracing_open(struct inode *inode, struct file *file, bool snapshot)
 	int cpu;
 
 	if (tracing_disabled)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ERR_PTR(-ENODEV);
+}
 
 	iter = __seq_open_private(file, &tracer_seq_ops, sizeof(*iter));
 	if (!iter)
@@ -3919,6 +4091,7 @@ __tracing_open(struct inode *inode, struct file *file, bool snapshot)
 
 int tracing_open_generic(struct inode *inode, struct file *filp)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (tracing_disabled)
 		return -ENODEV;
 
@@ -3928,6 +4101,7 @@ int tracing_open_generic(struct inode *inode, struct file *filp)
 
 bool tracing_is_disabled(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return (tracing_disabled) ? true: false;
 }
 
@@ -3940,7 +4114,9 @@ static int tracing_open_generic_tr(struct inode *inode, struct file *filp)
 	struct trace_array *tr = inode->i_private;
 
 	if (tracing_disabled)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENODEV;
+}
 
 	if (trace_array_get(tr) < 0)
 		return -ENODEV;
@@ -3958,6 +4134,7 @@ static int tracing_release(struct inode *inode, struct file *file)
 	int cpu;
 
 	if (!(file->f_mode & FMODE_READ)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		trace_array_put(tr);
 		return 0;
 	}
@@ -4015,7 +4192,9 @@ static int tracing_open(struct inode *inode, struct file *file)
 	int ret = 0;
 
 	if (trace_array_get(tr) < 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENODEV;
+}
 
 	/* If this file was open for write, then erase contents */
 	if ((file->f_mode & FMODE_WRITE) && (file->f_flags & O_TRUNC)) {
@@ -4062,6 +4241,7 @@ trace_ok_for_array(struct tracer *t, struct trace_array *tr)
 static struct tracer *
 get_tracer_for_array(struct trace_array *tr, struct tracer *t)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	while (t && !trace_ok_for_array(t, tr))
 		t = t->next;
 
@@ -4077,7 +4257,9 @@ t_next(struct seq_file *m, void *v, loff_t *pos)
 	(*pos)++;
 
 	if (t)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		t = get_tracer_for_array(tr, t->next);
+}
 
 	return t;
 }
@@ -4091,6 +4273,7 @@ static void *t_start(struct seq_file *m, loff_t *pos)
 	mutex_lock(&trace_types_lock);
 
 	t = get_tracer_for_array(tr, trace_types);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (; t && l < *pos; t = t_next(m, t, &l))
 			;
 
@@ -4099,6 +4282,7 @@ static void *t_start(struct seq_file *m, loff_t *pos)
 
 static void t_stop(struct seq_file *m, void *p)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	mutex_unlock(&trace_types_lock);
 }
 
@@ -4107,7 +4291,9 @@ static int t_show(struct seq_file *m, void *v)
 	struct tracer *t = v;
 
 	if (!t)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	seq_puts(m, t->name);
 	if (t->next)
@@ -4132,7 +4318,9 @@ static int show_traces_open(struct inode *inode, struct file *file)
 	int ret;
 
 	if (tracing_disabled)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENODEV;
+}
 
 	ret = seq_open(file, &show_traces_seq_ops);
 	if (ret)
@@ -4148,6 +4336,7 @@ static ssize_t
 tracing_write_stub(struct file *filp, const char __user *ubuf,
 		   size_t count, loff_t *ppos)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return count;
 }
 
@@ -4156,7 +4345,9 @@ loff_t tracing_lseek(struct file *file, loff_t offset, int whence)
 	int ret;
 
 	if (file->f_mode & FMODE_READ)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ret = seq_lseek(file, offset, whence);
+}
 	else
 		file->f_pos = ret = 0;
 
@@ -4182,6 +4373,7 @@ static ssize_t
 tracing_cpumask_read(struct file *filp, char __user *ubuf,
 		     size_t count, loff_t *ppos)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct trace_array *tr = file_inode(filp)->i_private;
 	char *mask_str;
 	int len;
@@ -4210,6 +4402,7 @@ static ssize_t
 tracing_cpumask_write(struct file *filp, const char __user *ubuf,
 		      size_t count, loff_t *ppos)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct trace_array *tr = file_inode(filp)->i_private;
 	cpumask_var_t tracing_cpumask_new;
 	int err, cpu;
@@ -4272,6 +4465,7 @@ static int tracing_trace_options_show(struct seq_file *m, void *v)
 	tracer_flags = tr->current_trace->flags->val;
 	trace_opts = tr->current_trace->flags->opts;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (i = 0; trace_options[i]; i++) {
 		if (tr->trace_flags & (1 << i))
 			seq_printf(m, "%s\n", trace_options[i]);
@@ -4299,7 +4493,9 @@ static int __set_tracer_option(struct trace_array *tr,
 
 	ret = trace->set_flag(tr, tracer_flags->val, opts->bit, !neg);
 	if (ret)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ret;
+}
 
 	if (neg)
 		tracer_flags->val &= ~opts->bit;
@@ -4316,6 +4512,7 @@ static int set_tracer_option(struct trace_array *tr, char *cmp, int neg)
 	struct tracer_opt *opts = NULL;
 	int i;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (i = 0; tracer_flags->opts[i].name; i++) {
 		opts = &tracer_flags->opts[i];
 
@@ -4329,6 +4526,7 @@ static int set_tracer_option(struct trace_array *tr, char *cmp, int neg)
 /* Some tracers require overwrite to stay enabled */
 int trace_keep_overwrite(struct tracer *tracer, u32 mask, int set)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (tracer->enabled && (mask & TRACE_ITER_OVERWRITE) && !set)
 		return -1;
 
@@ -4398,6 +4596,7 @@ static int trace_set_options(struct trace_array *tr, char *option)
 	cmp = strstrip(option);
 
 	if (strncmp(cmp, "no", 2) == 0) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		neg = 1;
 		cmp += 2;
 	}
@@ -4432,6 +4631,7 @@ static void __init apply_trace_boot_options(void)
 	char *buf = trace_boot_options_buf;
 	char *option;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	while (true) {
 		option = strsep(&buf, ",");
 
@@ -4439,11 +4639,15 @@ static void __init apply_trace_boot_options(void)
 			break;
 
 		if (*option)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			trace_set_options(&global_trace, option);
+}
 
 		/* Put back the comma to allow this to be called again */
 		if (buf)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			*(buf - 1) = ',';
+}
 	}
 }
 
@@ -4457,7 +4661,9 @@ tracing_trace_options_write(struct file *filp, const char __user *ubuf,
 	int ret;
 
 	if (cnt >= sizeof(buf))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	if (copy_from_user(buf, ubuf, cnt))
 		return -EFAULT;
@@ -4479,7 +4685,9 @@ static int tracing_trace_options_open(struct inode *inode, struct file *file)
 	int ret;
 
 	if (tracing_disabled)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENODEV;
+}
 
 	if (trace_array_get(tr) < 0)
 		return -ENODEV;
@@ -4730,6 +4938,7 @@ static void *saved_tgids_next(struct seq_file *m, void *v, loff_t *pos)
 {
 	int *ptr = v;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (*pos || m->count)
 		ptr++;
 
@@ -4749,7 +4958,9 @@ static void *saved_tgids_start(struct seq_file *m, loff_t *pos)
 	loff_t l = 0;
 
 	if (!tgid_map)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 
 	v = &tgid_map[0];
 	while (l <= *pos) {
@@ -4782,6 +4993,7 @@ static const struct seq_operations tracing_saved_tgids_seq_ops = {
 
 static int tracing_saved_tgids_open(struct inode *inode, struct file *filp)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (tracing_disabled)
 		return -ENODEV;
 
@@ -4800,6 +5012,7 @@ static void *saved_cmdlines_next(struct seq_file *m, void *v, loff_t *pos)
 {
 	unsigned int *ptr = v;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (*pos || m->count)
 		ptr++;
 
@@ -4825,6 +5038,7 @@ static void *saved_cmdlines_start(struct seq_file *m, loff_t *pos)
 	arch_spin_lock(&trace_cmdline_lock);
 
 	v = &savedcmd->map_cmdline_to_pid[0];
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	while (l <= *pos) {
 		v = saved_cmdlines_next(m, v, &l);
 		if (!v)
@@ -4836,6 +5050,7 @@ static void *saved_cmdlines_start(struct seq_file *m, loff_t *pos)
 
 static void saved_cmdlines_stop(struct seq_file *m, void *v)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	arch_spin_unlock(&trace_cmdline_lock);
 	preempt_enable();
 }
@@ -4859,6 +5074,7 @@ static const struct seq_operations tracing_saved_cmdlines_seq_ops = {
 
 static int tracing_saved_cmdlines_open(struct inode *inode, struct file *filp)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (tracing_disabled)
 		return -ENODEV;
 
@@ -4888,6 +5104,7 @@ tracing_saved_cmdlines_size_read(struct file *filp, char __user *ubuf,
 
 static void free_saved_cmdlines_buffer(struct saved_cmdlines_buffer *s)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	kfree(s->saved_cmdlines);
 	kfree(s->map_cmdline_to_pid);
 	kfree(s);
@@ -4899,7 +5116,9 @@ static int tracing_resize_saved_cmdlines(unsigned int val)
 
 	s = kmalloc(sizeof(*s), GFP_KERNEL);
 	if (!s)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 
 	if (allocate_cmdlines_buffer(val, s) < 0) {
 		kfree(s);
@@ -4924,7 +5143,9 @@ tracing_saved_cmdlines_size_write(struct file *filp, const char __user *ubuf,
 
 	ret = kstrtoul_from_user(ubuf, cnt, 10, &val);
 	if (ret)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ret;
+}
 
 	/* must have at least 1 entry or less than PID_MAX_DEFAULT */
 	if (!val || val > PID_MAX_DEFAULT)
@@ -5806,6 +6027,7 @@ tracing_fill_pipe_page(size_t rem, struct trace_iterator *iter)
 
 	/* Seq buffer is page-sized, exactly what we need. */
 	for (;;) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		save_len = iter->seq.seq.len;
 		ret = print_trace_line(iter);
 
@@ -5866,7 +6088,9 @@ static ssize_t tracing_splice_read_pipe(struct file *filp,
 	unsigned int i;
 
 	if (splice_grow_spd(pipe, &spd))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 
 	mutex_lock(&iter->mutex);
 
@@ -5934,6 +6158,7 @@ static ssize_t
 tracing_entries_read(struct file *filp, char __user *ubuf,
 		     size_t cnt, loff_t *ppos)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct inode *inode = file_inode(filp);
 	struct trace_array *tr = inode->i_private;
 	int cpu = tracing_get_cpu(inode);
@@ -5982,6 +6207,7 @@ static ssize_t
 tracing_entries_write(struct file *filp, const char __user *ubuf,
 		      size_t cnt, loff_t *ppos)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct inode *inode = file_inode(filp);
 	struct trace_array *tr = inode->i_private;
 	unsigned long val;
@@ -6016,6 +6242,7 @@ tracing_total_entries_read(struct file *filp, char __user *ubuf,
 	unsigned long size = 0, expanded_size = 0;
 
 	mutex_lock(&trace_types_lock);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for_each_tracing_cpu(cpu) {
 		size += per_cpu_ptr(tr->trace_buffer.data, cpu)->entries >> 10;
 		if (!ring_buffer_expanded)
@@ -6039,6 +6266,7 @@ tracing_free_buffer_write(struct file *filp, const char __user *ubuf,
 	 * is just to make sure that there is no error when "echo" is used
 	 */
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	*ppos += cnt;
 
 	return cnt;
@@ -6051,7 +6279,9 @@ tracing_free_buffer_release(struct inode *inode, struct file *filp)
 
 	/* disable tracing ? */
 	if (tr->trace_flags & TRACE_ITER_STOP_ON_FREE)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		tracer_tracing_off(tr);
+}
 	/* resize the ring buffer to 0 */
 	tracing_resize_ring_buffer(tr, 0, RING_BUFFER_ALL_CPUS);
 
@@ -6078,7 +6308,9 @@ tracing_mark_write(struct file *filp, const char __user *ubuf,
 #define FAULTED_SIZE (sizeof(faulted) - 1) /* '\0' is already accounted for */
 
 	if (tracing_disabled)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	if (!(tr->trace_flags & TRACE_ITER_MARKERS))
 		return -EINVAL;
@@ -6148,7 +6380,9 @@ tracing_mark_raw_write(struct file *filp, const char __user *ubuf,
 #define FAULT_SIZE_ID (FAULTED_SIZE + sizeof(int))
 
 	if (tracing_disabled)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	if (!(tr->trace_flags & TRACE_ITER_MARKERS))
 		return -EINVAL;
@@ -6197,6 +6431,7 @@ static int tracing_clock_show(struct seq_file *m, void *v)
 	struct trace_array *tr = m->private;
 	int i;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (i = 0; i < ARRAY_SIZE(trace_clocks); i++)
 		seq_printf(m,
 			"%s%s%s%s", i ? " " : "",
@@ -6211,6 +6446,7 @@ static int tracing_set_clock(struct trace_array *tr, const char *clockstr)
 {
 	int i;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (i = 0; i < ARRAY_SIZE(trace_clocks); i++) {
 		if (strcmp(trace_clocks[i].name, clockstr) == 0)
 			break;
@@ -6251,7 +6487,9 @@ static ssize_t tracing_clock_write(struct file *filp, const char __user *ubuf,
 	int ret;
 
 	if (cnt >= sizeof(buf))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	if (copy_from_user(buf, ubuf, cnt))
 		return -EFAULT;
@@ -6275,7 +6513,9 @@ static int tracing_clock_open(struct inode *inode, struct file *file)
 	int ret;
 
 	if (tracing_disabled)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENODEV;
+}
 
 	if (trace_array_get(tr))
 		return -ENODEV;
@@ -6560,7 +6800,9 @@ static int tracing_buffers_open(struct inode *inode, struct file *filp)
 	int ret;
 
 	if (tracing_disabled)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENODEV;
+}
 
 	if (trace_array_get(tr) < 0)
 		return -ENODEV;
@@ -6613,7 +6855,9 @@ tracing_buffers_read(struct file *filp, char __user *ubuf,
 	ssize_t size;
 
 	if (!count)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 #ifdef CONFIG_TRACER_MAX_TRACE
 	if (iter->snapshot && iter->tr->current_trace->use_max_tr)
@@ -6689,8 +6933,10 @@ static int tracing_buffers_release(struct inode *inode, struct file *file)
 	__trace_array_put(iter->tr);
 
 	if (info->spare)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ring_buffer_free_read_page(iter->trace_buffer->buffer,
 					   info->spare_cpu, info->spare);
+}
 	kfree(info);
 
 	mutex_unlock(&trace_types_lock);
@@ -6711,7 +6957,9 @@ static void buffer_pipe_buf_release(struct pipe_inode_info *pipe,
 	struct buffer_ref *ref = (struct buffer_ref *)buf->private;
 
 	if (--ref->ref)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	ring_buffer_free_read_page(ref->buffer, ref->cpu, ref->page);
 	kfree(ref);
@@ -6745,7 +6993,9 @@ static void buffer_spd_release(struct splice_pipe_desc *spd, unsigned int i)
 		(struct buffer_ref *)spd->partial[i].private;
 
 	if (--ref->ref)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	ring_buffer_free_read_page(ref->buffer, ref->cpu, ref->page);
 	kfree(ref);
@@ -6778,7 +7028,9 @@ tracing_buffers_splice_read(struct file *file, loff_t *ppos,
 #endif
 
 	if (*ppos & (PAGE_SIZE - 1))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	if (len & (PAGE_SIZE - 1)) {
 		if (len < PAGE_SIZE)
@@ -6874,6 +7126,7 @@ static ssize_t
 tracing_stats_read(struct file *filp, char __user *ubuf,
 		   size_t count, loff_t *ppos)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct inode *inode = file_inode(filp);
 	struct trace_array *tr = inode->i_private;
 	struct trace_buffer *trace_buf = &tr->trace_buffer;
@@ -7125,11 +7378,15 @@ static inline __init int register_snapshot_cmd(void) { return 0; }
 static struct dentry *tracing_get_dentry(struct trace_array *tr)
 {
 	if (WARN_ON(!tr->dir))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ERR_PTR(-ENODEV);
+}
 
 	/* Top directory uses NULL as the parent */
 	if (tr->flags & TRACE_ARRAY_FL_GLOBAL)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 
 	/* All sub buffers have a descriptor */
 	return tr->dir;
@@ -7140,11 +7397,15 @@ static struct dentry *tracing_dentry_percpu(struct trace_array *tr, int cpu)
 	struct dentry *d_tracer;
 
 	if (tr->percpu_dir)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return tr->percpu_dir;
+}
 
 	d_tracer = tracing_get_dentry(tr);
 	if (IS_ERR(d_tracer))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 
 	tr->percpu_dir = tracefs_create_dir("per_cpu", d_tracer);
 
@@ -7173,11 +7434,14 @@ tracing_init_tracefs_percpu(struct trace_array *tr, long cpu)
 	char cpu_dir[30]; /* 30 characters should be more than enough */
 
 	if (!d_percpu)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	snprintf(cpu_dir, 30, "cpu%ld", cpu);
 	d_cpu = tracefs_create_dir(cpu_dir, d_percpu);
 	if (!d_cpu) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_warn("Could not create tracefs '%s' entry\n", cpu_dir);
 		return;
 	}
@@ -7221,7 +7485,9 @@ trace_options_read(struct file *filp, char __user *ubuf, size_t cnt,
 	char *buf;
 
 	if (topt->flags->val & topt->opt->bit)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		buf = "1\n";
+}
 	else
 		buf = "0\n";
 
@@ -7238,7 +7504,9 @@ trace_options_write(struct file *filp, const char __user *ubuf, size_t cnt,
 
 	ret = kstrtoul_from_user(ubuf, cnt, 10, &val);
 	if (ret)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ret;
+}
 
 	if (val != 0 && val != 1)
 		return -EINVAL;
@@ -7292,6 +7560,7 @@ static const struct file_operations trace_options_fops = {
 static void get_tr_index(void *data, struct trace_array **ptr,
 			 unsigned int *pindex)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	*pindex = *(unsigned char *)data;
 
 	*ptr = container_of(data - *pindex, struct trace_array,
@@ -7310,7 +7579,9 @@ trace_options_core_read(struct file *filp, char __user *ubuf, size_t cnt,
 	get_tr_index(tr_index, &tr, &index);
 
 	if (tr->trace_flags & (1 << index))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		buf = "1\n";
+}
 	else
 		buf = "0\n";
 
@@ -7331,7 +7602,9 @@ trace_options_core_write(struct file *filp, const char __user *ubuf, size_t cnt,
 
 	ret = kstrtoul_from_user(ubuf, cnt, 10, &val);
 	if (ret)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ret;
+}
 
 	if (val != 0 && val != 1)
 		return -EINVAL;
@@ -7365,7 +7638,9 @@ struct dentry *trace_create_file(const char *name,
 
 	ret = tracefs_create_file(name, mode, parent, data, fops);
 	if (!ret)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_warn("Could not create tracefs '%s' entry\n", name);
+}
 
 	return ret;
 }
@@ -7376,18 +7651,24 @@ static struct dentry *trace_options_init_dentry(struct trace_array *tr)
 	struct dentry *d_tracer;
 
 	if (tr->options)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return tr->options;
+}
 
 	d_tracer = tracing_get_dentry(tr);
 	if (IS_ERR(d_tracer))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 
 	tr->options = tracefs_create_dir("options", d_tracer);
 	if (!tr->options) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_warn("Could not create tracefs directory 'options'\n");
 		return NULL;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return tr->options;
 }
 
@@ -7401,7 +7682,9 @@ create_trace_option_file(struct trace_array *tr,
 
 	t_options = trace_options_init_dentry(tr);
 	if (!t_options)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	topt->flags = flags;
 	topt->opt = opt;
@@ -7423,26 +7706,35 @@ create_trace_option_files(struct trace_array *tr, struct tracer *tracer)
 	int i;
 
 	if (!tracer)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	flags = tracer->flags;
 
 	if (!flags || !flags->opts)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	/*
 	 * If this is an instance, only create flags for tracers
 	 * the instance may have.
 	 */
 	if (!trace_ok_for_array(tracer, tr))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	for (i = 0; i < tr->nr_topts; i++) {
 		/* Make sure there's no duplicate flags. */
 		if (WARN_ON_ONCE(tr->topts[i].tracer->flags == tracer->flags))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return;
+}
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	opts = flags->opts;
 
 	for (cnt = 0; opts[cnt].name; cnt++)
@@ -7450,11 +7742,14 @@ create_trace_option_files(struct trace_array *tr, struct tracer *tracer)
 
 	topts = kcalloc(cnt + 1, sizeof(*topts), GFP_KERNEL);
 	if (!topts)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	tr_topts = krealloc(tr->topts, sizeof(*tr->topts) * (tr->nr_topts + 1),
 			    GFP_KERNEL);
 	if (!tr_topts) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		kfree(topts);
 		return;
 	}
@@ -7481,7 +7776,9 @@ create_trace_option_core_file(struct trace_array *tr,
 
 	t_options = trace_options_init_dentry(tr);
 	if (!t_options)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 
 	return trace_create_file(option, 0644, t_options,
 				 (void *)&tr->trace_flags_index[index],
@@ -7496,7 +7793,9 @@ static void create_trace_options_dir(struct trace_array *tr)
 
 	t_options = trace_options_init_dentry(tr);
 	if (!t_options)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	for (i = 0; trace_options[i]; i++) {
 		if (top_level ||
@@ -7530,7 +7829,9 @@ rb_simple_write(struct file *filp, const char __user *ubuf,
 
 	ret = kstrtoul_from_user(ubuf, cnt, 10, &val);
 	if (ret)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ret;
+}
 
 	if (buffer) {
 		mutex_lock(&trace_types_lock);
@@ -7575,10 +7876,13 @@ allocate_trace_buffer(struct trace_array *tr, struct trace_buffer *buf, int size
 
 	buf->buffer = ring_buffer_alloc(size, rb_flags);
 	if (!buf->buffer)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 
 	buf->data = alloc_percpu(struct trace_array_cpu);
 	if (!buf->data) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ring_buffer_free(buf->buffer);
 		buf->buffer = NULL;
 		return -ENOMEM;
@@ -7597,7 +7901,9 @@ static int allocate_trace_buffers(struct trace_array *tr, int size)
 
 	ret = allocate_trace_buffer(tr, &tr->trace_buffer, size);
 	if (ret)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ret;
+}
 
 #ifdef CONFIG_TRACER_MAX_TRACE
 	ret = allocate_trace_buffer(tr, &tr->max_buffer,
@@ -7622,6 +7928,7 @@ static int allocate_trace_buffers(struct trace_array *tr, int size)
 
 static void free_trace_buffer(struct trace_buffer *buf)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (buf->buffer) {
 		ring_buffer_free(buf->buffer);
 		buf->buffer = NULL;
@@ -7632,6 +7939,7 @@ static void free_trace_buffer(struct trace_buffer *buf)
 
 static void free_trace_buffers(struct trace_array *tr)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!tr)
 		return;
 
@@ -7674,6 +7982,7 @@ static int instance_mkdir(const char *name)
 	mutex_lock(&trace_types_lock);
 
 	ret = -EEXIST;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry(tr, &ftrace_trace_arrays, list) {
 		if (tr->name && strcmp(tr->name, name) == 0)
 			goto out_unlock;
@@ -7752,6 +8061,7 @@ static int instance_rmdir(const char *name)
 	mutex_lock(&trace_types_lock);
 
 	ret = -ENODEV;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry(tr, &ftrace_trace_arrays, list) {
 		if (tr->name && strcmp(tr->name, name) == 0) {
 			found = 1;
@@ -7804,8 +8114,10 @@ static __init void create_trace_instances(struct dentry *d_tracer)
 							 instance_mkdir,
 							 instance_rmdir);
 	if (WARN_ON(!trace_instance_dir))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
 }
+}
 
 static void
 init_tracer_tracefs(struct trace_array *tr, struct dentry *d_tracer)
@@ -7859,7 +8171,9 @@ init_tracer_tracefs(struct trace_array *tr, struct dentry *d_tracer)
 #endif
 
 	if (ftrace_create_function_files(tr, d_tracer))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		WARN(1, "Could not allocate function filter files");
+}
 
 #ifdef CONFIG_TRACER_SNAPSHOT
 	trace_create_file("snapshot", 0644, d_tracer,
@@ -7884,7 +8198,9 @@ static struct vfsmount *trace_automount(struct dentry *mntpt, void *ingore)
 	 */
 	type = get_fs_type("tracefs");
 	if (!type)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 	mnt = vfs_submount(mntpt, type, "tracefs", NULL);
 	put_filesystem(type);
 	if (IS_ERR(mnt))
@@ -7907,7 +8223,9 @@ struct dentry *tracing_init_dentry(void)
 
 	/* The top level trace array uses  NULL as parent */
 	if (tr->dir)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 
 	if (WARN_ON(!tracefs_initialized()) ||
 		(IS_ENABLED(CONFIG_DEBUG_FS) &&
@@ -7923,10 +8241,12 @@ struct dentry *tracing_init_dentry(void)
 	tr->dir = debugfs_create_automount("tracing", NULL,
 					   trace_automount, NULL);
 	if (!tr->dir) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_warn_once("Could not create debugfs directory 'tracing'\n");
 		return ERR_PTR(-ENOMEM);
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return NULL;
 }
 
@@ -7944,6 +8264,7 @@ static void __init trace_eval_init(void)
 #ifdef CONFIG_MODULES
 static void trace_module_add_evals(struct module *mod)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!mod->num_trace_evals)
 		return;
 
@@ -8020,7 +8341,9 @@ static __init int tracer_init_tracefs(void)
 
 	d_tracer = tracing_init_dentry();
 	if (IS_ERR(d_tracer))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	init_tracer_tracefs(&global_trace, d_tracer);
 	ftrace_init_tracefs_toplevel(&global_trace, d_tracer);
@@ -8063,6 +8386,7 @@ static __init int tracer_init_tracefs(void)
 static int trace_panic_handler(struct notifier_block *this,
 			       unsigned long event, void *unused)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (ftrace_dump_on_oops)
 		ftrace_dump(ftrace_dump_on_oops);
 	return NOTIFY_OK;
@@ -8081,7 +8405,9 @@ static int trace_die_handler(struct notifier_block *self,
 	switch (val) {
 	case DIE_OOPS:
 		if (ftrace_dump_on_oops)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			ftrace_dump(ftrace_dump_on_oops);
+}
 		break;
 	default:
 		break;
@@ -8132,6 +8458,7 @@ trace_printk_seq(struct trace_seq *s)
 
 void trace_init_global_iter(struct trace_iterator *iter)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	iter->tr = &global_trace;
 	iter->trace = iter->tr->current_trace;
 	iter->cpu_file = RING_BUFFER_ALL_CPUS;
@@ -8161,6 +8488,7 @@ void ftrace_dump(enum ftrace_dump_mode oops_dump_mode)
 
 	/* Only allow one dump user at a time. */
 	if (atomic_inc_return(&dump_running) != 1) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		atomic_dec(&dump_running);
 		return;
 	}
@@ -8271,9 +8599,11 @@ __init static int tracer_alloc_buffers(void)
 	 */
 	BUILD_BUG_ON(TRACE_ITER_LAST_BIT > TRACE_FLAGS_MAX_SIZE);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!alloc_cpumask_var(&tracing_buffer_mask, GFP_KERNEL))
 		goto out;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!alloc_cpumask_var(&global_trace.tracing_cpumask, GFP_KERNEL))
 		goto out_free_buffer_mask;
 
@@ -8284,7 +8614,9 @@ __init static int tracer_alloc_buffers(void)
 
 	/* To save memory, keep the ring buffer size to its minimum */
 	if (ring_buffer_expanded)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ring_buf_size = trace_buf_size;
+}
 	else
 		ring_buf_size = 1;
 
@@ -8315,15 +8647,19 @@ __init static int tracer_alloc_buffers(void)
 
 	/* TODO: make the number of buffers hot pluggable with CPUS */
 	if (allocate_trace_buffers(&global_trace, ring_buf_size) < 0) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		printk(KERN_ERR "tracer: failed to allocate ring buffer!\n");
 		WARN_ON(1);
 		goto out_free_savedcmd;
 	}
 
 	if (global_trace.buffer_disabled)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		tracing_off();
+}
 
 	if (trace_boot_clock) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ret = tracing_set_clock(&global_trace, trace_boot_clock);
 		if (ret < 0)
 			pr_warn("Trace clock %s not defined, going back to default\n",
@@ -8387,8 +8723,11 @@ void __init early_trace_init(void)
 	if (tracepoint_printk) {
 		tracepoint_print_iter =
 			kmalloc(sizeof(*tracepoint_print_iter), GFP_KERNEL);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (WARN_ON(!tracepoint_print_iter))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			tracepoint_printk = 0;
+}
 		else
 			static_key_enable(&tracepoint_printk_key.key);
 	}
@@ -8410,8 +8749,11 @@ __init static int clear_boot_tracer(void)
 	 * about to be freed.
 	 */
 	if (!default_bootup_tracer)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	printk(KERN_INFO "ftrace bootup tracer '%s' not registered.\n",
 	       default_bootup_tracer);
 	default_bootup_tracer = NULL;
diff --git a/kernel/trace/trace.h b/kernel/trace/trace.h
index 401b063..4742d4d 100644
--- a/kernel/trace/trace.h
+++ b/kernel/trace/trace.h
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /* SPDX-License-Identifier: GPL-2.0 */
 
 #ifndef _LINUX_KERNEL_TRACE_H
diff --git a/kernel/trace/trace_clock.c b/kernel/trace/trace_clock.c
index 5fdc779..a3d87a1 100644
--- a/kernel/trace/trace_clock.c
+++ b/kernel/trace/trace_clock.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * tracing clocks
  *
@@ -55,6 +57,7 @@ EXPORT_SYMBOL_GPL(trace_clock_local);
  */
 u64 notrace trace_clock(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return local_clock();
 }
 EXPORT_SYMBOL_GPL(trace_clock);
@@ -68,6 +71,7 @@ EXPORT_SYMBOL_GPL(trace_clock);
  */
 u64 notrace trace_clock_jiffies(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return jiffies_64_to_clock_t(jiffies_64 - INITIAL_JIFFIES);
 }
 EXPORT_SYMBOL_GPL(trace_clock_jiffies);
@@ -96,6 +100,7 @@ u64 notrace trace_clock_global(void)
 	int this_cpu;
 	u64 now;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	local_irq_save(flags);
 
 	this_cpu = raw_smp_processor_id();
@@ -137,5 +142,6 @@ static atomic64_t trace_counter;
  */
 u64 notrace trace_clock_counter(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return atomic64_add_return(1, &trace_counter);
 }
diff --git a/kernel/trace/trace_entries.h b/kernel/trace/trace_entries.h
index e954ae3..119b83e 100644
--- a/kernel/trace/trace_entries.h
+++ b/kernel/trace/trace_entries.h
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /* SPDX-License-Identifier: GPL-2.0 */
 /*
  * This file defines the trace event structures that go into the ring
diff --git a/kernel/trace/trace_events.c b/kernel/trace/trace_events.c
index d53268a..3e63f64 100644
--- a/kernel/trace/trace_events.c
+++ b/kernel/trace/trace_events.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * event tracer
  *
@@ -43,16 +45,19 @@ static struct kmem_cache *file_cachep;
 
 static inline int system_refcount(struct event_subsystem *system)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return system->ref_count;
 }
 
 static int system_refcount_inc(struct event_subsystem *system)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return system->ref_count++;
 }
 
 static int system_refcount_dec(struct event_subsystem *system)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return --system->ref_count;
 }
 
@@ -82,6 +87,7 @@ __find_event_field(struct list_head *head, char *name)
 {
 	struct ftrace_event_field *field;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry(field, head, link) {
 		if (!strcmp(field->name, name))
 			return field;
@@ -99,7 +105,9 @@ trace_find_event_field(struct trace_event_call *call, char *name)
 	head = trace_get_fields(call);
 	field = __find_event_field(head, name);
 	if (field)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return field;
+}
 
 	field = __find_event_field(&ftrace_generic_fields, name);
 	if (field)
@@ -116,7 +124,9 @@ static int __trace_define_field(struct list_head *head, const char *type,
 
 	field = kmem_cache_alloc(field_cachep, GFP_TRACE);
 	if (!field)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 
 	field->name = name;
 	field->type = type;
@@ -142,7 +152,9 @@ int trace_define_field(struct trace_event_call *call, const char *type,
 	struct list_head *head;
 
 	if (WARN_ON(!call->class))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	head = trace_get_fields(call);
 	return __trace_define_field(head, type, name, offset, size,
@@ -175,6 +187,7 @@ static int trace_define_generic_fields(void)
 	__generic_field(char *, COMM, FILTER_COMM);
 	__generic_field(char *, comm, FILTER_COMM);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return ret;
 }
 
@@ -188,6 +201,7 @@ static int trace_define_common_fields(void)
 	__common_field(unsigned char, preempt_count);
 	__common_field(int, pid);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return ret;
 }
 
@@ -197,6 +211,7 @@ static void trace_destroy_fields(struct trace_event_call *call)
 	struct list_head *head;
 
 	head = trace_get_fields(call);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry_safe(field, next, head, link) {
 		list_del(&field->link);
 		kmem_cache_free(field_cachep, field);
@@ -227,7 +242,9 @@ int trace_event_raw_init(struct trace_event_call *call)
 
 	id = register_trace_event(&call->event);
 	if (!id)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENODEV;
+}
 
 	return 0;
 }
@@ -239,6 +256,7 @@ bool trace_event_ignore_this_pid(struct trace_event_file *trace_file)
 	struct trace_array_cpu *data;
 	struct trace_pid_list *pid_list;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pid_list = rcu_dereference_sched(tr->filtered_pids);
 	if (!pid_list)
 		return false;
@@ -288,6 +306,7 @@ int trace_event_reg(struct trace_event_call *call,
 {
 	struct trace_event_file *file = data;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WARN_ON(!(call->flags & TRACE_EVENT_FL_TRACEPOINT));
 	switch (type) {
 	case TRACE_REG_REGISTER:
@@ -327,6 +346,7 @@ void trace_event_enable_cmd_record(bool enable)
 	struct trace_array *tr;
 
 	mutex_lock(&event_mutex);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	do_for_each_event_file(tr, file) {
 
 		if (!(file->flags & EVENT_FILE_FL_ENABLED))
@@ -349,6 +369,7 @@ void trace_event_enable_tgid_record(bool enable)
 	struct trace_array *tr;
 
 	mutex_lock(&event_mutex);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	do_for_each_event_file(tr, file) {
 		if (!(file->flags & EVENT_FILE_FL_ENABLED))
 			continue;
@@ -486,12 +507,14 @@ static int __ftrace_event_enable_disable(struct trace_event_file *file,
 int trace_event_enable_disable(struct trace_event_file *file,
 			       int enable, int soft_disable)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return __ftrace_event_enable_disable(file, enable, soft_disable);
 }
 
 static int ftrace_event_enable_disable(struct trace_event_file *file,
 				       int enable)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return __ftrace_event_enable_disable(file, enable, 0);
 }
 
@@ -500,6 +523,7 @@ static void ftrace_clear_events(struct trace_array *tr)
 	struct trace_event_file *file;
 
 	mutex_lock(&event_mutex);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry(file, &tr->events, list) {
 		ftrace_event_enable_disable(file, 0);
 	}
@@ -512,6 +536,7 @@ event_filter_pid_sched_process_exit(void *data, struct task_struct *task)
 	struct trace_pid_list *pid_list;
 	struct trace_array *tr = data;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pid_list = rcu_dereference_sched(tr->filtered_pids);
 	trace_filter_add_remove_task(pid_list, NULL, task);
 }
@@ -524,12 +549,14 @@ event_filter_pid_sched_process_fork(void *data,
 	struct trace_pid_list *pid_list;
 	struct trace_array *tr = data;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pid_list = rcu_dereference_sched(tr->filtered_pids);
 	trace_filter_add_remove_task(pid_list, self, task);
 }
 
 void trace_event_follow_fork(struct trace_array *tr, bool enable)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (enable) {
 		register_trace_prio_sched_process_fork(event_filter_pid_sched_process_fork,
 						       tr, INT_MIN);
@@ -550,6 +577,7 @@ event_filter_pid_sched_switch_probe_pre(void *data, bool preempt,
 	struct trace_array *tr = data;
 	struct trace_pid_list *pid_list;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pid_list = rcu_dereference_sched(tr->filtered_pids);
 
 	this_cpu_write(tr->trace_buffer.data->ignore_pid,
@@ -564,6 +592,7 @@ event_filter_pid_sched_switch_probe_post(void *data, bool preempt,
 	struct trace_array *tr = data;
 	struct trace_pid_list *pid_list;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pid_list = rcu_dereference_sched(tr->filtered_pids);
 
 	this_cpu_write(tr->trace_buffer.data->ignore_pid,
@@ -609,6 +638,7 @@ static void __ftrace_clear_event_pids(struct trace_array *tr)
 	struct trace_event_file *file;
 	int cpu;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pid_list = rcu_dereference_protected(tr->filtered_pids,
 					     lockdep_is_held(&event_mutex));
 	if (!pid_list)
@@ -643,6 +673,7 @@ static void __ftrace_clear_event_pids(struct trace_array *tr)
 
 static void ftrace_clear_event_pids(struct trace_array *tr)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	mutex_lock(&event_mutex);
 	__ftrace_clear_event_pids(tr);
 	mutex_unlock(&event_mutex);
@@ -652,6 +683,7 @@ static void __put_system(struct event_subsystem *system)
 {
 	struct event_filter *filter = system->filter;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WARN_ON_ONCE(system_refcount(system) == 0);
 	if (system_refcount_dec(system))
 		return;
@@ -668,12 +700,14 @@ static void __put_system(struct event_subsystem *system)
 
 static void __get_system(struct event_subsystem *system)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WARN_ON_ONCE(system_refcount(system) == 0);
 	system_refcount_inc(system);
 }
 
 static void __get_system_dir(struct trace_subsystem_dir *dir)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WARN_ON_ONCE(dir->ref_count == 0);
 	dir->ref_count++;
 	__get_system(dir->subsystem);
@@ -681,6 +715,7 @@ static void __get_system_dir(struct trace_subsystem_dir *dir)
 
 static void __put_system_dir(struct trace_subsystem_dir *dir)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WARN_ON_ONCE(dir->ref_count == 0);
 	/* If the subsystem is about to be freed, the dir must be too */
 	WARN_ON_ONCE(system_refcount(dir->subsystem) == 1 && dir->ref_count != 1);
@@ -692,6 +727,7 @@ static void __put_system_dir(struct trace_subsystem_dir *dir)
 
 static void put_system(struct trace_subsystem_dir *dir)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	mutex_lock(&event_mutex);
 	__put_system_dir(dir);
 	mutex_unlock(&event_mutex);
@@ -699,6 +735,7 @@ static void put_system(struct trace_subsystem_dir *dir)
 
 static void remove_subsystem(struct trace_subsystem_dir *dir)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!dir)
 		return;
 
@@ -715,6 +752,7 @@ static void remove_event_file_dir(struct trace_event_file *file)
 	struct dentry *child;
 
 	if (dir) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		spin_lock(&dir->d_lock);	/* probably unneeded */
 		list_for_each_entry(child, &dir->d_subdirs, d_child) {
 			if (d_really_is_positive(child))	/* probably unneeded */
@@ -744,6 +782,7 @@ __ftrace_set_clr_event_nolock(struct trace_array *tr, const char *match,
 	int ret = -EINVAL;
 	int eret = 0;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry(file, &tr->events, list) {
 
 		call = file->event_call;
@@ -813,6 +852,7 @@ static int ftrace_set_clr_event(struct trace_array *tr, char *buf, int set)
 
 	match = strsep(&buf, ":");
 	if (buf) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		sub = match;
 		event = buf;
 		match = NULL;
@@ -846,6 +886,7 @@ static int ftrace_set_clr_event(struct trace_array *tr, char *buf, int set)
  */
 int trace_set_clr_event(const char *system, const char *event, int set)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct trace_array *tr = top_trace_array();
 
 	if (!tr)
@@ -868,7 +909,9 @@ ftrace_event_write(struct file *file, const char __user *ubuf,
 	ssize_t read, ret;
 
 	if (!cnt)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	ret = tracing_update_buffers();
 	if (ret < 0)
@@ -909,6 +952,7 @@ t_next(struct seq_file *m, void *v, loff_t *pos)
 
 	(*pos)++;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry_continue(file, &tr->events, list) {
 		call = file->event_call;
 		/*
@@ -931,6 +975,7 @@ static void *t_start(struct seq_file *m, loff_t *pos)
 
 	mutex_lock(&event_mutex);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	file = list_entry(&tr->events, struct trace_event_file, list);
 	for (l = 0; l <= *pos; ) {
 		file = t_next(m, file, &l);
@@ -948,6 +993,7 @@ s_next(struct seq_file *m, void *v, loff_t *pos)
 
 	(*pos)++;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry_continue(file, &tr->events, list) {
 		if (file->flags & EVENT_FILE_FL_ENABLED)
 			return file;
@@ -964,6 +1010,7 @@ static void *s_start(struct seq_file *m, loff_t *pos)
 
 	mutex_lock(&event_mutex);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	file = list_entry(&tr->events, struct trace_event_file, list);
 	for (l = 0; l <= *pos; ) {
 		file = s_next(m, file, &l);
@@ -979,7 +1026,9 @@ static int t_show(struct seq_file *m, void *v)
 	struct trace_event_call *call = file->event_call;
 
 	if (strcmp(call->class->system, TRACE_SYSTEM) != 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		seq_printf(m, "%s:", call->class->system);
+}
 	seq_printf(m, "%s\n", trace_event_name(call));
 
 	return 0;
@@ -987,6 +1036,7 @@ static int t_show(struct seq_file *m, void *v)
 
 static void t_stop(struct seq_file *m, void *p)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	mutex_unlock(&event_mutex);
 }
 
@@ -994,6 +1044,7 @@ static void *
 p_next(struct seq_file *m, void *v, loff_t *pos)
 {
 	struct trace_array *tr = m->private;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct trace_pid_list *pid_list = rcu_dereference_sched(tr->filtered_pids);
 
 	return trace_pid_next(pid_list, v, pos);
@@ -1014,6 +1065,7 @@ static void *p_start(struct seq_file *m, loff_t *pos)
 	mutex_lock(&event_mutex);
 	rcu_read_lock_sched();
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pid_list = rcu_dereference_sched(tr->filtered_pids);
 
 	if (!pid_list)
@@ -1025,6 +1077,7 @@ static void *p_start(struct seq_file *m, loff_t *pos)
 static void p_stop(struct seq_file *m, void *p)
 	__releases(RCU)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rcu_read_unlock_sched();
 	mutex_unlock(&event_mutex);
 }
@@ -1040,7 +1093,9 @@ event_enable_read(struct file *filp, char __user *ubuf, size_t cnt,
 	mutex_lock(&event_mutex);
 	file = event_file_data(filp);
 	if (likely(file))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		flags = file->flags;
+}
 	mutex_unlock(&event_mutex);
 
 	if (!file)
@@ -1069,7 +1124,9 @@ event_enable_write(struct file *filp, const char __user *ubuf, size_t cnt,
 
 	ret = kstrtoul_from_user(ubuf, cnt, 10, &val);
 	if (ret)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ret;
+}
 
 	ret = tracing_update_buffers();
 	if (ret < 0)
@@ -1110,6 +1167,7 @@ system_enable_read(struct file *filp, char __user *ubuf, size_t cnt,
 	int ret;
 
 	mutex_lock(&event_mutex);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry(file, &tr->events, list) {
 		call = file->event_call;
 		if (!trace_event_name(call) || !call->class || !call->class->reg)
@@ -1153,7 +1211,9 @@ system_enable_write(struct file *filp, const char __user *ubuf, size_t cnt,
 
 	ret = kstrtoul_from_user(ubuf, cnt, 10, &val);
 	if (ret)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ret;
+}
 
 	ret = tracing_update_buffers();
 	if (ret < 0)
@@ -1189,6 +1249,7 @@ enum {
 
 static void *f_next(struct seq_file *m, void *v, loff_t *pos)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct trace_event_call *call = event_file_data(m->private);
 	struct list_head *common_head = &ftrace_common_fields;
 	struct list_head *head = trace_get_fields(call);
@@ -1221,6 +1282,7 @@ static void *f_next(struct seq_file *m, void *v, loff_t *pos)
 
 static int f_show(struct seq_file *m, void *v)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct trace_event_call *call = event_file_data(m->private);
 	struct ftrace_event_field *field;
 	const char *array_descriptor;
@@ -1277,7 +1339,9 @@ static void *f_start(struct seq_file *m, loff_t *pos)
 	/* ->stop() is called even if ->start() fails */
 	mutex_lock(&event_mutex);
 	if (!event_file_data(m->private))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ERR_PTR(-ENODEV);
+}
 
 	while (l < *pos && p)
 		p = f_next(m, p, &l);
@@ -1287,6 +1351,7 @@ static void *f_start(struct seq_file *m, loff_t *pos)
 
 static void f_stop(struct seq_file *m, void *p)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	mutex_unlock(&event_mutex);
 }
 
@@ -1304,7 +1369,9 @@ static int trace_format_open(struct inode *inode, struct file *file)
 
 	ret = seq_open(file, &trace_format_seq_ops);
 	if (ret < 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ret;
+}
 
 	m = file->private_data;
 	m->private = file;
@@ -1315,6 +1382,7 @@ static int trace_format_open(struct inode *inode, struct file *file)
 static ssize_t
 event_id_read(struct file *filp, char __user *ubuf, size_t cnt, loff_t *ppos)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	int id = (long)event_file_data(filp);
 	char buf[32];
 	int len;
@@ -1339,7 +1407,9 @@ event_filter_read(struct file *filp, char __user *ubuf, size_t cnt,
 	int r = -ENODEV;
 
 	if (*ppos)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	s = kmalloc(sizeof(*s), GFP_KERNEL);
 
@@ -1372,7 +1442,9 @@ event_filter_write(struct file *filp, const char __user *ubuf, size_t cnt,
 	int err = -ENODEV;
 
 	if (cnt >= PAGE_SIZE)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	buf = memdup_user_nul(ubuf, cnt);
 	if (IS_ERR(buf))
@@ -1403,7 +1475,9 @@ static int subsystem_open(struct inode *inode, struct file *filp)
 	int ret;
 
 	if (tracing_is_disabled())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENODEV;
+}
 
 	/* Make sure the system still exists */
 	mutex_lock(&trace_types_lock);
@@ -1452,7 +1526,9 @@ static int system_tr_open(struct inode *inode, struct file *filp)
 	int ret;
 
 	if (tracing_is_disabled())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENODEV;
+}
 
 	if (trace_array_get(tr) < 0)
 		return -ENODEV;
@@ -1490,7 +1566,9 @@ static int subsystem_release(struct inode *inode, struct file *file)
 	 * all subsystems.
 	 */
 	if (dir->subsystem)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		put_system(dir);
+}
 	else
 		kfree(dir);
 
@@ -1507,7 +1585,9 @@ subsystem_filter_read(struct file *filp, char __user *ubuf, size_t cnt,
 	int r;
 
 	if (*ppos)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	s = kmalloc(sizeof(*s), GFP_KERNEL);
 	if (!s)
@@ -1533,7 +1613,9 @@ subsystem_filter_write(struct file *filp, const char __user *ubuf, size_t cnt,
 	int err;
 
 	if (cnt >= PAGE_SIZE)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	buf = memdup_user_nul(ubuf, cnt);
 	if (IS_ERR(buf))
@@ -1557,7 +1639,9 @@ show_header(struct file *filp, char __user *ubuf, size_t cnt, loff_t *ppos)
 	int r;
 
 	if (*ppos)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	s = kmalloc(sizeof(*s), GFP_KERNEL);
 	if (!s)
@@ -1602,7 +1686,9 @@ ftrace_event_pid_write(struct file *filp, const char __user *ubuf,
 	ssize_t ret;
 
 	if (!cnt)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	ret = tracing_update_buffers();
 	if (ret < 0)
@@ -1784,7 +1870,9 @@ ftrace_event_open(struct inode *inode, struct file *file,
 
 	ret = seq_open(file, seq_ops);
 	if (ret < 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ret;
+}
 	m = file->private_data;
 	/* copy tr over to seq ops */
 	m->private = inode->i_private;
@@ -1817,7 +1905,9 @@ ftrace_event_set_open(struct inode *inode, struct file *file)
 	int ret;
 
 	if (trace_array_get(tr) < 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENODEV;
+}
 
 	if ((file->f_mode & FMODE_WRITE) &&
 	    (file->f_flags & O_TRUNC))
@@ -1837,7 +1927,9 @@ ftrace_event_set_pid_open(struct inode *inode, struct file *file)
 	int ret;
 
 	if (trace_array_get(tr) < 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENODEV;
+}
 
 	if ((file->f_mode & FMODE_WRITE) &&
 	    (file->f_flags & O_TRUNC))
@@ -1857,7 +1949,9 @@ create_new_subsystem(const char *name)
 	/* need to create new entry */
 	system = kmalloc(sizeof(*system), GFP_KERNEL);
 	if (!system)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 
 	system->ref_count = 1;
 
@@ -1907,8 +2001,11 @@ event_subsystem_dir(struct trace_array *tr, const char *name,
 	}
 	/* Reset system variable when not found */
 	if (&system->list == &event_subsystems)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		system = NULL;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	dir = kmalloc(sizeof(*dir), GFP_KERNEL);
 	if (!dir)
 		goto out_fail;
@@ -1918,10 +2015,13 @@ event_subsystem_dir(struct trace_array *tr, const char *name,
 		if (!system)
 			goto out_free;
 	} else
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		__get_system(system);
+}
 
 	dir->entry = tracefs_create_dir(name, parent);
 	if (!dir->entry) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_warn("Failed to create system directory %s\n", name);
 		__put_system(system);
 		goto out_free;
@@ -1936,6 +2036,7 @@ event_subsystem_dir(struct trace_array *tr, const char *name,
 	entry = tracefs_create_file("filter", 0644, dir->entry, dir,
 				    &ftrace_subsystem_filter_fops);
 	if (!entry) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		kfree(system->filter);
 		system->filter = NULL;
 		pr_warn("Could not create tracefs '%s/filter' entry\n", name);
@@ -1953,7 +2054,10 @@ event_subsystem_dir(struct trace_array *tr, const char *name,
  out_fail:
 	/* Only print this message if failed on memory allocation */
 	if (!dir || !system)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_warn("No memory to create event subsystem %s\n", name);
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return NULL;
 }
 
@@ -1974,13 +2078,18 @@ event_create_dir(struct dentry *parent, struct trace_event_file *file)
 	if (strcmp(call->class->system, TRACE_SYSTEM) != 0) {
 		d_events = event_subsystem_dir(tr, call->class->system, file, parent);
 		if (!d_events)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -ENOMEM;
+}
 	} else
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		d_events = parent;
+}
 
 	name = trace_event_name(call);
 	file->dir = tracefs_create_dir(name, d_events);
 	if (!file->dir) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_warn("Could not create tracefs '%s' directory\n", name);
 		return -1;
 	}
@@ -2004,6 +2113,7 @@ event_create_dir(struct dentry *parent, struct trace_event_file *file)
 	if (list_empty(head)) {
 		ret = call->class->define_fields(call);
 		if (ret < 0) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			pr_warn("Could not initialize trace point events/%s\n",
 				name);
 			return -1;
@@ -2035,6 +2145,7 @@ static void remove_event_from_tracers(struct trace_event_call *call)
 	struct trace_event_file *file;
 	struct trace_array *tr;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	do_for_each_event_file_safe(tr, file) {
 		if (file->event_call != call)
 			continue;
@@ -2055,6 +2166,7 @@ static void event_remove(struct trace_event_call *call)
 	struct trace_array *tr;
 	struct trace_event_file *file;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	do_for_each_event_file(tr, file) {
 		if (file->event_call != call)
 			continue;
@@ -2085,14 +2197,19 @@ static int event_init(struct trace_event_call *call)
 
 	name = trace_event_name(call);
 	if (WARN_ON(!name))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	if (call->class->raw_init) {
 		ret = call->class->raw_init(call);
 		if (ret < 0 && ret != -ENOSYS)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			pr_warn("Could not initialize trace events/%s\n", name);
+}
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return ret;
 }
 
@@ -2103,7 +2220,9 @@ __register_event(struct trace_event_call *call, struct module *mod)
 
 	ret = event_init(call);
 	if (ret < 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ret;
+}
 
 	list_add(&call->list, &ftrace_events);
 	call->mod = mod;
@@ -2120,7 +2239,9 @@ static char *eval_replace(char *ptr, struct trace_eval_map *map, int len)
 	elen = snprintf(ptr, 0, "%ld", map->eval_value);
 	/* Make sure there's enough room to replace the string with the value */
 	if (len < elen)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 
 	snprintf(ptr, elen + 1, "%ld", map->eval_value);
 
@@ -2142,6 +2263,7 @@ static void update_event_printk(struct trace_event_call *call,
 
 	for (ptr = call->print_fmt; *ptr; ptr++) {
 		if (*ptr == '\\') {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			ptr++;
 			/* paranoid */
 			if (!*ptr)
@@ -2174,7 +2296,9 @@ static void update_event_printk(struct trace_event_call *call,
 				ptr = eval_replace(ptr, map, len);
 				/* enum/sizeof string smaller than value */
 				if (WARN_ON_ONCE(!ptr))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 					return;
+}
 				/*
 				 * No need to decrement here, as eval_replace()
 				 * returns the pointer to the character passed
@@ -2221,6 +2345,7 @@ void trace_event_eval_update(struct trace_eval_map **map, int len)
 	list_for_each_entry_safe(call, p, &ftrace_events, list) {
 		/* events are usually grouped together with systems */
 		if (!last_system || call->class->system != last_system) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			first = true;
 			last_i = 0;
 			last_system = call->class->system;
@@ -2240,6 +2365,7 @@ void trace_event_eval_update(struct trace_eval_map **map, int len)
 			if (call->class->system == map[i]->system) {
 				/* Save the first system if need be */
 				if (first) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 					last_i = i;
 					first = false;
 				}
@@ -2258,7 +2384,9 @@ trace_create_new_event(struct trace_event_call *call,
 
 	file = kmem_cache_alloc(file_cachep, GFP_TRACE);
 	if (!file)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 
 	file->event_call = call;
 	file->tr = tr;
@@ -2278,7 +2406,9 @@ __trace_add_new_event(struct trace_event_call *call, struct trace_array *tr)
 
 	file = trace_create_new_event(call, tr);
 	if (!file)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 
 	return event_create_dir(tr->event_dir, file);
 }
@@ -2296,7 +2426,9 @@ __trace_early_add_new_event(struct trace_event_call *call,
 
 	file = trace_create_new_event(call, tr);
 	if (!file)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 
 	return 0;
 }
@@ -2313,7 +2445,9 @@ int trace_add_event_call(struct trace_event_call *call)
 
 	ret = __register_event(call, NULL);
 	if (ret >= 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		__add_event_to_tracers(call);
+}
 
 	mutex_unlock(&event_mutex);
 	mutex_unlock(&trace_types_lock);
@@ -2326,6 +2460,7 @@ int trace_add_event_call(struct trace_event_call *call)
  */
 static void __trace_remove_event_call(struct trace_event_call *call)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	event_remove(call);
 	trace_destroy_fields(call);
 	free_event_filter(call->filter);
@@ -2339,7 +2474,9 @@ static int probe_remove_event_call(struct trace_event_call *call)
 
 #ifdef CONFIG_PERF_EVENTS
 	if (call->perf_refcount)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EBUSY;
+}
 #endif
 	do_for_each_event_file(tr, file) {
 		if (file->event_call != call)
@@ -2393,7 +2530,9 @@ static void trace_module_add_events(struct module *mod)
 	struct trace_event_call **call, **start, **end;
 
 	if (!mod->num_trace_events)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	/* Don't add infrastructure for mods without tracepoints */
 	if (trace_module_has_bad_taint(mod)) {
@@ -2416,6 +2555,7 @@ static void trace_module_remove_events(struct module *mod)
 	struct trace_event_call *call, *p;
 
 	down_write(&trace_event_sem);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry_safe(call, p, &ftrace_events, list) {
 		if (call->mod == mod)
 			__trace_remove_event_call(call);
@@ -2467,6 +2607,7 @@ __trace_add_event_dirs(struct trace_array *tr)
 	struct trace_event_call *call;
 	int ret;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry(call, &ftrace_events, list) {
 		ret = __trace_add_new_event(call, tr);
 		if (ret < 0)
@@ -2482,6 +2623,7 @@ find_event_file(struct trace_array *tr, const char *system,  const char *event)
 	struct trace_event_call *call;
 	const char *name;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry(file, &tr->events, list) {
 
 		call = file->event_call;
@@ -2840,8 +2982,10 @@ __trace_early_add_event_dirs(struct trace_array *tr)
 	list_for_each_entry(file, &tr->events, list) {
 		ret = event_create_dir(tr->event_dir, file);
 		if (ret < 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			pr_warn("Could not create directory for event %s\n",
 				trace_event_name(file->event_call));
+}
 	}
 }
 
@@ -2864,8 +3008,10 @@ __trace_early_add_events(struct trace_array *tr)
 
 		ret = __trace_early_add_new_event(call, tr);
 		if (ret < 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			pr_warn("Could not create early event %s\n",
 				trace_event_name(call));
+}
 	}
 }
 
@@ -2875,6 +3021,7 @@ __trace_remove_event_dirs(struct trace_array *tr)
 {
 	struct trace_event_file *file, *next;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry_safe(file, next, &tr->events, list)
 		remove_event_file_dir(file);
 }
@@ -2883,6 +3030,7 @@ static void __add_event_to_tracers(struct trace_event_call *call)
 {
 	struct trace_array *tr;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry(tr, &ftrace_trace_arrays, list)
 		__trace_add_new_event(call, tr);
 }
@@ -2894,6 +3042,7 @@ static char bootup_event_buf[COMMAND_LINE_SIZE] __initdata;
 
 static __init int setup_trace_event(char *str)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	strlcpy(bootup_event_buf, str, COMMAND_LINE_SIZE);
 	ring_buffer_expanded = true;
 	tracing_selftest_disabled = true;
@@ -2912,12 +3061,14 @@ create_event_toplevel_files(struct dentry *parent, struct trace_array *tr)
 	entry = tracefs_create_file("set_event", 0644, parent,
 				    tr, &ftrace_set_event_fops);
 	if (!entry) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_warn("Could not create tracefs 'set_event' entry\n");
 		return -ENOMEM;
 	}
 
 	d_events = tracefs_create_dir("events", parent);
 	if (!d_events) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_warn("Could not create tracefs 'events' directory\n");
 		return -ENOMEM;
 	}
@@ -2925,6 +3076,7 @@ create_event_toplevel_files(struct dentry *parent, struct trace_array *tr)
 	entry = trace_create_file("enable", 0644, d_events,
 				  tr, &ftrace_tr_enable_fops);
 	if (!entry) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_warn("Could not create tracefs 'enable' entry\n");
 		return -ENOMEM;
 	}
@@ -2934,20 +3086,26 @@ create_event_toplevel_files(struct dentry *parent, struct trace_array *tr)
 	entry = tracefs_create_file("set_event_pid", 0644, parent,
 				    tr, &ftrace_set_event_pid_fops);
 	if (!entry)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_warn("Could not create tracefs 'set_event_pid' entry\n");
+}
 
 	/* ring buffer internal formats */
 	entry = trace_create_file("header_page", 0444, d_events,
 				  ring_buffer_print_page_header,
 				  &ftrace_show_header_fops);
 	if (!entry)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_warn("Could not create tracefs 'header_page' entry\n");
+}
 
 	entry = trace_create_file("header_event", 0444, d_events,
 				  ring_buffer_print_entry_header,
 				  &ftrace_show_header_fops);
 	if (!entry)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_warn("Could not create tracefs 'header_event' entry\n");
+}
 
 	tr->event_dir = d_events;
 
@@ -2975,6 +3133,7 @@ int event_trace_add_tracer(struct dentry *parent, struct trace_array *tr)
 	if (ret)
 		goto out_unlock;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	down_write(&trace_event_sem);
 	__trace_add_event_dirs(tr);
 	up_write(&trace_event_sem);
@@ -3012,6 +3171,7 @@ early_event_add_tracer(struct dentry *parent, struct trace_array *tr)
 
 int event_trace_del_tracer(struct trace_array *tr)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	mutex_lock(&event_mutex);
 
 	/* Disable any event triggers and associated soft-disabled events */
@@ -3052,6 +3212,7 @@ early_enable_events(struct trace_array *tr, bool disable_first)
 	char *token;
 	int ret;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	while (true) {
 		token = strsep(&buf, ",");
 
@@ -3061,16 +3222,23 @@ early_enable_events(struct trace_array *tr, bool disable_first)
 		if (*token) {
 			/* Restarting syscalls requires that we stop them first */
 			if (disable_first)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				ftrace_set_clr_event(tr, token, 0);
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			ret = ftrace_set_clr_event(tr, token, 1);
 			if (ret)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				pr_warn("Failed to enable trace event: %s\n", token);
+}
 		}
 
 		/* Put back the comma to allow this to be called again */
 		if (buf)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			*(buf - 1) = ',';
+}
 	}
 }
 
@@ -3081,7 +3249,9 @@ static __init int event_trace_enable(void)
 	int ret;
 
 	if (!tr)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENODEV;
+}
 
 	for_each_event(iter, __start_ftrace_events, __stop_ftrace_events) {
 
@@ -3126,7 +3296,9 @@ static __init int event_trace_enable_again(void)
 
 	tr = top_trace_array();
 	if (!tr)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENODEV;
+}
 
 	early_enable_events(tr, true);
 
@@ -3144,31 +3316,45 @@ static __init int event_trace_init(void)
 
 	tr = top_trace_array();
 	if (!tr)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENODEV;
+}
 
 	d_tracer = tracing_init_dentry();
 	if (IS_ERR(d_tracer))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	entry = tracefs_create_file("available_events", 0444, d_tracer,
 				    tr, &ftrace_avail_fops);
 	if (!entry)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_warn("Could not create tracefs 'available_events' entry\n");
+}
 
 	if (trace_define_generic_fields())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_warn("tracing: Failed to allocated generic fields");
+}
 
 	if (trace_define_common_fields())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_warn("tracing: Failed to allocate common fields");
+}
 
 	ret = early_event_add_tracer(d_tracer, tr);
 	if (ret)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ret;
+}
 
 #ifdef CONFIG_MODULES
 	ret = register_module_notifier(&trace_module_nb);
 	if (ret)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_warn("Failed to register trace events module notifier\n");
+}
 #endif
 	return 0;
 }
diff --git a/kernel/trace/trace_events_filter.c b/kernel/trace/trace_events_filter.c
index a764aec..8aaa8cd 100644
--- a/kernel/trace/trace_events_filter.c
+++ b/kernel/trace/trace_events_filter.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * trace_events_filter - generic event filtering
  *
@@ -274,6 +276,7 @@ static int filter_pred_cpu(struct filter_pred *pred, void *event)
 	int cpu, cmp;
 	int match = 0;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	cpu = raw_smp_processor_id();
 	cmp = pred->val;
 
@@ -314,6 +317,7 @@ static int filter_pred_comm(struct filter_pred *pred, void *event)
 
 static int filter_pred_none(struct filter_pred *pred, void *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
@@ -331,6 +335,7 @@ static int filter_pred_none(struct filter_pred *pred, void *event)
 
 static int regex_match_full(char *str, struct regex *r, int len)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (strncmp(str, r->pattern, len) == 0)
 		return 1;
 	return 0;
@@ -338,6 +343,7 @@ static int regex_match_full(char *str, struct regex *r, int len)
 
 static int regex_match_front(char *str, struct regex *r, int len)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (strncmp(str, r->pattern, r->len) == 0)
 		return 1;
 	return 0;
@@ -345,6 +351,7 @@ static int regex_match_front(char *str, struct regex *r, int len)
 
 static int regex_match_middle(char *str, struct regex *r, int len)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (strnstr(str, r->pattern, len))
 		return 1;
 	return 0;
@@ -362,6 +369,7 @@ static int regex_match_end(char *str, struct regex *r, int len)
 
 static int regex_match_glob(char *str, struct regex *r, int len __maybe_unused)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (glob_match(r->pattern, str))
 		return 1;
 	return 0;
@@ -389,6 +397,7 @@ enum regex_type filter_parse_regex(char *buff, int len, char **search, int *not)
 	int i;
 
 	if (buff[0] == '!') {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		*not = 1;
 		buff++;
 		len--;
@@ -429,6 +438,7 @@ static void filter_build_regex(struct filter_pred *pred)
 	int not = 0;
 
 	if (pred->op == OP_GLOB) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		type = filter_parse_regex(r->pattern, r->len, &search, &not);
 		r->len = strlen(search);
 		memmove(r->pattern, search, r->len+1);
@@ -465,6 +475,7 @@ static struct filter_pred *
 get_pred_parent(struct filter_pred *pred, struct filter_pred *preds,
 		int index, enum move_type *move)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (pred->parent & FILTER_PRED_IS_RIGHT)
 		*move = MOVE_UP_FROM_RIGHT;
 	else
@@ -558,6 +569,7 @@ static int process_ops(struct filter_pred *preds,
 	 */
 	type = op->op == OP_OR;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (i = 0; i < op->val; i++) {
 		pred = &preds[op->ops[i]];
 		if (!WARN_ON_ONCE(!pred->fn))
@@ -629,7 +641,9 @@ int filter_match_preds(struct event_filter *filter, void *rec)
 
 	/* no filter is considered a match */
 	if (!filter)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 1;
+}
 
 	n_preds = filter->n_preds;
 	if (!n_preds)
@@ -651,12 +665,14 @@ EXPORT_SYMBOL_GPL(filter_match_preds);
 
 static void parse_error(struct filter_parse_state *ps, int err, int pos)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	ps->lasterr = err;
 	ps->lasterr_pos = pos;
 }
 
 static void remove_filter_string(struct event_filter *filter)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!filter)
 		return;
 
@@ -667,6 +683,7 @@ static void remove_filter_string(struct event_filter *filter)
 static int replace_filter_string(struct event_filter *filter,
 				 char *filter_string)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	kfree(filter->filter_string);
 	filter->filter_string = kstrdup(filter_string, GFP_KERNEL);
 	if (!filter->filter_string)
@@ -681,6 +698,7 @@ static int append_filter_string(struct event_filter *filter,
 	int newlen;
 	char *new_filter_string;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	BUG_ON(!filter->filter_string);
 	newlen = strlen(filter->filter_string) + strlen(string) + 1;
 	new_filter_string = kmalloc(newlen, GFP_KERNEL);
@@ -703,7 +721,9 @@ static void append_filter_err(struct filter_parse_state *ps,
 
 	buf = (char *)__get_free_page(GFP_KERNEL);
 	if (!buf)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	append_filter_string(filter, "\n");
 	memset(buf, ' ', PAGE_SIZE);
@@ -719,12 +739,14 @@ static void append_filter_err(struct filter_parse_state *ps,
 
 static inline struct event_filter *event_filter(struct trace_event_file *file)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return file->filter;
 }
 
 /* caller must hold event_mutex */
 void print_event_filter(struct trace_event_file *file, struct trace_seq *s)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct event_filter *filter = event_filter(file);
 
 	if (filter && filter->filter_string)
@@ -740,6 +762,7 @@ void print_subsystem_event_filter(struct event_subsystem *system,
 
 	mutex_lock(&event_mutex);
 	filter = system->filter;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (filter && filter->filter_string)
 		trace_seq_printf(s, "%s\n", filter->filter_string);
 	else
@@ -749,6 +772,7 @@ void print_subsystem_event_filter(struct event_subsystem *system,
 
 static int __alloc_pred_stack(struct pred_stack *stack, int n_preds)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	stack->preds = kcalloc(n_preds + 1, sizeof(*stack->preds), GFP_KERNEL);
 	if (!stack->preds)
 		return -ENOMEM;
@@ -758,6 +782,7 @@ static int __alloc_pred_stack(struct pred_stack *stack, int n_preds)
 
 static void __free_pred_stack(struct pred_stack *stack)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	kfree(stack->preds);
 	stack->index = 0;
 }
@@ -767,6 +792,7 @@ static int __push_pred_stack(struct pred_stack *stack,
 {
 	int index = stack->index;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (WARN_ON(index == 0))
 		return -ENOSPC;
 
@@ -783,7 +809,9 @@ __pop_pred_stack(struct pred_stack *stack)
 
 	pred = stack->preds[index++];
 	if (!pred)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 
 	stack->index = index;
 	return pred;
@@ -801,6 +829,7 @@ static int filter_set_pred(struct event_filter *filter,
 	*dest = *src;
 	dest->index = idx;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (dest->op == OP_OR || dest->op == OP_AND) {
 		right = __pop_pred_stack(stack);
 		left = __pop_pred_stack(stack);
@@ -842,6 +871,7 @@ static void __free_preds(struct event_filter *filter)
 	int i;
 
 	if (filter->preds) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		for (i = 0; i < filter->n_preds; i++)
 			kfree(filter->preds[i].ops);
 		kfree(filter->preds);
@@ -858,11 +888,14 @@ static void filter_disable(struct trace_event_file *file)
 	file->flags &= ~EVENT_FILE_FL_FILTERED;
 
 	if (old_flags != file->flags)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		trace_buffered_event_disable();
 }
+}
 
 static void __free_filter(struct event_filter *filter)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!filter)
 		return;
 
@@ -873,6 +906,7 @@ static void __free_filter(struct event_filter *filter)
 
 void free_event_filter(struct event_filter *filter)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	__free_filter(filter);
 }
 
@@ -890,7 +924,9 @@ static int __alloc_preds(struct event_filter *filter, int n_preds)
 	int i;
 
 	if (filter->preds)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		__free_preds(filter);
+}
 
 	filter->preds = kcalloc(n_preds, sizeof(*filter->preds), GFP_KERNEL);
 
@@ -910,6 +946,7 @@ static int __alloc_preds(struct event_filter *filter, int n_preds)
 
 static inline void __remove_filter(struct trace_event_file *file)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	filter_disable(file);
 	remove_filter_string(file->filter);
 }
@@ -919,6 +956,7 @@ static void filter_free_subsystem_preds(struct trace_subsystem_dir *dir,
 {
 	struct trace_event_file *file;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry(file, &tr->events, list) {
 		if (file->system != dir)
 			continue;
@@ -928,6 +966,7 @@ static void filter_free_subsystem_preds(struct trace_subsystem_dir *dir,
 
 static inline void __free_subsystem_filter(struct trace_event_file *file)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	__free_filter(file->filter);
 	file->filter = NULL;
 }
@@ -937,6 +976,7 @@ static void filter_free_subsystem_filters(struct trace_subsystem_dir *dir,
 {
 	struct trace_event_file *file;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry(file, &tr->events, list) {
 		if (file->system != dir)
 			continue;
@@ -951,6 +991,7 @@ static int filter_add_pred(struct filter_parse_state *ps,
 {
 	int err;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (WARN_ON(filter->n_preds == filter->a_preds)) {
 		parse_error(ps, FILT_ERR_TOO_MANY_PREDS, 0);
 		return -ENOSPC;
@@ -968,16 +1009,21 @@ static int filter_add_pred(struct filter_parse_state *ps,
 int filter_assign_type(const char *type)
 {
 	if (strstr(type, "__data_loc") && strstr(type, "char"))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return FILTER_DYN_STRING;
+}
 
 	if (strchr(type, '[') && strstr(type, "char"))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return FILTER_STATIC_STRING;
+}
 
 	return FILTER_OTHER;
 }
 
 static bool is_legal_op(struct ftrace_event_field *field, enum filter_op_ids op)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (is_string_field(field) &&
 	    (op != OP_EQ && op != OP_NE && op != OP_GLOB))
 		return false;
@@ -1042,6 +1088,7 @@ static int init_pred(struct filter_parse_state *ps,
 	pred->offset = field->offset;
 
 	if (!is_legal_op(field, pred->op)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		parse_error(ps, FILT_ERR_ILLEGAL_FIELD_OP, 0);
 		return -EINVAL;
 	}
@@ -1098,6 +1145,7 @@ static void parse_init(struct filter_parse_state *ps,
 		       struct filter_op *ops,
 		       char *infix_string)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	memset(ps, '\0', sizeof(*ps));
 
 	ps->infix.string = infix_string;
@@ -1110,6 +1158,7 @@ static void parse_init(struct filter_parse_state *ps,
 
 static char infix_next(struct filter_parse_state *ps)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!ps->infix.cnt)
 		return 0;
 
@@ -1120,6 +1169,7 @@ static char infix_next(struct filter_parse_state *ps)
 
 static char infix_peek(struct filter_parse_state *ps)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (ps->infix.tail == strlen(ps->infix.string))
 		return 0;
 
@@ -1128,6 +1178,7 @@ static char infix_peek(struct filter_parse_state *ps)
 
 static void infix_advance(struct filter_parse_state *ps)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!ps->infix.cnt)
 		return;
 
@@ -1138,6 +1189,7 @@ static void infix_advance(struct filter_parse_state *ps)
 static inline int is_precedence_lower(struct filter_parse_state *ps,
 				      int a, int b)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return ps->ops[a].precedence < ps->ops[b].precedence;
 }
 
@@ -1145,6 +1197,7 @@ static inline int is_op_char(struct filter_parse_state *ps, char c)
 {
 	int i;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (i = 0; strcmp(ps->ops[i].string, "OP_NONE"); i++) {
 		if (ps->ops[i].string[0] == c)
 			return 1;
@@ -1155,6 +1208,7 @@ static inline int is_op_char(struct filter_parse_state *ps, char c)
 
 static int infix_get_op(struct filter_parse_state *ps, char firstc)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	char nextc = infix_peek(ps);
 	char opstr[3];
 	int i;
@@ -1182,12 +1236,14 @@ static int infix_get_op(struct filter_parse_state *ps, char firstc)
 
 static inline void clear_operand_string(struct filter_parse_state *ps)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	memset(ps->operand.string, '\0', MAX_FILTER_STR_VAL);
 	ps->operand.tail = 0;
 }
 
 static inline int append_operand_char(struct filter_parse_state *ps, char c)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (ps->operand.tail == MAX_FILTER_STR_VAL - 1)
 		return -EINVAL;
 
@@ -1203,7 +1259,9 @@ static int filter_opstack_push(struct filter_parse_state *ps,
 
 	opstack_op = kmalloc(sizeof(*opstack_op), GFP_KERNEL);
 	if (!opstack_op)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 
 	opstack_op->op = op;
 	list_add(&opstack_op->list, &ps->opstack);
@@ -1213,6 +1271,7 @@ static int filter_opstack_push(struct filter_parse_state *ps,
 
 static int filter_opstack_empty(struct filter_parse_state *ps)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return list_empty(&ps->opstack);
 }
 
@@ -1221,7 +1280,9 @@ static int filter_opstack_top(struct filter_parse_state *ps)
 	struct opstack_op *opstack_op;
 
 	if (filter_opstack_empty(ps))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return OP_NONE;
+}
 
 	opstack_op = list_first_entry(&ps->opstack, struct opstack_op, list);
 
@@ -1234,7 +1295,9 @@ static int filter_opstack_pop(struct filter_parse_state *ps)
 	enum filter_op_ids op;
 
 	if (filter_opstack_empty(ps))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return OP_NONE;
+}
 
 	opstack_op = list_first_entry(&ps->opstack, struct opstack_op, list);
 	op = opstack_op->op;
@@ -1247,12 +1310,14 @@ static int filter_opstack_pop(struct filter_parse_state *ps)
 
 static void filter_opstack_clear(struct filter_parse_state *ps)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	while (!filter_opstack_empty(ps))
 		filter_opstack_pop(ps);
 }
 
 static char *curr_operand(struct filter_parse_state *ps)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return ps->operand.string;
 }
 
@@ -1262,7 +1327,9 @@ static int postfix_append_operand(struct filter_parse_state *ps, char *operand)
 
 	elt = kmalloc(sizeof(*elt), GFP_KERNEL);
 	if (!elt)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 
 	elt->op = OP_NONE;
 	elt->operand = kstrdup(operand, GFP_KERNEL);
@@ -1282,7 +1349,9 @@ static int postfix_append_op(struct filter_parse_state *ps, enum filter_op_ids o
 
 	elt = kmalloc(sizeof(*elt), GFP_KERNEL);
 	if (!elt)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 
 	elt->op = op;
 	elt->operand = NULL;
@@ -1296,6 +1365,7 @@ static void postfix_clear(struct filter_parse_state *ps)
 {
 	struct postfix_elt *elt;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	while (!list_empty(&ps->postfix)) {
 		elt = list_first_entry(&ps->postfix, struct postfix_elt, list);
 		list_del(&elt->list);
@@ -1310,6 +1380,7 @@ static int filter_parse(struct filter_parse_state *ps)
 	int in_string = 0;
 	char ch;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	while ((ch = infix_next(ps))) {
 		if (ch == '"') {
 			in_string ^= 1;
@@ -1407,6 +1478,7 @@ static struct filter_pred *create_pred(struct filter_parse_state *ps,
 	memset(&pred, 0, sizeof(pred));
 	pred.op = op;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (op == OP_AND || op == OP_OR)
 		return &pred;
 
@@ -1433,6 +1505,7 @@ static int check_preds(struct filter_parse_state *ps)
 	struct postfix_elt *elt;
 	int cnt = 0;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry(elt, &ps->postfix, list) {
 		if (elt->op == OP_NONE) {
 			cnt++;
@@ -1465,6 +1538,7 @@ static int count_preds(struct filter_parse_state *ps)
 	struct postfix_elt *elt;
 	int n_preds = 0;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry(elt, &ps->postfix, list) {
 		if (elt->op == OP_NONE)
 			continue;
@@ -1484,6 +1558,7 @@ static int check_pred_tree_cb(enum move_type move, struct filter_pred *pred,
 {
 	struct check_pred_data *d = data;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (WARN_ON(d->count++ > d->max)) {
 		*err = -EINVAL;
 		return WALK_PRED_ABORT;
@@ -1531,6 +1606,7 @@ static int count_leafs(struct filter_pred *preds, struct filter_pred *root)
 	int count = 0, ret;
 
 	ret = walk_pred_tree(preds, root, count_leafs_cb, &count);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WARN_ON(ret);
 	return count;
 }
@@ -1548,7 +1624,9 @@ static int fold_pred_cb(enum move_type move, struct filter_pred *pred,
 	struct filter_pred *root = d->root;
 
 	if (move != MOVE_DOWN)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return WALK_PRED_DEFAULT;
+}
 	if (pred->left != FILTER_PRED_INVALID)
 		return WALK_PRED_DEFAULT;
 
@@ -1575,7 +1653,9 @@ static int fold_pred(struct filter_pred *preds, struct filter_pred *root)
 
 	/* If the root is a leaf then do nothing */
 	if (root->left == FILTER_PRED_INVALID)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	/* count the children */
 	children = count_leafs(preds, &preds[root->left]);
@@ -1596,7 +1676,9 @@ static int fold_pred_tree_cb(enum move_type move, struct filter_pred *pred,
 	struct filter_pred *preds = data;
 
 	if (move != MOVE_DOWN)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return WALK_PRED_DEFAULT;
+}
 	if (!(pred->index & FILTER_PRED_FOLD))
 		return WALK_PRED_DEFAULT;
 
@@ -1616,6 +1698,7 @@ static int fold_pred_tree_cb(enum move_type move, struct filter_pred *pred,
 static int fold_pred_tree(struct event_filter *filter,
 			   struct filter_pred *root)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return walk_pred_tree(filter->preds, root, fold_pred_tree_cb,
 			      filter->preds);
 }
@@ -1635,6 +1718,7 @@ static int replace_preds(struct trace_event_call *call,
 
 	n_preds = count_preds(ps);
 	if (n_preds >= MAX_FILTER_PRED) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		parse_error(ps, FILT_ERR_TOO_MANY_PREDS, 0);
 		return -ENOSPC;
 	}
@@ -1740,35 +1824,42 @@ static inline void event_set_filtered_flag(struct trace_event_file *file)
 	file->flags |= EVENT_FILE_FL_FILTERED;
 
 	if (old_flags != file->flags)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		trace_buffered_event_enable();
 }
+}
 
 static inline void event_set_filter(struct trace_event_file *file,
 				    struct event_filter *filter)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rcu_assign_pointer(file->filter, filter);
 }
 
 static inline void event_clear_filter(struct trace_event_file *file)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	RCU_INIT_POINTER(file->filter, NULL);
 }
 
 static inline void
 event_set_no_set_filter_flag(struct trace_event_file *file)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	file->flags |= EVENT_FILE_FL_NO_SET_FILTER;
 }
 
 static inline void
 event_clear_no_set_filter_flag(struct trace_event_file *file)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	file->flags &= ~EVENT_FILE_FL_NO_SET_FILTER;
 }
 
 static inline bool
 event_no_set_filter_flag(struct trace_event_file *file)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (file->flags & EVENT_FILE_FL_NO_SET_FILTER)
 		return true;
 
@@ -1792,6 +1883,7 @@ static int replace_system_preds(struct trace_subsystem_dir *dir,
 	bool fail = true;
 	int err;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry(file, &tr->events, list) {
 		if (file->system != dir)
 			continue;
@@ -1893,6 +1985,7 @@ static int create_filter_start(char *filter_str, bool set_str,
 	struct filter_parse_state *ps = NULL;
 	int err = 0;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WARN_ON_ONCE(*psp || *filterp);
 
 	/* allocate everything, and if any fails, free all and fail */
@@ -1921,6 +2014,7 @@ static int create_filter_start(char *filter_str, bool set_str,
 
 static void create_filter_finish(struct filter_parse_state *ps)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (ps) {
 		filter_opstack_clear(ps);
 		postfix_clear(ps);
@@ -1954,6 +2048,7 @@ static int create_filter(struct trace_event_call *call,
 
 	err = create_filter_start(filter_str, set_str, &ps, &filter);
 	if (!err) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		err = replace_preds(call, filter, ps, false);
 		if (err && set_str)
 			append_filter_err(ps, filter);
@@ -1972,6 +2067,7 @@ int create_event_filter(struct trace_event_call *call,
 			char *filter_str, bool set_str,
 			struct event_filter **filterp)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return create_filter(call, filter_str, set_str, filterp);
 }
 
@@ -1994,6 +2090,7 @@ static int create_system_filter(struct trace_subsystem_dir *dir,
 
 	err = create_filter_start(filter_str, true, &ps, &filter);
 	if (!err) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		err = replace_system_preds(dir, tr, ps, filter_str);
 		if (!err) {
 			/* System filters just show a default message */
@@ -2017,6 +2114,7 @@ int apply_event_filter(struct trace_event_file *file, char *filter_string)
 	int err;
 
 	if (!strcmp(strstrip(filter_string), "0")) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		filter_disable(file);
 		filter = event_filter(file);
 
@@ -2073,6 +2171,7 @@ int apply_subsystem_event_filter(struct trace_subsystem_dir *dir,
 
 	/* Make sure the system still has events */
 	if (!dir->nr_events) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		err = -ENODEV;
 		goto out_unlock;
 	}
@@ -2251,6 +2350,7 @@ static int ftrace_function_set_filter(struct perf_event *event,
 static int ftrace_function_set_filter(struct perf_event *event,
 				      struct event_filter *filter)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return -ENODEV;
 }
 #endif /* CONFIG_FUNCTION_TRACER */
@@ -2270,6 +2370,7 @@ int ftrace_profile_set_filter(struct perf_event *event, int event_id,
 	if (!call)
 		goto out_unlock;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	err = -EEXIST;
 	if (event->filter)
 		goto out_unlock;
diff --git a/kernel/trace/trace_events_trigger.c b/kernel/trace/trace_events_trigger.c
index f2ac9d4..3fa7d54f 100644
--- a/kernel/trace/trace_events_trigger.c
+++ b/kernel/trace/trace_events_trigger.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * trace_events_trigger - trace event triggers
  *
@@ -31,6 +33,7 @@ static DEFINE_MUTEX(trigger_cmd_mutex);
 
 void trigger_data_free(struct event_trigger_data *data)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (data->cmd_ops->set_filter)
 		data->cmd_ops->set_filter(NULL, data, NULL);
 
@@ -70,7 +73,9 @@ event_triggers_call(struct trace_event_file *file, void *rec)
 	struct event_filter *filter;
 
 	if (list_empty(&file->triggers))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return tt;
+}
 
 	list_for_each_entry_rcu(data, &file->triggers, list) {
 		if (data->paused)
@@ -112,6 +117,7 @@ event_triggers_post_call(struct trace_event_file *file,
 {
 	struct event_trigger_data *data;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry_rcu(data, &file->triggers, list) {
 		if (data->paused)
 			continue;
@@ -125,6 +131,7 @@ EXPORT_SYMBOL_GPL(event_triggers_post_call);
 
 static void *trigger_next(struct seq_file *m, void *t, loff_t *pos)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct trace_event_file *event_file = event_file_data(m->private);
 
 	if (t == SHOW_AVAILABLE_TRIGGERS)
@@ -141,7 +148,9 @@ static void *trigger_start(struct seq_file *m, loff_t *pos)
 	mutex_lock(&event_mutex);
 	event_file = event_file_data(m->private);
 	if (unlikely(!event_file))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ERR_PTR(-ENODEV);
+}
 
 	if (list_empty(&event_file->triggers))
 		return *pos == 0 ? SHOW_AVAILABLE_TRIGGERS : NULL;
@@ -151,6 +160,7 @@ static void *trigger_start(struct seq_file *m, loff_t *pos)
 
 static void trigger_stop(struct seq_file *m, void *t)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	mutex_unlock(&event_mutex);
 }
 
@@ -160,6 +170,7 @@ static int trigger_show(struct seq_file *m, void *v)
 	struct event_command *p;
 
 	if (v == SHOW_AVAILABLE_TRIGGERS) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		seq_puts(m, "# Available triggers:\n");
 		seq_putc(m, '#');
 		mutex_lock(&trigger_cmd_mutex);
@@ -190,6 +201,7 @@ static int event_trigger_regex_open(struct inode *inode, struct file *file)
 	mutex_lock(&event_mutex);
 
 	if (unlikely(!event_file_data(file))) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		mutex_unlock(&event_mutex);
 		return -ENODEV;
 	}
@@ -227,6 +239,7 @@ static int trigger_process_regex(struct trace_event_file *file, char *buff)
 	int ret = -EINVAL;
 
 	command = strsep(&next, ": \t");
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	command = (command[0] != '!') ? command : command + 1;
 
 	mutex_lock(&trigger_cmd_mutex);
@@ -251,7 +264,9 @@ static ssize_t event_trigger_regex_write(struct file *file,
 	char *buf;
 
 	if (!cnt)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	if (cnt >= PAGE_SIZE)
 		return -EINVAL;
@@ -284,6 +299,7 @@ static ssize_t event_trigger_regex_write(struct file *file,
 
 static int event_trigger_regex_release(struct inode *inode, struct file *file)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	mutex_lock(&event_mutex);
 
 	if (file->f_mode & FMODE_READ)
@@ -298,18 +314,21 @@ static ssize_t
 event_trigger_write(struct file *filp, const char __user *ubuf,
 		    size_t cnt, loff_t *ppos)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return event_trigger_regex_write(filp, ubuf, cnt, ppos);
 }
 
 static int
 event_trigger_open(struct inode *inode, struct file *filp)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return event_trigger_regex_open(inode, filp);
 }
 
 static int
 event_trigger_release(struct inode *inode, struct file *file)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return event_trigger_regex_release(inode, file);
 }
 
@@ -333,6 +352,7 @@ __init int register_event_command(struct event_command *cmd)
 	mutex_lock(&trigger_cmd_mutex);
 	list_for_each_entry(p, &trigger_commands, list) {
 		if (strcmp(cmd->name, p->name) == 0) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			ret = -EBUSY;
 			goto out_unlock;
 		}
@@ -355,6 +375,7 @@ __init int unregister_event_command(struct event_command *cmd)
 
 	mutex_lock(&trigger_cmd_mutex);
 	list_for_each_entry_safe(p, n, &trigger_commands, list) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (strcmp(cmd->name, p->name) == 0) {
 			ret = 0;
 			list_del_init(&p->list);
@@ -390,7 +411,9 @@ event_trigger_print(const char *name, struct seq_file *m,
 	seq_puts(m, name);
 
 	if (count == -1)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		seq_puts(m, ":unlimited");
+}
 	else
 		seq_printf(m, ":count=%ld", count);
 
@@ -417,6 +440,7 @@ event_trigger_print(const char *name, struct seq_file *m,
 int event_trigger_init(struct event_trigger_ops *ops,
 		       struct event_trigger_data *data)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	data->ref++;
 	return 0;
 }
@@ -435,6 +459,7 @@ static void
 event_trigger_free(struct event_trigger_ops *ops,
 		   struct event_trigger_data *data)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (WARN_ON_ONCE(data->ref <= 0))
 		return;
 
@@ -449,6 +474,7 @@ int trace_event_trigger_enable_disable(struct trace_event_file *file,
 	int ret = 0;
 
 	if (trigger_enable) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (atomic_inc_return(&file->tm_ref) > 1)
 			return ret;
 		set_bit(EVENT_FILE_FL_TRIGGER_MODE_BIT, &file->flags);
@@ -481,6 +507,7 @@ clear_event_triggers(struct trace_array *tr)
 {
 	struct trace_event_file *file;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry(file, &tr->events, list) {
 		struct event_trigger_data *data;
 		list_for_each_entry_rcu(data, &file->triggers, list) {
@@ -506,6 +533,7 @@ void update_cond_flag(struct trace_event_file *file)
 	struct event_trigger_data *data;
 	bool set_cond = false;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry_rcu(data, &file->triggers, list) {
 		if (data->filter || event_command_post_trigger(data->cmd_ops) ||
 		    event_command_needs_rec(data->cmd_ops)) {
@@ -541,6 +569,7 @@ static int register_trigger(char *glob, struct event_trigger_ops *ops,
 	struct event_trigger_data *test;
 	int ret = 0;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry_rcu(test, &file->triggers, list) {
 		if (test->cmd_ops->trigger_type == data->cmd_ops->trigger_type) {
 			ret = -EEXIST;
@@ -586,6 +615,7 @@ void unregister_trigger(char *glob, struct event_trigger_ops *ops,
 	struct event_trigger_data *data;
 	bool unregistered = false;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry_rcu(data, &file->triggers, list) {
 		if (data->cmd_ops->trigger_type == test->cmd_ops->trigger_type) {
 			unregistered = true;
@@ -728,6 +758,7 @@ int set_trigger_filter(char *filter_str,
 	if (!filter_str) /* clear the current filter */
 		goto assign;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	s = strsep(&filter_str, " \t");
 
 	if (!strlen(s) || strcmp(s, "if") != 0)
@@ -787,7 +818,9 @@ struct event_trigger_data *find_named_trigger(const char *name)
 	struct event_trigger_data *data;
 
 	if (!name)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 
 	list_for_each_entry(data, &named_triggers, named_list) {
 		if (data->named_data)
@@ -809,6 +842,7 @@ bool is_named_trigger(struct event_trigger_data *test)
 {
 	struct event_trigger_data *data;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry(data, &named_triggers, named_list) {
 		if (test == data)
 			return true;
@@ -826,6 +860,7 @@ bool is_named_trigger(struct event_trigger_data *test)
  */
 int save_named_trigger(const char *name, struct event_trigger_data *data)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	data->name = kstrdup(name, GFP_KERNEL);
 	if (!data->name)
 		return -ENOMEM;
@@ -841,6 +876,7 @@ int save_named_trigger(const char *name, struct event_trigger_data *data)
  */
 void del_named_trigger(struct event_trigger_data *data)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	kfree(data->name);
 	data->name = NULL;
 
@@ -851,6 +887,7 @@ static void __pause_named_trigger(struct event_trigger_data *data, bool pause)
 {
 	struct event_trigger_data *test;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry(test, &named_triggers, named_list) {
 		if (strcmp(test->name, data->name) == 0) {
 			if (pause) {
@@ -874,6 +911,7 @@ static void __pause_named_trigger(struct event_trigger_data *data, bool pause)
  */
 void pause_named_trigger(struct event_trigger_data *data)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	__pause_named_trigger(data, true);
 }
 
@@ -888,6 +926,7 @@ void pause_named_trigger(struct event_trigger_data *data)
  */
 void unpause_named_trigger(struct event_trigger_data *data)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	__pause_named_trigger(data, false);
 }
 
@@ -905,12 +944,14 @@ void unpause_named_trigger(struct event_trigger_data *data)
 void set_named_trigger_data(struct event_trigger_data *data,
 			    struct event_trigger_data *named_data)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	data->named_data = named_data;
 }
 
 static void
 traceon_trigger(struct event_trigger_data *data, void *rec)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (tracing_is_on())
 		return;
 
@@ -920,6 +961,7 @@ traceon_trigger(struct event_trigger_data *data, void *rec)
 static void
 traceon_count_trigger(struct event_trigger_data *data, void *rec)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (tracing_is_on())
 		return;
 
@@ -935,6 +977,7 @@ traceon_count_trigger(struct event_trigger_data *data, void *rec)
 static void
 traceoff_trigger(struct event_trigger_data *data, void *rec)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!tracing_is_on())
 		return;
 
@@ -944,6 +987,7 @@ traceoff_trigger(struct event_trigger_data *data, void *rec)
 static void
 traceoff_count_trigger(struct event_trigger_data *data, void *rec)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!tracing_is_on())
 		return;
 
@@ -960,6 +1004,7 @@ static int
 traceon_trigger_print(struct seq_file *m, struct event_trigger_ops *ops,
 		      struct event_trigger_data *data)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return event_trigger_print("traceon", m, (void *)data->count,
 				   data->filter_str);
 }
@@ -968,6 +1013,7 @@ static int
 traceoff_trigger_print(struct seq_file *m, struct event_trigger_ops *ops,
 		       struct event_trigger_data *data)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return event_trigger_print("traceoff", m, (void *)data->count,
 				   data->filter_str);
 }
@@ -1007,8 +1053,10 @@ onoff_get_trigger_ops(char *cmd, char *param)
 
 	/* we register both traceon and traceoff to this callback */
 	if (strcmp(cmd, "traceon") == 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ops = param ? &traceon_count_trigger_ops :
 			&traceon_trigger_ops;
+}
 	else
 		ops = param ? &traceoff_count_trigger_ops :
 			&traceoff_trigger_ops;
@@ -1134,12 +1182,14 @@ static __init int register_trigger_snapshot_cmd(void) { return 0; }
 static void
 stacktrace_trigger(struct event_trigger_data *data, void *rec)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	trace_dump_stack(STACK_SKIP);
 }
 
 static void
 stacktrace_count_trigger(struct event_trigger_data *data, void *rec)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!data->count)
 		return;
 
@@ -1153,6 +1203,7 @@ static int
 stacktrace_trigger_print(struct seq_file *m, struct event_trigger_ops *ops,
 			 struct event_trigger_data *data)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return event_trigger_print("stacktrace", m, (void *)data->count,
 				   data->filter_str);
 }
@@ -1174,6 +1225,7 @@ static struct event_trigger_ops stacktrace_count_trigger_ops = {
 static struct event_trigger_ops *
 stacktrace_get_trigger_ops(char *cmd, char *param)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return param ? &stacktrace_count_trigger_ops : &stacktrace_trigger_ops;
 }
 
@@ -1203,6 +1255,7 @@ static __init int register_trigger_stacktrace_cmd(void) { return 0; }
 
 static __init void unregister_trigger_traceon_traceoff_cmds(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	unregister_event_command(&trigger_traceon_cmd);
 	unregister_event_command(&trigger_traceoff_cmd);
 }
@@ -1213,7 +1266,9 @@ event_enable_trigger(struct event_trigger_data *data, void *rec)
 	struct enable_trigger_data *enable_data = data->private_data;
 
 	if (enable_data->enable)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		clear_bit(EVENT_FILE_FL_SOFT_DISABLED_BIT, &enable_data->file->flags);
+}
 	else
 		set_bit(EVENT_FILE_FL_SOFT_DISABLED_BIT, &enable_data->file->flags);
 }
@@ -1224,7 +1279,9 @@ event_enable_count_trigger(struct event_trigger_data *data, void *rec)
 	struct enable_trigger_data *enable_data = data->private_data;
 
 	if (!data->count)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	/* Skip if the event is in a state we want to switch to */
 	if (enable_data->enable == !(enable_data->file->flags & EVENT_FILE_FL_SOFT_DISABLED))
@@ -1267,6 +1324,7 @@ void event_enable_trigger_free(struct event_trigger_ops *ops,
 {
 	struct enable_trigger_data *enable_data = data->private_data;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (WARN_ON_ONCE(data->ref <= 0))
 		return;
 
@@ -1326,7 +1384,9 @@ int event_enable_trigger_func(struct event_command *cmd_ops,
 	int ret;
 
 	if (!param)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	/* separate the trigger from the filter (s:e:n [if filter]) */
 	trigger = strsep(&param, " \t");
@@ -1460,6 +1520,7 @@ int event_enable_register_trigger(char *glob,
 	struct event_trigger_data *test;
 	int ret = 0;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry_rcu(test, &file->triggers, list) {
 		test_enable_data = test->private_data;
 		if (test_enable_data &&
@@ -1500,6 +1561,7 @@ void event_enable_unregister_trigger(char *glob,
 	struct event_trigger_data *data;
 	bool unregistered = false;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry_rcu(data, &file->triggers, list) {
 		enable_data = data->private_data;
 		if (enable_data &&
@@ -1531,8 +1593,10 @@ event_enable_get_trigger_ops(char *cmd, char *param)
 	enable = strcmp(cmd, ENABLE_EVENT_STR) == 0;
 #endif
 	if (enable)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ops = param ? &event_enable_count_trigger_ops :
 			&event_enable_trigger_ops;
+}
 	else
 		ops = param ? &event_disable_count_trigger_ops :
 			&event_disable_trigger_ops;
@@ -1562,6 +1626,7 @@ static struct event_command trigger_disable_cmd = {
 
 static __init void unregister_trigger_enable_disable_cmds(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	unregister_event_command(&trigger_enable_cmd);
 	unregister_event_command(&trigger_disable_cmd);
 }
@@ -1572,11 +1637,16 @@ static __init int register_trigger_enable_disable_cmds(void)
 
 	ret = register_event_command(&trigger_enable_cmd);
 	if (WARN_ON(ret < 0))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ret;
+}
 	ret = register_event_command(&trigger_disable_cmd);
 	if (WARN_ON(ret < 0))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		unregister_trigger_enable_disable_cmds();
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return ret;
 }
 
@@ -1586,11 +1656,16 @@ static __init int register_trigger_traceon_traceoff_cmds(void)
 
 	ret = register_event_command(&trigger_traceon_cmd);
 	if (WARN_ON(ret < 0))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ret;
+}
 	ret = register_event_command(&trigger_traceoff_cmd);
 	if (WARN_ON(ret < 0))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		unregister_trigger_traceon_traceoff_cmds();
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return ret;
 }
 
diff --git a/kernel/trace/trace_functions.c b/kernel/trace/trace_functions.c
index 27f7ad1..9f777e6 100644
--- a/kernel/trace/trace_functions.c
+++ b/kernel/trace/trace_functions.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 /*
  * ring buffer based function tracer
diff --git a/kernel/trace/trace_functions_graph.c b/kernel/trace/trace_functions_graph.c
index 23c0b0c..7b212e3 100644
--- a/kernel/trace/trace_functions_graph.c
+++ b/kernel/trace/trace_functions_graph.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 /*
  *
diff --git a/kernel/trace/trace_kprobe.c b/kernel/trace/trace_kprobe.c
index 8a907e1..127b4fe 100644
--- a/kernel/trace/trace_kprobe.c
+++ b/kernel/trace/trace_kprobe.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * Kprobes-based tracing events
  *
@@ -45,27 +47,32 @@ struct trace_kprobe {
 
 static nokprobe_inline bool trace_kprobe_is_return(struct trace_kprobe *tk)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return tk->rp.handler != NULL;
 }
 
 static nokprobe_inline const char *trace_kprobe_symbol(struct trace_kprobe *tk)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return tk->symbol ? tk->symbol : "unknown";
 }
 
 static nokprobe_inline unsigned long trace_kprobe_offset(struct trace_kprobe *tk)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return tk->rp.kp.offset;
 }
 
 static nokprobe_inline bool trace_kprobe_has_gone(struct trace_kprobe *tk)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return !!(kprobe_gone(&tk->rp.kp));
 }
 
 static nokprobe_inline bool trace_kprobe_within_module(struct trace_kprobe *tk,
 						 struct module *mod)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	int len = strlen(mod->name);
 	const char *name = trace_kprobe_symbol(tk);
 	return strncmp(mod->name, name, len) == 0 && name[len] == ':';
@@ -73,6 +80,7 @@ static nokprobe_inline bool trace_kprobe_within_module(struct trace_kprobe *tk,
 
 static nokprobe_inline bool trace_kprobe_is_on_module(struct trace_kprobe *tk)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return !!strchr(trace_kprobe_symbol(tk), ':');
 }
 
@@ -81,6 +89,7 @@ static nokprobe_inline unsigned long trace_kprobe_nhit(struct trace_kprobe *tk)
 	unsigned long nhit = 0;
 	int cpu;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for_each_possible_cpu(cpu)
 		nhit += *per_cpu_ptr(tk->nhit, cpu);
 
@@ -106,6 +115,7 @@ struct symbol_cache {
 
 unsigned long update_symbol_cache(struct symbol_cache *sc)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	sc->addr = (unsigned long)kallsyms_lookup_name(sc->symbol);
 
 	if (sc->addr)
@@ -116,6 +126,7 @@ unsigned long update_symbol_cache(struct symbol_cache *sc)
 
 void free_symbol_cache(struct symbol_cache *sc)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	kfree(sc->symbol);
 	kfree(sc);
 }
@@ -124,6 +135,7 @@ struct symbol_cache *alloc_symbol_cache(const char *sym, long offset)
 {
 	struct symbol_cache *sc;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!sym || strlen(sym) == 0)
 		return NULL;
 
@@ -184,7 +196,9 @@ static void FETCH_FUNC_NAME(memory, string)(struct pt_regs *regs,
 	long ret;
 
 	if (!maxlen)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	/*
 	 * Try to get string again, since the string can be changed while
@@ -214,6 +228,7 @@ static void FETCH_FUNC_NAME(memory, string_size)(struct pt_regs *regs,
 	pagefault_disable();
 
 	do {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ret = __copy_from_user_inatomic(&c, (u8 *)addr + len, 1);
 		len++;
 	} while (c && ret == 0 && len < MAX_STRING_SIZE);
@@ -291,7 +306,9 @@ static struct trace_kprobe *alloc_trace_kprobe(const char *group,
 
 	tk = kzalloc(SIZEOF_TRACE_KPROBE(nargs), GFP_KERNEL);
 	if (!tk)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ERR_PTR(ret);
+}
 
 	tk->nhit = alloc_percpu(unsigned long);
 	if (!tk->nhit)
@@ -347,6 +364,7 @@ static void free_trace_kprobe(struct trace_kprobe *tk)
 {
 	int i;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (i = 0; i < tk->tp.nr_args; i++)
 		traceprobe_free_probe_arg(&tk->tp.args[i]);
 
@@ -362,6 +380,7 @@ static struct trace_kprobe *find_trace_kprobe(const char *event,
 {
 	struct trace_kprobe *tk;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry(tk, &probe_list, list)
 		if (strcmp(trace_event_name(&tk->tp.call), event) == 0 &&
 		    strcmp(tk->tp.call.class->system, group) == 0)
@@ -383,6 +402,7 @@ enable_trace_kprobe(struct trace_kprobe *tk, struct trace_event_file *file)
 
 		link = kmalloc(sizeof(*link), GFP_KERNEL);
 		if (!link) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			ret = -ENOMEM;
 			goto out;
 		}
@@ -416,6 +436,7 @@ disable_trace_kprobe(struct trace_kprobe *tk, struct trace_event_file *file)
 	int ret = 0;
 
 	if (file) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		link = find_event_file_link(&tk->tp, file);
 		if (!link) {
 			ret = -EINVAL;
@@ -461,7 +482,9 @@ static int __register_trace_kprobe(struct trace_kprobe *tk)
 	int i, ret;
 
 	if (trace_probe_is_registered(&tk->tp))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	for (i = 0; i < tk->tp.nr_args; i++)
 		traceprobe_update_arg(&tk->tp.args[i]);
@@ -498,6 +521,7 @@ static int __register_trace_kprobe(struct trace_kprobe *tk)
 /* Internal unregister function - just handle k*probes and flags */
 static void __unregister_trace_kprobe(struct trace_kprobe *tk)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (trace_probe_is_registered(&tk->tp)) {
 		if (trace_kprobe_is_return(tk))
 			unregister_kretprobe(&tk->rp);
@@ -539,6 +563,7 @@ static int register_trace_kprobe(struct trace_kprobe *tk)
 	old_tk = find_trace_kprobe(trace_event_name(&tk->tp.call),
 			tk->tp.call.class->system);
 	if (old_tk) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ret = unregister_trace_kprobe(old_tk);
 		if (ret < 0)
 			goto end;
@@ -573,7 +598,9 @@ static int trace_kprobe_module_callback(struct notifier_block *nb,
 	int ret;
 
 	if (val != MODULE_STATE_COMING)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NOTIFY_DONE;
+}
 
 	/* Update probes on coming module */
 	mutex_lock(&probe_lock);
@@ -601,6 +628,7 @@ static struct notifier_block trace_kprobe_module_nb = {
 /* Convert certain expected symbols into '_' when generating event names */
 static inline void sanitize_event_name(char *name)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	while (*name++ != '\0')
 		if (*name == ':' || *name == '.')
 			*name = '_';
@@ -641,7 +669,9 @@ static int create_trace_kprobe(int argc, char **argv)
 
 	/* argc must be >= 1 */
 	if (argv[0][0] == 'p')
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		is_return = false;
+}
 	else if (argv[0][0] == 'r')
 		is_return = true;
 	else if (argv[0][0] == '-')
@@ -846,17 +876,20 @@ static int release_all_trace_kprobes(void)
 /* Probes listing interfaces */
 static void *probes_seq_start(struct seq_file *m, loff_t *pos)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	mutex_lock(&probe_lock);
 	return seq_list_start(&probe_list, *pos);
 }
 
 static void *probes_seq_next(struct seq_file *m, void *v, loff_t *pos)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return seq_list_next(v, &probe_list, pos);
 }
 
 static void probes_seq_stop(struct seq_file *m, void *v)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	mutex_unlock(&probe_lock);
 }
 
@@ -865,6 +898,7 @@ static int probes_seq_show(struct seq_file *m, void *v)
 	struct trace_kprobe *tk = v;
 	int i;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	seq_putc(m, trace_kprobe_is_return(tk) ? 'r' : 'p');
 	seq_printf(m, ":%s/%s", tk->tp.call.class->system,
 			trace_event_name(&tk->tp.call));
@@ -895,6 +929,7 @@ static int probes_open(struct inode *inode, struct file *file)
 {
 	int ret;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if ((file->f_mode & FMODE_WRITE) && (file->f_flags & O_TRUNC)) {
 		ret = release_all_trace_kprobes();
 		if (ret < 0)
@@ -907,6 +942,7 @@ static int probes_open(struct inode *inode, struct file *file)
 static ssize_t probes_write(struct file *file, const char __user *buffer,
 			    size_t count, loff_t *ppos)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return traceprobe_probes_write(file, buffer, count, ppos,
 			create_trace_kprobe);
 }
@@ -942,6 +978,7 @@ static const struct seq_operations profile_seq_op = {
 
 static int profile_open(struct inode *inode, struct file *file)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return seq_open(file, &profile_seq_op);
 }
 
@@ -965,6 +1002,7 @@ __kprobe_trace_func(struct trace_kprobe *tk, struct pt_regs *regs,
 	unsigned long irq_flags;
 	struct trace_event_call *call = &tk->tp.call;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WARN_ON(call != trace_file->event_call);
 
 	if (trace_trigger_soft_disabled(trace_file))
@@ -995,6 +1033,7 @@ kprobe_trace_func(struct trace_kprobe *tk, struct pt_regs *regs)
 {
 	struct event_file_link *link;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry_rcu(link, &tk->tp.files, list)
 		__kprobe_trace_func(tk, regs, link->file);
 }
@@ -1013,6 +1052,7 @@ __kretprobe_trace_func(struct trace_kprobe *tk, struct kretprobe_instance *ri,
 	unsigned long irq_flags;
 	struct trace_event_call *call = &tk->tp.call;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WARN_ON(call != trace_file->event_call);
 
 	if (trace_trigger_soft_disabled(trace_file))
@@ -1045,6 +1085,7 @@ kretprobe_trace_func(struct trace_kprobe *tk, struct kretprobe_instance *ri,
 {
 	struct event_file_link *link;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry_rcu(link, &tk->tp.files, list)
 		__kretprobe_trace_func(tk, ri, regs, link->file);
 }
@@ -1062,6 +1103,7 @@ print_kprobe_event(struct trace_iterator *iter, int flags,
 	int i;
 
 	field = (struct kprobe_trace_entry_head *)iter->ent;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	tp = container_of(event, struct trace_probe, call.event);
 
 	trace_seq_printf(s, "%s: (", trace_event_name(&tp->call));
@@ -1093,6 +1135,7 @@ print_kretprobe_event(struct trace_iterator *iter, int flags,
 	int i;
 
 	field = (struct kretprobe_trace_entry_head *)iter->ent;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	tp = container_of(event, struct trace_probe, call.event);
 
 	trace_seq_printf(s, "%s: (", trace_event_name(&tp->call));
@@ -1126,6 +1169,7 @@ static int kprobe_event_define_fields(struct trace_event_call *event_call)
 	struct kprobe_trace_entry_head field;
 	struct trace_kprobe *tk = (struct trace_kprobe *)event_call->data;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	DEFINE_FIELD(unsigned long, ip, FIELD_STRING_IP, 0);
 	/* Set argument names as fields */
 	for (i = 0; i < tk->tp.nr_args; i++) {
@@ -1149,6 +1193,7 @@ static int kretprobe_event_define_fields(struct trace_event_call *event_call)
 	struct kretprobe_trace_entry_head field;
 	struct trace_kprobe *tk = (struct trace_kprobe *)event_call->data;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	DEFINE_FIELD(unsigned long, func, FIELD_STRING_FUNC, 0);
 	DEFINE_FIELD(unsigned long, ret_ip, FIELD_STRING_RETIP, 0);
 	/* Set argument names as fields */
@@ -1180,6 +1225,7 @@ kprobe_perf_func(struct trace_kprobe *tk, struct pt_regs *regs)
 	int size, __size, dsize;
 	int rctx;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (prog && !trace_call_bpf(prog, regs))
 		return;
 
@@ -1216,6 +1262,7 @@ kretprobe_perf_func(struct trace_kprobe *tk, struct kretprobe_instance *ri,
 	int size, __size, dsize;
 	int rctx;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (prog && !trace_call_bpf(prog, regs))
 		return;
 
@@ -1276,6 +1323,7 @@ static int kprobe_register(struct trace_event_call *event,
 
 static int kprobe_dispatcher(struct kprobe *kp, struct pt_regs *regs)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct trace_kprobe *tk = container_of(kp, struct trace_kprobe, rp.kp);
 
 	raw_cpu_inc(*tk->nhit);
@@ -1293,6 +1341,7 @@ NOKPROBE_SYMBOL(kprobe_dispatcher);
 static int
 kretprobe_dispatcher(struct kretprobe_instance *ri, struct pt_regs *regs)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct trace_kprobe *tk = container_of(ri->rp, struct trace_kprobe, rp);
 
 	raw_cpu_inc(*tk->nhit);
@@ -1323,6 +1372,7 @@ static int register_kprobe_event(struct trace_kprobe *tk)
 	/* Initialize trace_event_call */
 	INIT_LIST_HEAD(&call->class->fields);
 	if (trace_kprobe_is_return(tk)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		call->event.funcs = &kretprobe_funcs;
 		call->class->define_fields = kretprobe_event_define_fields;
 	} else {
@@ -1356,7 +1406,9 @@ static int unregister_kprobe_event(struct trace_kprobe *tk)
 	/* tp->event is unregistered in trace_remove_event_call() */
 	ret = trace_remove_event_call(&tk->tp.call);
 	if (!ret)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		kfree(tk->tp.call.print_fmt);
+}
 	return ret;
 }
 
@@ -1367,25 +1419,34 @@ static __init int init_kprobe_trace(void)
 	struct dentry *entry;
 
 	if (register_module_notifier(&trace_kprobe_module_nb))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	d_tracer = tracing_init_dentry();
 	if (IS_ERR(d_tracer))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	entry = tracefs_create_file("kprobe_events", 0644, d_tracer,
 				    NULL, &kprobe_events_ops);
 
 	/* Event list interface */
 	if (!entry)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_warn("Could not create tracefs 'kprobe_events' entry\n");
+}
 
 	/* Profile interface */
 	entry = tracefs_create_file("kprobe_profile", 0444, d_tracer,
 				    NULL, &kprobe_profile_ops);
 
 	if (!entry)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_warn("Could not create tracefs 'kprobe_profile' entry\n");
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 fs_initcall(init_kprobe_trace);
diff --git a/kernel/trace/trace_mmiotrace.c b/kernel/trace/trace_mmiotrace.c
index b038801..05da161 100644
--- a/kernel/trace/trace_mmiotrace.c
+++ b/kernel/trace/trace_mmiotrace.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 /*
  * Memory mapped I/O tracing
diff --git a/kernel/trace/trace_output.c b/kernel/trace/trace_output.c
index c738e76..ce9d245 100644
--- a/kernel/trace/trace_output.c
+++ b/kernel/trace/trace_output.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * trace_output.c
  *
@@ -27,6 +29,7 @@ enum print_line_t trace_print_bputs_msg_only(struct trace_iterator *iter)
 	struct trace_entry *entry = iter->ent;
 	struct bputs_entry *field;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	trace_assign_type(field, entry);
 
 	trace_seq_puts(s, field->str);
@@ -40,6 +43,7 @@ enum print_line_t trace_print_bprintk_msg_only(struct trace_iterator *iter)
 	struct trace_entry *entry = iter->ent;
 	struct bprint_entry *field;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	trace_assign_type(field, entry);
 
 	trace_seq_bprintf(s, field->fmt, field->buf);
@@ -53,6 +57,7 @@ enum print_line_t trace_print_printk_msg_only(struct trace_iterator *iter)
 	struct trace_entry *entry = iter->ent;
 	struct print_entry *field;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	trace_assign_type(field, entry);
 
 	trace_seq_puts(s, field->buf);
@@ -70,6 +75,7 @@ trace_print_flags_seq(struct trace_seq *p, const char *delim,
 	const char *ret = trace_seq_buffer_ptr(p);
 	int i, first = 1;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (i = 0;  flag_array[i].name && flags; i++) {
 
 		mask = flag_array[i].mask;
@@ -105,6 +111,7 @@ trace_print_symbols_seq(struct trace_seq *p, unsigned long val,
 	int i;
 	const char *ret = trace_seq_buffer_ptr(p);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (i = 0;  symbol_array[i].name; i++) {
 
 		if (val != symbol_array[i].mask)
@@ -192,6 +199,7 @@ const char *
 trace_print_bitmask_seq(struct trace_seq *p, void *bitmask_ptr,
 			unsigned int bitmask_size)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	const char *ret = trace_seq_buffer_ptr(p);
 
 	trace_seq_bitmask(p, bitmask_ptr, bitmask_size * 8);
@@ -219,6 +227,7 @@ trace_print_hex_seq(struct trace_seq *p, const unsigned char *buf, int buf_len,
 	int i;
 	const char *ret = trace_seq_buffer_ptr(p);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (i = 0; i < buf_len; i++)
 		trace_seq_printf(p, "%s%2.2x", concatenate || i == 0 ? "" : " ",
 				 buf[i]);
@@ -232,6 +241,7 @@ const char *
 trace_print_array_seq(struct trace_seq *p, const void *buf, int count,
 		      size_t el_size)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	const char *ret = trace_seq_buffer_ptr(p);
 	const char *prefix = "";
 	void *ptr = (void *)buf;
@@ -281,6 +291,7 @@ int trace_raw_output_prep(struct trace_iterator *iter,
 	struct trace_seq *p = &iter->tmp_seq;
 	struct trace_entry *entry;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	event = container_of(trace_event, struct trace_event_call, event);
 	entry = iter->ent;
 
@@ -327,7 +338,9 @@ static inline const char *kretprobed(const char *name)
 	int size = sizeof(tramp_name);
 
 	if (strncmp(tramp_name, name, size) == 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return "[unknown/kretprobe'd]";
+}
 	return name;
 }
 #else
@@ -348,6 +361,7 @@ seq_print_sym_short(struct trace_seq *s, const char *fmt, unsigned long address)
 
 	name = kretprobed(str);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (name && strlen(name)) {
 		trace_seq_printf(s, fmt, name);
 		return;
@@ -368,6 +382,7 @@ seq_print_sym_offset(struct trace_seq *s, const char *fmt,
 	sprint_symbol(str, address);
 	name = kretprobed(str);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (name && strlen(name)) {
 		trace_seq_printf(s, fmt, name);
 		return;
@@ -391,7 +406,9 @@ static int seq_print_user_ip(struct trace_seq *s, struct mm_struct *mm,
 	int ret = 1;
 
 	if (s->full)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	if (mm) {
 		const struct vm_area_struct *vma;
@@ -418,6 +435,7 @@ static int seq_print_user_ip(struct trace_seq *s, struct mm_struct *mm,
 int
 seq_print_ip_sym(struct trace_seq *s, unsigned long ip, unsigned long sym_flags)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!ip) {
 		trace_seq_putc(s, '0');
 		goto out;
@@ -530,6 +548,7 @@ char trace_find_mark(unsigned long long d)
 	int i;
 	int size = ARRAY_SIZE(mark);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (i = 0; i < size; i++) {
 		if (d > mark[i].val)
 			break;
@@ -549,6 +568,7 @@ lat_print_timestamp(struct trace_iterator *iter, u64 next_ts)
 	struct trace_seq *s = &iter->seq;
 
 	if (in_ns) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		abs_ts = ns2usecs(abs_ts);
 		rel_ts = ns2usecs(rel_ts);
 	}
@@ -598,6 +618,7 @@ int trace_print_context(struct trace_iterator *iter)
 			       comm, entry->pid, iter->cpu);
 
 	if (tr->trace_flags & TRACE_ITER_RECORD_TGID) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		unsigned int tgid = trace_find_tgid(entry->pid);
 
 		if (!tgid)
@@ -636,7 +657,9 @@ int trace_print_lat_context(struct trace_iterator *iter)
 	iter->ent_size = ent_size;
 
 	if (!next_entry)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		next_ts = iter->ts;
+}
 
 	if (verbose) {
 		char comm[TASK_COMM_LEN];
@@ -672,9 +695,12 @@ struct trace_event *ftrace_find_event(int type)
 
 	hlist_for_each_entry(event, &event_hash[key], node) {
 		if (event->type == type)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return event;
+}
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return NULL;
 }
 
@@ -686,6 +712,7 @@ static int trace_search_list(struct list_head **list)
 	int last = __TRACE_LAST_TYPE;
 
 	if (list_empty(&ftrace_event_list)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		*list = &ftrace_event_list;
 		return last + 1;
 	}
@@ -710,11 +737,13 @@ static int trace_search_list(struct list_head **list)
 
 void trace_event_read_lock(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	down_read(&trace_event_sem);
 }
 
 void trace_event_read_unlock(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	up_read(&trace_event_sem);
 }
 
@@ -753,6 +782,7 @@ int register_trace_event(struct trace_event *event)
 
 		if (next_event_type > TRACE_EVENT_TYPE_MAX) {
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			event->type = trace_search_list(&list);
 			if (!event->type)
 				goto out;
@@ -769,7 +799,9 @@ int register_trace_event(struct trace_event *event)
 		list_add_tail(&event->list, list);
 
 	} else if (event->type > __TRACE_LAST_TYPE) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		printk(KERN_WARNING "Need to add type to trace.h\n");
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		WARN_ON(1);
 		goto out;
 	} else {
@@ -779,7 +811,9 @@ int register_trace_event(struct trace_event *event)
 	}
 
 	if (event->funcs->trace == NULL)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		event->funcs->trace = trace_nop_print;
+}
 	if (event->funcs->raw == NULL)
 		event->funcs->raw = trace_nop_print;
 	if (event->funcs->hex == NULL)
@@ -804,6 +838,7 @@ EXPORT_SYMBOL_GPL(register_trace_event);
  */
 int __unregister_trace_event(struct trace_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	hlist_del(&event->node);
 	list_del(&event->list);
 	return 0;
@@ -815,6 +850,7 @@ int __unregister_trace_event(struct trace_event *event)
  */
 int unregister_trace_event(struct trace_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	down_write(&trace_event_sem);
 	__unregister_trace_event(event);
 	up_write(&trace_event_sem);
@@ -830,6 +866,7 @@ EXPORT_SYMBOL_GPL(unregister_trace_event);
 enum print_line_t trace_nop_print(struct trace_iterator *iter, int flags,
 				  struct trace_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	trace_seq_printf(&iter->seq, "type: %d\n", iter->ent->type);
 
 	return trace_handle_return(&iter->seq);
@@ -842,6 +879,7 @@ static enum print_line_t trace_fn_trace(struct trace_iterator *iter, int flags,
 	struct ftrace_entry *field;
 	struct trace_seq *s = &iter->seq;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	trace_assign_type(field, iter->ent);
 
 	seq_print_ip_sym(s, field->ip, flags);
@@ -861,6 +899,7 @@ static enum print_line_t trace_fn_raw(struct trace_iterator *iter, int flags,
 {
 	struct ftrace_entry *field;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	trace_assign_type(field, iter->ent);
 
 	trace_seq_printf(&iter->seq, "%lx %lx\n",
@@ -876,6 +915,7 @@ static enum print_line_t trace_fn_hex(struct trace_iterator *iter, int flags,
 	struct ftrace_entry *field;
 	struct trace_seq *s = &iter->seq;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	trace_assign_type(field, iter->ent);
 
 	SEQ_PUT_HEX_FIELD(s, field->ip);
@@ -890,6 +930,7 @@ static enum print_line_t trace_fn_bin(struct trace_iterator *iter, int flags,
 	struct ftrace_entry *field;
 	struct trace_seq *s = &iter->seq;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	trace_assign_type(field, iter->ent);
 
 	SEQ_PUT_FIELD(s, field->ip);
@@ -919,6 +960,7 @@ static enum print_line_t trace_ctxwake_print(struct trace_iterator *iter,
 	int S, T;
 
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	trace_assign_type(field, iter->ent);
 
 	T = __task_state_to_char(field->next_state);
@@ -940,12 +982,14 @@ static enum print_line_t trace_ctxwake_print(struct trace_iterator *iter,
 static enum print_line_t trace_ctx_print(struct trace_iterator *iter, int flags,
 					 struct trace_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return trace_ctxwake_print(iter, "==>");
 }
 
 static enum print_line_t trace_wake_print(struct trace_iterator *iter,
 					  int flags, struct trace_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return trace_ctxwake_print(iter, "  +");
 }
 
@@ -954,6 +998,7 @@ static int trace_ctxwake_raw(struct trace_iterator *iter, char S)
 	struct ctx_switch_entry *field;
 	int T;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	trace_assign_type(field, iter->ent);
 
 	if (!S)
@@ -974,12 +1019,14 @@ static int trace_ctxwake_raw(struct trace_iterator *iter, char S)
 static enum print_line_t trace_ctx_raw(struct trace_iterator *iter, int flags,
 				       struct trace_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return trace_ctxwake_raw(iter, 0);
 }
 
 static enum print_line_t trace_wake_raw(struct trace_iterator *iter, int flags,
 					struct trace_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return trace_ctxwake_raw(iter, '+');
 }
 
@@ -990,6 +1037,7 @@ static int trace_ctxwake_hex(struct trace_iterator *iter, char S)
 	struct trace_seq *s = &iter->seq;
 	int T;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	trace_assign_type(field, iter->ent);
 
 	if (!S)
@@ -1010,12 +1058,14 @@ static int trace_ctxwake_hex(struct trace_iterator *iter, char S)
 static enum print_line_t trace_ctx_hex(struct trace_iterator *iter, int flags,
 				       struct trace_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return trace_ctxwake_hex(iter, 0);
 }
 
 static enum print_line_t trace_wake_hex(struct trace_iterator *iter, int flags,
 					struct trace_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return trace_ctxwake_hex(iter, '+');
 }
 
@@ -1025,6 +1075,7 @@ static enum print_line_t trace_ctxwake_bin(struct trace_iterator *iter,
 	struct ctx_switch_entry *field;
 	struct trace_seq *s = &iter->seq;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	trace_assign_type(field, iter->ent);
 
 	SEQ_PUT_FIELD(s, field->prev_pid);
@@ -1072,6 +1123,7 @@ static enum print_line_t trace_stack_print(struct trace_iterator *iter,
 	unsigned long *p;
 	unsigned long *end;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	trace_assign_type(field, iter->ent);
 	end = (unsigned long *)((long)iter->ent + iter->ent_size);
 
@@ -1109,6 +1161,7 @@ static enum print_line_t trace_user_stack_print(struct trace_iterator *iter,
 	struct mm_struct *mm = NULL;
 	unsigned int i;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	trace_assign_type(field, iter->ent);
 
 	trace_seq_puts(s, "<user stack trace>\n");
@@ -1168,6 +1221,7 @@ trace_hwlat_print(struct trace_iterator *iter, int flags,
 	struct trace_seq *s = &iter->seq;
 	struct hwlat_entry *field;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	trace_assign_type(field, entry);
 
 	trace_seq_printf(s, "#%-5u inner/outer(us): %4llu/%-5llu ts:%lld.%09ld",
@@ -1202,6 +1256,7 @@ trace_hwlat_raw(struct trace_iterator *iter, int flags,
 	struct hwlat_entry *field;
 	struct trace_seq *s = &iter->seq;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	trace_assign_type(field, iter->ent);
 
 	trace_seq_printf(s, "%llu %lld %lld %09ld %u\n",
@@ -1233,6 +1288,7 @@ trace_bputs_print(struct trace_iterator *iter, int flags,
 	struct trace_seq *s = &iter->seq;
 	struct bputs_entry *field;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	trace_assign_type(field, entry);
 
 	seq_print_ip_sym(s, field->ip, flags);
@@ -1250,6 +1306,7 @@ trace_bputs_raw(struct trace_iterator *iter, int flags,
 	struct bputs_entry *field;
 	struct trace_seq *s = &iter->seq;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	trace_assign_type(field, iter->ent);
 
 	trace_seq_printf(s, ": %lx : ", field->ip);
@@ -1277,6 +1334,7 @@ trace_bprint_print(struct trace_iterator *iter, int flags,
 	struct trace_seq *s = &iter->seq;
 	struct bprint_entry *field;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	trace_assign_type(field, entry);
 
 	seq_print_ip_sym(s, field->ip, flags);
@@ -1294,6 +1352,7 @@ trace_bprint_raw(struct trace_iterator *iter, int flags,
 	struct bprint_entry *field;
 	struct trace_seq *s = &iter->seq;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	trace_assign_type(field, iter->ent);
 
 	trace_seq_printf(s, ": %lx : ", field->ip);
@@ -1319,6 +1378,7 @@ static enum print_line_t trace_print_print(struct trace_iterator *iter,
 	struct print_entry *field;
 	struct trace_seq *s = &iter->seq;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	trace_assign_type(field, iter->ent);
 
 	seq_print_ip_sym(s, field->ip, flags);
@@ -1332,6 +1392,7 @@ static enum print_line_t trace_print_raw(struct trace_iterator *iter, int flags,
 {
 	struct print_entry *field;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	trace_assign_type(field, iter->ent);
 
 	trace_seq_printf(&iter->seq, "# %lx %s", field->ip, field->buf);
@@ -1355,6 +1416,7 @@ static enum print_line_t trace_raw_data(struct trace_iterator *iter, int flags,
 	struct raw_data_entry *field;
 	int i;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	trace_assign_type(field, iter->ent);
 
 	trace_seq_printf(&iter->seq, "# %x buf:", field->id);
@@ -1399,10 +1461,12 @@ __init static int init_events(void)
 	int i, ret;
 
 	for (i = 0; events[i]; i++) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		event = events[i];
 
 		ret = register_trace_event(event);
 		if (!ret) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			printk(KERN_WARNING "event %d failed to register\n",
 			       event->type);
 			WARN_ON_ONCE(1);
diff --git a/kernel/trace/trace_printk.c b/kernel/trace/trace_printk.c
index ad1d616..3d69744 100644
--- a/kernel/trace/trace_printk.c
+++ b/kernel/trace/trace_printk.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * trace binary printk
  *
@@ -38,7 +40,9 @@ static inline struct trace_bprintk_fmt *lookup_format(const char *fmt)
 	struct trace_bprintk_fmt *pos;
 
 	if (!fmt)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ERR_PTR(-EINVAL);
+}
 
 	list_for_each_entry(pos, &trace_bprintk_fmt_list, list) {
 		if (!strcmp(pos->fmt, fmt))
@@ -55,7 +59,9 @@ void hold_module_trace_bprintk_format(const char **start, const char **end)
 
 	/* allocate the trace_printk per cpu buffers */
 	if (start != end)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		trace_printk_init_buffers();
+}
 
 	mutex_lock(&btrace_mutex);
 	for (iter = start; iter < end; iter++) {
@@ -92,7 +98,9 @@ static int module_trace_bprintk_format_notify(struct notifier_block *self,
 		const char **end = start + mod->num_trace_bprintk_fmt;
 
 		if (val == MODULE_STATE_COMING)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			hold_module_trace_bprintk_format(start, end);
+}
 	}
 	return 0;
 }
@@ -123,7 +131,9 @@ find_next_mod_format(int start_index, void *v, const char **fmt, loff_t *pos)
 	struct trace_bprintk_fmt *mod_fmt;
 
 	if (list_empty(&trace_bprintk_fmt_list))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 
 	/*
 	 * v will point to the address of the fmt record from t_next
@@ -159,11 +169,13 @@ find_next_mod_format(int start_index, void *v, const char **fmt, loff_t *pos)
 
 static void format_mod_start(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	mutex_lock(&btrace_mutex);
 }
 
 static void format_mod_stop(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	mutex_unlock(&btrace_mutex);
 }
 
@@ -187,6 +199,7 @@ static bool __read_mostly trace_printk_enabled = true;
 
 void trace_printk_control(bool enabled)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	trace_printk_enabled = enabled;
 }
 
@@ -201,7 +214,9 @@ int __trace_bprintk(unsigned long ip, const char *fmt, ...)
 	va_list ap;
 
 	if (unlikely(!fmt))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	if (!trace_printk_enabled)
 		return 0;
@@ -215,6 +230,7 @@ EXPORT_SYMBOL_GPL(__trace_bprintk);
 
 int __ftrace_vbprintk(unsigned long ip, const char *fmt, va_list ap)
  {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (unlikely(!fmt))
 		return 0;
 
@@ -231,7 +247,9 @@ int __trace_printk(unsigned long ip, const char *fmt, ...)
 	va_list ap;
 
 	if (!trace_printk_enabled)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	va_start(ap, fmt);
 	ret = trace_vprintk(ip, fmt, ap);
@@ -242,6 +260,7 @@ EXPORT_SYMBOL_GPL(__trace_printk);
 
 int __ftrace_vprintk(unsigned long ip, const char *fmt, va_list ap)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!trace_printk_enabled)
 		return 0;
 
@@ -258,7 +277,9 @@ static const char **find_next(void *v, loff_t *pos)
 	start_index = __stop___trace_bprintk_fmt - __start___trace_bprintk_fmt;
 
 	if (*pos < start_index)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return __start___trace_bprintk_fmt + *pos;
+}
 
 	/*
 	 * The __tracepoint_str section is treated the same as the
@@ -285,12 +306,14 @@ static const char **find_next(void *v, loff_t *pos)
 static void *
 t_start(struct seq_file *m, loff_t *pos)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	format_mod_start();
 	return find_next(NULL, pos);
 }
 
 static void *t_next(struct seq_file *m, void * v, loff_t *pos)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	(*pos)++;
 	return find_next(v, pos);
 }
@@ -302,7 +325,9 @@ static int t_show(struct seq_file *m, void *v)
 	int i;
 
 	if (!*fmt)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	seq_printf(m, "0x%lx : \"", *(unsigned long *)fmt);
 
@@ -334,6 +359,7 @@ static int t_show(struct seq_file *m, void *v)
 
 static void t_stop(struct seq_file *m, void *p)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	format_mod_stop();
 }
 
@@ -347,6 +373,7 @@ static const struct seq_operations show_format_seq_ops = {
 static int
 ftrace_formats_open(struct inode *inode, struct file *file)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return seq_open(file, &show_format_seq_ops);
 }
 
@@ -363,7 +390,9 @@ static __init int init_trace_printk_function_export(void)
 
 	d_tracer = tracing_init_dentry();
 	if (IS_ERR(d_tracer))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	trace_create_file("printk_formats", 0444, d_tracer,
 				    NULL, &ftrace_formats_fops);
diff --git a/kernel/trace/trace_stack.c b/kernel/trace/trace_stack.c
index 719a52a..c815282 100644
--- a/kernel/trace/trace_stack.c
+++ b/kernel/trace/trace_stack.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 /*
  * Copyright (C) 2008 Steven Rostedt <srostedt@redhat.com>
diff --git a/kernel/trace/trace_stat.c b/kernel/trace/trace_stat.c
index 75bf1bc..dfe9dd1 100644
--- a/kernel/trace/trace_stat.c
+++ b/kernel/trace/trace_stat.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 /*
  * Infrastructure for statistic tracing (histogram output).
@@ -48,6 +50,7 @@ static void __reset_stat_session(struct stat_session *session)
 {
 	struct stat_node *snode, *n;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rbtree_postorder_for_each_entry_safe(snode, n, &session->stat_root, node) {
 		if (session->ts->stat_release)
 			session->ts->stat_release(snode->stat);
@@ -59,6 +62,7 @@ static void __reset_stat_session(struct stat_session *session)
 
 static void reset_stat_session(struct stat_session *session)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	mutex_lock(&session->stat_mutex);
 	__reset_stat_session(session);
 	mutex_unlock(&session->stat_mutex);
@@ -66,6 +70,7 @@ static void reset_stat_session(struct stat_session *session)
 
 static void destroy_session(struct stat_session *session)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	tracefs_remove(session->file);
 	__reset_stat_session(session);
 	mutex_destroy(&session->stat_mutex);
@@ -81,7 +86,9 @@ static int insert_stat(struct rb_root *root, void *stat, cmp_stat_t cmp)
 
 	data = kzalloc(sizeof(*data), GFP_KERNEL);
 	if (!data)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 	data->stat = stat;
 
 	/*
@@ -114,6 +121,7 @@ static int insert_stat(struct rb_root *root, void *stat, cmp_stat_t cmp)
  */
 static int dummy_cmp(void *p1, void *p2)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return -1;
 }
 
@@ -134,7 +142,9 @@ static int stat_seq_init(struct stat_session *session)
 	__reset_stat_session(session);
 
 	if (!ts->stat_cmp)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ts->stat_cmp = dummy_cmp;
+}
 
 	stat = ts->stat_start(ts);
 	if (!stat)
@@ -182,6 +192,7 @@ static void *stat_seq_start(struct seq_file *s, loff_t *pos)
 
 	/* If we are in the beginning of the file, print the headers */
 	if (session->ts->stat_headers) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (n == 0)
 			return SEQ_START_TOKEN;
 		n--;
@@ -202,7 +213,9 @@ static void *stat_seq_next(struct seq_file *s, void *p, loff_t *pos)
 	(*pos)++;
 
 	if (p == SEQ_START_TOKEN)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return rb_first(&session->stat_root);
+}
 
 	return rb_next(node);
 }
@@ -216,6 +229,7 @@ static void stat_seq_stop(struct seq_file *s, void *p)
 static int stat_seq_show(struct seq_file *s, void *v)
 {
 	struct stat_session *session = s->private;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct stat_node *l = container_of(v, struct stat_node, node);
 
 	if (v == SEQ_START_TOKEN)
@@ -240,7 +254,9 @@ static int tracing_stat_open(struct inode *inode, struct file *file)
 
 	ret = stat_seq_init(session);
 	if (ret)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ret;
+}
 
 	ret = seq_open(file, &trace_stat_seq_ops);
 	if (ret) {
@@ -278,24 +294,33 @@ static int tracing_stat_init(void)
 
 	d_tracing = tracing_init_dentry();
 	if (IS_ERR(d_tracing))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	stat_dir = tracefs_create_dir("trace_stat", d_tracing);
 	if (!stat_dir)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_warn("Could not create tracefs 'trace_stat' entry\n");
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
 static int init_stat_file(struct stat_session *session)
 {
 	if (!stat_dir && tracing_stat_init())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENODEV;
+}
 
 	session->file = tracefs_create_file(session->ts->name, 0644,
 					    stat_dir,
 					    session, &tracing_stat_fops);
 	if (!session->file)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 	return 0;
 }
 
@@ -305,15 +330,21 @@ int register_stat_tracer(struct tracer_stat *trace)
 	int ret;
 
 	if (!trace)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	if (!trace->stat_start || !trace->stat_next || !trace->stat_show)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	/* Already registered? */
 	mutex_lock(&all_stat_sessions_mutex);
 	list_for_each_entry(node, &all_stat_sessions, session_list) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (node->ts == trace) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			mutex_unlock(&all_stat_sessions_mutex);
 			return -EINVAL;
 		}
@@ -323,7 +354,9 @@ int register_stat_tracer(struct tracer_stat *trace)
 	/* Init the session */
 	session = kzalloc(sizeof(*session), GFP_KERNEL);
 	if (!session)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 
 	session->ts = trace;
 	INIT_LIST_HEAD(&session->session_list);
@@ -331,6 +364,7 @@ int register_stat_tracer(struct tracer_stat *trace)
 
 	ret = init_stat_file(session);
 	if (ret) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		destroy_session(session);
 		return ret;
 	}
@@ -348,6 +382,7 @@ void unregister_stat_tracer(struct tracer_stat *trace)
 	struct stat_session *node, *tmp;
 
 	mutex_lock(&all_stat_sessions_mutex);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry_safe(node, tmp, &all_stat_sessions, session_list) {
 		if (node->ts == trace) {
 			list_del(&node->session_list);
diff --git a/kernel/trace/trace_syscalls.c b/kernel/trace/trace_syscalls.c
index a2a642f..afc9b97 100644
--- a/kernel/trace/trace_syscalls.c
+++ b/kernel/trace/trace_syscalls.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 #include <trace/syscall.h>
 #include <trace/events/syscalls.h>
diff --git a/kernel/trace/trace_uprobe.c b/kernel/trace/trace_uprobe.c
index 4525e02..f56325c 100644
--- a/kernel/trace/trace_uprobe.c
+++ b/kernel/trace/trace_uprobe.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * uprobes-based tracing events
  *
@@ -89,6 +91,7 @@ static unsigned long adjust_stack_addr(unsigned long addr, unsigned int n)
 #else
 static unsigned long adjust_stack_addr(unsigned long addr, unsigned int n)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return addr + (n * sizeof(long));
 }
 #endif
@@ -101,7 +104,9 @@ static unsigned long get_user_stack_nth(struct pt_regs *regs, unsigned int n)
 	addr = adjust_stack_addr(addr, n);
 
 	if (copy_from_user(&ret, (void __force __user *) addr, sizeof(ret)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	return ret;
 }
@@ -148,7 +153,9 @@ static void FETCH_FUNC_NAME(memory, string)(struct pt_regs *regs,
 	void __user *src = (void __force __user *) addr;
 
 	if (!maxlen)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	ret = strncpy_from_user(dst, src, maxlen);
 
@@ -168,6 +175,7 @@ static void FETCH_FUNC_NAME(memory, string_size)(struct pt_regs *regs,
 
 	len = strnlen_user(vaddr, MAX_STRING_SIZE);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (len == 0 || len > MAX_STRING_SIZE)  /* Failed to check length */
 		*(u32 *)dest = 0;
 	else
@@ -223,6 +231,7 @@ static const struct fetch_type uprobes_fetch_type_table[] = {
 
 static inline void init_trace_uprobe_filter(struct trace_uprobe_filter *filter)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rwlock_init(&filter->rwlock);
 	filter->nr_systemwide = 0;
 	INIT_LIST_HEAD(&filter->perf_events);
@@ -230,11 +239,13 @@ static inline void init_trace_uprobe_filter(struct trace_uprobe_filter *filter)
 
 static inline bool uprobe_filter_is_empty(struct trace_uprobe_filter *filter)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return !filter->nr_systemwide && list_empty(&filter->perf_events);
 }
 
 static inline bool is_ret_probe(struct trace_uprobe *tu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return tu->consumer.ret_handler != NULL;
 }
 
@@ -246,6 +257,7 @@ alloc_trace_uprobe(const char *group, const char *event, int nargs, bool is_ret)
 {
 	struct trace_uprobe *tu;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!event || !is_good_name(event))
 		return ERR_PTR(-EINVAL);
 
@@ -284,6 +296,7 @@ static void free_trace_uprobe(struct trace_uprobe *tu)
 {
 	int i;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (i = 0; i < tu->tp.nr_args; i++)
 		traceprobe_free_probe_arg(&tu->tp.args[i]);
 
@@ -298,6 +311,7 @@ static struct trace_uprobe *find_probe_event(const char *event, const char *grou
 {
 	struct trace_uprobe *tu;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry(tu, &uprobe_list, list)
 		if (strcmp(trace_event_name(&tu->tp.call), event) == 0 &&
 		    strcmp(tu->tp.call.class->system, group) == 0)
@@ -313,7 +327,9 @@ static int unregister_trace_uprobe(struct trace_uprobe *tu)
 
 	ret = unregister_uprobe_event(tu);
 	if (ret)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ret;
+}
 
 	list_del(&tu->list);
 	free_trace_uprobe(tu);
@@ -378,7 +394,9 @@ static int create_trace_uprobe(int argc, char **argv)
 
 	/* argc must be >= 1 */
 	if (argv[0][0] == '-')
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		is_delete = true;
+}
 	else if (argv[0][0] == 'r')
 		is_return = true;
 	else if (argv[0][0] != 'p') {
@@ -569,6 +587,7 @@ static int cleanup_all_probes(void)
 	int ret = 0;
 
 	mutex_lock(&uprobe_lock);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	while (!list_empty(&uprobe_list)) {
 		tu = list_entry(uprobe_list.next, struct trace_uprobe, list);
 		ret = unregister_trace_uprobe(tu);
@@ -582,23 +601,27 @@ static int cleanup_all_probes(void)
 /* Probes listing interfaces */
 static void *probes_seq_start(struct seq_file *m, loff_t *pos)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	mutex_lock(&uprobe_lock);
 	return seq_list_start(&uprobe_list, *pos);
 }
 
 static void *probes_seq_next(struct seq_file *m, void *v, loff_t *pos)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return seq_list_next(v, &uprobe_list, pos);
 }
 
 static void probes_seq_stop(struct seq_file *m, void *v)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	mutex_unlock(&uprobe_lock);
 }
 
 static int probes_seq_show(struct seq_file *m, void *v)
 {
 	struct trace_uprobe *tu = v;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	char c = is_ret_probe(tu) ? 'r' : 'p';
 	int i;
 
@@ -639,6 +662,7 @@ static int probes_open(struct inode *inode, struct file *file)
 {
 	int ret;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if ((file->f_mode & FMODE_WRITE) && (file->f_flags & O_TRUNC)) {
 		ret = cleanup_all_probes();
 		if (ret)
@@ -651,6 +675,7 @@ static int probes_open(struct inode *inode, struct file *file)
 static ssize_t probes_write(struct file *file, const char __user *buffer,
 			    size_t count, loff_t *ppos)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return traceprobe_probes_write(file, buffer, count, ppos, create_trace_uprobe);
 }
 
@@ -682,6 +707,7 @@ static const struct seq_operations profile_seq_op = {
 
 static int profile_open(struct inode *inode, struct file *file)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return seq_open(file, &profile_seq_op);
 }
 
@@ -706,7 +732,9 @@ static int uprobe_buffer_init(void)
 
 	uprobe_cpu_buffer = alloc_percpu(struct uprobe_cpu_buffer);
 	if (uprobe_cpu_buffer == NULL)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 
 	for_each_possible_cpu(cpu) {
 		struct page *p = alloc_pages_node(cpu_to_node(cpu),
@@ -736,6 +764,7 @@ static int uprobe_buffer_enable(void)
 {
 	int ret = 0;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	BUG_ON(!mutex_is_locked(&event_mutex));
 
 	if (uprobe_buffer_refcnt++ == 0) {
@@ -751,6 +780,7 @@ static void uprobe_buffer_disable(void)
 {
 	int cpu;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	BUG_ON(!mutex_is_locked(&event_mutex));
 
 	if (--uprobe_buffer_refcnt == 0) {
@@ -768,6 +798,7 @@ static struct uprobe_cpu_buffer *uprobe_buffer_get(void)
 	struct uprobe_cpu_buffer *ucb;
 	int cpu;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	cpu = raw_smp_processor_id();
 	ucb = per_cpu_ptr(uprobe_cpu_buffer, cpu);
 
@@ -782,6 +813,7 @@ static struct uprobe_cpu_buffer *uprobe_buffer_get(void)
 
 static void uprobe_buffer_put(struct uprobe_cpu_buffer *ucb)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	mutex_unlock(&ucb->mutex);
 }
 
@@ -797,6 +829,7 @@ static void __uprobe_trace_func(struct trace_uprobe *tu,
 	int size, esize;
 	struct trace_event_call *call = &tu->tp.call;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WARN_ON(call != trace_file->event_call);
 
 	if (WARN_ON_ONCE(tu->tp.size + dsize > PAGE_SIZE))
@@ -834,7 +867,9 @@ static int uprobe_trace_func(struct trace_uprobe *tu, struct pt_regs *regs,
 	struct event_file_link *link;
 
 	if (is_ret_probe(tu))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	rcu_read_lock();
 	list_for_each_entry_rcu(link, &tu->tp.files, list)
@@ -851,6 +886,7 @@ static void uretprobe_trace_func(struct trace_uprobe *tu, unsigned long func,
 	struct event_file_link *link;
 
 	rcu_read_lock();
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry_rcu(link, &tu->tp.files, list)
 		__uprobe_trace_func(tu, func, regs, ucb, dsize, link->file);
 	rcu_read_unlock();
@@ -867,6 +903,7 @@ print_uprobe_event(struct trace_iterator *iter, int flags, struct trace_event *e
 	int i;
 
 	entry = (struct uprobe_trace_entry_head *)iter->ent;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	tu = container_of(event, struct trace_uprobe, tp.call.event);
 
 	if (is_ret_probe(tu)) {
@@ -902,6 +939,7 @@ static int
 probe_event_enable(struct trace_uprobe *tu, struct trace_event_file *file,
 		   filter_func_t filter)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	bool enabled = trace_probe_is_enabled(&tu->tp);
 	struct event_file_link *link = NULL;
 	int ret;
@@ -958,6 +996,7 @@ probe_event_enable(struct trace_uprobe *tu, struct trace_event_file *file,
 static void
 probe_event_disable(struct trace_uprobe *tu, struct trace_event_file *file)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!trace_probe_is_enabled(&tu->tp))
 		return;
 
@@ -992,6 +1031,7 @@ static int uprobe_event_define_fields(struct trace_event_call *event_call)
 	struct trace_uprobe *tu = event_call->data;
 
 	if (is_ret_probe(tu)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		DEFINE_FIELD(unsigned long, vaddr[0], FIELD_STRING_FUNC, 0);
 		DEFINE_FIELD(unsigned long, vaddr[1], FIELD_STRING_RETIP, 0);
 		size = SIZEOF_TRACE_ENTRY(true);
@@ -1021,7 +1061,9 @@ __uprobe_perf_filter(struct trace_uprobe_filter *filter, struct mm_struct *mm)
 	struct perf_event *event;
 
 	if (filter->nr_systemwide)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return true;
+}
 
 	list_for_each_entry(event, &filter->perf_events, hw.tp_list) {
 		if (event->hw.target->mm == mm)
@@ -1034,6 +1076,7 @@ __uprobe_perf_filter(struct trace_uprobe_filter *filter, struct mm_struct *mm)
 static inline bool
 uprobe_filter_event(struct trace_uprobe *tu, struct perf_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return __uprobe_perf_filter(&tu->filter, event->hw.target->mm);
 }
 
@@ -1043,6 +1086,7 @@ static int uprobe_perf_close(struct trace_uprobe *tu, struct perf_event *event)
 
 	write_lock(&tu->filter.rwlock);
 	if (event->hw.target) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		list_del(&event->hw.tp_list);
 		done = tu->filter.nr_systemwide ||
 			(event->hw.target->flags & PF_EXITING) ||
@@ -1099,6 +1143,7 @@ static bool uprobe_perf_filter(struct uprobe_consumer *uc,
 	struct trace_uprobe *tu;
 	int ret;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	tu = container_of(uc, struct trace_uprobe, consumer);
 	read_lock(&tu->filter.rwlock);
 	ret = __uprobe_perf_filter(&tu->filter, mm);
@@ -1119,6 +1164,7 @@ static void __uprobe_perf_func(struct trace_uprobe *tu,
 	int size, esize;
 	int rctx;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (prog && !trace_call_bpf(prog, regs))
 		return;
 
@@ -1165,6 +1211,7 @@ static void __uprobe_perf_func(struct trace_uprobe *tu,
 static int uprobe_perf_func(struct trace_uprobe *tu, struct pt_regs *regs,
 			    struct uprobe_cpu_buffer *ucb, int dsize)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!uprobe_perf_filter(&tu->consumer, 0, current->mm))
 		return UPROBE_HANDLER_REMOVE;
 
@@ -1177,6 +1224,7 @@ static void uretprobe_perf_func(struct trace_uprobe *tu, unsigned long func,
 				struct pt_regs *regs,
 				struct uprobe_cpu_buffer *ucb, int dsize)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	__uprobe_perf_func(tu, func, regs, ucb, dsize);
 }
 #endif	/* CONFIG_PERF_EVENTS */
@@ -1226,6 +1274,7 @@ static int uprobe_dispatcher(struct uprobe_consumer *con, struct pt_regs *regs)
 	int ret = 0;
 
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	tu = container_of(con, struct trace_uprobe, consumer);
 	tu->nhit++;
 
@@ -1262,6 +1311,7 @@ static int uretprobe_dispatcher(struct uprobe_consumer *con,
 	struct uprobe_cpu_buffer *ucb;
 	int dsize, esize;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	tu = container_of(con, struct trace_uprobe, consumer);
 
 	udd.tu = tu;
@@ -1304,7 +1354,9 @@ static int register_uprobe_event(struct trace_uprobe *tu)
 	call->class->define_fields = uprobe_event_define_fields;
 
 	if (set_print_fmt(&tu->tp, is_ret_probe(tu)) < 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 
 	ret = register_trace_event(&call->event);
 	if (!ret) {
@@ -1334,7 +1386,9 @@ static int unregister_uprobe_event(struct trace_uprobe *tu)
 	/* tu->event is unregistered in trace_remove_event_call() */
 	ret = trace_remove_event_call(&tu->tp.call);
 	if (ret)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ret;
+}
 	kfree(tu->tp.call.print_fmt);
 	tu->tp.call.print_fmt = NULL;
 	return 0;
@@ -1347,7 +1401,9 @@ static __init int init_uprobe_trace(void)
 
 	d_tracer = tracing_init_dentry();
 	if (IS_ERR(d_tracer))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	trace_create_file("uprobe_events", 0644, d_tracer,
 				    NULL, &uprobe_events_ops);
diff --git a/kernel/tracepoint.c b/kernel/tracepoint.c
index 685c50a..72ff3f2 100644
--- a/kernel/tracepoint.c
+++ b/kernel/tracepoint.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * Copyright (C) 2008-2014 Mathieu Desnoyers
  *
@@ -62,6 +64,7 @@ struct tp_probes {
 
 static inline void *allocate_probes(int count)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct tp_probes *p  = kmalloc(count * sizeof(struct tracepoint_func)
 			+ sizeof(struct tp_probes), GFP_KERNEL);
 	return p == NULL ? NULL : p->probes;
@@ -69,11 +72,13 @@ static inline void *allocate_probes(int count)
 
 static void rcu_free_old_probes(struct rcu_head *head)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	kfree(container_of(head, struct tp_probes, rcu));
 }
 
 static inline void release_probes(struct tracepoint_func *old)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (old) {
 		struct tp_probes *tp_probes = container_of(old,
 			struct tp_probes, probes[0]);
@@ -85,6 +90,7 @@ static void debug_print_probes(struct tracepoint_func *funcs)
 {
 	int i;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!tracepoint_debug || !funcs)
 		return;
 
@@ -100,6 +106,7 @@ func_add(struct tracepoint_func **funcs, struct tracepoint_func *tp_func,
 	int nr_probes = 0;
 	int pos = -1;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (WARN_ON(!tp_func->func))
 		return ERR_PTR(-EINVAL);
 
@@ -149,7 +156,9 @@ static void *func_remove(struct tracepoint_func **funcs,
 	old = *funcs;
 
 	if (!old)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ERR_PTR(-ENOENT);
+}
 
 	debug_print_probes(*funcs);
 	/* (N -> M), (N > 1, M >= 0) probes */
@@ -197,6 +206,7 @@ static int tracepoint_add_func(struct tracepoint *tp,
 	struct tracepoint_func *old, *tp_funcs;
 	int ret;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (tp->regfunc && !static_key_enabled(&tp->key)) {
 		ret = tp->regfunc();
 		if (ret < 0)
@@ -236,6 +246,7 @@ static int tracepoint_remove_func(struct tracepoint *tp,
 {
 	struct tracepoint_func *old, *tp_funcs;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	tp_funcs = rcu_dereference_protected(tp->funcs,
 			lockdep_is_held(&tracepoints_mutex));
 	old = func_remove(&tp_funcs, func);
@@ -301,6 +312,7 @@ EXPORT_SYMBOL_GPL(tracepoint_probe_register_prio);
  */
 int tracepoint_probe_register(struct tracepoint *tp, void *probe, void *data)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return tracepoint_probe_register_prio(tp, probe, data, TRACEPOINT_DEFAULT_PRIO);
 }
 EXPORT_SYMBOL_GPL(tracepoint_probe_register);
@@ -330,6 +342,7 @@ EXPORT_SYMBOL_GPL(tracepoint_probe_unregister);
 #ifdef CONFIG_MODULES
 bool trace_module_has_bad_taint(struct module *mod)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return mod->taints & ~((1 << TAINT_OOT_MODULE) | (1 << TAINT_CRAP) |
 			       (1 << TAINT_UNSIGNED_MODULE));
 }
@@ -354,6 +367,7 @@ int register_tracepoint_module_notifier(struct notifier_block *nb)
 	ret = blocking_notifier_chain_register(&tracepoint_notify_list, nb);
 	if (ret)
 		goto end;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry(tp_mod, &tracepoint_module_list, list)
 		(void) nb->notifier_call(nb, MODULE_STATE_COMING, tp_mod);
 end:
@@ -378,6 +392,7 @@ int unregister_tracepoint_module_notifier(struct notifier_block *nb)
 	ret = blocking_notifier_chain_unregister(&tracepoint_notify_list, nb);
 	if (ret)
 		goto end;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry(tp_mod, &tracepoint_module_list, list)
 		(void) nb->notifier_call(nb, MODULE_STATE_GOING, tp_mod);
 end:
@@ -397,7 +412,9 @@ static void tp_module_going_check_quiescent(struct tracepoint * const *begin,
 	struct tracepoint * const *iter;
 
 	if (!begin)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 	for (iter = begin; iter < end; iter++)
 		WARN_ON_ONCE((*iter)->funcs);
 }
@@ -408,7 +425,9 @@ static int tracepoint_module_coming(struct module *mod)
 	int ret = 0;
 
 	if (!mod->num_tracepoints)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	/*
 	 * We skip modules that taint the kernel, especially those with different
@@ -437,7 +456,9 @@ static void tracepoint_module_going(struct module *mod)
 	struct tp_module *tp_mod;
 
 	if (!mod->num_tracepoints)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	mutex_lock(&tracepoint_module_list_mutex);
 	list_for_each_entry(tp_mod, &tracepoint_module_list, list) {
@@ -496,7 +517,9 @@ static __init int init_tracepoints(void)
 
 	ret = register_module_notifier(&tracepoint_module_nb);
 	if (ret)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_warn("Failed to register tracepoint module enter notifier\n");
+}
 
 	return ret;
 }
@@ -511,7 +534,9 @@ static void for_each_tracepoint_range(struct tracepoint * const *begin,
 	struct tracepoint * const *iter;
 
 	if (!begin)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 	for (iter = begin; iter < end; iter++)
 		fct(*iter, priv);
 }
@@ -524,6 +549,7 @@ static void for_each_tracepoint_range(struct tracepoint * const *begin,
 void for_each_kernel_tracepoint(void (*fct)(struct tracepoint *tp, void *priv),
 		void *priv)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for_each_tracepoint_range(__start___tracepoints_ptrs,
 		__stop___tracepoints_ptrs, fct, priv);
 }
@@ -539,6 +565,7 @@ int syscall_regfunc(void)
 	struct task_struct *p, *t;
 
 	if (!sys_tracepoint_refcount) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		read_lock(&tasklist_lock);
 		for_each_process_thread(p, t) {
 			set_tsk_thread_flag(t, TIF_SYSCALL_TRACEPOINT);
@@ -556,6 +583,7 @@ void syscall_unregfunc(void)
 
 	sys_tracepoint_refcount--;
 	if (!sys_tracepoint_refcount) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		read_lock(&tasklist_lock);
 		for_each_process_thread(p, t) {
 			clear_tsk_thread_flag(t, TIF_SYSCALL_TRACEPOINT);
diff --git a/kernel/tsacct.c b/kernel/tsacct.c
index 370724b..55ae83d 100644
--- a/kernel/tsacct.c
+++ b/kernel/tsacct.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * tsacct.c - System accounting over taskstats interface
  *
@@ -36,6 +38,7 @@ void bacct_add_tsk(struct user_namespace *user_ns,
 	u64 utime, stime, utimescaled, stimescaled;
 	u64 delta;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	BUILD_BUG_ON(TS_COMM_LEN < TASK_COMM_LEN);
 
 	/* calculate task elapsed time in nsec */
@@ -130,13 +133,17 @@ static void __acct_update_integrals(struct task_struct *tsk,
 	u64 time, delta;
 
 	if (!likely(tsk->mm))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	time = stime + utime;
 	delta = time - tsk->acct_timexpd;
 
 	if (delta < TICK_NSEC)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	tsk->acct_timexpd = time;
 	/*
@@ -158,6 +165,7 @@ void acct_update_integrals(struct task_struct *tsk)
 	unsigned long flags;
 
 	local_irq_save(flags);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	task_cputime(tsk, &utime, &stime);
 	__acct_update_integrals(tsk, utime, stime);
 	local_irq_restore(flags);
diff --git a/kernel/ucount.c b/kernel/ucount.c
index b4eeee0..750d7c6 100644
--- a/kernel/ucount.c
+++ b/kernel/ucount.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  *  This program is free software; you can redistribute it and/or
  *  modify it under the terms of the GNU General Public License as
@@ -27,11 +29,13 @@ static DEFINE_SPINLOCK(ucounts_lock);
 static struct ctl_table_set *
 set_lookup(struct ctl_table_root *root)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return &current_user_ns()->set;
 }
 
 static int set_is_seen(struct ctl_table_set *set)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return &current_user_ns()->set == set;
 }
 
@@ -97,6 +101,7 @@ bool setup_userns_sysctls(struct user_namespace *ns)
 		ns->sysctls = __register_sysctl_table(&ns->set, "user", tbl);
 	}
 	if (!ns->sysctls) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		kfree(tbl);
 		retire_sysctl_set(&ns->set);
 		return false;
@@ -123,8 +128,11 @@ static struct ucounts *find_ucounts(struct user_namespace *ns, kuid_t uid, struc
 
 	hlist_for_each_entry(ucounts, hashent, node) {
 		if (uid_eq(ucounts->uid, uid) && (ucounts->ns == ns))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return ucounts;
+}
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return NULL;
 }
 
@@ -136,11 +144,14 @@ static struct ucounts *get_ucounts(struct user_namespace *ns, kuid_t uid)
 	spin_lock_irq(&ucounts_lock);
 	ucounts = find_ucounts(ns, uid, hashent);
 	if (!ucounts) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		spin_unlock_irq(&ucounts_lock);
 
 		new = kzalloc(sizeof(*new), GFP_KERNEL);
 		if (!new)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return NULL;
+}
 
 		new->ns = ns;
 		new->uid = uid;
@@ -149,6 +160,7 @@ static struct ucounts *get_ucounts(struct user_namespace *ns, kuid_t uid)
 		spin_lock_irq(&ucounts_lock);
 		ucounts = find_ucounts(ns, uid, hashent);
 		if (ucounts) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			kfree(new);
 		} else {
 			hlist_add_head(&new->node, hashent);
@@ -156,9 +168,12 @@ static struct ucounts *get_ucounts(struct user_namespace *ns, kuid_t uid)
 		}
 	}
 	if (ucounts->count == INT_MAX)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ucounts = NULL;
+}
 	else
 		ucounts->count += 1;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_unlock_irq(&ucounts_lock);
 	return ucounts;
 }
@@ -170,9 +185,12 @@ static void put_ucounts(struct ucounts *ucounts)
 	spin_lock_irqsave(&ucounts_lock, flags);
 	ucounts->count -= 1;
 	if (!ucounts->count)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		hlist_del_init(&ucounts->node);
+}
 	else
 		ucounts = NULL;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_unlock_irqrestore(&ucounts_lock, flags);
 
 	kfree(ucounts);
@@ -184,10 +202,15 @@ static inline bool atomic_inc_below(atomic_t *v, int u)
 	c = atomic_read(v);
 	for (;;) {
 		if (unlikely(c >= u))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return false;
+}
 		old = atomic_cmpxchg(v, c, c+1);
 		if (likely(old == c))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return true;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		c = old;
 	}
 }
@@ -205,12 +228,17 @@ struct ucounts *inc_ucount(struct user_namespace *ns, kuid_t uid,
 		if (!atomic_inc_below(&iter->ucount[type], max))
 			goto fail;
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return ucounts;
 fail:
 	bad = iter;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (iter = ucounts; iter != bad; iter = iter->ns->ucounts)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		atomic_dec(&iter->ucount[type]);
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	put_ucounts(ucounts);
 	return NULL;
 }
diff --git a/kernel/umh.c b/kernel/umh.c
index 6ff9905..dd242e6 100644
--- a/kernel/umh.c
+++ b/kernel/umh.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * umh - the kernel usermode helper
  */
@@ -81,6 +83,7 @@ static int call_usermodehelper_exec_async(void *data)
 	if (!new)
 		goto out;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_lock(&umh_sysctl_lock);
 	new->cap_bset = cap_intersect(usermodehelper_bset, new->cap_bset);
 	new->cap_inheritable = cap_intersect(usermodehelper_inheritable,
@@ -88,8 +91,10 @@ static int call_usermodehelper_exec_async(void *data)
 	spin_unlock(&umh_sysctl_lock);
 
 	if (sub_info->init) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		retval = sub_info->init(sub_info, new);
 		if (retval) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			abort_creds(new);
 			goto out;
 		}
@@ -110,6 +115,7 @@ static int call_usermodehelper_exec_async(void *data)
 		umh_complete(sub_info);
 	if (!retval)
 		return 0;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	do_exit(0);
 }
 
@@ -122,6 +128,7 @@ static void call_usermodehelper_exec_sync(struct subprocess_info *sub_info)
 	kernel_sigaction(SIGCHLD, SIG_DFL);
 	pid = kernel_thread(call_usermodehelper_exec_async, sub_info, SIGCHLD);
 	if (pid < 0) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		sub_info->retval = pid;
 	} else {
 		int ret = -ECHILD;
@@ -183,6 +190,7 @@ static void call_usermodehelper_exec_work(struct work_struct *work)
 		pid = kernel_thread(call_usermodehelper_exec_async, sub_info,
 				    CLONE_PARENT | SIGCHLD);
 		if (pid < 0) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			sub_info->retval = pid;
 			umh_complete(sub_info);
 		}
@@ -220,6 +228,7 @@ static DECLARE_WAIT_QUEUE_HEAD(usermodehelper_disabled_waitq);
 
 int usermodehelper_read_trylock(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	DEFINE_WAIT(wait);
 	int ret = 0;
 
@@ -250,6 +259,7 @@ EXPORT_SYMBOL_GPL(usermodehelper_read_trylock);
 
 long usermodehelper_read_lock_wait(long timeout)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	DEFINE_WAIT(wait);
 
 	if (timeout < 0)
@@ -277,6 +287,7 @@ EXPORT_SYMBOL_GPL(usermodehelper_read_lock_wait);
 
 void usermodehelper_read_unlock(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	up_read(&umhelper_sem);
 }
 EXPORT_SYMBOL_GPL(usermodehelper_read_unlock);
@@ -307,7 +318,9 @@ int __usermodehelper_disable(enum umh_disable_depth depth)
 	long retval;
 
 	if (!depth)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	down_write(&umhelper_sem);
 	usermodehelper_disabled = depth;
@@ -331,6 +344,7 @@ int __usermodehelper_disable(enum umh_disable_depth depth)
 
 static void helper_lock(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	atomic_inc(&running_helpers);
 	smp_mb__after_atomic();
 }
@@ -411,11 +425,13 @@ int call_usermodehelper_exec(struct subprocess_info *sub_info, int wait)
 	int retval = 0;
 
 	if (!sub_info->path) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		call_usermodehelper_freeinfo(sub_info);
 		return -EINVAL;
 	}
 	helper_lock();
 	if (usermodehelper_disabled) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		retval = -EBUSY;
 		goto out;
 	}
@@ -451,6 +467,7 @@ int call_usermodehelper_exec(struct subprocess_info *sub_info, int wait)
 		/* fallthrough, umh_complete() was already called */
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	wait_for_completion(&done);
 wait_done:
 	retval = sub_info->retval;
@@ -478,6 +495,7 @@ EXPORT_SYMBOL(call_usermodehelper_exec);
 int call_usermodehelper(const char *path, char **argv, char **envp, int wait)
 {
 	struct subprocess_info *info;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	gfp_t gfp_mask = (wait == UMH_NO_WAIT) ? GFP_ATOMIC : GFP_KERNEL;
 
 	info = call_usermodehelper_setup(path, argv, envp, gfp_mask,
@@ -497,6 +515,7 @@ static int proc_cap_handler(struct ctl_table *table, int write,
 	kernel_cap_t new_cap;
 	int err, i;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (write && (!capable(CAP_SETPCAP) ||
 		      !capable(CAP_SYS_MODULE)))
 		return -EPERM;
diff --git a/kernel/user.c b/kernel/user.c
index 00281ad..d5fd76e 100644
--- a/kernel/user.c
+++ b/kernel/user.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * The "user cache".
  *
@@ -121,6 +123,7 @@ static struct user_struct *uid_hash_find(kuid_t uid, struct hlist_head *hashent)
 		}
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return NULL;
 }
 
@@ -131,6 +134,7 @@ static struct user_struct *uid_hash_find(kuid_t uid, struct hlist_head *hashent)
 static void free_user(struct user_struct *up, unsigned long flags)
 	__releases(&uidhash_lock)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	uid_hash_remove(up);
 	spin_unlock_irqrestore(&uidhash_lock, flags);
 	key_put(up->uid_keyring);
@@ -149,6 +153,7 @@ struct user_struct *find_user(kuid_t uid)
 	struct user_struct *ret;
 	unsigned long flags;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_lock_irqsave(&uidhash_lock, flags);
 	ret = uid_hash_find(uid, uidhashentry(uid));
 	spin_unlock_irqrestore(&uidhash_lock, flags);
@@ -160,7 +165,9 @@ void free_uid(struct user_struct *up)
 	unsigned long flags;
 
 	if (!up)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	local_irq_save(flags);
 	if (atomic_dec_and_lock(&up->__count, &uidhash_lock))
@@ -197,12 +204,15 @@ struct user_struct *alloc_uid(kuid_t uid)
 			key_put(new->session_keyring);
 			kmem_cache_free(uid_cachep, new);
 		} else {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			uid_hash_insert(new, hashent);
 			up = new;
 		}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		spin_unlock_irq(&uidhash_lock);
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return up;
 
 out_unlock:
@@ -221,6 +231,7 @@ static int __init uid_cache_init(void)
 
 	/* Insert the root user immediately (init already runs as root) */
 	spin_lock_irq(&uidhash_lock);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	uid_hash_insert(&root_user, uidhashentry(GLOBAL_ROOT_UID));
 	spin_unlock_irq(&uidhash_lock);
 
diff --git a/kernel/user_namespace.c b/kernel/user_namespace.c
index c490f1e..785062a 100644
--- a/kernel/user_namespace.c
+++ b/kernel/user_namespace.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  *  This program is free software; you can redistribute it and/or
  *  modify it under the terms of the GNU General Public License as
diff --git a/kernel/utsname.c b/kernel/utsname.c
index 913fe43..f41d9f9 100644
--- a/kernel/utsname.c
+++ b/kernel/utsname.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  *  Copyright (C) 2004 IBM Corporation
  *
@@ -21,11 +23,13 @@
 
 static struct ucounts *inc_uts_namespaces(struct user_namespace *ns)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return inc_ucount(ns, current_euid(), UCOUNT_UTS_NAMESPACES);
 }
 
 static void dec_uts_namespaces(struct ucounts *ucounts)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	dec_ucount(ucounts, UCOUNT_UTS_NAMESPACES);
 }
 
@@ -35,7 +39,9 @@ static struct uts_namespace *create_uts_ns(void)
 
 	uts_ns = kmalloc(sizeof(struct uts_namespace), GFP_KERNEL);
 	if (uts_ns)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		kref_init(&uts_ns->kref);
+}
 	return uts_ns;
 }
 
@@ -56,6 +62,7 @@ static struct uts_namespace *clone_uts_ns(struct user_namespace *user_ns,
 	if (!ucounts)
 		goto fail;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	err = -ENOMEM;
 	ns = create_uts_ns();
 	if (!ns)
@@ -94,11 +101,15 @@ struct uts_namespace *copy_utsname(unsigned long flags,
 	struct uts_namespace *new_ns;
 
 	BUG_ON(!old_ns);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	get_uts_ns(old_ns);
 
 	if (!(flags & CLONE_NEWUTS))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return old_ns;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	new_ns = clone_uts_ns(user_ns, old_ns);
 
 	put_uts_ns(old_ns);
@@ -109,6 +120,7 @@ void free_uts_ns(struct kref *kref)
 {
 	struct uts_namespace *ns;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	ns = container_of(kref, struct uts_namespace, kref);
 	dec_uts_namespaces(ns->ucounts);
 	put_user_ns(ns->user_ns);
@@ -132,6 +144,7 @@ static struct ns_common *utsns_get(struct task_struct *task)
 		ns = nsproxy->uts_ns;
 		get_uts_ns(ns);
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	task_unlock(task);
 
 	return ns ? &ns->ns : NULL;
@@ -144,6 +157,7 @@ static void utsns_put(struct ns_common *ns)
 
 static int utsns_install(struct nsproxy *nsproxy, struct ns_common *new)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct uts_namespace *ns = to_uts_ns(new);
 
 	if (!ns_capable(ns->user_ns, CAP_SYS_ADMIN) ||
@@ -158,6 +172,7 @@ static int utsns_install(struct nsproxy *nsproxy, struct ns_common *new)
 
 static struct user_namespace *utsns_owner(struct ns_common *ns)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return to_uts_ns(ns)->user_ns;
 }
 
diff --git a/kernel/utsname_sysctl.c b/kernel/utsname_sysctl.c
index 233cd8f..5335823 100644
--- a/kernel/utsname_sysctl.c
+++ b/kernel/utsname_sysctl.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  *  Copyright (C) 2007
  *
@@ -50,13 +52,16 @@ static int proc_do_uts_string(struct ctl_table *table, int write,
 {
 	struct ctl_table uts_table;
 	int r;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	memcpy(&uts_table, table, sizeof(uts_table));
 	uts_table.data = get_uts(table, write);
 	r = proc_dostring(&uts_table, write, buffer, lenp, ppos);
 	put_uts(table, write, uts_table.data);
 
 	if (write)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		proc_sys_poll_notify(table->poll);
+}
 
 	return r;
 }
diff --git a/kernel/watchdog.c b/kernel/watchdog.c
index c8e0670..c2513fb 100644
--- a/kernel/watchdog.c
+++ b/kernel/watchdog.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 /*
  * Detect hard and soft lockups on a system
diff --git a/kernel/watchdog_hld.c b/kernel/watchdog_hld.c
index e449a23..52a3c2a 100644
--- a/kernel/watchdog_hld.c
+++ b/kernel/watchdog_hld.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 /*
  * Detect hard lockups on a system
diff --git a/kernel/workqueue.c b/kernel/workqueue.c
index 8365a52..d68bcea 100644
--- a/kernel/workqueue.c
+++ b/kernel/workqueue.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * kernel/workqueue.c - generic async execution with shared worker pool
  *
@@ -2448,6 +2450,7 @@ struct wq_barrier {
 
 static void wq_barrier_func(struct work_struct *work)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct wq_barrier *barr = container_of(work, struct wq_barrier, work);
 	complete(&barr->done);
 }
@@ -2518,6 +2521,7 @@ static void insert_wq_barrier(struct pool_workqueue *pwq,
 		__set_bit(WORK_STRUCT_LINKED_BIT, bits);
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	debug_work_activate(&barr->work);
 	insert_work(pwq, &barr->work, head,
 		    work_color_to_flags(WORK_NO_COLOR) | linked);
@@ -2574,6 +2578,7 @@ static bool flush_workqueue_prep_pwqs(struct workqueue_struct *wq,
 			WARN_ON_ONCE(pwq->flush_color != -1);
 
 			if (pwq->nr_in_flight[flush_color]) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				pwq->flush_color = flush_color;
 				atomic_inc(&wq->nr_pwqs_to_flush);
 				wait = true;
@@ -2585,6 +2590,7 @@ static bool flush_workqueue_prep_pwqs(struct workqueue_struct *wq,
 			pwq->work_color = work_color;
 		}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		spin_unlock_irq(&pool->lock);
 	}
 
@@ -2611,9 +2617,13 @@ void flush_workqueue(struct workqueue_struct *wq)
 	int next_color;
 
 	if (WARN_ON(!wq_online))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lock_map_acquire(&wq->lockdep_map);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lock_map_release(&wq->lockdep_map);
 
 	mutex_lock(&wq->mutex);
@@ -2661,6 +2671,7 @@ void flush_workqueue(struct workqueue_struct *wq)
 		list_add_tail(&this_flusher.list, &wq->flusher_overflow);
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	check_flush_dependency(wq, NULL);
 
 	mutex_unlock(&wq->mutex);
@@ -2674,30 +2685,40 @@ void flush_workqueue(struct workqueue_struct *wq)
 	 * handling overflow.  Non-first flushers can simply return.
 	 */
 	if (wq->first_flusher != &this_flusher)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	mutex_lock(&wq->mutex);
 
 	/* we might have raced, check again with mutex held */
 	if (wq->first_flusher != &this_flusher)
 		goto out_unlock;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	wq->first_flusher = NULL;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WARN_ON_ONCE(!list_empty(&this_flusher.list));
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WARN_ON_ONCE(wq->flush_color != this_flusher.flush_color);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	while (true) {
 		struct wq_flusher *next, *tmp;
 
 		/* complete all the flushers sharing the current flush color */
 		list_for_each_entry_safe(next, tmp, &wq->flusher_queue, list) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			if (next->flush_color != wq->flush_color)
 				break;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			list_del_init(&next->list);
 			complete(&next->done);
 		}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		WARN_ON_ONCE(!list_empty(&wq->flusher_overflow) &&
 			     wq->flush_color != work_next_color(wq->work_color));
 
@@ -2715,6 +2736,7 @@ void flush_workqueue(struct workqueue_struct *wq)
 			list_for_each_entry(tmp, &wq->flusher_overflow, list)
 				tmp->flush_color = wq->work_color;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			wq->work_color = work_next_color(wq->work_color);
 
 			list_splice_tail_init(&wq->flusher_overflow,
@@ -2722,7 +2744,9 @@ void flush_workqueue(struct workqueue_struct *wq)
 			flush_workqueue_prep_pwqs(wq, -1, wq->work_color);
 		}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (list_empty(&wq->flusher_queue)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			WARN_ON_ONCE(wq->flush_color != wq->work_color);
 			break;
 		}
@@ -2732,6 +2756,7 @@ void flush_workqueue(struct workqueue_struct *wq)
 		 * the new first flusher and arm pwqs.
 		 */
 		WARN_ON_ONCE(wq->flush_color == wq->work_color);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		WARN_ON_ONCE(wq->flush_color != next->flush_color);
 
 		list_del_init(&next->list);
@@ -2775,7 +2800,9 @@ void drain_workqueue(struct workqueue_struct *wq)
 	 */
 	mutex_lock(&wq->mutex);
 	if (!wq->nr_drainers++)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		wq->flags |= __WQ_DRAINING;
+}
 	mutex_unlock(&wq->mutex);
 reflush:
 	flush_workqueue(wq);
@@ -2822,6 +2849,7 @@ static bool start_flush_work(struct work_struct *work, struct wq_barrier *barr)
 		return false;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_lock(&pool->lock);
 	/* see the comment in try_to_grab_pending() with the same code */
 	pwq = get_work_pwq(work);
@@ -2850,10 +2878,13 @@ static bool start_flush_work(struct work_struct *work, struct wq_barrier *barr)
 	 * forward progress.
 	 */
 	if (pwq->wq->saved_max_active == 1 || pwq->wq->rescuer) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		lock_map_acquire(&pwq->wq->lockdep_map);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		lock_map_release(&pwq->wq->lockdep_map);
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return true;
 already_gone:
 	spin_unlock_irq(&pool->lock);
@@ -2876,9 +2907,13 @@ bool flush_work(struct work_struct *work)
 	struct wq_barrier barr;
 
 	if (WARN_ON(!wq_online))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return false;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lock_map_acquire(&work->lockdep_map);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lock_map_release(&work->lockdep_map);
 
 	if (start_flush_work(work, &barr)) {
@@ -2886,6 +2921,7 @@ bool flush_work(struct work_struct *work)
 		destroy_work_on_stack(&barr.work);
 		return true;
 	} else {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return false;
 	}
 }
@@ -2898,6 +2934,7 @@ struct cwt_wait {
 
 static int cwt_wakefn(wait_queue_entry_t *wait, unsigned mode, int sync, void *key)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cwt_wait *cwait = container_of(wait, struct cwt_wait, wait);
 
 	if (cwait->work != key)
@@ -2932,14 +2969,19 @@ static bool __cancel_work_timer(struct work_struct *work, bool is_dwork)
 		if (unlikely(ret == -ENOENT)) {
 			struct cwt_wait cwait;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			init_wait(&cwait.wait);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			cwait.wait.func = cwt_wakefn;
 			cwait.work = work;
 
 			prepare_to_wait_exclusive(&cancel_waitq, &cwait.wait,
 						  TASK_UNINTERRUPTIBLE);
 			if (work_is_canceling(work))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				schedule();
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			finish_wait(&cancel_waitq, &cwait.wait);
 		}
 	} while (unlikely(ret < 0));
@@ -2964,7 +3006,9 @@ static bool __cancel_work_timer(struct work_struct *work, bool is_dwork)
 	 */
 	smp_mb();
 	if (waitqueue_active(&cancel_waitq))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		__wake_up(&cancel_waitq, TASK_NORMAL, 1, work);
+}
 
 	return ret;
 }
@@ -3007,6 +3051,7 @@ EXPORT_SYMBOL_GPL(cancel_work_sync);
  */
 bool flush_delayed_work(struct delayed_work *dwork)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	local_irq_disable();
 	if (del_timer_sync(&dwork->timer))
 		__queue_work(dwork->cpu, dwork->wq, &dwork->work);
@@ -3025,7 +3070,9 @@ static bool __cancel_work(struct work_struct *work, bool is_dwork)
 	} while (unlikely(ret == -EAGAIN));
 
 	if (unlikely(ret < 0))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return false;
+}
 
 	set_work_pool_and_clear_pending(work, get_work_pool_id(work));
 	local_irq_restore(flags);
@@ -3037,6 +3084,7 @@ static bool __cancel_work(struct work_struct *work, bool is_dwork)
  */
 bool cancel_work(struct work_struct *work)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return __cancel_work(work, false);
 }
 
@@ -3095,7 +3143,9 @@ int schedule_on_each_cpu(work_func_t func)
 
 	works = alloc_percpu(struct work_struct);
 	if (!works)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 
 	get_online_cpus();
 
@@ -3128,6 +3178,7 @@ int schedule_on_each_cpu(work_func_t func)
  */
 int execute_in_process_context(work_func_t fn, struct execute_work *ew)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!in_interrupt()) {
 		fn(&ew->work);
 		return 0;
@@ -3149,6 +3200,7 @@ EXPORT_SYMBOL_GPL(execute_in_process_context);
 void free_workqueue_attrs(struct workqueue_attrs *attrs)
 {
 	if (attrs) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		free_cpumask_var(attrs->cpumask);
 		kfree(attrs);
 	}
@@ -3209,9 +3261,13 @@ static bool wqattrs_equal(const struct workqueue_attrs *a,
 			  const struct workqueue_attrs *b)
 {
 	if (a->nice != b->nice)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return false;
+}
 	if (!cpumask_equal(a->cpumask, b->cpumask))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return false;
+}
 	return true;
 }
 
@@ -3253,7 +3309,9 @@ static int init_worker_pool(struct worker_pool *pool)
 	/* shouldn't fail above this point */
 	pool->attrs = alloc_workqueue_attrs(GFP_KERNEL);
 	if (!pool->attrs)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 	return 0;
 }
 
@@ -3273,6 +3331,7 @@ static void rcu_free_wq(struct rcu_head *rcu)
 
 static void rcu_free_pool(struct rcu_head *rcu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct worker_pool *pool = container_of(rcu, struct worker_pool, rcu);
 
 	ida_destroy(&pool->worker_ida);
@@ -3296,6 +3355,7 @@ static void put_unbound_pool(struct worker_pool *pool)
 	DECLARE_COMPLETION_ONSTACK(detach_completion);
 	struct worker *worker;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&wq_pool_mutex);
 
 	if (--pool->refcnt)
@@ -3363,6 +3423,7 @@ static struct worker_pool *get_unbound_pool(const struct workqueue_attrs *attrs)
 	int node;
 	int target_node = NUMA_NO_NODE;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&wq_pool_mutex);
 
 	/* do we already have a matching pool? */
@@ -3375,9 +3436,12 @@ static struct worker_pool *get_unbound_pool(const struct workqueue_attrs *attrs)
 
 	/* if cpumask is contained inside a NUMA node, we belong to that node */
 	if (wq_numa_enabled) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		for_each_node(node) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			if (cpumask_subset(attrs->cpumask,
 					   wq_numa_possible_cpumask[node])) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				target_node = node;
 				break;
 			}
@@ -3389,6 +3453,7 @@ static struct worker_pool *get_unbound_pool(const struct workqueue_attrs *attrs)
 	if (!pool || init_worker_pool(pool) < 0)
 		goto fail;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_set_subclass(&pool->lock, 1);	/* see put_pwq() */
 	copy_workqueue_attrs(pool->attrs, attrs);
 	pool->node = target_node;
@@ -3412,7 +3477,10 @@ static struct worker_pool *get_unbound_pool(const struct workqueue_attrs *attrs)
 	return pool;
 fail:
 	if (pool)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		put_unbound_pool(pool);
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return NULL;
 }
 
@@ -3428,6 +3496,7 @@ static void rcu_free_pwq(struct rcu_head *rcu)
  */
 static void pwq_unbound_release_workfn(struct work_struct *work)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct pool_workqueue *pwq = container_of(work, struct pool_workqueue,
 						  unbound_release_work);
 	struct workqueue_struct *wq = pwq->wq;
@@ -3475,7 +3544,9 @@ static void pwq_adjust_max_active(struct pool_workqueue *pwq)
 
 	/* fast exit for non-freezable wqs */
 	if (!freezable && pwq->max_active == wq->saved_max_active)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	/* this function can be called during early boot w/ irq disabled */
 	spin_lock_irqsave(&pwq->pool->lock, flags);
@@ -3498,6 +3569,7 @@ static void pwq_adjust_max_active(struct pool_workqueue *pwq)
 		 */
 		wake_up_worker(pwq->pool);
 	} else {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pwq->max_active = 0;
 	}
 
@@ -3510,6 +3582,7 @@ static void init_pwq(struct pool_workqueue *pwq, struct workqueue_struct *wq,
 {
 	BUG_ON((unsigned long)pwq & WORK_STRUCT_FLAG_MASK);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	memset(pwq, 0, sizeof(*pwq));
 
 	pwq->pool = pool;
@@ -3527,11 +3600,14 @@ static void link_pwq(struct pool_workqueue *pwq)
 {
 	struct workqueue_struct *wq = pwq->wq;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&wq->mutex);
 
 	/* may be called multiple times, ignore if already linked */
 	if (!list_empty(&pwq->pwqs_node))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	/* set the matching work_color */
 	pwq->work_color = wq->work_color;
@@ -3550,14 +3626,18 @@ static struct pool_workqueue *alloc_unbound_pwq(struct workqueue_struct *wq,
 	struct worker_pool *pool;
 	struct pool_workqueue *pwq;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&wq_pool_mutex);
 
 	pool = get_unbound_pool(attrs);
 	if (!pool)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 
 	pwq = kmem_cache_alloc_node(pwq_cache, GFP_KERNEL, pool->node);
 	if (!pwq) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		put_unbound_pool(pool);
 		return NULL;
 	}
@@ -3597,8 +3677,11 @@ static bool wq_calc_node_cpumask(const struct workqueue_attrs *attrs, int node,
 	/* does @node have any online CPUs @attrs wants? */
 	cpumask_and(cpumask, cpumask_of_node(node), attrs->cpumask);
 	if (cpu_going_down >= 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		cpumask_clear_cpu(cpu_going_down, cpumask);
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (cpumask_empty(cpumask))
 		goto use_dfl;
 
@@ -3606,11 +3689,13 @@ static bool wq_calc_node_cpumask(const struct workqueue_attrs *attrs, int node,
 	cpumask_and(cpumask, attrs->cpumask, wq_numa_possible_cpumask[node]);
 
 	if (cpumask_empty(cpumask)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_warn_once("WARNING: workqueue cpumask: online intersect > "
 				"possible intersect\n");
 		return false;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return !cpumask_equal(cpumask, attrs->cpumask);
 
 use_dfl:
@@ -3625,7 +3710,9 @@ static struct pool_workqueue *numa_pwq_tbl_install(struct workqueue_struct *wq,
 {
 	struct pool_workqueue *old_pwq;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&wq_pool_mutex);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&wq->mutex);
 
 	/* link_pwq() can handle duplicate calls */
@@ -3670,6 +3757,7 @@ apply_wqattrs_prepare(struct workqueue_struct *wq,
 	struct workqueue_attrs *new_attrs, *tmp_attrs;
 	int node;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&wq_pool_mutex);
 
 	ctx = kzalloc(sizeof(*ctx) + nr_node_ids * sizeof(ctx->pwq_tbl[0]),
@@ -3688,7 +3776,9 @@ apply_wqattrs_prepare(struct workqueue_struct *wq,
 	copy_workqueue_attrs(new_attrs, attrs);
 	cpumask_and(new_attrs->cpumask, new_attrs->cpumask, wq_unbound_cpumask);
 	if (unlikely(cpumask_empty(new_attrs->cpumask)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		cpumask_copy(new_attrs->cpumask, wq_unbound_cpumask);
+}
 
 	/*
 	 * We may create multiple pwqs with differing cpumasks.  Make a
@@ -3708,6 +3798,7 @@ apply_wqattrs_prepare(struct workqueue_struct *wq,
 
 	for_each_node(node) {
 		if (wq_calc_node_cpumask(new_attrs, node, -1, tmp_attrs->cpumask)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			ctx->pwq_tbl[node] = alloc_unbound_pwq(wq, tmp_attrs);
 			if (!ctx->pwq_tbl[node])
 				goto out_free;
@@ -3775,19 +3866,27 @@ static int apply_workqueue_attrs_locked(struct workqueue_struct *wq,
 
 	/* only unbound workqueues can change attributes */
 	if (WARN_ON(!(wq->flags & WQ_UNBOUND)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	/* creating multiple pwqs breaks ordering guarantee */
 	if (!list_empty(&wq->pwqs)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (WARN_ON(wq->flags & __WQ_ORDERED_EXPLICIT))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -EINVAL;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		wq->flags &= ~__WQ_ORDERED;
 	}
 
 	ctx = apply_wqattrs_prepare(wq, attrs);
 	if (!ctx)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 
 	/* the ctx has been prepared successfully, let's commit it */
 	apply_wqattrs_commit(ctx);
@@ -3849,12 +3948,14 @@ int apply_workqueue_attrs(struct workqueue_struct *wq,
 static void wq_update_unbound_numa(struct workqueue_struct *wq, int cpu,
 				   bool online)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	int node = cpu_to_node(cpu);
 	int cpu_off = online ? -1 : cpu;
 	struct pool_workqueue *old_pwq = NULL, *pwq;
 	struct workqueue_attrs *target_attrs;
 	cpumask_t *cpumask;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&wq_pool_mutex);
 
 	if (!wq_numa_enabled || !(wq->flags & WQ_UNBOUND) ||
@@ -3879,8 +3980,11 @@ static void wq_update_unbound_numa(struct workqueue_struct *wq, int cpu,
 	 * equals the default pwq's, the default pwq should be used.
 	 */
 	if (wq_calc_node_cpumask(wq->dfl_pwq->pool->attrs, node, cpu_off, cpumask)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (cpumask_equal(cpumask, pwq->pool->attrs->cpumask))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return;
+}
 	} else {
 		goto use_dfl_pwq;
 	}
@@ -3888,6 +3992,7 @@ static void wq_update_unbound_numa(struct workqueue_struct *wq, int cpu,
 	/* create a new pwq */
 	pwq = alloc_unbound_pwq(wq, target_attrs);
 	if (!pwq) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_warn("workqueue: allocation failed while updating NUMA affinity of \"%s\"\n",
 			wq->name);
 		goto use_dfl_pwq;
@@ -3917,7 +4022,9 @@ static int alloc_and_link_pwqs(struct workqueue_struct *wq)
 	if (!(wq->flags & WQ_UNBOUND)) {
 		wq->cpu_pwqs = alloc_percpu(struct pool_workqueue);
 		if (!wq->cpu_pwqs)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -ENOMEM;
+}
 
 		for_each_possible_cpu(cpu) {
 			struct pool_workqueue *pwq =
@@ -3931,6 +4038,7 @@ static int alloc_and_link_pwqs(struct workqueue_struct *wq)
 			link_pwq(pwq);
 			mutex_unlock(&wq->mutex);
 		}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
 	} else if (wq->flags & __WQ_ORDERED) {
 		ret = apply_workqueue_attrs(wq, ordered_wq_attrs[highpri]);
@@ -3950,8 +4058,10 @@ static int wq_clamp_max_active(int max_active, unsigned int flags,
 	int lim = flags & WQ_UNBOUND ? WQ_UNBOUND_MAX_ACTIVE : WQ_MAX_ACTIVE;
 
 	if (max_active < 1 || max_active > lim)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_warn("workqueue: max_active %d requested for %s is out of range, clamping between %d and %d\n",
 			max_active, name, 1, lim);
+}
 
 	return clamp_val(max_active, 1, lim);
 }
@@ -3979,15 +4089,21 @@ struct workqueue_struct *__alloc_workqueue_key(const char *fmt,
 
 	/* see the comment above the definition of WQ_POWER_EFFICIENT */
 	if ((flags & WQ_POWER_EFFICIENT) && wq_power_efficient)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		flags |= WQ_UNBOUND;
+}
 
 	/* allocate wq and format name */
 	if (flags & WQ_UNBOUND)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		tbl_size = nr_node_ids * sizeof(wq->numa_pwq_tbl[0]);
+}
 
 	wq = kzalloc(sizeof(*wq) + tbl_size, GFP_KERNEL);
 	if (!wq)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 
 	if (flags & WQ_UNBOUND) {
 		wq->unbound_attrs = alloc_workqueue_attrs(GFP_KERNEL);
@@ -4006,12 +4122,14 @@ struct workqueue_struct *__alloc_workqueue_key(const char *fmt,
 	wq->flags = flags;
 	wq->saved_max_active = max_active;
 	mutex_init(&wq->mutex);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	atomic_set(&wq->nr_pwqs_to_flush, 0);
 	INIT_LIST_HEAD(&wq->pwqs);
 	INIT_LIST_HEAD(&wq->flusher_queue);
 	INIT_LIST_HEAD(&wq->flusher_overflow);
 	INIT_LIST_HEAD(&wq->maydays);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_init_map(&wq->lockdep_map, lock_name, key, 0);
 	INIT_LIST_HEAD(&wq->list);
 
@@ -4033,6 +4151,7 @@ struct workqueue_struct *__alloc_workqueue_key(const char *fmt,
 		rescuer->task = kthread_create(rescuer_thread, rescuer, "%s",
 					       wq->name);
 		if (IS_ERR(rescuer->task)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			kfree(rescuer);
 			goto err_destroy;
 		}
@@ -4089,6 +4208,7 @@ void destroy_workqueue(struct workqueue_struct *wq)
 
 	/* sanity checks */
 	mutex_lock(&wq->mutex);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for_each_pwq(pwq, wq) {
 		int i;
 
@@ -4194,6 +4314,7 @@ EXPORT_SYMBOL_GPL(workqueue_set_max_active);
  */
 bool current_is_workqueue_rescuer(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct worker *worker = current_wq_worker();
 
 	return worker && worker->rescue_wq;
@@ -4225,7 +4346,9 @@ bool workqueue_congested(int cpu, struct workqueue_struct *wq)
 	rcu_read_lock_sched();
 
 	if (cpu == WORK_CPU_UNBOUND)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		cpu = smp_processor_id();
+}
 
 	if (!(wq->flags & WQ_UNBOUND))
 		pwq = per_cpu_ptr(wq->cpu_pwqs, cpu);
@@ -4256,6 +4379,7 @@ unsigned int work_busy(struct work_struct *work)
 	unsigned long flags;
 	unsigned int ret = 0;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (work_pending(work))
 		ret |= WORK_BUSY_PENDING;
 
@@ -4285,6 +4409,7 @@ EXPORT_SYMBOL_GPL(work_busy);
  */
 void set_worker_desc(const char *fmt, ...)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct worker *worker = current_wq_worker();
 	va_list args;
 
@@ -4320,7 +4445,9 @@ void print_worker_info(const char *log_lvl, struct task_struct *task)
 	struct worker *worker;
 
 	if (!(task->flags & PF_WQ_WORKER))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	/*
 	 * This function is called without any synchronization and @task
@@ -4352,6 +4479,7 @@ void print_worker_info(const char *log_lvl, struct task_struct *task)
 
 static void pr_cont_pool_info(struct worker_pool *pool)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pr_cont(" cpus=%*pbl", nr_cpumask_bits, pool->attrs->cpumask);
 	if (pool->node != NUMA_NO_NODE)
 		pr_cont(" node=%d", pool->node);
@@ -4360,6 +4488,7 @@ static void pr_cont_pool_info(struct worker_pool *pool)
 
 static void pr_cont_work(bool comma, struct work_struct *work)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (work->func == wq_barrier_func) {
 		struct wq_barrier *barr;
 
@@ -4383,6 +4512,7 @@ static void show_pwq(struct pool_workqueue *pwq)
 	pr_info("  pwq %d:", pool->id);
 	pr_cont_pool_info(pool);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pr_cont(" active=%d/%d%s\n", pwq->nr_active, pwq->max_active,
 		!list_empty(&pwq->mayday_node) ? " MAYDAY" : "");
 
@@ -4460,6 +4590,7 @@ void show_workqueue_state(void)
 
 	pr_info("Showing busy workqueues and worker pools:\n");
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry_rcu(wq, &workqueues, list) {
 		struct pool_workqueue *pwq;
 		bool idle = true;
@@ -4541,6 +4672,7 @@ void show_workqueue_state(void)
 
 static void wq_unbind_fn(struct work_struct *work)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	int cpu = smp_processor_id();
 	struct worker_pool *pool;
 	struct worker *worker;
@@ -4603,6 +4735,7 @@ static void rebind_workers(struct worker_pool *pool)
 {
 	struct worker *worker;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&pool->attach_mutex);
 
 	/*
@@ -4683,6 +4816,7 @@ static void restore_unbound_workers_cpumask(struct worker_pool *pool, int cpu)
 	static cpumask_t cpumask;
 	struct worker *worker;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&pool->attach_mutex);
 
 	/* is @cpu allowed for @pool? */
@@ -4700,6 +4834,7 @@ int workqueue_prepare_cpu(unsigned int cpu)
 {
 	struct worker_pool *pool;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for_each_cpu_worker_pool(pool, cpu) {
 		if (pool->nr_workers)
 			continue;
@@ -4717,6 +4852,7 @@ int workqueue_online_cpu(unsigned int cpu)
 
 	mutex_lock(&wq_pool_mutex);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for_each_pool(pool, pi) {
 		mutex_lock(&pool->attach_mutex);
 
@@ -4768,6 +4904,7 @@ struct work_for_cpu {
 
 static void work_for_cpu_fn(struct work_struct *work)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct work_for_cpu *wfc = container_of(work, struct work_for_cpu, work);
 
 	wfc->ret = wfc->fn(wfc->arg);
@@ -4788,6 +4925,7 @@ long work_on_cpu(int cpu, long (*fn)(void *), void *arg)
 {
 	struct work_for_cpu wfc = { .fn = fn, .arg = arg };
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	INIT_WORK_ONSTACK(&wfc.work, work_for_cpu_fn);
 	schedule_work_on(cpu, &wfc.work);
 	flush_work(&wfc.work);
@@ -4813,7 +4951,9 @@ long work_on_cpu_safe(int cpu, long (*fn)(void *), void *arg)
 
 	get_online_cpus();
 	if (cpu_online(cpu))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ret = work_on_cpu(cpu, fn, arg);
+}
 	put_online_cpus();
 	return ret;
 }
@@ -4839,6 +4979,7 @@ void freeze_workqueues_begin(void)
 
 	mutex_lock(&wq_pool_mutex);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WARN_ON_ONCE(workqueue_freezing);
 	workqueue_freezing = true;
 
@@ -4873,6 +5014,7 @@ bool freeze_workqueues_busy(void)
 
 	mutex_lock(&wq_pool_mutex);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WARN_ON_ONCE(!workqueue_freezing);
 
 	list_for_each_entry(wq, &workqueues, list) {
@@ -4917,6 +5059,7 @@ void thaw_workqueues(void)
 	if (!workqueue_freezing)
 		goto out_unlock;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	workqueue_freezing = false;
 
 	/* restore max_active and repopulate worklist */
@@ -4939,6 +5082,7 @@ static int workqueue_apply_unbound_cpumask(void)
 	struct workqueue_struct *wq;
 	struct apply_wqattrs_ctx *ctx, *n;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&wq_pool_mutex);
 
 	list_for_each_entry(wq, &workqueues, list) {
@@ -4984,7 +5128,9 @@ int workqueue_set_unbound_cpumask(cpumask_var_t cpumask)
 	cpumask_var_t saved_cpumask;
 
 	if (!zalloc_cpumask_var(&saved_cpumask, GFP_KERNEL))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 
 	cpumask_and(cpumask, cpumask, cpu_possible_mask);
 	if (!cpumask_empty(cpumask)) {
@@ -5030,6 +5176,7 @@ struct wq_device {
 
 static struct workqueue_struct *dev_to_wq(struct device *dev)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct wq_device *wq_dev = container_of(dev, struct wq_device, dev);
 
 	return wq_dev->wq;
@@ -5038,6 +5185,7 @@ static struct workqueue_struct *dev_to_wq(struct device *dev)
 static ssize_t per_cpu_show(struct device *dev, struct device_attribute *attr,
 			    char *buf)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct workqueue_struct *wq = dev_to_wq(dev);
 
 	return scnprintf(buf, PAGE_SIZE, "%d\n", (bool)!(wq->flags & WQ_UNBOUND));
@@ -5047,6 +5195,7 @@ static DEVICE_ATTR_RO(per_cpu);
 static ssize_t max_active_show(struct device *dev,
 			       struct device_attribute *attr, char *buf)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct workqueue_struct *wq = dev_to_wq(dev);
 
 	return scnprintf(buf, PAGE_SIZE, "%d\n", wq->saved_max_active);
@@ -5056,6 +5205,7 @@ static ssize_t max_active_store(struct device *dev,
 				struct device_attribute *attr, const char *buf,
 				size_t count)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct workqueue_struct *wq = dev_to_wq(dev);
 	int val;
 
@@ -5077,6 +5227,7 @@ ATTRIBUTE_GROUPS(wq_sysfs);
 static ssize_t wq_pool_ids_show(struct device *dev,
 				struct device_attribute *attr, char *buf)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct workqueue_struct *wq = dev_to_wq(dev);
 	const char *delim = "";
 	int node, written = 0;
@@ -5097,6 +5248,7 @@ static ssize_t wq_pool_ids_show(struct device *dev,
 static ssize_t wq_nice_show(struct device *dev, struct device_attribute *attr,
 			    char *buf)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct workqueue_struct *wq = dev_to_wq(dev);
 	int written;
 
@@ -5112,6 +5264,7 @@ static struct workqueue_attrs *wq_sysfs_prep_attrs(struct workqueue_struct *wq)
 {
 	struct workqueue_attrs *attrs;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&wq_pool_mutex);
 
 	attrs = alloc_workqueue_attrs(GFP_KERNEL);
@@ -5125,6 +5278,7 @@ static struct workqueue_attrs *wq_sysfs_prep_attrs(struct workqueue_struct *wq)
 static ssize_t wq_nice_store(struct device *dev, struct device_attribute *attr,
 			     const char *buf, size_t count)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct workqueue_struct *wq = dev_to_wq(dev);
 	struct workqueue_attrs *attrs;
 	int ret = -ENOMEM;
@@ -5150,6 +5304,7 @@ static ssize_t wq_nice_store(struct device *dev, struct device_attribute *attr,
 static ssize_t wq_cpumask_show(struct device *dev,
 			       struct device_attribute *attr, char *buf)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct workqueue_struct *wq = dev_to_wq(dev);
 	int written;
 
@@ -5164,6 +5319,7 @@ static ssize_t wq_cpumask_store(struct device *dev,
 				struct device_attribute *attr,
 				const char *buf, size_t count)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct workqueue_struct *wq = dev_to_wq(dev);
 	struct workqueue_attrs *attrs;
 	int ret = -ENOMEM;
@@ -5187,6 +5343,7 @@ static ssize_t wq_cpumask_store(struct device *dev,
 static ssize_t wq_numa_show(struct device *dev, struct device_attribute *attr,
 			    char *buf)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct workqueue_struct *wq = dev_to_wq(dev);
 	int written;
 
@@ -5201,6 +5358,7 @@ static ssize_t wq_numa_show(struct device *dev, struct device_attribute *attr,
 static ssize_t wq_numa_store(struct device *dev, struct device_attribute *attr,
 			     const char *buf, size_t count)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct workqueue_struct *wq = dev_to_wq(dev);
 	struct workqueue_attrs *attrs;
 	int v, ret = -ENOMEM;
@@ -5256,7 +5414,9 @@ static ssize_t wq_unbound_cpumask_store(struct device *dev,
 	int ret;
 
 	if (!zalloc_cpumask_var(&cpumask, GFP_KERNEL))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 
 	ret = cpumask_parse(buf, cpumask);
 	if (!ret)
@@ -5276,7 +5436,9 @@ static int __init wq_sysfs_init(void)
 
 	err = subsys_virtual_register(&wq_subsys, NULL);
 	if (err)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return err;
+}
 
 	return device_create_file(wq_subsys.dev_root, &wq_sysfs_cpumask_attr);
 }
@@ -5284,6 +5446,7 @@ core_initcall(wq_sysfs_init);
 
 static void wq_device_release(struct device *dev)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct wq_device *wq_dev = container_of(dev, struct wq_device, dev);
 
 	kfree(wq_dev);
@@ -5315,11 +5478,15 @@ int workqueue_sysfs_register(struct workqueue_struct *wq)
 	 * workqueues.
 	 */
 	if (WARN_ON(wq->flags & __WQ_ORDERED_EXPLICIT))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	wq->wq_dev = wq_dev = kzalloc(sizeof(*wq_dev), GFP_KERNEL);
 	if (!wq_dev)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 
 	wq_dev->wq = wq;
 	wq_dev->dev.bus = &wq_subsys;
@@ -5334,6 +5501,7 @@ int workqueue_sysfs_register(struct workqueue_struct *wq)
 
 	ret = device_register(&wq_dev->dev);
 	if (ret) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		kfree(wq_dev);
 		wq->wq_dev = NULL;
 		return ret;
@@ -5345,6 +5513,7 @@ int workqueue_sysfs_register(struct workqueue_struct *wq)
 		for (attr = wq_sysfs_unbound_attrs; attr->attr.name; attr++) {
 			ret = device_create_file(&wq_dev->dev, attr);
 			if (ret) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				device_unregister(&wq_dev->dev);
 				wq->wq_dev = NULL;
 				return ret;
@@ -5352,6 +5521,7 @@ int workqueue_sysfs_register(struct workqueue_struct *wq)
 		}
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	dev_set_uevent_suppress(&wq_dev->dev, false);
 	kobject_uevent(&wq_dev->dev.kobj, KOBJ_ADD);
 	return 0;
@@ -5368,7 +5538,9 @@ static void workqueue_sysfs_unregister(struct workqueue_struct *wq)
 	struct wq_device *wq_dev = wq->wq_dev;
 
 	if (!wq->wq_dev)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	wq->wq_dev = NULL;
 	device_unregister(&wq_dev->dev);
@@ -5531,7 +5703,9 @@ static void __init wq_numa_init(void)
 	int node, cpu;
 
 	if (num_possible_nodes() <= 1)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	if (wq_disable_numa) {
 		pr_info("workqueue: NUMA affinity support disabled\n");
@@ -5582,8 +5756,10 @@ int __init workqueue_init_early(void)
 	int std_nice[NR_STD_WORKER_POOLS] = { 0, HIGHPRI_NICE_LEVEL };
 	int i, cpu;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WARN_ON(__alignof__(struct pool_workqueue) < __alignof__(long long));
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	BUG_ON(!alloc_cpumask_var(&wq_unbound_cpumask, GFP_KERNEL));
 	cpumask_copy(wq_unbound_cpumask, cpu_possible_mask);
 
diff --git a/kernel/workqueue_internal.h b/kernel/workqueue_internal.h
index d390d1b..3f87e42 100644
--- a/kernel/workqueue_internal.h
+++ b/kernel/workqueue_internal.h
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /* SPDX-License-Identifier: GPL-2.0 */
 /*
  * kernel/workqueue_internal.h
-- 
2.7.4

