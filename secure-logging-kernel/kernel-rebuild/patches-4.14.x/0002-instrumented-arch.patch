From b84861889c0aab61e1b9fec5e10782504b2db052 Mon Sep 17 00:00:00 2001
From: Yiwen Li <detectivelyw@gmail.com>
Date: Wed, 5 Jun 2019 13:46:27 -0400
Subject: [PATCH 2/2] instrumented arch.

---
 arch/x86/crypto/aes_glue.c                 |   2 +
 arch/x86/crypto/aesni-intel_glue.c         |   2 +
 arch/x86/crypto/blowfish_glue.c            |   2 +
 arch/x86/crypto/camellia_aesni_avx2_glue.c |   2 +
 arch/x86/crypto/camellia_aesni_avx_glue.c  |   2 +
 arch/x86/crypto/camellia_glue.c            |   2 +
 arch/x86/crypto/cast5_avx_glue.c           |   2 +
 arch/x86/crypto/cast6_avx_glue.c           |   2 +
 arch/x86/crypto/chacha20_glue.c            |   2 +
 arch/x86/crypto/crc32-pclmul_glue.c        |   2 +
 arch/x86/crypto/crc32c-intel_glue.c        |   2 +
 arch/x86/crypto/des3_ede_glue.c            |   2 +
 arch/x86/crypto/ghash-clmulni-intel_glue.c |   2 +
 arch/x86/crypto/poly1305_glue.c            |   2 +
 arch/x86/crypto/salsa20_glue.c             |   2 +
 arch/x86/crypto/serpent_avx2_glue.c        |   2 +
 arch/x86/crypto/serpent_avx_glue.c         |   2 +
 arch/x86/crypto/serpent_sse2_glue.c        |   2 +
 arch/x86/crypto/sha1_ssse3_glue.c          |   2 +
 arch/x86/crypto/sha256_ssse3_glue.c        |   2 +
 arch/x86/crypto/sha512_ssse3_glue.c        |   2 +
 arch/x86/crypto/twofish_avx_glue.c         |   2 +
 arch/x86/crypto/twofish_glue.c             |   2 +
 arch/x86/crypto/twofish_glue_3way.c        |   2 +
 arch/x86/entry/common.c                    |  19 +++
 arch/x86/entry/vsyscall/vsyscall_64.c      |  16 +++
 arch/x86/entry/vsyscall/vsyscall_gtod.c    |   4 +
 arch/x86/entry/vsyscall/vsyscall_trace.h   |   2 +
 arch/x86/events/amd/core.c                 |  32 +++++
 arch/x86/events/amd/ibs.c                  |  48 +++++++
 arch/x86/events/amd/uncore.c               |  51 +++++++
 arch/x86/events/core.c                     | 142 ++++++++++++++++++++
 arch/x86/events/intel/bts.c                |  26 ++++
 arch/x86/events/intel/core.c               |  83 ++++++++++++
 arch/x86/events/intel/cstate.c             |  22 +++
 arch/x86/events/intel/pt.c                 |  60 +++++++++
 arch/x86/events/intel/rapl.c               |  34 +++++
 arch/x86/events/intel/uncore.c             |  66 +++++++++
 arch/x86/events/msr.c                      |  16 +++
 arch/x86/events/perf_event.h               |   2 +
 arch/x86/kernel/acpi/boot.c                | 123 +++++++++++++++++
 arch/x86/kernel/acpi/cstate.c              |   7 +
 arch/x86/kernel/alternative.c              |  27 ++++
 arch/x86/kernel/amd_nb.c                   |  57 ++++++++
 arch/x86/kernel/apic/apic.c                | 165 +++++++++++++++++++++++
 arch/x86/kernel/apic/apic_flat_64.c        |  14 ++
 arch/x86/kernel/apic/htirq.c               |  10 ++
 arch/x86/kernel/apic/hw_nmi.c              |   5 +
 arch/x86/kernel/apic/io_apic.c             | 206 +++++++++++++++++++++++++++++
 arch/x86/kernel/apic/ipi.c                 |   7 +
 arch/x86/kernel/apic/msi.c                 |  27 ++++
 arch/x86/kernel/apic/probe_64.c            |   9 ++
 arch/x86/kernel/apic/vector.c              |  70 ++++++++++
 arch/x86/kernel/apic/x2apic_cluster.c      |   2 +
 arch/x86/kernel/apic/x2apic_phys.c         |   2 +
 arch/x86/kernel/audit_64.c                 |   3 +
 arch/x86/kernel/bootflag.c                 |  12 ++
 arch/x86/kernel/cpu/amd.c                  |  85 ++++++++++++
 arch/x86/kernel/cpu/aperfmperf.c           |  21 +++
 arch/x86/kernel/cpu/bugs.c                 |  36 +++++
 arch/x86/kernel/cpu/common.c               |  97 ++++++++++++++
 arch/x86/kernel/cpu/cpuid-deps.c           |   9 ++
 arch/x86/kernel/cpu/hypervisor.c           |   2 +
 arch/x86/kernel/cpu/intel_cacheinfo.c      |  83 ++++++++++++
 arch/x86/kernel/cpu/match.c                |   4 +
 arch/x86/kernel/cpu/microcode/core.c       |  79 +++++++++++
 arch/x86/kernel/cpu/mshyperv.c             |   2 +
 arch/x86/kernel/cpu/mtrr/cleanup.c         |  50 +++++++
 arch/x86/kernel/cpu/mtrr/generic.c         |  61 +++++++++
 arch/x86/kernel/cpu/mtrr/if.c              |   9 ++
 arch/x86/kernel/cpu/mtrr/main.c            |  43 ++++++
 arch/x86/kernel/cpu/proc.c                 |   6 +
 arch/x86/kernel/cpu/rdrand.c               |   7 +
 arch/x86/kernel/cpu/scattered.c            |   5 +
 arch/x86/kernel/cpu/vmware.c               |   2 +
 arch/x86/kernel/cpuid.c                    |   9 ++
 arch/x86/kernel/e820.c                     |  94 +++++++++++++
 arch/x86/kernel/early-quirks.c             |  39 ++++++
 arch/x86/kernel/ebda.c                     |   8 ++
 arch/x86/kernel/fpu/core.c                 |  31 +++++
 arch/x86/kernel/fpu/init.c                 |  22 +++
 arch/x86/kernel/fpu/signal.c               |  60 +++++++++
 arch/x86/kernel/fpu/xstate.c               |  27 ++++
 arch/x86/kernel/ftrace.c                   |   2 +
 arch/x86/kernel/head64.c                   |  29 ++++
 arch/x86/kernel/hpet.c                     | 124 +++++++++++++++++
 arch/x86/kernel/hw_breakpoint.c            |  14 ++
 arch/x86/kernel/i8237.c                    |   3 +
 arch/x86/kernel/i8259.c                    |  24 ++++
 arch/x86/kernel/idt.c                      |   6 +
 arch/x86/kernel/io_delay.c                 |   4 +
 arch/x86/kernel/irq.c                      |  18 +++
 arch/x86/kernel/irq_64.c                   |   7 +
 arch/x86/kernel/irqinit.c                  |   5 +
 arch/x86/kernel/jump_label.c               |   2 +
 arch/x86/kernel/kdebugfs.c                 |  12 ++
 arch/x86/kernel/kprobes/core.c             |   2 +
 arch/x86/kernel/ksysfs.c                   |  29 ++++
 arch/x86/kernel/kvm.c                      |   2 +
 arch/x86/kernel/kvmclock.c                 |   2 +
 arch/x86/kernel/module.c                   |   9 ++
 arch/x86/kernel/mpparse.c                  |  38 ++++++
 arch/x86/kernel/msr.c                      |  11 ++
 arch/x86/kernel/nmi.c                      |  14 ++
 arch/x86/kernel/paravirt-spinlocks.c       |   2 +
 arch/x86/kernel/paravirt.c                 |   2 +
 arch/x86/kernel/paravirt_patch_64.c        |   2 +
 arch/x86/kernel/pci-dma.c                  |  24 ++++
 arch/x86/kernel/pci-iommu_table.c          |   7 +
 arch/x86/kernel/pci-nommu.c                |  13 ++
 arch/x86/kernel/pci-swiotlb.c              |  12 ++
 arch/x86/kernel/pcspeaker.c                |   2 +
 arch/x86/kernel/platform-quirks.c          |   4 +
 arch/x86/kernel/probe_roms.c               |  14 ++
 arch/x86/kernel/process.c                  |  59 +++++++++
 arch/x86/kernel/process_64.c               |  43 ++++++
 arch/x86/kernel/ptrace.c                   |  12 ++
 arch/x86/kernel/quirks.c                   |  28 ++++
 arch/x86/kernel/reboot.c                   |  30 +++++
 arch/x86/kernel/rtc.c                      |  20 +++
 arch/x86/kernel/setup.c                    |  61 +++++++++
 arch/x86/kernel/setup_percpu.c             |  15 +++
 arch/x86/kernel/signal.c                   |  28 ++++
 arch/x86/kernel/signal_compat.c            |  14 ++
 arch/x86/kernel/smpboot.c                  |  90 +++++++++++++
 arch/x86/kernel/step.c                     |  18 +++
 arch/x86/kernel/sys_x86_64.c               |  30 +++++
 arch/x86/kernel/sysfb.c                    |   9 ++
 arch/x86/kernel/sysfb_efi.c                |   4 +
 arch/x86/kernel/time.c                     |   7 +
 arch/x86/kernel/topology.c                 |   8 ++
 arch/x86/kernel/traps.c                    |  38 ++++++
 arch/x86/kernel/tsc.c                      | 108 +++++++++++++++
 arch/x86/kernel/tsc_msr.c                  |  15 +++
 arch/x86/kernel/tsc_sync.c                 |  24 ++++
 arch/x86/kernel/unwind_orc.c               |  12 ++
 arch/x86/kernel/uprobes.c                  |  35 +++++
 arch/x86/kernel/vsmp_64.c                  |  14 ++
 arch/x86/kernel/x86_init.c                 |   8 +-
 arch/x86/lib/cmdline.c                     |  26 ++++
 arch/x86/lib/cpu.c                         |   4 +
 arch/x86/lib/csum-partial_64.c             |   7 +
 arch/x86/lib/csum-wrappers_64.c            |   8 ++
 arch/x86/lib/delay.c                       |  10 ++
 arch/x86/lib/msr.c                         |  16 +++
 arch/x86/lib/usercopy_64.c                 |   8 ++
 arch/x86/mm/cpu_entry_area.c               |  13 ++
 arch/x86/mm/extable.c                      |  12 ++
 arch/x86/mm/fault.c                        | 177 +++++++++++++++++++++++++
 arch/x86/mm/hugetlbpage.c                  |  24 ++++
 arch/x86/mm/init.c                         |  45 +++++++
 arch/x86/mm/init_64.c                      |  89 +++++++++++++
 arch/x86/mm/ioremap.c                      |  37 ++++++
 arch/x86/mm/kaslr.c                        |  15 +++
 arch/x86/mm/mm_internal.h                  |   2 +
 arch/x86/mm/mmap.c                         |  23 ++++
 arch/x86/mm/mmio-mod.c                     |   2 +
 arch/x86/mm/pageattr.c                     | 151 +++++++++++++++++++++
 arch/x86/mm/pat.c                          | 100 ++++++++++++++
 arch/x86/mm/pat_rbtree.c                   |  26 ++++
 arch/x86/mm/pgtable.c                      |  30 +++++
 arch/x86/mm/physaddr.c                     |   6 +
 arch/x86/mm/physaddr.h                     |   2 +
 arch/x86/mm/pkeys.c                        |   6 +
 arch/x86/mm/pti.c                          |  22 +++
 arch/x86/mm/setup_nx.c                     |   5 +
 arch/x86/mm/tlb.c                          |  40 ++++++
 arch/x86/net/bpf_jit_comp.c                |   2 +
 arch/x86/oprofile/init.c                   |   2 +
 arch/x86/oprofile/nmi_int.c                |   2 +
 arch/x86/oprofile/op_model_amd.c           |   2 +
 arch/x86/pci/acpi.c                        |  42 ++++++
 arch/x86/pci/amd_bus.c                     |  54 ++++++++
 arch/x86/pci/common.c                      |  35 +++++
 arch/x86/pci/direct.c                      |  45 +++++++
 arch/x86/pci/early.c                       |   8 ++
 arch/x86/pci/fixup.c                       |  24 ++++
 arch/x86/pci/i386.c                        |  25 ++++
 arch/x86/pci/init.c                        |   6 +
 arch/x86/pci/irq.c                         |  49 +++++++
 arch/x86/pci/legacy.c                      |  10 ++
 arch/x86/pci/mmconfig-shared.c             |  60 +++++++++
 arch/x86/pci/mmconfig_64.c                 |  11 ++
 arch/x86/platform/efi/quirks.c             |  18 +++
 arch/x86/power/cpu.c                       |  11 ++
 arch/x86/realmode/init.c                   |  10 ++
 arch/x86/xen/apic.c                        |   2 +
 arch/x86/xen/enlighten_hvm.c               |   2 +
 arch/x86/xen/enlighten_pv.c                |   2 +
 arch/x86/xen/grant-table.c                 |   2 +
 arch/x86/xen/pci-swiotlb-xen.c             |   2 +
 arch/x86/xen/platform-pci-unplug.c         |   2 +
 192 files changed, 4810 insertions(+), 1 deletion(-)

diff --git a/arch/x86/crypto/aes_glue.c b/arch/x86/crypto/aes_glue.c
index e26984f..8f40117 100644
--- a/arch/x86/crypto/aes_glue.c
+++ b/arch/x86/crypto/aes_glue.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * Glue Code for the asm optimized version of the AES Cipher Algorithm
  *
diff --git a/arch/x86/crypto/aesni-intel_glue.c b/arch/x86/crypto/aesni-intel_glue.c
index c690ddc..ad99c72 100644
--- a/arch/x86/crypto/aesni-intel_glue.c
+++ b/arch/x86/crypto/aesni-intel_glue.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * Support for Intel AES-NI instructions. This file contains glue
  * code, the real AES implementation is in intel-aes_asm.S.
diff --git a/arch/x86/crypto/blowfish_glue.c b/arch/x86/crypto/blowfish_glue.c
index f9eca34..05e32ef 100644
--- a/arch/x86/crypto/blowfish_glue.c
+++ b/arch/x86/crypto/blowfish_glue.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * Glue Code for assembler optimized version of Blowfish
  *
diff --git a/arch/x86/crypto/camellia_aesni_avx2_glue.c b/arch/x86/crypto/camellia_aesni_avx2_glue.c
index 60907c1..289f4dd 100644
--- a/arch/x86/crypto/camellia_aesni_avx2_glue.c
+++ b/arch/x86/crypto/camellia_aesni_avx2_glue.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * Glue Code for x86_64/AVX2/AES-NI assembler optimized version of Camellia
  *
diff --git a/arch/x86/crypto/camellia_aesni_avx_glue.c b/arch/x86/crypto/camellia_aesni_avx_glue.c
index d96429d..528e8cc 100644
--- a/arch/x86/crypto/camellia_aesni_avx_glue.c
+++ b/arch/x86/crypto/camellia_aesni_avx_glue.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * Glue Code for x86_64/AVX/AES-NI assembler optimized version of Camellia
  *
diff --git a/arch/x86/crypto/camellia_glue.c b/arch/x86/crypto/camellia_glue.c
index af4840a..0a8af69 100644
--- a/arch/x86/crypto/camellia_glue.c
+++ b/arch/x86/crypto/camellia_glue.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * Glue Code for assembler optimized version of Camellia
  *
diff --git a/arch/x86/crypto/cast5_avx_glue.c b/arch/x86/crypto/cast5_avx_glue.c
index dbea602..6266abf 100644
--- a/arch/x86/crypto/cast5_avx_glue.c
+++ b/arch/x86/crypto/cast5_avx_glue.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * Glue Code for the AVX assembler implemention of the Cast5 Cipher
  *
diff --git a/arch/x86/crypto/cast6_avx_glue.c b/arch/x86/crypto/cast6_avx_glue.c
index 50e6847..d900e9f 100644
--- a/arch/x86/crypto/cast6_avx_glue.c
+++ b/arch/x86/crypto/cast6_avx_glue.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * Glue Code for the AVX assembler implemention of the Cast6 Cipher
  *
diff --git a/arch/x86/crypto/chacha20_glue.c b/arch/x86/crypto/chacha20_glue.c
index 1e6af1b..5951364c 100644
--- a/arch/x86/crypto/chacha20_glue.c
+++ b/arch/x86/crypto/chacha20_glue.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * ChaCha20 256-bit cipher algorithm, RFC7539, SIMD glue code
  *
diff --git a/arch/x86/crypto/crc32-pclmul_glue.c b/arch/x86/crypto/crc32-pclmul_glue.c
index c8d9cda..e01f9da 100644
--- a/arch/x86/crypto/crc32-pclmul_glue.c
+++ b/arch/x86/crypto/crc32-pclmul_glue.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /* GPL HEADER START
  *
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
diff --git a/arch/x86/crypto/crc32c-intel_glue.c b/arch/x86/crypto/crc32c-intel_glue.c
index 5773e11..5cc368f 100644
--- a/arch/x86/crypto/crc32c-intel_glue.c
+++ b/arch/x86/crypto/crc32c-intel_glue.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * Using hardware provided CRC32 instruction to accelerate the CRC32 disposal.
  * CRC32C polynomial:0x1EDC6F41(BE)/0x82F63B78(LE)
diff --git a/arch/x86/crypto/des3_ede_glue.c b/arch/x86/crypto/des3_ede_glue.c
index 30c0a37..d87c1f3 100644
--- a/arch/x86/crypto/des3_ede_glue.c
+++ b/arch/x86/crypto/des3_ede_glue.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * Glue Code for assembler optimized version of 3DES
  *
diff --git a/arch/x86/crypto/ghash-clmulni-intel_glue.c b/arch/x86/crypto/ghash-clmulni-intel_glue.c
index 0420bab..911efc4 100644
--- a/arch/x86/crypto/ghash-clmulni-intel_glue.c
+++ b/arch/x86/crypto/ghash-clmulni-intel_glue.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * Accelerated GHASH implementation with Intel PCLMULQDQ-NI
  * instructions. This file contains glue code.
diff --git a/arch/x86/crypto/poly1305_glue.c b/arch/x86/crypto/poly1305_glue.c
index 28c3720..0a10038 100644
--- a/arch/x86/crypto/poly1305_glue.c
+++ b/arch/x86/crypto/poly1305_glue.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * Poly1305 authenticator algorithm, RFC7539, SIMD glue code
  *
diff --git a/arch/x86/crypto/salsa20_glue.c b/arch/x86/crypto/salsa20_glue.c
index cb91a64..529192b 100644
--- a/arch/x86/crypto/salsa20_glue.c
+++ b/arch/x86/crypto/salsa20_glue.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * Glue code for optimized assembly version of  Salsa20.
  *
diff --git a/arch/x86/crypto/serpent_avx2_glue.c b/arch/x86/crypto/serpent_avx2_glue.c
index 870f6d8..9c42da3 100644
--- a/arch/x86/crypto/serpent_avx2_glue.c
+++ b/arch/x86/crypto/serpent_avx2_glue.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * Glue Code for x86_64/AVX2 assembler optimized version of Serpent
  *
diff --git a/arch/x86/crypto/serpent_avx_glue.c b/arch/x86/crypto/serpent_avx_glue.c
index 6f778d3..3a74d9ed 100644
--- a/arch/x86/crypto/serpent_avx_glue.c
+++ b/arch/x86/crypto/serpent_avx_glue.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * Glue Code for AVX assembler versions of Serpent Cipher
  *
diff --git a/arch/x86/crypto/serpent_sse2_glue.c b/arch/x86/crypto/serpent_sse2_glue.c
index ac0e831..4125f08 100644
--- a/arch/x86/crypto/serpent_sse2_glue.c
+++ b/arch/x86/crypto/serpent_sse2_glue.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * Glue Code for SSE2 assembler versions of Serpent Cipher
  *
diff --git a/arch/x86/crypto/sha1_ssse3_glue.c b/arch/x86/crypto/sha1_ssse3_glue.c
index fc61739..8aa0510 100644
--- a/arch/x86/crypto/sha1_ssse3_glue.c
+++ b/arch/x86/crypto/sha1_ssse3_glue.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * Cryptographic API.
  *
diff --git a/arch/x86/crypto/sha256_ssse3_glue.c b/arch/x86/crypto/sha256_ssse3_glue.c
index 9e79baf..2ae5db3 100644
--- a/arch/x86/crypto/sha256_ssse3_glue.c
+++ b/arch/x86/crypto/sha256_ssse3_glue.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * Cryptographic API.
  *
diff --git a/arch/x86/crypto/sha512_ssse3_glue.c b/arch/x86/crypto/sha512_ssse3_glue.c
index 2b0e2a6..a9b64c5a 100644
--- a/arch/x86/crypto/sha512_ssse3_glue.c
+++ b/arch/x86/crypto/sha512_ssse3_glue.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * Cryptographic API.
  *
diff --git a/arch/x86/crypto/twofish_avx_glue.c b/arch/x86/crypto/twofish_avx_glue.c
index b7a3904..6a9b451 100644
--- a/arch/x86/crypto/twofish_avx_glue.c
+++ b/arch/x86/crypto/twofish_avx_glue.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * Glue Code for AVX assembler version of Twofish Cipher
  *
diff --git a/arch/x86/crypto/twofish_glue.c b/arch/x86/crypto/twofish_glue.c
index 77e06c2..2948c94 100644
--- a/arch/x86/crypto/twofish_glue.c
+++ b/arch/x86/crypto/twofish_glue.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * Glue Code for assembler optimized version of TWOFISH
  *
diff --git a/arch/x86/crypto/twofish_glue_3way.c b/arch/x86/crypto/twofish_glue_3way.c
index 243e90a..07a4815 100644
--- a/arch/x86/crypto/twofish_glue_3way.c
+++ b/arch/x86/crypto/twofish_glue_3way.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * Glue Code for 3-way parallel assembler optimized version of Twofish
  *
diff --git a/arch/x86/entry/common.c b/arch/x86/entry/common.c
index 60e21cc..2cd7a9f 100644
--- a/arch/x86/entry/common.c
+++ b/arch/x86/entry/common.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * common.c - C code for kernel entry and exit
  * Copyright (c) 2015 Andrew Lutomirski
@@ -66,6 +68,7 @@ static void do_audit_syscall_entry(struct pt_regs *regs, u32 arch)
  */
 static long syscall_trace_enter(struct pt_regs *regs)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	u32 arch = in_ia32_syscall() ? AUDIT_ARCH_I386 : AUDIT_ARCH_X86_64;
 
 	struct thread_info *ti = current_thread_info();
@@ -152,7 +155,9 @@ static void exit_to_usermode_loop(struct pt_regs *regs, u32 cached_flags)
 			schedule();
 
 		if (cached_flags & _TIF_UPROBE)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			uprobe_notify_resume(regs);
+}
 
 		/* deal with pending signal delivery */
 		if (cached_flags & _TIF_SIGPENDING)
@@ -164,10 +169,14 @@ static void exit_to_usermode_loop(struct pt_regs *regs, u32 cached_flags)
 		}
 
 		if (cached_flags & _TIF_USER_RETURN_NOTIFY)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			fire_user_return_notifiers();
+}
 
 		if (cached_flags & _TIF_PATCH_PENDING)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			klp_update_patch_state(current);
+}
 
 		/* Disable IRQs and retry */
 		local_irq_disable();
@@ -226,7 +235,9 @@ static void syscall_slow_exit_work(struct pt_regs *regs, u32 cached_flags)
 	audit_syscall_exit(regs);
 
 	if (cached_flags & _TIF_SYSCALL_TRACEPOINT)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		trace_sys_exit(regs, regs->ax);
+}
 
 	/*
 	 * If TIF_SYSCALL_EMU is set, we only get here because of
@@ -261,7 +272,9 @@ __visible inline void syscall_return_slowpath(struct pt_regs *regs)
 	 * want to run them exactly once per syscall exit with IRQs on.
 	 */
 	if (unlikely(cached_flags & SYSCALL_EXIT_WORK_FLAGS))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		syscall_slow_exit_work(regs, cached_flags);
+}
 
 	local_irq_disable();
 	prepare_exit_to_usermode(regs);
@@ -270,6 +283,7 @@ __visible inline void syscall_return_slowpath(struct pt_regs *regs)
 #ifdef CONFIG_X86_64
 __visible void do_syscall_64(struct pt_regs *regs)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct thread_info *ti = current_thread_info();
 	unsigned long nr = regs->orig_ax;
 
@@ -277,7 +291,9 @@ __visible void do_syscall_64(struct pt_regs *regs)
 	local_irq_enable();
 
 	if (READ_ONCE(ti->flags) & _TIF_WORK_SYSCALL_ENTRY)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		nr = syscall_trace_enter(regs);
+}
 
 	/*
 	 * NB: Native and x32 syscalls are dispatched from the same
@@ -304,6 +320,7 @@ __visible void do_syscall_64(struct pt_regs *regs)
  */
 static __always_inline void do_syscall_32_irqs_on(struct pt_regs *regs)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct thread_info *ti = current_thread_info();
 	unsigned int nr = (unsigned int)regs->orig_ax;
 
@@ -341,6 +358,7 @@ static __always_inline void do_syscall_32_irqs_on(struct pt_regs *regs)
 /* Handles int $0x80 */
 __visible void do_int80_syscall_32(struct pt_regs *regs)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	enter_from_user_mode();
 	local_irq_enable();
 	do_syscall_32_irqs_on(regs);
@@ -354,6 +372,7 @@ __visible long do_fast_syscall_32(struct pt_regs *regs)
 	 * convention.  Adjust regs so it looks like we entered using int80.
 	 */
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	unsigned long landing_pad = (unsigned long)current->mm->context.vdso +
 		vdso_image_32.sym_int80_landing_pad;
 
diff --git a/arch/x86/entry/vsyscall/vsyscall_64.c b/arch/x86/entry/vsyscall/vsyscall_64.c
index 577fa8a..d55d9ce 100644
--- a/arch/x86/entry/vsyscall/vsyscall_64.c
+++ b/arch/x86/entry/vsyscall/vsyscall_64.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 /*
  * Copyright (c) 2012-2014 Andy Lutomirski <luto@amacapital.net>
@@ -53,6 +55,7 @@ static enum { EMULATE, NATIVE, NONE } vsyscall_mode =
 
 static int __init vsyscall_setup(char *str)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (str) {
 		if (!strcmp("emulate", str))
 			vsyscall_mode = EMULATE;
@@ -73,6 +76,7 @@ early_param("vsyscall", vsyscall_setup);
 static void warn_bad_vsyscall(const char *level, struct pt_regs *regs,
 			      const char *message)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!show_unhandled_signals)
 		return;
 
@@ -87,7 +91,9 @@ static int addr_to_vsyscall_nr(unsigned long addr)
 	int nr;
 
 	if ((addr & ~0xC00UL) != VSYSCALL_ADDR)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	nr = (addr & 0xC00UL) >> 10;
 	if (nr >= 3)
@@ -103,6 +109,7 @@ static bool write_ok_or_segv(unsigned long ptr, size_t size)
 	 * sig_on_uaccess_err, this could go away.
 	 */
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!access_ok(VERIFY_WRITE, (void __user *)ptr, size)) {
 		siginfo_t info;
 		struct thread_struct *thread = &current->thread;
@@ -137,6 +144,7 @@ bool emulate_vsyscall(struct pt_regs *regs, unsigned long address)
 	 * trap to a high address, which means that we're in 64-bit user code.
 	 */
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WARN_ON_ONCE(address != regs->ip);
 
 	/* This should be unreachable in NATIVE mode. */
@@ -307,15 +315,21 @@ struct vm_area_struct *get_gate_vma(struct mm_struct *mm)
 {
 #ifdef CONFIG_COMPAT
 	if (!mm || mm->context.ia32_compat)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 #endif
 	if (vsyscall_mode == NONE)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return &gate_vma;
 }
 
 int in_gate_area(struct mm_struct *mm, unsigned long addr)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct vm_area_struct *vma = get_gate_vma(mm);
 
 	if (!vma)
@@ -331,6 +345,7 @@ int in_gate_area(struct mm_struct *mm, unsigned long addr)
  */
 int in_gate_area_no_mm(unsigned long addr)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return vsyscall_mode != NONE && (addr & PAGE_MASK) == VSYSCALL_ADDR;
 }
 
@@ -376,6 +391,7 @@ void __init map_vsyscall(void)
 		set_vsyscall_pgtable_user_bits(swapper_pg_dir);
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	BUILD_BUG_ON((unsigned long)__fix_to_virt(VSYSCALL_PAGE) !=
 		     (unsigned long)VSYSCALL_ADDR);
 }
diff --git a/arch/x86/entry/vsyscall/vsyscall_gtod.c b/arch/x86/entry/vsyscall/vsyscall_gtod.c
index e1216dd..13edda5 100644
--- a/arch/x86/entry/vsyscall/vsyscall_gtod.c
+++ b/arch/x86/entry/vsyscall/vsyscall_gtod.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 /*
  *  Copyright (C) 2001 Andrea Arcangeli <andrea@suse.de> SuSE
@@ -23,6 +25,7 @@ DEFINE_VVAR(struct vsyscall_gtod_data, vsyscall_gtod_data);
 
 void update_vsyscall_tz(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	vsyscall_gtod_data.tz_minuteswest = sys_tz.tz_minuteswest;
 	vsyscall_gtod_data.tz_dsttime = sys_tz.tz_dsttime;
 }
@@ -74,5 +77,6 @@ void update_vsyscall(struct timekeeper *tk)
 		vdata->monotonic_time_coarse_sec++;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	gtod_write_end(vdata);
 }
diff --git a/arch/x86/entry/vsyscall/vsyscall_trace.h b/arch/x86/entry/vsyscall/vsyscall_trace.h
index 3c3f976..5544a3d 100644
--- a/arch/x86/entry/vsyscall/vsyscall_trace.h
+++ b/arch/x86/entry/vsyscall/vsyscall_trace.h
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /* SPDX-License-Identifier: GPL-2.0 */
 #undef TRACE_SYSTEM
 #define TRACE_SYSTEM vsyscall
diff --git a/arch/x86/events/amd/core.c b/arch/x86/events/amd/core.c
index c84584b..65bbf79 100644
--- a/arch/x86/events/amd/core.c
+++ b/arch/x86/events/amd/core.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 #include <linux/perf_event.h>
 #include <linux/export.h>
 #include <linux/types.h>
@@ -129,6 +131,7 @@ static const u64 amd_perfmon_event_map[PERF_COUNT_HW_MAX] =
 
 static u64 amd_pmu_event_map(int hw_event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return amd_perfmon_event_map[hw_event];
 }
 
@@ -150,7 +153,9 @@ static inline int amd_pmu_addr_offset(int index, bool eventsel)
 	int offset;
 
 	if (!index)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return index;
+}
 
 	if (eventsel)
 		offset = event_offsets[index];
@@ -158,10 +163,14 @@ static inline int amd_pmu_addr_offset(int index, bool eventsel)
 		offset = count_offsets[index];
 
 	if (offset)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return offset;
+}
 
 	if (!boot_cpu_has(X86_FEATURE_PERFCTR_CORE))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		offset = index;
+}
 	else
 		offset = index << 1;
 
@@ -170,11 +179,13 @@ static inline int amd_pmu_addr_offset(int index, bool eventsel)
 	else
 		count_offsets[index] = offset;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return offset;
 }
 
 static int amd_core_hw_config(struct perf_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (event->attr.exclude_host && event->attr.exclude_guest)
 		/*
 		 * When HO == GO == 1 the hardware treats that as GO == HO == 0
@@ -196,11 +207,13 @@ static int amd_core_hw_config(struct perf_event *event)
  */
 static inline unsigned int amd_get_event_code(struct hw_perf_event *hwc)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return ((hwc->config >> 24) & 0x0f00) | (hwc->config & 0x00ff);
 }
 
 static inline int amd_is_nb_event(struct hw_perf_event *hwc)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return (hwc->config & 0xe0) == 0xe0;
 }
 
@@ -208,6 +221,7 @@ static inline int amd_has_nb(struct cpu_hw_events *cpuc)
 {
 	struct amd_nb *nb = cpuc->amd_nb;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return nb && nb->nb_id != -1;
 }
 
@@ -298,7 +312,9 @@ __amd_get_nb_event_constraints(struct cpu_hw_events *cpuc, struct perf_event *ev
 	int idx, new = -1;
 
 	if (!c)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		c = &unconstrained;
+}
 
 	if (cpuc->is_fake)
 		return c;
@@ -349,7 +365,9 @@ static struct amd_nb *amd_alloc_nb(int cpu)
 
 	nb = kzalloc_node(sizeof(struct amd_nb), GFP_KERNEL, cpu_to_node(cpu));
 	if (!nb)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 
 	nb->nb_id = -1;
 
@@ -365,6 +383,7 @@ static struct amd_nb *amd_alloc_nb(int cpu)
 
 static int amd_pmu_cpu_prepare(int cpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cpu_hw_events *cpuc = &per_cpu(cpu_hw_events, cpu);
 
 	WARN_ON_ONCE(cpuc->amd_nb);
@@ -381,6 +400,7 @@ static int amd_pmu_cpu_prepare(int cpu)
 
 static void amd_pmu_cpu_starting(int cpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cpu_hw_events *cpuc = &per_cpu(cpu_hw_events, cpu);
 	void **onln = &cpuc->kfree_on_online[X86_PERF_KFREE_SHARED];
 	struct amd_nb *nb;
@@ -415,7 +435,9 @@ static void amd_pmu_cpu_dead(int cpu)
 	struct cpu_hw_events *cpuhw;
 
 	if (!x86_pmu.amd_nb_constraints)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	cpuhw = &per_cpu(cpu_hw_events, cpu);
 
@@ -445,6 +467,7 @@ amd_get_event_constraints(struct cpu_hw_events *cpuc, int idx,
 static void amd_put_event_constraints(struct cpu_hw_events *cpuc,
 				      struct perf_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (amd_has_nb(cpuc) && amd_is_nb_event(&event->hw))
 		__amd_put_nb_event_constraints(cpuc, event);
 }
@@ -655,8 +678,11 @@ static __initconst const struct x86_pmu amd_pmu = {
 static int __init amd_core_pmu_init(void)
 {
 	if (!boot_cpu_has(X86_FEATURE_PERFCTR_CORE))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	switch (boot_cpu_data.x86) {
 	case 0x15:
 		pr_cont("Fam15h ");
@@ -698,13 +724,17 @@ __init int amd_pmu_init(void)
 
 	/* Performance-monitoring supported from K7 and later: */
 	if (boot_cpu_data.x86 < 6)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENODEV;
+}
 
 	x86_pmu = amd_pmu;
 
 	ret = amd_core_pmu_init();
 	if (ret)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ret;
+}
 
 	if (num_possible_cpus() == 1) {
 		/*
@@ -723,6 +753,7 @@ __init int amd_pmu_init(void)
 
 void amd_pmu_enable_virt(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cpu_hw_events *cpuc = this_cpu_ptr(&cpu_hw_events);
 
 	cpuc->perf_ctr_virt_mask = 0;
@@ -735,6 +766,7 @@ EXPORT_SYMBOL_GPL(amd_pmu_enable_virt);
 
 void amd_pmu_disable_virt(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cpu_hw_events *cpuc = this_cpu_ptr(&cpu_hw_events);
 
 	/*
diff --git a/arch/x86/events/amd/ibs.c b/arch/x86/events/amd/ibs.c
index 786fd87..ea989d5 100644
--- a/arch/x86/events/amd/ibs.c
+++ b/arch/x86/events/amd/ibs.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * Performance events - AMD IBS
  *
@@ -110,6 +112,7 @@ struct perf_ibs_data {
 static int
 perf_event_set_period(struct hw_perf_event *hwc, u64 min, u64 max, u64 *hw_period)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	s64 left = local64_read(&hwc->period_left);
 	s64 period = hwc->sample_period;
 	int overflow = 0;
@@ -166,6 +169,7 @@ perf_event_try_update(struct perf_event *event, u64 new_raw_count, int width)
 	 * count to the generic event atomically:
 	 */
 	prev_raw_count = local64_read(&hwc->prev_count);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (local64_cmpxchg(&hwc->prev_count, prev_raw_count,
 					new_raw_count) != prev_raw_count)
 		return 0;
@@ -192,6 +196,7 @@ static struct perf_ibs perf_ibs_op;
 
 static struct perf_ibs *get_ibs_pmu(int type)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (perf_ibs_fetch.pmu.type == type)
 		return &perf_ibs_fetch;
 	if (perf_ibs_op.pmu.type == type)
@@ -218,6 +223,7 @@ static struct perf_ibs *get_ibs_pmu(int type)
  */
 static int perf_ibs_precise_event(struct perf_event *event, u64 *config)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	switch (event->attr.precise_ip) {
 	case 0:
 		return -ENOENT;
@@ -271,6 +277,7 @@ static int perf_ibs_init(struct perf_event *event)
 
 	perf_ibs = get_ibs_pmu(event->attr.type);
 	if (perf_ibs) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		config = event->attr.config;
 	} else {
 		perf_ibs = &perf_ibs_op;
@@ -339,6 +346,7 @@ static int perf_ibs_set_period(struct perf_ibs *perf_ibs,
 
 static u64 get_ibs_fetch_count(u64 config)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return (config & IBS_FETCH_CNT) >> 12;
 }
 
@@ -347,7 +355,9 @@ static u64 get_ibs_op_count(u64 config)
 	u64 count = 0;
 
 	if (config & IBS_OP_VAL)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		count += (config & IBS_OP_MAX_CNT) << 4; /* cnt rolled over */
+}
 
 	if (ibs_caps & IBS_CAPS_RDWROPCNT)
 		count += (config & IBS_OP_CUR_CNT) >> 32;
@@ -359,6 +369,7 @@ static void
 perf_ibs_event_update(struct perf_ibs *perf_ibs, struct perf_event *event,
 		      u64 *config)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	u64 count = perf_ibs->get_count(*config);
 
 	/*
@@ -375,6 +386,7 @@ perf_ibs_event_update(struct perf_ibs *perf_ibs, struct perf_event *event,
 static inline void perf_ibs_enable_event(struct perf_ibs *perf_ibs,
 					 struct hw_perf_event *hwc, u64 config)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	wrmsrl(hwc->config_base, hwc->config | config | perf_ibs->enable_mask);
 }
 
@@ -388,6 +400,7 @@ static inline void perf_ibs_enable_event(struct perf_ibs *perf_ibs,
 static inline void perf_ibs_disable_event(struct perf_ibs *perf_ibs,
 					  struct hw_perf_event *hwc, u64 config)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	config &= ~perf_ibs->cnt_mask;
 	wrmsrl(hwc->config_base, config);
 	config &= ~perf_ibs->enable_mask;
@@ -403,6 +416,7 @@ static inline void perf_ibs_disable_event(struct perf_ibs *perf_ibs,
 static void perf_ibs_start(struct perf_event *event, int flags)
 {
 	struct hw_perf_event *hwc = &event->hw;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct perf_ibs *perf_ibs = container_of(event->pmu, struct perf_ibs, pmu);
 	struct cpu_perf_ibs *pcpu = this_cpu_ptr(perf_ibs->pcpu);
 	u64 period;
@@ -428,6 +442,7 @@ static void perf_ibs_start(struct perf_event *event, int flags)
 static void perf_ibs_stop(struct perf_event *event, int flags)
 {
 	struct hw_perf_event *hwc = &event->hw;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct perf_ibs *perf_ibs = container_of(event->pmu, struct perf_ibs, pmu);
 	struct cpu_perf_ibs *pcpu = this_cpu_ptr(perf_ibs->pcpu);
 	u64 config;
@@ -481,6 +496,7 @@ static void perf_ibs_stop(struct perf_event *event, int flags)
 
 static int perf_ibs_add(struct perf_event *event, int flags)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct perf_ibs *perf_ibs = container_of(event->pmu, struct perf_ibs, pmu);
 	struct cpu_perf_ibs *pcpu = this_cpu_ptr(perf_ibs->pcpu);
 
@@ -499,6 +515,7 @@ static int perf_ibs_add(struct perf_event *event, int flags)
 
 static void perf_ibs_del(struct perf_event *event, int flags)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct perf_ibs *perf_ibs = container_of(event->pmu, struct perf_ibs, pmu);
 	struct cpu_perf_ibs *pcpu = this_cpu_ptr(perf_ibs->pcpu);
 
@@ -577,6 +594,7 @@ static struct perf_ibs perf_ibs_op = {
 
 static int perf_ibs_handle_irq(struct perf_ibs *perf_ibs, struct pt_regs *iregs)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cpu_perf_ibs *pcpu = this_cpu_ptr(perf_ibs->pcpu);
 	struct perf_event *event = pcpu->event;
 	struct hw_perf_event *hwc = &event->hw;
@@ -681,6 +699,7 @@ static int perf_ibs_handle_irq(struct perf_ibs *perf_ibs, struct pt_regs *iregs)
 static int
 perf_ibs_nmi_handler(unsigned int cmd, struct pt_regs *regs)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	u64 stamp = sched_clock();
 	int handled = 0;
 
@@ -703,7 +722,9 @@ static __init int perf_ibs_pmu_init(struct perf_ibs *perf_ibs, char *name)
 
 	pcpu = alloc_percpu(struct cpu_perf_ibs);
 	if (!pcpu)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 
 	perf_ibs->pcpu = pcpu;
 
@@ -734,6 +755,7 @@ static __init void perf_event_ibs_init(void)
 	perf_ibs_pmu_init(&perf_ibs_fetch, "ibs_fetch");
 
 	if (ibs_caps & IBS_CAPS_OPCNT) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		perf_ibs_op.config_mask |= IBS_OP_CNT_CTL;
 		*attr++ = &format_attr_cnt_ctl.attr;
 	}
@@ -757,18 +779,24 @@ static __init u32 __get_ibs_caps(void)
 	unsigned int max_level;
 
 	if (!boot_cpu_has(X86_FEATURE_IBS))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	/* check IBS cpuid feature flags */
 	max_level = cpuid_eax(0x80000000);
 	if (max_level < IBS_CPUID_FEATURES)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return IBS_CAPS_DEFAULT;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	caps = cpuid_eax(IBS_CPUID_FEATURES);
 	if (!(caps & IBS_CAPS_AVAIL))
 		/* cpuid flags not valid */
 		return IBS_CAPS_DEFAULT;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return caps;
 }
 
@@ -781,11 +809,13 @@ EXPORT_SYMBOL(get_ibs_caps);
 
 static inline int get_eilvt(int offset)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return !setup_APIC_eilvt(offset, 0, APIC_EILVT_MSG_NMI, 1);
 }
 
 static inline int put_eilvt(int offset)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return !setup_APIC_eilvt(offset, 0, 0, 1);
 }
 
@@ -804,6 +834,7 @@ static inline int ibs_eilvt_valid(void)
 	offset = val & IBSCTL_LVT_OFFSET_MASK;
 
 	if (!(val & IBSCTL_LVT_OFFSET_VALID)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_err(FW_BUG "cpu %d, invalid IBS interrupt offset %d (MSR%08X=0x%016llx)\n",
 		       smp_processor_id(), offset, MSR_AMD64_IBSCTL, val);
 		goto out;
@@ -831,6 +862,7 @@ static int setup_ibs_ctl(int ibs_eilvt_off)
 	nodes = 0;
 	cpu_cfg = NULL;
 	do {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		cpu_cfg = pci_get_device(PCI_VENDOR_ID_AMD,
 					 PCI_DEVICE_ID_AMD_10H_NB_MISC,
 					 cpu_cfg);
@@ -917,7 +949,9 @@ static inline int get_ibs_lvt_offset(void)
 
 	rdmsrl(MSR_AMD64_IBSCTL, val);
 	if (!(val & IBSCTL_LVT_OFFSET_VALID))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	return val & IBSCTL_LVT_OFFSET_MASK;
 }
@@ -930,6 +964,7 @@ static void setup_APIC_ibs(void)
 	if (offset < 0)
 		goto failed;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!setup_APIC_eilvt(offset, 0, APIC_EILVT_MSG_NMI, 0))
 		return;
 failed:
@@ -943,11 +978,14 @@ static void clear_APIC_ibs(void)
 
 	offset = get_ibs_lvt_offset();
 	if (offset >= 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		setup_APIC_eilvt(offset, 0, APIC_EILVT_MSG_FIX, 1);
 }
+}
 
 static int x86_pmu_amd_ibs_starting_cpu(unsigned int cpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	setup_APIC_ibs();
 	return 0;
 }
@@ -956,12 +994,14 @@ static int x86_pmu_amd_ibs_starting_cpu(unsigned int cpu)
 
 static int perf_ibs_suspend(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	clear_APIC_ibs();
 	return 0;
 }
 
 static void perf_ibs_resume(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	ibs_eilvt_setup();
 	setup_APIC_ibs();
 }
@@ -973,6 +1013,7 @@ static struct syscore_ops perf_ibs_syscore_ops = {
 
 static void perf_ibs_pm_init(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	register_syscore_ops(&perf_ibs_syscore_ops);
 }
 
@@ -984,6 +1025,7 @@ static inline void perf_ibs_pm_init(void) { }
 
 static int x86_pmu_amd_ibs_dying_cpu(unsigned int cpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	clear_APIC_ibs();
 	return 0;
 }
@@ -994,13 +1036,19 @@ static __init int amd_ibs_init(void)
 
 	caps = __get_ibs_caps();
 	if (!caps)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENODEV;	/* ibs not supported by the cpu */
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	ibs_eilvt_setup();
 
 	if (!ibs_eilvt_valid())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	perf_ibs_pm_init();
 
 	ibs_caps = caps;
diff --git a/arch/x86/events/amd/uncore.c b/arch/x86/events/amd/uncore.c
index f5cbbba..1092183 100644
--- a/arch/x86/events/amd/uncore.c
+++ b/arch/x86/events/amd/uncore.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * Copyright (C) 2013 Advanced Micro Devices, Inc.
  *
@@ -62,16 +64,19 @@ static cpumask_t amd_llc_active_mask;
 
 static bool is_nb_event(struct perf_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return event->pmu->type == amd_nb_pmu.type;
 }
 
 static bool is_llc_event(struct perf_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return event->pmu->type == amd_llc_pmu.type;
 }
 
 static struct amd_uncore *event_to_amd_uncore(struct perf_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (is_nb_event(event) && amd_uncore_nb)
 		return *per_cpu_ptr(amd_uncore_nb, event->cpu);
 	else if (is_llc_event(event) && amd_uncore_llc)
@@ -104,7 +109,9 @@ static void amd_uncore_start(struct perf_event *event, int flags)
 	struct hw_perf_event *hwc = &event->hw;
 
 	if (flags & PERF_EF_RELOAD)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		wrmsrl(hwc->event_base, (u64)local64_read(&hwc->prev_count));
+}
 
 	hwc->state = 0;
 	wrmsrl(hwc->config_base, (hwc->config | ARCH_PERFMON_EVENTSEL_ENABLE));
@@ -118,6 +125,7 @@ static void amd_uncore_stop(struct perf_event *event, int flags)
 	wrmsrl(hwc->config_base, hwc->config);
 	hwc->state |= PERF_HES_STOPPED;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if ((flags & PERF_EF_UPDATE) && !(hwc->state & PERF_HES_UPTODATE)) {
 		amd_uncore_read(event);
 		hwc->state |= PERF_HES_UPTODATE;
@@ -173,6 +181,7 @@ static void amd_uncore_del(struct perf_event *event, int flags)
 
 	amd_uncore_stop(event, PERF_EF_UPDATE);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (i = 0; i < uncore->num_counters; i++) {
 		if (cmpxchg(&uncore->events[i], event, NULL) == event)
 			break;
@@ -187,7 +196,9 @@ static int amd_uncore_event_init(struct perf_event *event)
 	struct hw_perf_event *hwc = &event->hw;
 
 	if (event->attr.type != event->pmu->type)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOENT;
+}
 
 	/*
 	 * NB and Last level cache counters (MSRs) are shared across all cores
@@ -232,7 +243,9 @@ static ssize_t amd_uncore_attr_show_cpumask(struct device *dev,
 	struct pmu *pmu = dev_get_drvdata(dev);
 
 	if (pmu->type == amd_nb_pmu.type)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		active_mask = &amd_nb_active_mask;
+}
 	else if (pmu->type == amd_llc_pmu.type)
 		active_mask = &amd_llc_active_mask;
 	else
@@ -321,6 +334,7 @@ static int amd_uncore_cpu_up_prepare(unsigned int cpu)
 	struct amd_uncore *uncore_nb = NULL, *uncore_llc;
 
 	if (amd_uncore_nb) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		uncore_nb = amd_uncore_alloc(cpu);
 		if (!uncore_nb)
 			goto fail;
@@ -364,6 +378,7 @@ amd_uncore_find_online_sibling(struct amd_uncore *this,
 	unsigned int cpu;
 	struct amd_uncore *that;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for_each_online_cpu(cpu) {
 		that = *per_cpu_ptr(uncores, cpu);
 
@@ -390,6 +405,7 @@ static int amd_uncore_cpu_starting(unsigned int cpu)
 	struct amd_uncore *uncore;
 
 	if (amd_uncore_nb) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		uncore = *per_cpu_ptr(amd_uncore_nb, cpu);
 		cpuid(0x8000001e, &eax, &ebx, &ecx, &edx);
 		uncore->id = ecx & 0xff;
@@ -432,6 +448,7 @@ static void uncore_clean_online(void)
 	struct amd_uncore *uncore;
 	struct hlist_node *n;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	hlist_for_each_entry_safe(uncore, n, &uncore_unused_list, node) {
 		hlist_del(&uncore->node);
 		kfree(uncore);
@@ -441,6 +458,7 @@ static void uncore_clean_online(void)
 static void uncore_online(unsigned int cpu,
 			  struct amd_uncore * __percpu *uncores)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct amd_uncore *uncore = *per_cpu_ptr(uncores, cpu);
 
 	uncore_clean_online();
@@ -451,6 +469,7 @@ static void uncore_online(unsigned int cpu,
 
 static int amd_uncore_cpu_online(unsigned int cpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (amd_uncore_nb)
 		uncore_online(cpu, amd_uncore_nb);
 
@@ -464,6 +483,7 @@ static void uncore_down_prepare(unsigned int cpu,
 				struct amd_uncore * __percpu *uncores)
 {
 	unsigned int i;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct amd_uncore *this = *per_cpu_ptr(uncores, cpu);
 
 	if (this->cpu != cpu)
@@ -488,6 +508,7 @@ static void uncore_down_prepare(unsigned int cpu,
 
 static int amd_uncore_cpu_down_prepare(unsigned int cpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (amd_uncore_nb)
 		uncore_down_prepare(cpu, amd_uncore_nb);
 
@@ -499,6 +520,7 @@ static int amd_uncore_cpu_down_prepare(unsigned int cpu)
 
 static void uncore_dead(unsigned int cpu, struct amd_uncore * __percpu *uncores)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct amd_uncore *uncore = *per_cpu_ptr(uncores, cpu);
 
 	if (cpu == uncore->cpu)
@@ -511,6 +533,7 @@ static void uncore_dead(unsigned int cpu, struct amd_uncore * __percpu *uncores)
 
 static int amd_uncore_cpu_dead(unsigned int cpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (amd_uncore_nb)
 		uncore_dead(cpu, amd_uncore_nb);
 
@@ -525,11 +548,16 @@ static int __init amd_uncore_init(void)
 	int ret = -ENODEV;
 
 	if (boot_cpu_data.x86_vendor != X86_VENDOR_AMD)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENODEV;
+}
 
 	if (!boot_cpu_has(X86_FEATURE_TOPOEXT))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENODEV;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (boot_cpu_data.x86 == 0x17) {
 		/*
 		 * For F17h, the Northbridge counters are repurposed as Data
@@ -543,6 +571,7 @@ static int __init amd_uncore_init(void)
 		format_attr_event_df.show = &event_show_df;
 		format_attr_event_l3.show = &event_show_l3;
 	} else {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		num_counters_nb		  = NUM_COUNTERS_NB;
 		num_counters_llc	  = NUM_COUNTERS_L2;
 		amd_nb_pmu.name		  = "amd_nb";
@@ -551,33 +580,44 @@ static int __init amd_uncore_init(void)
 		format_attr_event_l3	  = format_attr_event;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	amd_nb_pmu.attr_groups	= amd_uncore_attr_groups_df;
 	amd_llc_pmu.attr_groups = amd_uncore_attr_groups_l3;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (boot_cpu_has(X86_FEATURE_PERFCTR_NB)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		amd_uncore_nb = alloc_percpu(struct amd_uncore *);
 		if (!amd_uncore_nb) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			ret = -ENOMEM;
 			goto fail_nb;
 		}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ret = perf_pmu_register(&amd_nb_pmu, amd_nb_pmu.name, -1);
 		if (ret)
 			goto fail_nb;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_info("AMD NB counters detected\n");
 		ret = 0;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (boot_cpu_has(X86_FEATURE_PERFCTR_LLC)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		amd_uncore_llc = alloc_percpu(struct amd_uncore *);
 		if (!amd_uncore_llc) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			ret = -ENOMEM;
 			goto fail_llc;
 		}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ret = perf_pmu_register(&amd_llc_pmu, amd_llc_pmu.name, -1);
 		if (ret)
 			goto fail_llc;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_info("AMD LLC counters detected\n");
 		ret = 0;
 	}
@@ -590,15 +630,18 @@ static int __init amd_uncore_init(void)
 			      amd_uncore_cpu_up_prepare, amd_uncore_cpu_dead))
 		goto fail_llc;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (cpuhp_setup_state(CPUHP_AP_PERF_X86_AMD_UNCORE_STARTING,
 			      "perf/x86/amd/uncore:starting",
 			      amd_uncore_cpu_starting, NULL))
 		goto fail_prep;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (cpuhp_setup_state(CPUHP_AP_PERF_X86_AMD_UNCORE_ONLINE,
 			      "perf/x86/amd/uncore:online",
 			      amd_uncore_cpu_online,
 			      amd_uncore_cpu_down_prepare))
 		goto fail_start;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 
 fail_start:
@@ -607,13 +650,21 @@ static int __init amd_uncore_init(void)
 	cpuhp_remove_state(CPUHP_PERF_X86_AMD_UNCORE_PREP);
 fail_llc:
 	if (boot_cpu_has(X86_FEATURE_PERFCTR_NB))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		perf_pmu_unregister(&amd_nb_pmu);
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (amd_uncore_llc)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		free_percpu(amd_uncore_llc);
+}
 fail_nb:
 	if (amd_uncore_nb)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		free_percpu(amd_uncore_nb);
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return ret;
 }
 device_initcall(amd_uncore_init);
diff --git a/arch/x86/events/core.c b/arch/x86/events/core.c
index 589af1e..6b06a13 100644
--- a/arch/x86/events/core.c
+++ b/arch/x86/events/core.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * Performance events x86 architecture code
  *
@@ -73,7 +75,9 @@ u64 x86_perf_event_update(struct perf_event *event)
 	u64 delta;
 
 	if (idx == INTEL_PMC_IDX_FIXED_BTS)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	/*
 	 * Careful: an NMI might modify the previous event value.
@@ -118,7 +122,9 @@ static int x86_pmu_extra_regs(u64 config, struct perf_event *event)
 	reg = &event->hw.extra_reg;
 
 	if (!x86_pmu.extra_regs)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	for (er = x86_pmu.extra_regs; er->msr; er++) {
 		if (er->event != (config & er->config_mask))
@@ -147,6 +153,7 @@ static bool reserve_pmc_hardware(void)
 {
 	int i;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (i = 0; i < x86_pmu.num_counters; i++) {
 		if (!reserve_perfctr_nmi(x86_pmu_event_addr(i)))
 			goto perfctr_fail;
@@ -176,6 +183,7 @@ static void release_pmc_hardware(void)
 {
 	int i;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (i = 0; i < x86_pmu.num_counters; i++) {
 		release_perfctr_nmi(x86_pmu_event_addr(i));
 		release_evntsel_nmi(x86_pmu_config_addr(i));
@@ -206,21 +214,27 @@ static bool check_hw_exists(void)
 		if (ret)
 			goto msr_fail;
 		if (val & ARCH_PERFMON_EVENTSEL_ENABLE) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			bios_fail = 1;
 			val_fail = val;
 			reg_fail = reg;
 		} else {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			reg_safe = i;
 		}
 	}
 
 	if (x86_pmu.num_counters_fixed) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		reg = MSR_ARCH_PERFMON_FIXED_CTR_CTRL;
 		ret = rdmsrl_safe(reg, &val);
 		if (ret)
 			goto msr_fail;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		for (i = 0; i < x86_pmu.num_counters_fixed; i++) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			if (val & (0x03 << i*4)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				bios_fail = 1;
 				val_fail = val;
 				reg_fail = reg;
@@ -235,6 +249,7 @@ static bool check_hw_exists(void)
 	 */
 
 	if (reg_safe == -1) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		reg = reg_safe;
 		goto msr_fail;
 	}
@@ -257,33 +272,39 @@ static bool check_hw_exists(void)
 	 * We still allow the PMU driver to operate:
 	 */
 	if (bios_fail) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_cont("Broken BIOS detected, complain to your hardware vendor.\n");
 		pr_err(FW_BUG "the BIOS has corrupted hw-PMU resources (MSR %x is %Lx)\n",
 			      reg_fail, val_fail);
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return true;
 
 msr_fail:
 	if (boot_cpu_has(X86_FEATURE_HYPERVISOR)) {
 		pr_cont("PMU not available due to virtualization, using software events only.\n");
 	} else {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_cont("Broken PMU hardware detected, using software events only.\n");
 		pr_err("Failed to access perfctr msr (MSR %x is %Lx)\n",
 		       reg, val_new);
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return false;
 }
 
 static void hw_perf_event_destroy(struct perf_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	x86_release_hardware();
 	atomic_dec(&active_events);
 }
 
 void hw_perf_lbr_event_destroy(struct perf_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	hw_perf_event_destroy(event);
 
 	/* undo the lbr/bts event accounting */
@@ -292,6 +313,7 @@ void hw_perf_lbr_event_destroy(struct perf_event *event)
 
 static inline int x86_pmu_initialized(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return x86_pmu.handle_irq != NULL;
 }
 
@@ -306,7 +328,9 @@ set_ext_hw_attr(struct hw_perf_event *hwc, struct perf_event *event)
 
 	cache_type = (config >>  0) & 0xff;
 	if (cache_type >= PERF_COUNT_HW_CACHE_MAX)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	cache_op = (config >>  8) & 0xff;
 	if (cache_op >= PERF_COUNT_HW_CACHE_OP_MAX)
@@ -334,6 +358,7 @@ int x86_reserve_hardware(void)
 	int err = 0;
 
 	if (!atomic_inc_not_zero(&pmc_refcount)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		mutex_lock(&pmc_reserve_mutex);
 		if (atomic_read(&pmc_refcount) == 0) {
 			if (!reserve_pmc_hardware())
@@ -351,6 +376,7 @@ int x86_reserve_hardware(void)
 
 void x86_release_hardware(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (atomic_dec_and_mutex_lock(&pmc_refcount, &pmc_reserve_mutex)) {
 		release_pmc_hardware();
 		release_ds_buffers();
@@ -393,6 +419,7 @@ int x86_add_exclusive(unsigned int what)
 
 void x86_del_exclusive(unsigned int what)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (x86_pmu.lbr_pt_coexist && what == x86_lbr_exclusive_pt)
 		return;
 
@@ -407,6 +434,7 @@ int x86_setup_perfctr(struct perf_event *event)
 	u64 config;
 
 	if (!is_sampling_event(event)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		hwc->sample_period = x86_pmu.max_period;
 		hwc->last_period = hwc->sample_period;
 		local64_set(&hwc->period_left, hwc->sample_period);
@@ -470,7 +498,9 @@ static inline int precise_br_compat(struct perf_event *event)
 
 	/* must capture all branches */
 	if (!(m & PERF_SAMPLE_BRANCH_ANY))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	m &= PERF_SAMPLE_BRANCH_KERNEL | PERF_SAMPLE_BRANCH_USER;
 
@@ -507,6 +537,7 @@ int x86_pmu_max_precise(void)
 
 int x86_pmu_hw_config(struct perf_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (event->attr.precise_ip) {
 		int precise = x86_pmu_max_precise();
 
@@ -585,7 +616,9 @@ static int __x86_pmu_event_init(struct perf_event *event)
 	int err;
 
 	if (!x86_pmu_initialized())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENODEV;
+}
 
 	err = x86_reserve_hardware();
 	if (err)
@@ -607,6 +640,7 @@ static int __x86_pmu_event_init(struct perf_event *event)
 
 void x86_pmu_disable_all(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cpu_hw_events *cpuc = this_cpu_ptr(&cpu_hw_events);
 	int idx;
 
@@ -638,6 +672,7 @@ void x86_pmu_disable_all(void)
  */
 static void x86_pmu_disable(struct pmu *pmu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cpu_hw_events *cpuc = this_cpu_ptr(&cpu_hw_events);
 
 	if (!x86_pmu_initialized())
@@ -655,6 +690,7 @@ static void x86_pmu_disable(struct pmu *pmu)
 
 void x86_pmu_enable_all(int added)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cpu_hw_events *cpuc = this_cpu_ptr(&cpu_hw_events);
 	int idx;
 
@@ -672,6 +708,7 @@ static struct pmu pmu;
 
 static inline int is_x86_event(struct perf_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return event->pmu == &pmu;
 }
 
@@ -718,6 +755,7 @@ static void perf_sched_init(struct perf_sched *sched, struct event_constraint **
 	sched->max_gp		= gpmax;
 	sched->constraints	= constraints;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (idx = 0; idx < num; idx++) {
 		if (constraints[idx]->weight == wmin)
 			break;
@@ -730,6 +768,7 @@ static void perf_sched_init(struct perf_sched *sched, struct event_constraint **
 
 static void perf_sched_save_state(struct perf_sched *sched)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (WARN_ON_ONCE(sched->saved_states >= SCHED_STATES_MAX))
 		return;
 
@@ -739,6 +778,7 @@ static void perf_sched_save_state(struct perf_sched *sched)
 
 static bool perf_sched_restore_state(struct perf_sched *sched)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!sched->saved_states)
 		return false;
 
@@ -761,7 +801,9 @@ static bool __perf_sched_find_counter(struct perf_sched *sched)
 	int idx;
 
 	if (!sched->state.unassigned)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return false;
+}
 
 	if (sched->state.event >= sched->max_events)
 		return false;
@@ -800,6 +842,7 @@ static bool __perf_sched_find_counter(struct perf_sched *sched)
 
 static bool perf_sched_find_counter(struct perf_sched *sched)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	while (!__perf_sched_find_counter(sched)) {
 		if (!perf_sched_restore_state(sched))
 			return false;
@@ -816,6 +859,7 @@ static bool perf_sched_next_event(struct perf_sched *sched)
 {
 	struct event_constraint *c;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!sched->state.unassigned || !--sched->state.unassigned)
 		return false;
 
@@ -848,6 +892,7 @@ int perf_assign_events(struct event_constraint **constraints, int n,
 	perf_sched_init(&sched, constraints, n, wmin, wmax, gpmax);
 
 	do {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (!perf_sched_find_counter(&sched))
 			break;	/* failed */
 		if (assign)
@@ -869,7 +914,9 @@ int x86_schedule_events(struct cpu_hw_events *cpuc, int n, int *assign)
 	bitmap_zero(used_mask, X86_PMC_IDX_MAX);
 
 	if (x86_pmu.start_scheduling)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		x86_pmu.start_scheduling(cpuc);
+}
 
 	for (i = 0, wmin = X86_PMC_IDX_MAX, wmax = 0; i < n; i++) {
 		cpuc->event_constraint[i] = NULL;
@@ -982,6 +1029,7 @@ static int collect_events(struct cpu_hw_events *cpuc, struct perf_event *leader,
 	n = cpuc->n_events;
 
 	if (is_x86_event(leader)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (n >= max_count)
 			return -EINVAL;
 		cpuc->event_list[n] = leader;
@@ -1010,6 +1058,7 @@ static inline void x86_assign_hw_event(struct perf_event *event,
 	struct hw_perf_event *hwc = &event->hw;
 
 	hwc->idx = cpuc->assign[i];
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	hwc->last_cpu = smp_processor_id();
 	hwc->last_tag = ++cpuc->tags[i];
 
@@ -1031,6 +1080,7 @@ static inline int match_prev_assignment(struct hw_perf_event *hwc,
 					struct cpu_hw_events *cpuc,
 					int i)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return hwc->idx == cpuc->assign[i] &&
 		hwc->last_cpu == smp_processor_id() &&
 		hwc->last_tag == cpuc->tags[i];
@@ -1040,6 +1090,7 @@ static void x86_pmu_start(struct perf_event *event, int flags);
 
 static void x86_pmu_enable(struct pmu *pmu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cpu_hw_events *cpuc = this_cpu_ptr(&cpu_hw_events);
 	struct perf_event *event;
 	struct hw_perf_event *hwc;
@@ -1124,7 +1175,9 @@ int x86_perf_event_set_period(struct perf_event *event)
 	int ret = 0, idx = hwc->idx;
 
 	if (idx == INTEL_PMC_IDX_FIXED_BTS)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	/*
 	 * If we are way outside a reasonable range then just skip forward:
@@ -1184,6 +1237,7 @@ int x86_perf_event_set_period(struct perf_event *event)
 
 void x86_pmu_enable_event(struct perf_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (__this_cpu_read(cpu_hw_events.enabled))
 		__x86_pmu_enable_event(&event->hw,
 				       ARCH_PERFMON_EVENTSEL_ENABLE);
@@ -1197,6 +1251,7 @@ void x86_pmu_enable_event(struct perf_event *event)
  */
 static int x86_pmu_add(struct perf_event *event, int flags)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cpu_hw_events *cpuc = this_cpu_ptr(&cpu_hw_events);
 	struct hw_perf_event *hwc;
 	int assign[X86_PMC_IDX_MAX];
@@ -1257,6 +1312,7 @@ static int x86_pmu_add(struct perf_event *event, int flags)
 
 static void x86_pmu_start(struct perf_event *event, int flags)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cpu_hw_events *cpuc = this_cpu_ptr(&cpu_hw_events);
 	int idx = event->hw.idx;
 
@@ -1289,7 +1345,9 @@ void perf_event_print_debug(void)
 	int cpu, idx;
 
 	if (!x86_pmu.num_counters)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	local_irq_save(flags);
 
@@ -1342,6 +1400,7 @@ void perf_event_print_debug(void)
 
 void x86_pmu_stop(struct perf_event *event, int flags)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cpu_hw_events *cpuc = this_cpu_ptr(&cpu_hw_events);
 	struct hw_perf_event *hwc = &event->hw;
 
@@ -1364,6 +1423,7 @@ void x86_pmu_stop(struct perf_event *event, int flags)
 
 static void x86_pmu_del(struct perf_event *event, int flags)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cpu_hw_events *cpuc = this_cpu_ptr(&cpu_hw_events);
 	int i;
 
@@ -1430,6 +1490,7 @@ int x86_pmu_handle_irq(struct pt_regs *regs)
 	int idx, handled = 0;
 	u64 val;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	cpuc = this_cpu_ptr(&cpu_hw_events);
 
 	/*
@@ -1482,7 +1543,9 @@ int x86_pmu_handle_irq(struct pt_regs *regs)
 void perf_events_lapic_init(void)
 {
 	if (!x86_pmu.apic || !x86_pmu_initialized())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	/*
 	 * Always use NMI for PMU
@@ -1502,7 +1565,9 @@ perf_event_nmi_handler(unsigned int cmd, struct pt_regs *regs)
 	 * increment active_events for their events.
 	 */
 	if (!atomic_read(&active_events))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NMI_DONE;
+}
 
 	start_clock = sched_clock();
 	ret = x86_pmu.handle_irq(regs);
@@ -1519,6 +1584,7 @@ struct event_constraint unconstrained;
 
 static int x86_pmu_prepare_cpu(unsigned int cpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cpu_hw_events *cpuc = &per_cpu(cpu_hw_events, cpu);
 	int i;
 
@@ -1531,6 +1597,7 @@ static int x86_pmu_prepare_cpu(unsigned int cpu)
 
 static int x86_pmu_dead_cpu(unsigned int cpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (x86_pmu.cpu_dead)
 		x86_pmu.cpu_dead(cpu);
 	return 0;
@@ -1538,6 +1605,7 @@ static int x86_pmu_dead_cpu(unsigned int cpu)
 
 static int x86_pmu_online_cpu(unsigned int cpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cpu_hw_events *cpuc = &per_cpu(cpu_hw_events, cpu);
 	int i;
 
@@ -1550,6 +1618,7 @@ static int x86_pmu_online_cpu(unsigned int cpu)
 
 static int x86_pmu_starting_cpu(unsigned int cpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (x86_pmu.cpu_starting)
 		x86_pmu.cpu_starting(cpu);
 	return 0;
@@ -1557,6 +1626,7 @@ static int x86_pmu_starting_cpu(unsigned int cpu)
 
 static int x86_pmu_dying_cpu(unsigned int cpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (x86_pmu.cpu_dying)
 		x86_pmu.cpu_dying(cpu);
 	return 0;
@@ -1565,8 +1635,11 @@ static int x86_pmu_dying_cpu(unsigned int cpu)
 static void __init pmu_check_apic(void)
 {
 	if (boot_cpu_has(X86_FEATURE_APIC))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	x86_pmu.apic = 0;
 	pr_info("no APIC, boot with the \"lapic\" boot parameter to force-enable it.\n");
 	pr_info("no hardware sampling interrupt available.\n");
@@ -1597,6 +1670,7 @@ static void __init filter_events(struct attribute **attrs)
 	int offset = 0;
 	int i, j;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (i = 0; attrs[i]; i++) {
 		d = (struct device_attribute *)attrs[i];
 		pmu_attr = container_of(d, struct perf_pmu_events_attr, attr);
@@ -1628,6 +1702,7 @@ __init struct attribute **merge_attr(struct attribute **a, struct attribute **b)
 	struct attribute **new;
 	int j, i;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (j = 0; a[j]; j++)
 		;
 	for (i = 0; b[i]; i++)
@@ -1734,7 +1809,9 @@ ssize_t x86_event_sysfs_show(char *page, u64 config, u64 event)
 	ret = sprintf(page, "event=0x%02llx", event);
 
 	if (umask)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ret += sprintf(page + ret, ",umask=0x%02llx", umask);
+}
 
 	if (edge)
 		ret += sprintf(page + ret, ",edge");
@@ -1777,6 +1854,7 @@ static int __init init_hw_perf_events(void)
 		err = -ENOTSUPP;
 	}
 	if (err != 0) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_cont("no PMU driver, software events only.\n");
 		return 0;
 	}
@@ -1785,18 +1863,28 @@ static int __init init_hw_perf_events(void)
 
 	/* sanity check that the hardware exists or is emulated */
 	if (!check_hw_exists())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pr_cont("%s PMU driver.\n", x86_pmu.name);
 
 	x86_pmu.attr_rdpmc = 1; /* enable userspace RDPMC usage by default */
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (quirk = x86_pmu.quirks; quirk; quirk = quirk->next)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		quirk->func();
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!x86_pmu.intel_ctrl)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		x86_pmu.intel_ctrl = (1 << x86_pmu.num_counters) - 1;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	perf_events_lapic_init();
 	register_nmi_handler(NMI_LOCAL, perf_event_nmi_handler, 0, "PMI");
 
@@ -1810,34 +1898,52 @@ static int __init init_hw_perf_events(void)
 		struct attribute **tmp;
 
 		tmp = merge_attr(x86_pmu_caps_group.attrs, x86_pmu.caps_attrs);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (!WARN_ON(!tmp))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			x86_pmu_caps_group.attrs = tmp;
+}
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (x86_pmu.event_attrs)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		x86_pmu_events_group.attrs = x86_pmu.event_attrs;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!x86_pmu.events_sysfs_show)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		x86_pmu_events_group.attrs = &empty_attrs;
+}
 	else
 		filter_events(x86_pmu_events_group.attrs);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (x86_pmu.cpu_events) {
 		struct attribute **tmp;
 
 		tmp = merge_attr(x86_pmu_events_group.attrs, x86_pmu.cpu_events);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (!WARN_ON(!tmp))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			x86_pmu_events_group.attrs = tmp;
+}
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (x86_pmu.attrs) {
 		struct attribute **tmp;
 
 		tmp = merge_attr(x86_pmu_attr_group.attrs, x86_pmu.attrs);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (!WARN_ON(!tmp))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			x86_pmu_attr_group.attrs = tmp;
+}
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pr_info("... version:                %d\n",     x86_pmu.version);
 	pr_info("... bit width:              %d\n",     x86_pmu.cntval_bits);
 	pr_info("... generic registers:      %d\n",     x86_pmu.num_counters);
@@ -1853,23 +1959,29 @@ static int __init init_hw_perf_events(void)
 	err = cpuhp_setup_state(CPUHP_PERF_X86_PREPARE, "perf/x86:prepare",
 				x86_pmu_prepare_cpu, x86_pmu_dead_cpu);
 	if (err)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return err;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	err = cpuhp_setup_state(CPUHP_AP_PERF_X86_STARTING,
 				"perf/x86:starting", x86_pmu_starting_cpu,
 				x86_pmu_dying_cpu);
 	if (err)
 		goto out;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	err = cpuhp_setup_state(CPUHP_AP_PERF_X86_ONLINE, "perf/x86:online",
 				x86_pmu_online_cpu, NULL);
 	if (err)
 		goto out1;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	err = perf_pmu_register(&pmu, "cpu", PERF_TYPE_RAW);
 	if (err)
 		goto out2;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 
 out2:
@@ -1884,6 +1996,7 @@ early_initcall(init_hw_perf_events);
 
 static inline void x86_pmu_read(struct perf_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	x86_perf_event_update(event);
 }
 
@@ -1898,6 +2011,7 @@ static inline void x86_pmu_read(struct perf_event *event)
  */
 static void x86_pmu_start_txn(struct pmu *pmu, unsigned int txn_flags)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cpu_hw_events *cpuc = this_cpu_ptr(&cpu_hw_events);
 
 	WARN_ON_ONCE(cpuc->txn_flags);		/* txn already in flight */
@@ -1918,6 +2032,7 @@ static void x86_pmu_start_txn(struct pmu *pmu, unsigned int txn_flags)
 static void x86_pmu_cancel_txn(struct pmu *pmu)
 {
 	unsigned int txn_flags;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cpu_hw_events *cpuc = this_cpu_ptr(&cpu_hw_events);
 
 	WARN_ON_ONCE(!cpuc->txn_flags);	/* no txn in flight */
@@ -1945,6 +2060,7 @@ static void x86_pmu_cancel_txn(struct pmu *pmu)
  */
 static int x86_pmu_commit_txn(struct pmu *pmu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cpu_hw_events *cpuc = this_cpu_ptr(&cpu_hw_events);
 	int assign[X86_PMC_IDX_MAX];
 	int n, ret;
@@ -1985,6 +2101,7 @@ static int x86_pmu_commit_txn(struct pmu *pmu)
  */
 static void free_fake_cpuc(struct cpu_hw_events *cpuc)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	kfree(cpuc->shared_regs);
 	kfree(cpuc);
 }
@@ -1992,6 +2109,7 @@ static void free_fake_cpuc(struct cpu_hw_events *cpuc)
 static struct cpu_hw_events *allocate_fake_cpuc(void)
 {
 	struct cpu_hw_events *cpuc;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	int cpu = raw_smp_processor_id();
 
 	cpuc = kzalloc(sizeof(*cpuc), GFP_KERNEL);
@@ -2022,7 +2140,9 @@ static int validate_event(struct perf_event *event)
 
 	fake_cpuc = allocate_fake_cpuc();
 	if (IS_ERR(fake_cpuc))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return PTR_ERR(fake_cpuc);
+}
 
 	c = x86_pmu.get_event_constraints(fake_cpuc, -1, event);
 
@@ -2056,7 +2176,9 @@ static int validate_group(struct perf_event *event)
 
 	fake_cpuc = allocate_fake_cpuc();
 	if (IS_ERR(fake_cpuc))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return PTR_ERR(fake_cpuc);
+}
 	/*
 	 * the event is not yet connected with its
 	 * siblings therefore we must first collect
@@ -2126,11 +2248,13 @@ static int x86_pmu_event_init(struct perf_event *event)
 
 static void refresh_pce(void *ignored)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	load_mm_cr4(this_cpu_read(cpu_tlbstate.loaded_mm));
 }
 
 static void x86_pmu_event_mapped(struct perf_event *event, struct mm_struct *mm)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!(event->hw.flags & PERF_X86_EVENT_RDPMC_ALLOWED))
 		return;
 
@@ -2153,6 +2277,7 @@ static void x86_pmu_event_mapped(struct perf_event *event, struct mm_struct *mm)
 static void x86_pmu_event_unmapped(struct perf_event *event, struct mm_struct *mm)
 {
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!(event->hw.flags & PERF_X86_EVENT_RDPMC_ALLOWED))
 		return;
 
@@ -2165,7 +2290,9 @@ static int x86_pmu_event_idx(struct perf_event *event)
 	int idx = event->hw.idx;
 
 	if (!(event->hw.flags & PERF_X86_EVENT_RDPMC_ALLOWED))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	if (x86_pmu.num_counters_fixed && idx >= INTEL_PMC_IDX_FIXED) {
 		idx -= INTEL_PMC_IDX_FIXED;
@@ -2179,6 +2306,7 @@ static ssize_t get_attr_rdpmc(struct device *cdev,
 			      struct device_attribute *attr,
 			      char *buf)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return snprintf(buf, 40, "%d\n", x86_pmu.attr_rdpmc);
 }
 
@@ -2191,7 +2319,9 @@ static ssize_t set_attr_rdpmc(struct device *cdev,
 
 	ret = kstrtoul(buf, 0, &val);
 	if (ret)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ret;
+}
 
 	if (val > 2)
 		return -EINVAL;
@@ -2232,6 +2362,7 @@ static ssize_t max_precise_show(struct device *cdev,
 				  struct device_attribute *attr,
 				  char *buf)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return snprintf(buf, PAGE_SIZE, "%d\n", x86_pmu_max_precise());
 }
 
@@ -2257,12 +2388,14 @@ static const struct attribute_group *x86_pmu_attr_groups[] = {
 
 static void x86_pmu_sched_task(struct perf_event_context *ctx, bool sched_in)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (x86_pmu.sched_task)
 		x86_pmu.sched_task(ctx, sched_in);
 }
 
 void perf_check_microcode(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (x86_pmu.check_microcode)
 		x86_pmu.check_microcode();
 }
@@ -2305,6 +2438,7 @@ void arch_perf_update_userpage(struct perf_event *event,
 		!!(event->hw.flags & PERF_X86_EVENT_RDPMC_ALLOWED);
 	userpg->pmc_width = x86_pmu.cntval_bits;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!using_native_sched_clock() || !sched_clock_stable())
 		return;
 
@@ -2339,6 +2473,7 @@ perf_callchain_kernel(struct perf_callchain_entry_ctx *entry, struct pt_regs *re
 	struct unwind_state state;
 	unsigned long addr;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (perf_guest_cbs && perf_guest_cbs->is_in_guest()) {
 		/* TODO: We don't support guest os callchain now */
 		return;
@@ -2358,6 +2493,7 @@ perf_callchain_kernel(struct perf_callchain_entry_ctx *entry, struct pt_regs *re
 static inline int
 valid_user_frame(const void __user *fp, unsigned long size)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return (__range_not_ok(fp, size, TASK_SIZE) == 0);
 }
 
@@ -2402,7 +2538,9 @@ perf_callchain_user32(struct pt_regs *regs, struct perf_callchain_entry_ctx *ent
 	const void __user *fp;
 
 	if (!test_thread_flag(TIF_IA32))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	cs_base = get_segment_base(regs->cs);
 	ss_base = get_segment_base(regs->ss);
@@ -2444,6 +2582,7 @@ perf_callchain_user(struct perf_callchain_entry_ctx *entry, struct pt_regs *regs
 	struct stack_frame frame;
 	const unsigned long __user *fp;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (perf_guest_cbs && perf_guest_cbs->is_in_guest()) {
 		/* TODO: We don't support guest os callchain now */
 		return;
@@ -2528,6 +2667,7 @@ static unsigned long code_segment_base(struct pt_regs *regs)
 
 unsigned long perf_instruction_pointer(struct pt_regs *regs)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (perf_guest_cbs && perf_guest_cbs->is_in_guest())
 		return perf_guest_cbs->get_guest_ip();
 
@@ -2538,6 +2678,7 @@ unsigned long perf_misc_flags(struct pt_regs *regs)
 {
 	int misc = 0;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (perf_guest_cbs && perf_guest_cbs->is_in_guest()) {
 		if (perf_guest_cbs->is_user_mode())
 			misc |= PERF_RECORD_MISC_GUEST_USER;
@@ -2558,6 +2699,7 @@ unsigned long perf_misc_flags(struct pt_regs *regs)
 
 void perf_get_x86_pmu_capability(struct x86_pmu_capability *cap)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	cap->version		= x86_pmu.version;
 	cap->num_counters_gp	= x86_pmu.num_counters;
 	cap->num_counters_fixed	= x86_pmu.num_counters_fixed;
diff --git a/arch/x86/events/intel/bts.c b/arch/x86/events/intel/bts.c
index 24ffa1e..8454fa4 100644
--- a/arch/x86/events/intel/bts.c
+++ b/arch/x86/events/intel/bts.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * BTS PMU driver for perf
  * Copyright (c) 2013-2014, Intel Corporation.
@@ -73,6 +75,7 @@ static struct pmu bts_pmu;
 
 static size_t buf_size(struct page *page)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 1 << (PAGE_SHIFT + page_private(page));
 }
 
@@ -81,6 +84,7 @@ bts_buffer_setup_aux(int cpu, void **pages, int nr_pages, bool overwrite)
 {
 	struct bts_buffer *buf;
 	struct page *page;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	int node = (cpu == -1) ? cpu : cpu_to_node(cpu);
 	unsigned long offset;
 	size_t size = nr_pages << PAGE_SHIFT;
@@ -132,17 +136,20 @@ bts_buffer_setup_aux(int cpu, void **pages, int nr_pages, bool overwrite)
 
 static void bts_buffer_free_aux(void *data)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	kfree(data);
 }
 
 static unsigned long bts_buffer_offset(struct bts_buffer *buf, unsigned int idx)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return buf->buf[idx].offset + buf->buf[idx].displacement;
 }
 
 static void
 bts_config_buffer(struct bts_buffer *buf)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	int cpu = raw_smp_processor_id();
 	struct debug_store *ds = per_cpu(cpu_hw_events, cpu).ds;
 	struct bts_phys *phys = &buf->buf[buf->cur_buf];
@@ -182,6 +189,7 @@ static void bts_buffer_pad_out(struct bts_phys *phys, unsigned long head)
 
 static void bts_update(struct bts_ctx *bts)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	int cpu = raw_smp_processor_id();
 	struct debug_store *ds = per_cpu(cpu_hw_events, cpu).ds;
 	struct bts_buffer *buf = perf_get_aux(&bts->handle);
@@ -225,6 +233,7 @@ bts_buffer_reset(struct bts_buffer *buf, struct perf_output_handle *handle);
 
 static void __bts_event_start(struct perf_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct bts_ctx *bts = this_cpu_ptr(&bts_ctx);
 	struct bts_buffer *buf = perf_get_aux(&bts->handle);
 	u64 config = 0;
@@ -253,6 +262,7 @@ static void __bts_event_start(struct perf_event *event)
 
 static void bts_event_start(struct perf_event *event, int flags)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cpu_hw_events *cpuc = this_cpu_ptr(&cpu_hw_events);
 	struct bts_ctx *bts = this_cpu_ptr(&bts_ctx);
 	struct bts_buffer *buf;
@@ -284,6 +294,7 @@ static void bts_event_start(struct perf_event *event, int flags)
 
 static void __bts_event_stop(struct perf_event *event, int state)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct bts_ctx *bts = this_cpu_ptr(&bts_ctx);
 
 	/* ACTIVE -> INACTIVE(PMI)/STOPPED(->stop()) */
@@ -298,6 +309,7 @@ static void __bts_event_stop(struct perf_event *event, int state)
 
 static void bts_event_stop(struct perf_event *event, int flags)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cpu_hw_events *cpuc = this_cpu_ptr(&cpu_hw_events);
 	struct bts_ctx *bts = this_cpu_ptr(&bts_ctx);
 	struct bts_buffer *buf = NULL;
@@ -332,6 +344,7 @@ static void bts_event_stop(struct perf_event *event, int flags)
 
 void intel_bts_enable_local(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct bts_ctx *bts = this_cpu_ptr(&bts_ctx);
 	int state = READ_ONCE(bts->state);
 
@@ -352,6 +365,7 @@ void intel_bts_enable_local(void)
 
 void intel_bts_disable_local(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct bts_ctx *bts = this_cpu_ptr(&bts_ctx);
 
 	/*
@@ -374,7 +388,9 @@ bts_buffer_reset(struct bts_buffer *buf, struct perf_output_handle *handle)
 	int ret;
 
 	if (buf->snapshot)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	head = handle->head & ((buf->nr_pages << PAGE_SHIFT) - 1);
 
@@ -443,6 +459,7 @@ bts_buffer_reset(struct bts_buffer *buf, struct perf_output_handle *handle)
 
 int intel_bts_interrupt(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct debug_store *ds = this_cpu_ptr(&cpu_hw_events)->ds;
 	struct bts_ctx *bts = this_cpu_ptr(&bts_ctx);
 	struct perf_event *event = bts->handle.event;
@@ -507,11 +524,13 @@ int intel_bts_interrupt(void)
 
 static void bts_event_del(struct perf_event *event, int mode)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	bts_event_stop(event, PERF_EF_UPDATE);
 }
 
 static int bts_event_add(struct perf_event *event, int mode)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct bts_ctx *bts = this_cpu_ptr(&bts_ctx);
 	struct cpu_hw_events *cpuc = this_cpu_ptr(&cpu_hw_events);
 	struct hw_perf_event *hwc = &event->hw;
@@ -535,6 +554,7 @@ static int bts_event_add(struct perf_event *event, int mode)
 
 static void bts_event_destroy(struct perf_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	x86_release_hardware();
 	x86_del_exclusive(x86_lbr_exclusive_bts);
 }
@@ -544,7 +564,9 @@ static int bts_event_init(struct perf_event *event)
 	int ret;
 
 	if (event->attr.type != bts_pmu.type)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOENT;
+}
 
 	/*
 	 * BTS leaks kernel addresses even when CPL0 tracing is
@@ -580,8 +602,11 @@ static void bts_event_read(struct perf_event *event)
 static __init int bts_init(void)
 {
 	if (!boot_cpu_has(X86_FEATURE_DTES64) || !x86_pmu.bts)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENODEV;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (boot_cpu_has(X86_FEATURE_PTI)) {
 		/*
 		 * BTS hardware writes through a virtual memory map we must
@@ -600,6 +625,7 @@ static __init int bts_init(void)
 		return -ENODEV;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	bts_pmu.capabilities	= PERF_PMU_CAP_AUX_NO_SG | PERF_PMU_CAP_ITRACE |
 				  PERF_PMU_CAP_EXCLUSIVE;
 	bts_pmu.task_ctx_nr	= perf_sw_context;
diff --git a/arch/x86/events/intel/core.c b/arch/x86/events/intel/core.c
index 56457cb..ae6a188 100644
--- a/arch/x86/events/intel/core.c
+++ b/arch/x86/events/intel/core.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * Per core/cpu state
  *
@@ -334,6 +336,7 @@ static struct event_constraint intel_bdw_event_constraints[] = {
 
 static u64 intel_pmu_event_map(int hw_event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return intel_perfmon_event_map[hw_event];
 }
 
@@ -1873,6 +1876,7 @@ static __initconst const u64 knl_hw_cache_extra_regs
  */
 static void __intel_pmu_disable_all(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cpu_hw_events *cpuc = this_cpu_ptr(&cpu_hw_events);
 
 	wrmsrl(MSR_CORE_PERF_GLOBAL_CTRL, 0);
@@ -1885,12 +1889,14 @@ static void __intel_pmu_disable_all(void)
 
 static void intel_pmu_disable_all(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	__intel_pmu_disable_all();
 	intel_pmu_lbr_disable_all();
 }
 
 static void __intel_pmu_enable_all(int added, bool pmi)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cpu_hw_events *cpuc = this_cpu_ptr(&cpu_hw_events);
 
 	intel_pmu_pebs_enable_all();
@@ -1911,6 +1917,7 @@ static void __intel_pmu_enable_all(int added, bool pmi)
 
 static void intel_pmu_enable_all(int added)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	__intel_pmu_enable_all(added, false);
 }
 
@@ -1930,6 +1937,7 @@ static void intel_pmu_enable_all(int added)
  */
 static void intel_pmu_nhm_workaround(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cpu_hw_events *cpuc = this_cpu_ptr(&cpu_hw_events);
 	static const unsigned long nhm_magic[4] = {
 		0x4300B5,
@@ -1990,6 +1998,7 @@ static void intel_pmu_nhm_workaround(void)
 
 static void intel_pmu_nhm_enable_all(int added)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (added)
 		intel_pmu_nhm_workaround();
 	intel_pmu_enable_all(added);
@@ -2006,6 +2015,7 @@ static inline u64 intel_pmu_get_status(void)
 
 static inline void intel_pmu_ack_status(u64 ack)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	wrmsrl(MSR_CORE_PERF_GLOBAL_OVF_CTRL, ack);
 }
 
@@ -2023,12 +2033,14 @@ static void intel_pmu_disable_fixed(struct hw_perf_event *hwc)
 
 static inline bool event_is_checkpointed(struct perf_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return (event->hw.config & HSW_IN_TX_CHECKPOINTED) != 0;
 }
 
 static void intel_pmu_disable_event(struct perf_event *event)
 {
 	struct hw_perf_event *hwc = &event->hw;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cpu_hw_events *cpuc = this_cpu_ptr(&cpu_hw_events);
 
 	if (unlikely(hwc->idx == INTEL_PMC_IDX_FIXED_BTS)) {
@@ -2054,6 +2066,7 @@ static void intel_pmu_disable_event(struct perf_event *event)
 
 static void intel_pmu_del_event(struct perf_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (needs_branch_stack(event))
 		intel_pmu_lbr_del(event);
 	if (event->attr.precise_ip)
@@ -2072,7 +2085,9 @@ static void intel_pmu_enable_fixed(struct hw_perf_event *hwc)
 	 */
 	bits = 0x8ULL;
 	if (hwc->config & ARCH_PERFMON_EVENTSEL_USR)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		bits |= 0x2;
+}
 	if (hwc->config & ARCH_PERFMON_EVENTSEL_OS)
 		bits |= 0x1;
 
@@ -2094,6 +2109,7 @@ static void intel_pmu_enable_fixed(struct hw_perf_event *hwc)
 static void intel_pmu_enable_event(struct perf_event *event)
 {
 	struct hw_perf_event *hwc = &event->hw;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cpu_hw_events *cpuc = this_cpu_ptr(&cpu_hw_events);
 
 	if (unlikely(hwc->idx == INTEL_PMC_IDX_FIXED_BTS)) {
@@ -2125,6 +2141,7 @@ static void intel_pmu_enable_event(struct perf_event *event)
 
 static void intel_pmu_add_event(struct perf_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (event->attr.precise_ip)
 		intel_pmu_pebs_add(event);
 	if (needs_branch_stack(event))
@@ -2137,6 +2154,7 @@ static void intel_pmu_add_event(struct perf_event *event)
  */
 int intel_pmu_save_and_restart(struct perf_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	x86_perf_event_update(event);
 	/*
 	 * For a checkpointed counter always reset back to 0.  This
@@ -2154,6 +2172,7 @@ int intel_pmu_save_and_restart(struct perf_event *event)
 
 static void intel_pmu_reset(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct debug_store *ds = __this_cpu_read(cpu_hw_events.ds);
 	unsigned long flags;
 	int idx;
@@ -2202,6 +2221,7 @@ static int intel_pmu_handle_irq(struct pt_regs *regs)
 	u64 status;
 	int handled;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	cpuc = this_cpu_ptr(&cpu_hw_events);
 
 	/*
@@ -2341,7 +2361,9 @@ intel_bts_constraints(struct perf_event *event)
 	unsigned int hw_event, bts_event;
 
 	if (event->attr.freq)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 
 	hw_event = hwc->config & INTEL_ARCH_EVENT_MASK;
 	bts_event = x86_pmu.event_map(PERF_COUNT_HW_BRANCH_INSTRUCTIONS);
@@ -2357,7 +2379,9 @@ static int intel_alt_er(int idx, u64 config)
 	int alt_idx = idx;
 
 	if (!(x86_pmu.flags & PMU_FL_HAS_RSP_1))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return idx;
+}
 
 	if (idx == EXTRA_REG_RSP_0)
 		alt_idx = EXTRA_REG_RSP_1;
@@ -2373,6 +2397,7 @@ static int intel_alt_er(int idx, u64 config)
 
 static void intel_fixup_er(struct perf_event *event, int idx)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	event->hw.extra_reg.idx = idx;
 
 	if (idx == EXTRA_REG_RSP_0) {
@@ -2503,6 +2528,7 @@ intel_shared_regs_constraints(struct cpu_hw_events *cpuc,
 
 	xreg = &event->hw.extra_reg;
 	if (xreg->idx != EXTRA_REG_NONE) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		c = __intel_shared_reg_get_constraints(cpuc, event, xreg);
 		if (c == &emptyconstraint)
 			return c;
@@ -2525,6 +2551,7 @@ x86_get_event_constraints(struct cpu_hw_events *cpuc, int idx,
 	struct event_constraint *c;
 
 	if (x86_pmu.event_constraints) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		for_each_event_constraint(c, x86_pmu.event_constraints) {
 			if ((event->hw.config & c->cmask) == c->code) {
 				event->hw.flags |= c->flags;
@@ -2544,7 +2571,9 @@ __intel_get_event_constraints(struct cpu_hw_events *cpuc, int idx,
 
 	c = intel_bts_constraints(event);
 	if (c)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return c;
+}
 
 	c = intel_shared_regs_constraints(cpuc, event);
 	if (c)
@@ -2594,6 +2623,7 @@ static void intel_commit_scheduling(struct cpu_hw_events *cpuc, int idx, int cnt
 	struct intel_excl_states *xl;
 	int tid = cpuc->excl_thread_id;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (cpuc->is_fake || !is_ht_workaround_enabled())
 		return;
 
@@ -2764,7 +2794,9 @@ intel_get_event_constraints(struct cpu_hw_events *cpuc, int idx,
 	struct event_constraint *c2;
 
 	if (idx >= 0) /* fake does < 0 */
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		c1 = cpuc->event_constraint[idx];
+}
 
 	/*
 	 * first time only
@@ -2796,7 +2828,9 @@ static void intel_put_excl_constraints(struct cpu_hw_events *cpuc,
 	 * nothing needed if in group validation mode
 	 */
 	if (cpuc->is_fake)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	if (WARN_ON_ONCE(!excl_cntrs))
 		return;
@@ -2837,7 +2871,9 @@ intel_put_shared_regs_event_constraints(struct cpu_hw_events *cpuc,
 
 	reg = &event->hw.extra_reg;
 	if (reg->idx != EXTRA_REG_NONE)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		__intel_shared_reg_put_constraints(cpuc, reg);
+}
 
 	reg = &event->hw.branch_reg;
 	if (reg->idx != EXTRA_REG_NONE)
@@ -2847,6 +2883,7 @@ intel_put_shared_regs_event_constraints(struct cpu_hw_events *cpuc,
 static void intel_put_event_constraints(struct cpu_hw_events *cpuc,
 					struct perf_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	intel_put_shared_regs_event_constraints(cpuc, event);
 
 	/*
@@ -2860,6 +2897,7 @@ static void intel_put_event_constraints(struct cpu_hw_events *cpuc,
 
 static void intel_pebs_aliases_core2(struct perf_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if ((event->hw.config & X86_RAW_EVENT_MASK) == 0x003c) {
 		/*
 		 * Use an alternative encoding for CPU_CLK_UNHALTED.THREAD_P
@@ -2888,6 +2926,7 @@ static void intel_pebs_aliases_core2(struct perf_event *event)
 
 static void intel_pebs_aliases_snb(struct perf_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if ((event->hw.config & X86_RAW_EVENT_MASK) == 0x003c) {
 		/*
 		 * Use an alternative encoding for CPU_CLK_UNHALTED.THREAD_P
@@ -2916,6 +2955,7 @@ static void intel_pebs_aliases_snb(struct perf_event *event)
 
 static void intel_pebs_aliases_precdist(struct perf_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if ((event->hw.config & X86_RAW_EVENT_MASK) == 0x003c) {
 		/*
 		 * Use an alternative encoding for CPU_CLK_UNHALTED.THREAD_P
@@ -2940,6 +2980,7 @@ static void intel_pebs_aliases_precdist(struct perf_event *event)
 
 static void intel_pebs_aliases_ivb(struct perf_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (event->attr.precise_ip < 3)
 		return intel_pebs_aliases_snb(event);
 	return intel_pebs_aliases_precdist(event);
@@ -2947,6 +2988,7 @@ static void intel_pebs_aliases_ivb(struct perf_event *event)
 
 static void intel_pebs_aliases_skl(struct perf_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (event->attr.precise_ip < 3)
 		return intel_pebs_aliases_core2(event);
 	return intel_pebs_aliases_precdist(event);
@@ -2957,7 +2999,9 @@ static unsigned long intel_pmu_free_running_flags(struct perf_event *event)
 	unsigned long flags = x86_pmu.free_running_flags;
 
 	if (event->attr.use_clockid)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		flags &= ~PERF_SAMPLE_TIME;
+}
 	if (!event->attr.exclude_kernel)
 		flags &= ~PERF_SAMPLE_REGS_USER;
 	if (event->attr.sample_regs_user & ~PEBS_REGS)
@@ -2967,6 +3011,7 @@ static unsigned long intel_pmu_free_running_flags(struct perf_event *event)
 
 static int intel_pmu_hw_config(struct perf_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	int ret = x86_pmu_hw_config(event);
 
 	if (ret)
@@ -3019,6 +3064,7 @@ static int intel_pmu_hw_config(struct perf_event *event)
 
 struct perf_guest_switch_msr *perf_guest_get_msrs(int *nr)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (x86_pmu.guest_get_msrs)
 		return x86_pmu.guest_get_msrs(nr);
 	*nr = 0;
@@ -3028,6 +3074,7 @@ EXPORT_SYMBOL_GPL(perf_guest_get_msrs);
 
 static struct perf_guest_switch_msr *intel_guest_get_msrs(int *nr)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cpu_hw_events *cpuc = this_cpu_ptr(&cpu_hw_events);
 	struct perf_guest_switch_msr *arr = cpuc->guest_switch_msrs;
 
@@ -3049,6 +3096,7 @@ static struct perf_guest_switch_msr *intel_guest_get_msrs(int *nr)
 
 static struct perf_guest_switch_msr *core_guest_get_msrs(int *nr)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cpu_hw_events *cpuc = this_cpu_ptr(&cpu_hw_events);
 	struct perf_guest_switch_msr *arr = cpuc->guest_switch_msrs;
 	int idx;
@@ -3077,12 +3125,14 @@ static struct perf_guest_switch_msr *core_guest_get_msrs(int *nr)
 
 static void core_pmu_enable_event(struct perf_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!event->attr.exclude_host)
 		x86_pmu_enable_event(event);
 }
 
 static void core_pmu_enable_all(int added)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cpu_hw_events *cpuc = this_cpu_ptr(&cpu_hw_events);
 	int idx;
 
@@ -3099,6 +3149,7 @@ static void core_pmu_enable_all(int added)
 
 static int hsw_hw_config(struct perf_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	int ret = intel_pmu_hw_config(event);
 
 	if (ret)
@@ -3150,6 +3201,7 @@ hsw_get_event_constraints(struct cpu_hw_events *cpuc, int idx,
 
 	/* Handle special quirk on in_tx_checkpointed only in counter 2 */
 	if (event->hw.config & HSW_IN_TX_CHECKPOINTED) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (c->idxmsk64 & (1U << 2))
 			return &counter2_constraint;
 		return &emptyconstraint;
@@ -3166,7 +3218,9 @@ glp_get_event_constraints(struct cpu_hw_events *cpuc, int idx,
 
 	/* :ppp means to do reduced skid PEBS which is PMC0 only. */
 	if (event->attr.precise_ip == 3)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return &counter0_constraint;
+}
 
 	c = intel_get_event_constraints(cpuc, idx, event);
 
@@ -3190,6 +3244,7 @@ glp_get_event_constraints(struct cpu_hw_events *cpuc, int idx,
  */
 static unsigned bdw_limit_period(struct perf_event *event, unsigned left)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if ((event->hw.config & INTEL_ARCH_EVENT_MASK) ==
 			X86_CONFIG(.event=0xc0, .umask=0x01)) {
 		if (left < 128)
@@ -3252,6 +3307,7 @@ static struct intel_excl_cntrs *allocate_excl_cntrs(int cpu)
 	c = kzalloc_node(sizeof(struct intel_excl_cntrs),
 			 GFP_KERNEL, cpu_to_node(cpu));
 	if (c) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		raw_spin_lock_init(&c->lock);
 		c->core_id = -1;
 	}
@@ -3260,6 +3316,7 @@ static struct intel_excl_cntrs *allocate_excl_cntrs(int cpu)
 
 static int intel_pmu_cpu_prepare(int cpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cpu_hw_events *cpuc = &per_cpu(cpu_hw_events, cpu);
 
 	if (x86_pmu.extra_regs || x86_pmu.lbr_sel_map) {
@@ -3301,6 +3358,7 @@ static void flip_smm_bit(void *data)
 	unsigned long set = *(unsigned long *)data;
 
 	if (set > 0) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		msr_set_bit(MSR_IA32_DEBUGCTLMSR,
 			    DEBUGCTLMSR_FREEZE_IN_SMM_BIT);
 	} else {
@@ -3311,6 +3369,7 @@ static void flip_smm_bit(void *data)
 
 static void intel_pmu_cpu_starting(int cpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cpu_hw_events *cpuc = &per_cpu(cpu_hw_events, cpu);
 	int core_id = topology_core_id(cpu);
 	int i;
@@ -3368,6 +3427,7 @@ static void intel_pmu_cpu_starting(int cpu)
 
 static void free_excl_cntrs(int cpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cpu_hw_events *cpuc = &per_cpu(cpu_hw_events, cpu);
 	struct intel_excl_cntrs *c;
 
@@ -3383,6 +3443,7 @@ static void free_excl_cntrs(int cpu)
 
 static void intel_pmu_cpu_dying(int cpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cpu_hw_events *cpuc = &per_cpu(cpu_hw_events, cpu);
 	struct intel_shared_regs *pc;
 
@@ -3401,6 +3462,7 @@ static void intel_pmu_cpu_dying(int cpu)
 static void intel_pmu_sched_task(struct perf_event_context *ctx,
 				 bool sched_in)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	intel_pmu_pebs_sched_task(ctx, sched_in);
 	intel_pmu_lbr_sched_task(ctx, sched_in);
 }
@@ -3553,6 +3615,7 @@ static int intel_snb_pebs_broken(int cpu)
 {
 	u32 rev = UINT_MAX; /* default to broken for unknown models */
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	switch (cpu_data(cpu).x86_model) {
 	case INTEL_FAM6_SANDYBRIDGE:
 		rev = 0x28;
@@ -3573,6 +3636,7 @@ static void intel_snb_check_microcode(void)
 	int pebs_broken = 0;
 	int cpu;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for_each_online_cpu(cpu) {
 		if ((pebs_broken = intel_snb_pebs_broken(cpu)))
 			break;
@@ -3597,6 +3661,7 @@ static bool is_lbr_from(unsigned long msr)
 {
 	unsigned long lbr_from_nr = x86_pmu.lbr_from + x86_pmu.lbr_nr;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return x86_pmu.lbr_from <= msr && msr < lbr_from_nr;
 }
 
@@ -3614,7 +3679,9 @@ static bool check_msr(unsigned long msr, u64 mask)
 	 * (qemu/kvm) that don't trap on the MSR access and always return 0s.
 	 */
 	if (rdmsrl_safe(msr, &val_old))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return false;
+}
 
 	/*
 	 * Only change the bits which can be updated by wrmsrl.
@@ -3648,6 +3715,7 @@ static bool check_msr(unsigned long msr, u64 mask)
 
 static __init void intel_sandybridge_quirk(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	x86_pmu.check_microcode = intel_snb_check_microcode;
 	cpus_read_lock();
 	intel_snb_check_microcode();
@@ -3709,6 +3777,7 @@ static __init void intel_nehalem_quirk(void)
  */
 static __init void intel_ht_bug(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	x86_pmu.flags |= PMU_FL_EXCL_CNTRS | PMU_FL_EXCL_ENABLED;
 
 	x86_pmu.start_scheduling = intel_start_scheduling;
@@ -3764,6 +3833,7 @@ static struct attribute *hsw_tsx_events_attrs[] = {
 
 static __init struct attribute **get_hsw_events_attrs(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return boot_cpu_has(X86_FEATURE_RTM) ?
 		merge_attr(hsw_events_attrs, hsw_tsx_events_attrs) :
 		hsw_events_attrs;
@@ -3773,6 +3843,7 @@ static ssize_t freeze_on_smi_show(struct device *cdev,
 				  struct device_attribute *attr,
 				  char *buf)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return sprintf(buf, "%lu\n", x86_pmu.attr_freeze_on_smi);
 }
 
@@ -3787,7 +3858,9 @@ static ssize_t freeze_on_smi_store(struct device *cdev,
 
 	ret = kstrtoul(buf, 0, &val);
 	if (ret)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ret;
+}
 
 	if (val > 1)
 		return -EINVAL;
@@ -3814,6 +3887,7 @@ static ssize_t branches_show(struct device *cdev,
 			     struct device_attribute *attr,
 			     char *buf)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return snprintf(buf, PAGE_SIZE, "%d\n", x86_pmu.lbr_nr);
 }
 
@@ -3830,6 +3904,7 @@ static ssize_t pmu_name_show(struct device *cdev,
 			     struct device_attribute *attr,
 			     char *buf)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return snprintf(buf, PAGE_SIZE, "%s\n", pmu_name_str);
 }
 
@@ -3859,6 +3934,7 @@ __init int intel_pmu_init(void)
 	char *name;
 
 	if (!cpu_has(&boot_cpu_data, X86_FEATURE_ARCH_PERFMON)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		switch (boot_cpu_data.x86) {
 		case 0x6:
 			return p6_pmu_init();
@@ -4420,13 +4496,18 @@ static __init int fixup_ht_bug(void)
 	 * problem not present on this CPU model, nothing to do
 	 */
 	if (!(x86_pmu.flags & PMU_FL_EXCL_ENABLED))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (topology_max_smt_threads() > 1) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_info("PMU erratum BJ122, BV98, HSD29 worked around, HT is on\n");
 		return 0;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	cpus_read_lock();
 
 	hardlockup_detector_perf_stop();
@@ -4439,9 +4520,11 @@ static __init int fixup_ht_bug(void)
 
 	hardlockup_detector_perf_restart();
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for_each_online_cpu(c)
 		free_excl_cntrs(c);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	cpus_read_unlock();
 	pr_info("PMU erratum BJ122, BV98, HSD29 workaround disabled, HT off\n");
 	return 0;
diff --git a/arch/x86/events/intel/cstate.c b/arch/x86/events/intel/cstate.c
index 72db066..69bb477 100644
--- a/arch/x86/events/intel/cstate.c
+++ b/arch/x86/events/intel/cstate.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * Support cstate residency counters
  *
@@ -259,6 +261,7 @@ static ssize_t cstate_get_attr_cpumask(struct device *dev,
 				       struct device_attribute *attr,
 				       char *buf)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct pmu *pmu = dev_get_drvdata(dev);
 
 	if (pmu == &cstate_core_pmu)
@@ -275,7 +278,9 @@ static int cstate_pmu_event_init(struct perf_event *event)
 	int cpu;
 
 	if (event->attr.type != event->pmu->type)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOENT;
+}
 
 	/* unsupported modes and filters */
 	if (event->attr.exclude_user   ||
@@ -345,21 +350,25 @@ static void cstate_pmu_event_update(struct perf_event *event)
 
 static void cstate_pmu_event_start(struct perf_event *event, int mode)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	local64_set(&event->hw.prev_count, cstate_pmu_read_counter(event));
 }
 
 static void cstate_pmu_event_stop(struct perf_event *event, int mode)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	cstate_pmu_event_update(event);
 }
 
 static void cstate_pmu_event_del(struct perf_event *event, int mode)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	cstate_pmu_event_stop(event, PERF_EF_UPDATE);
 }
 
 static int cstate_pmu_event_add(struct perf_event *event, int mode)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (mode & PERF_EF_START)
 		cstate_pmu_event_start(event, mode);
 
@@ -580,6 +589,7 @@ static bool __init cstate_probe_msr(const unsigned long evmsk, int max,
 	unsigned int bit;
 	u64 val;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (bit = 0; bit < max; bit++) {
 		if (test_bit(bit, &evmsk) && !rdmsrl_safe(msr[bit].msr, &val)) {
 			*attrs++ = &msr[bit].attr->attr.attr;
@@ -617,6 +627,7 @@ static int __init cstate_probe(const struct cstate_model *cm)
 
 static inline void cstate_cleanup(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	cpuhp_remove_state_nocalls(CPUHP_AP_PERF_X86_CSTATE_ONLINE);
 	cpuhp_remove_state_nocalls(CPUHP_AP_PERF_X86_CSTATE_STARTING);
 
@@ -637,6 +648,7 @@ static int __init cstate_init(void)
 			  "perf/x86/cstate:online", NULL, cstate_cpu_exit);
 
 	if (has_cstate_core) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		err = perf_pmu_register(&cstate_core_pmu, cstate_core_pmu.name, -1);
 		if (err) {
 			has_cstate_core = false;
@@ -664,22 +676,32 @@ static int __init cstate_pmu_init(void)
 	int err;
 
 	if (boot_cpu_has(X86_FEATURE_HYPERVISOR))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENODEV;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	id = x86_match_cpu(intel_cstates_match);
 	if (!id)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENODEV;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	err = cstate_probe((const struct cstate_model *) id->driver_data);
 	if (err)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return err;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return cstate_init();
 }
 module_init(cstate_pmu_init);
 
 static void __exit cstate_pmu_exit(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	cstate_cleanup();
 }
 module_exit(cstate_pmu_exit);
diff --git a/arch/x86/events/intel/pt.c b/arch/x86/events/intel/pt.c
index 81fd41d..13ec59e 100644
--- a/arch/x86/events/intel/pt.c
+++ b/arch/x86/events/intel/pt.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * Intel(R) Processor Trace PMU driver for perf
  * Copyright (c) 2013-2014, Intel Corporation.
@@ -307,7 +309,9 @@ static bool pt_event_valid(struct perf_event *event)
 	u64 allowed, requested;
 
 	if ((config & PT_CONFIG_MASK) != config)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return false;
+}
 
 	if (config & RTIT_CTL_CYC_PSB) {
 		if (!pt_cap_get(PT_CAP_psb_cyc))
@@ -428,6 +432,7 @@ static const struct pt_address_range {
 static u64 pt_config_filters(struct perf_event *event)
 {
 	struct pt_filters *filters = event->hw.addr_filters;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct pt *pt = this_cpu_ptr(&pt_ctx);
 	unsigned int range = 0;
 	u64 rtit_ctl = 0;
@@ -468,6 +473,7 @@ static u64 pt_config_filters(struct perf_event *event)
 
 static void pt_config(struct perf_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct pt *pt = this_cpu_ptr(&pt_ctx);
 	u64 reg;
 
@@ -509,6 +515,7 @@ static void pt_config(struct perf_event *event)
 
 static void pt_config_stop(struct perf_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct pt *pt = this_cpu_ptr(&pt_ctx);
 	u64 ctl = READ_ONCE(event->hw.config);
 
@@ -582,6 +589,7 @@ struct topa {
  */
 static struct topa *topa_alloc(int cpu, gfp_t gfp)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	int node = cpu_to_node(cpu);
 	struct topa *topa;
 	struct page *p;
@@ -612,6 +620,7 @@ static struct topa *topa_alloc(int cpu, gfp_t gfp)
  */
 static void topa_free(struct topa *topa)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	free_page((unsigned long)topa);
 }
 
@@ -631,6 +640,7 @@ static void topa_insert_table(struct pt_buffer *buf, struct topa *topa)
 	list_add_tail(&topa->list, &buf->tables);
 
 	if (!buf->first) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		buf->first = buf->last = buf->cur = topa;
 		return;
 	}
@@ -678,7 +688,9 @@ static int topa_insert_pages(struct pt_buffer *buf, gfp_t gfp)
 
 	p = virt_to_page(buf->data_pages[buf->nr_pages]);
 	if (PagePrivate(p))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		order = page_private(p);
+}
 
 	if (topa_table_full(topa)) {
 		topa = topa_alloc(buf->cpu, gfp);
@@ -711,6 +723,7 @@ static void pt_topa_dump(struct pt_buffer *buf)
 {
 	struct topa *topa;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry(topa, &buf->tables, list) {
 		int i;
 
@@ -741,6 +754,7 @@ static void pt_topa_dump(struct pt_buffer *buf)
  */
 static void pt_buffer_advance(struct pt_buffer *buf)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	buf->output_off = 0;
 	buf->cur_idx++;
 
@@ -762,6 +776,7 @@ static void pt_buffer_advance(struct pt_buffer *buf)
  */
 static void pt_update_head(struct pt *pt)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct pt_buffer *buf = perf_get_aux(&pt->handle);
 	u64 topa_idx, base, old;
 
@@ -790,6 +805,7 @@ static void pt_update_head(struct pt *pt)
  */
 static void *pt_buffer_region(struct pt_buffer *buf)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return phys_to_virt(buf->cur->table[buf->cur_idx].base << TOPA_SHIFT);
 }
 
@@ -799,6 +815,7 @@ static void *pt_buffer_region(struct pt_buffer *buf)
  */
 static size_t pt_buffer_region_size(struct pt_buffer *buf)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return sizes(buf->cur->table[buf->cur_idx].size);
 }
 
@@ -808,6 +825,7 @@ static size_t pt_buffer_region_size(struct pt_buffer *buf)
  */
 static void pt_handle_status(struct pt *pt)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct pt_buffer *buf = perf_get_aux(&pt->handle);
 	int advance = 0;
 	u64 status;
@@ -919,6 +937,7 @@ static int pt_buffer_reset_markers(struct pt_buffer *buf,
 				   struct perf_output_handle *handle)
 
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	unsigned long head = local64_read(&buf->head);
 	unsigned long idx, npages, wakeup;
 
@@ -977,6 +996,7 @@ static int pt_buffer_reset_markers(struct pt_buffer *buf,
 static void pt_buffer_setup_topa_index(struct pt_buffer *buf)
 {
 	struct topa *cur = buf->first, *prev = buf->last;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct topa_entry *te_cur = TOPA_ENTRY(cur, 0),
 		*te_prev = TOPA_ENTRY(prev, prev->last - 1);
 	int pg = 0, idx = 0;
@@ -1022,7 +1042,9 @@ static void pt_buffer_reset_offsets(struct pt_buffer *buf, unsigned long head)
 	int pg;
 
 	if (buf->snapshot)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		head &= (buf->nr_pages << PAGE_SHIFT) - 1;
+}
 
 	pg = (head >> PAGE_SHIFT) & (buf->nr_pages - 1);
 	pg = pt_topa_next_entry(buf, pg);
@@ -1044,6 +1066,7 @@ static void pt_buffer_fini_topa(struct pt_buffer *buf)
 {
 	struct topa *topa, *iter;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry_safe(topa, iter, &buf->tables, list) {
 		/*
 		 * right now, this is in free_aux() path only, so
@@ -1067,7 +1090,9 @@ static int pt_buffer_init_topa(struct pt_buffer *buf, unsigned long nr_pages,
 
 	topa = topa_alloc(buf->cpu, gfp);
 	if (!topa)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 
 	topa_insert_table(buf, topa);
 
@@ -1110,7 +1135,9 @@ pt_buffer_setup_aux(int cpu, void **pages, int nr_pages, bool snapshot)
 	int node, ret;
 
 	if (!nr_pages)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 
 	if (cpu == -1)
 		cpu = raw_smp_processor_id();
@@ -1151,6 +1178,7 @@ static void pt_buffer_free_aux(void *data)
 static int pt_addr_filters_init(struct perf_event *event)
 {
 	struct pt_filters *filters;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	int node = event->cpu == -1 ? -1 : cpu_to_node(event->cpu);
 
 	if (!pt_cap_get(PT_CAP_num_address_ranges))
@@ -1171,12 +1199,14 @@ static int pt_addr_filters_init(struct perf_event *event)
 
 static void pt_addr_filters_fini(struct perf_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	kfree(event->hw.addr_filters);
 	event->hw.addr_filters = NULL;
 }
 
 static inline bool valid_kernel_ip(unsigned long ip)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return virt_addr_valid(ip) && kernel_ip(ip);
 }
 
@@ -1185,6 +1215,7 @@ static int pt_event_addr_filters_validate(struct list_head *filters)
 	struct perf_addr_filter *filter;
 	int range = 0;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry(filter, filters, entry) {
 		/* PT doesn't support single address triggers */
 		if (!filter->range || !filter->size)
@@ -1207,6 +1238,7 @@ static int pt_event_addr_filters_validate(struct list_head *filters)
 
 static void pt_event_addr_filters_sync(struct perf_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct perf_addr_filters_head *head = perf_event_addr_filters(event);
 	unsigned long msr_a, msr_b, *offs = event->addr_filters_offs;
 	struct pt_filters *filters = event->hw.addr_filters;
@@ -1239,6 +1271,7 @@ static void pt_event_addr_filters_sync(struct perf_event *event)
  */
 void intel_pt_interrupt(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct pt *pt = this_cpu_ptr(&pt_ctx);
 	struct pt_buffer *buf;
 	struct perf_event *event = pt->handle.event;
@@ -1293,6 +1326,7 @@ void intel_pt_interrupt(void)
 
 void intel_pt_handle_vmx(int on)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct pt *pt = this_cpu_ptr(&pt_ctx);
 	struct perf_event *event;
 	unsigned long flags;
@@ -1334,6 +1368,7 @@ EXPORT_SYMBOL_GPL(intel_pt_handle_vmx);
 static void pt_event_start(struct perf_event *event, int mode)
 {
 	struct hw_perf_event *hwc = &event->hw;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct pt *pt = this_cpu_ptr(&pt_ctx);
 	struct pt_buffer *buf;
 
@@ -1364,6 +1399,7 @@ static void pt_event_start(struct perf_event *event, int mode)
 
 static void pt_event_stop(struct perf_event *event, int mode)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct pt *pt = this_cpu_ptr(&pt_ctx);
 
 	/*
@@ -1404,11 +1440,13 @@ static void pt_event_stop(struct perf_event *event, int mode)
 
 static void pt_event_del(struct perf_event *event, int mode)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pt_event_stop(event, PERF_EF_UPDATE);
 }
 
 static int pt_event_add(struct perf_event *event, int mode)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct pt *pt = this_cpu_ptr(&pt_ctx);
 	struct hw_perf_event *hwc = &event->hw;
 	int ret = -EBUSY;
@@ -1437,12 +1475,14 @@ static void pt_event_read(struct perf_event *event)
 
 static void pt_event_destroy(struct perf_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pt_addr_filters_fini(event);
 	x86_del_exclusive(x86_lbr_exclusive_pt);
 }
 
 static int pt_event_init(struct perf_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (event->attr.type != pt_pmu.pmu.type)
 		return -ENOENT;
 
@@ -1464,6 +1504,7 @@ static int pt_event_init(struct perf_event *event)
 
 void cpu_emergency_stop_pt(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct pt *pt = this_cpu_ptr(&pt_ctx);
 
 	if (pt->handle.event)
@@ -1474,41 +1515,60 @@ static __init int pt_init(void)
 {
 	int ret, cpu, prior_warn = 0;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	BUILD_BUG_ON(sizeof(struct topa) > PAGE_SIZE);
 
 	if (!boot_cpu_has(X86_FEATURE_INTEL_PT))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENODEV;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	get_online_cpus();
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for_each_online_cpu(cpu) {
 		u64 ctl;
 
 		ret = rdmsrl_safe_on_cpu(cpu, MSR_IA32_RTIT_CTL, &ctl);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (!ret && (ctl & RTIT_CTL_TRACEEN))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			prior_warn++;
+}
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	put_online_cpus();
 
 	if (prior_warn) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		x86_add_exclusive(x86_lbr_exclusive_pt);
 		pr_warn("PT is enabled at boot time, doing nothing\n");
 
 		return -EBUSY;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	ret = pt_pmu_hw_init();
 	if (ret)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ret;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!pt_cap_get(PT_CAP_topa_output)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_warn("ToPA output is not supported on this CPU\n");
 		return -ENODEV;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!pt_cap_get(PT_CAP_topa_multiple_entries))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pt_pmu.pmu.capabilities =
 			PERF_PMU_CAP_AUX_NO_SG | PERF_PMU_CAP_AUX_SW_DOUBLEBUF;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pt_pmu.pmu.capabilities	|= PERF_PMU_CAP_EXCLUSIVE | PERF_PMU_CAP_ITRACE;
 	pt_pmu.pmu.attr_groups		 = pt_attr_groups;
 	pt_pmu.pmu.task_ctx_nr		 = perf_sw_context;
diff --git a/arch/x86/events/intel/rapl.c b/arch/x86/events/intel/rapl.c
index 005908e..2da34c9 100644
--- a/arch/x86/events/intel/rapl.c
+++ b/arch/x86/events/intel/rapl.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * Support Intel RAPL energy consumption counters
  * Copyright (C) 2013 Google, Inc., Stephane Eranian
@@ -161,6 +163,7 @@ static u64 rapl_timer_ms;
 
 static inline struct rapl_pmu *cpu_to_rapl_pmu(unsigned int cpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	unsigned int pkgid = topology_logical_package_id(cpu);
 
 	/*
@@ -179,6 +182,7 @@ static inline u64 rapl_read_counter(struct perf_event *event)
 
 static inline u64 rapl_scale(u64 v, int cfg)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (cfg > NR_RAPL_DOMAINS) {
 		pr_warn("Invalid domain %d, failed to scale data\n", cfg);
 		return v;
@@ -229,12 +233,14 @@ static u64 rapl_event_update(struct perf_event *event)
 
 static void rapl_start_hrtimer(struct rapl_pmu *pmu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
        hrtimer_start(&pmu->hrtimer, pmu->timer_interval,
 		     HRTIMER_MODE_REL_PINNED);
 }
 
 static enum hrtimer_restart rapl_hrtimer_handle(struct hrtimer *hrtimer)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct rapl_pmu *pmu = container_of(hrtimer, struct rapl_pmu, hrtimer);
 	struct perf_event *event;
 	unsigned long flags;
@@ -265,6 +271,7 @@ static void rapl_hrtimer_init(struct rapl_pmu *pmu)
 static void __rapl_pmu_event_start(struct rapl_pmu *pmu,
 				   struct perf_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (WARN_ON_ONCE(!(event->hw.state & PERF_HES_STOPPED)))
 		return;
 
@@ -284,6 +291,7 @@ static void rapl_pmu_event_start(struct perf_event *event, int mode)
 	struct rapl_pmu *pmu = event->pmu_private;
 	unsigned long flags;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	raw_spin_lock_irqsave(&pmu->lock, flags);
 	__rapl_pmu_event_start(pmu, event);
 	raw_spin_unlock_irqrestore(&pmu->lock, flags);
@@ -295,6 +303,7 @@ static void rapl_pmu_event_stop(struct perf_event *event, int mode)
 	struct hw_perf_event *hwc = &event->hw;
 	unsigned long flags;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	raw_spin_lock_irqsave(&pmu->lock, flags);
 
 	/* mark event as deactivated and stopped */
@@ -329,6 +338,7 @@ static int rapl_pmu_event_add(struct perf_event *event, int mode)
 	struct hw_perf_event *hwc = &event->hw;
 	unsigned long flags;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	raw_spin_lock_irqsave(&pmu->lock, flags);
 
 	hwc->state = PERF_HES_UPTODATE | PERF_HES_STOPPED;
@@ -343,6 +353,7 @@ static int rapl_pmu_event_add(struct perf_event *event, int mode)
 
 static void rapl_pmu_event_del(struct perf_event *event, int flags)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rapl_pmu_event_stop(event, PERF_EF_UPDATE);
 }
 
@@ -354,7 +365,9 @@ static int rapl_pmu_event_init(struct perf_event *event)
 
 	/* only look at RAPL events */
 	if (event->attr.type != rapl_pmus->pmu.type)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOENT;
+}
 
 	/* check only supported bits are set */
 	if (event->attr.config & ~RAPL_EVENT_MASK)
@@ -421,12 +434,14 @@ static int rapl_pmu_event_init(struct perf_event *event)
 
 static void rapl_pmu_event_read(struct perf_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rapl_event_update(event);
 }
 
 static ssize_t rapl_get_attr_cpumask(struct device *dev,
 				struct device_attribute *attr, char *buf)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return cpumap_print_to_pagebuf(true, buf, &rapl_cpu_mask);
 }
 
@@ -568,6 +583,7 @@ static const struct attribute_group *rapl_attr_groups[] = {
 
 static int rapl_cpu_offline(unsigned int cpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct rapl_pmu *pmu = cpu_to_rapl_pmu(cpu);
 	int target;
 
@@ -590,6 +606,7 @@ static int rapl_cpu_offline(unsigned int cpu)
 
 static int rapl_cpu_online(unsigned int cpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct rapl_pmu *pmu = cpu_to_rapl_pmu(cpu);
 	int target;
 
@@ -627,7 +644,9 @@ static int rapl_check_hw_unit(bool apply_quirk)
 
 	/* protect rdmsrl() to handle virtualization */
 	if (rdmsrl_safe(MSR_RAPL_POWER_UNIT, &msr_rapl_power_unit_bits))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -1;
+}
 	for (i = 0; i < NR_RAPL_DOMAINS; i++)
 		rapl_hw_unit[i] = (msr_rapl_power_unit_bits >> 8) & 0x1FULL;
 
@@ -659,6 +678,7 @@ static void __init rapl_advertise(void)
 {
 	int i;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pr_info("API unit is 2^-32 Joules, %d fixed counters, %llu ms ovfl timer\n",
 		hweight32(rapl_cntr_mask), rapl_timer_ms);
 
@@ -674,6 +694,7 @@ static void cleanup_rapl_pmus(void)
 {
 	int i;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (i = 0; i < rapl_pmus->maxpkg; i++)
 		kfree(rapl_pmus->pmus[i]);
 	kfree(rapl_pmus);
@@ -687,7 +708,9 @@ static int __init init_rapl_pmus(void)
 	size = sizeof(*rapl_pmus) + maxpkg * sizeof(struct rapl_pmu *);
 	rapl_pmus = kzalloc(size, GFP_KERNEL);
 	if (!rapl_pmus)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 
 	rapl_pmus->maxpkg		= maxpkg;
 	rapl_pmus->pmu.attr_groups	= rapl_attr_groups;
@@ -792,8 +815,11 @@ static int __init rapl_pmu_init(void)
 
 	id = x86_match_cpu(rapl_cpu_match);
 	if (!id)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENODEV;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rapl_init = (struct intel_rapl_init_fun *)id->driver_data;
 	apply_quirk = rapl_init->apply_quirk;
 	rapl_cntr_mask = rapl_init->cntr_mask;
@@ -801,11 +827,16 @@ static int __init rapl_pmu_init(void)
 
 	ret = rapl_check_hw_unit(apply_quirk);
 	if (ret)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ret;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	ret = init_rapl_pmus();
 	if (ret)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ret;
+}
 
 	/*
 	 * Install callbacks. Core will call them for each online cpu.
@@ -816,10 +847,12 @@ static int __init rapl_pmu_init(void)
 	if (ret)
 		goto out;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	ret = perf_pmu_register(&rapl_pmus->pmu, "power", -1);
 	if (ret)
 		goto out1;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rapl_advertise();
 	return 0;
 
@@ -834,6 +867,7 @@ module_init(rapl_pmu_init);
 
 static void __exit intel_rapl_exit(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	cpuhp_remove_state_nocalls(CPUHP_AP_PERF_X86_RAPL_ONLINE);
 	perf_pmu_unregister(&rapl_pmus->pmu);
 	cleanup_rapl_pmus();
diff --git a/arch/x86/events/intel/uncore.c b/arch/x86/events/intel/uncore.c
index d45e063..e11af22 100644
--- a/arch/x86/events/intel/uncore.c
+++ b/arch/x86/events/intel/uncore.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 #include <linux/module.h>
 
 #include <asm/cpu_device_id.h>
@@ -33,6 +35,7 @@ static int uncore_pcibus_to_physid(struct pci_bus *bus)
 	int phys_id = -1;
 
 	raw_spin_lock(&pci2phy_map_lock);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry(map, &pci2phy_map_head, list) {
 		if (map->segment == pci_domain_nr(bus)) {
 			phys_id = map->pbus_to_physid[bus->number];
@@ -48,6 +51,7 @@ static void uncore_free_pcibus_map(void)
 {
 	struct pci2phy_map *map, *tmp;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry_safe(map, tmp, &pci2phy_map_head, list) {
 		list_del(&map->list);
 		kfree(map);
@@ -59,6 +63,7 @@ struct pci2phy_map *__find_pci2phy_map(int segment)
 	struct pci2phy_map *map, *alloc = NULL;
 	int i;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&pci2phy_map_lock);
 
 lookup:
@@ -100,6 +105,7 @@ ssize_t uncore_event_show(struct kobject *kobj,
 
 struct intel_uncore_box *uncore_pmu_to_box(struct intel_uncore_pmu *pmu, int cpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	unsigned int pkgid = topology_logical_package_id(cpu);
 
 	/*
@@ -188,6 +194,7 @@ u64 uncore_shared_reg_config(struct intel_uncore_box *box, int idx)
 
 	er = &box->shared_regs[idx];
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	raw_spin_lock_irqsave(&er->lock, flags);
 	config = er->config;
 	raw_spin_unlock_irqrestore(&er->lock, flags);
@@ -204,6 +211,7 @@ static void uncore_assign_hw_event(struct intel_uncore_box *box,
 	hwc->last_tag = ++box->tags[idx];
 
 	if (hwc->idx == UNCORE_PMC_IDX_FIXED) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		hwc->event_base = uncore_fixed_ctr(box);
 		hwc->config_base = uncore_fixed_ctl(box);
 		return;
@@ -219,7 +227,9 @@ void uncore_perf_event_update(struct intel_uncore_box *box, struct perf_event *e
 	int shift;
 
 	if (event->hw.idx >= UNCORE_PMC_IDX_FIXED)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		shift = 64 - uncore_fixed_ctr_bits(box);
+}
 	else
 		shift = 64 - uncore_perf_ctr_bits(box);
 
@@ -248,6 +258,7 @@ static enum hrtimer_restart uncore_pmu_hrtimer(struct hrtimer *hrtimer)
 	unsigned long flags;
 	int bit;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	box = container_of(hrtimer, struct intel_uncore_box, hrtimer);
 	if (!box->n_active || box->cpu != smp_processor_id())
 		return HRTIMER_NORESTART;
@@ -276,17 +287,20 @@ static enum hrtimer_restart uncore_pmu_hrtimer(struct hrtimer *hrtimer)
 
 void uncore_pmu_start_hrtimer(struct intel_uncore_box *box)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	hrtimer_start(&box->hrtimer, ns_to_ktime(box->hrtimer_duration),
 		      HRTIMER_MODE_REL_PINNED);
 }
 
 void uncore_pmu_cancel_hrtimer(struct intel_uncore_box *box)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	hrtimer_cancel(&box->hrtimer);
 }
 
 static void uncore_pmu_init_hrtimer(struct intel_uncore_box *box)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	hrtimer_init(&box->hrtimer, CLOCK_MONOTONIC, HRTIMER_MODE_REL);
 	box->hrtimer.function = uncore_pmu_hrtimer;
 }
@@ -301,7 +315,9 @@ static struct intel_uncore_box *uncore_alloc_box(struct intel_uncore_type *type,
 
 	box = kzalloc_node(size, GFP_KERNEL, node);
 	if (!box)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 
 	for (i = 0; i < numshared; i++)
 		raw_spin_lock_init(&box->shared_regs[i].lock);
@@ -327,6 +343,7 @@ static int uncore_pmu_event_init(struct perf_event *event);
 
 static bool is_box_event(struct intel_uncore_box *box, struct perf_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return &box->pmu->pmu == event->pmu;
 }
 
@@ -339,7 +356,9 @@ uncore_collect_events(struct intel_uncore_box *box, struct perf_event *leader,
 
 	max_count = box->pmu->type->num_counters;
 	if (box->pmu->type->fixed_ctl)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		max_count++;
+}
 
 	if (box->n_events >= max_count)
 		return -EINVAL;
@@ -375,6 +394,7 @@ uncore_get_event_constraint(struct intel_uncore_box *box, struct perf_event *eve
 	struct event_constraint *c;
 
 	if (type->ops->get_constraint) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		c = type->ops->get_constraint(box, event);
 		if (c)
 			return c;
@@ -396,6 +416,7 @@ uncore_get_event_constraint(struct intel_uncore_box *box, struct perf_event *eve
 static void uncore_put_event_constraint(struct intel_uncore_box *box,
 					struct perf_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (box->pmu->type->ops->put_constraint)
 		box->pmu->type->ops->put_constraint(box, event);
 }
@@ -409,6 +430,7 @@ static int uncore_assign_events(struct intel_uncore_box *box, int assign[], int
 
 	bitmap_zero(used_mask, UNCORE_PMC_IDX_MAX);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (i = 0, wmin = UNCORE_PMC_IDX_MAX, wmax = 0; i < n; i++) {
 		c = uncore_get_event_constraint(box, box->event_list[i]);
 		box->event_constraint[i] = c;
@@ -451,6 +473,7 @@ static int uncore_assign_events(struct intel_uncore_box *box, int assign[], int
 
 static void uncore_pmu_event_start(struct perf_event *event, int flags)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct intel_uncore_box *box = uncore_event_to_box(event);
 	int idx = event->hw.idx;
 
@@ -476,6 +499,7 @@ static void uncore_pmu_event_start(struct perf_event *event, int flags)
 
 static void uncore_pmu_event_stop(struct perf_event *event, int flags)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct intel_uncore_box *box = uncore_event_to_box(event);
 	struct hw_perf_event *hwc = &event->hw;
 
@@ -504,6 +528,7 @@ static void uncore_pmu_event_stop(struct perf_event *event, int flags)
 
 static int uncore_pmu_event_add(struct perf_event *event, int flags)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct intel_uncore_box *box = uncore_event_to_box(event);
 	struct hw_perf_event *hwc = &event->hw;
 	int assign[UNCORE_PMC_IDX_MAX];
@@ -565,6 +590,7 @@ static int uncore_pmu_event_add(struct perf_event *event, int flags)
 
 static void uncore_pmu_event_del(struct perf_event *event, int flags)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct intel_uncore_box *box = uncore_event_to_box(event);
 	int i;
 
@@ -588,6 +614,7 @@ static void uncore_pmu_event_del(struct perf_event *event, int flags)
 
 void uncore_pmu_event_read(struct perf_event *event)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct intel_uncore_box *box = uncore_event_to_box(event);
 	uncore_perf_event_update(box, event);
 }
@@ -605,7 +632,9 @@ static int uncore_validate_group(struct intel_uncore_pmu *pmu,
 
 	fake_box = uncore_alloc_box(pmu->type, NUMA_NO_NODE);
 	if (!fake_box)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 
 	fake_box->pmu = pmu;
 	/*
@@ -639,7 +668,9 @@ static int uncore_pmu_event_init(struct perf_event *event)
 	int ret;
 
 	if (event->attr.type != event->pmu->type)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOENT;
+}
 
 	pmu = uncore_event_to_pmu(event);
 	/* no device found for this pmu */
@@ -711,6 +742,7 @@ static int uncore_pmu_event_init(struct perf_event *event)
 static ssize_t uncore_get_attr_cpumask(struct device *dev,
 				struct device_attribute *attr, char *buf)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return cpumap_print_to_pagebuf(true, buf, &uncore_cpu_mask);
 }
 
@@ -764,6 +796,7 @@ static int uncore_pmu_register(struct intel_uncore_pmu *pmu)
 
 static void uncore_pmu_unregister(struct intel_uncore_pmu *pmu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!pmu->registered)
 		return;
 	perf_pmu_unregister(&pmu->pmu);
@@ -774,6 +807,7 @@ static void uncore_free_boxes(struct intel_uncore_pmu *pmu)
 {
 	int pkg;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (pkg = 0; pkg < max_packages; pkg++)
 		kfree(pmu->boxes[pkg]);
 	kfree(pmu->boxes);
@@ -785,6 +819,7 @@ static void uncore_type_exit(struct intel_uncore_type *type)
 	int i;
 
 	if (pmu) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		for (i = 0; i < type->num_boxes; i++, pmu++) {
 			uncore_pmu_unregister(pmu);
 			uncore_free_boxes(pmu);
@@ -798,6 +833,7 @@ static void uncore_type_exit(struct intel_uncore_type *type)
 
 static void uncore_types_exit(struct intel_uncore_type **types)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (; *types; types++)
 		uncore_type_exit(*types);
 }
@@ -812,7 +848,9 @@ static int __init uncore_type_init(struct intel_uncore_type *type, bool setid)
 
 	pmus = kzalloc(sizeof(*pmus) * type->num_boxes, GFP_KERNEL);
 	if (!pmus)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 
 	size = max_packages * sizeof(struct intel_uncore_box *);
 
@@ -865,6 +903,7 @@ uncore_types_init(struct intel_uncore_type **types, bool setid)
 {
 	int ret;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (; *types; types++) {
 		ret = uncore_type_init(*types, setid);
 		if (ret)
@@ -885,7 +924,9 @@ static int uncore_pci_probe(struct pci_dev *pdev, const struct pci_device_id *id
 
 	phys_id = uncore_pcibus_to_physid(pdev->bus);
 	if (phys_id < 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENODEV;
+}
 
 	pkg = topology_phys_to_logical_pkg(phys_id);
 	if (pkg < 0)
@@ -979,6 +1020,7 @@ static void uncore_pci_remove(struct pci_dev *pdev)
 
 	box = pci_get_drvdata(pdev);
 	if (!box) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		for (i = 0; i < UNCORE_EXTRA_PCI_DEV_MAX; i++) {
 			if (uncore_extra_pci_dev[pkg].dev[i] == pdev) {
 				uncore_extra_pci_dev[pkg].dev[i] = NULL;
@@ -1009,6 +1051,7 @@ static int __init uncore_pci_init(void)
 	size = max_packages * sizeof(struct pci_extra_dev);
 	uncore_extra_pci_dev = kzalloc(size, GFP_KERNEL);
 	if (!uncore_extra_pci_dev) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ret = -ENOMEM;
 		goto err;
 	}
@@ -1039,6 +1082,7 @@ static int __init uncore_pci_init(void)
 
 static void uncore_pci_exit(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (pcidrv_registered) {
 		pcidrv_registered = false;
 		pci_unregister_driver(uncore_pci_driver);
@@ -1055,6 +1099,7 @@ static void uncore_change_type_ctx(struct intel_uncore_type *type, int old_cpu,
 	struct intel_uncore_box *box;
 	int i, pkg;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pkg = topology_logical_package_id(old_cpu < 0 ? new_cpu : old_cpu);
 	for (i = 0; i < type->num_boxes; i++, pmu++) {
 		box = pmu->boxes[pkg];
@@ -1081,6 +1126,7 @@ static void uncore_change_type_ctx(struct intel_uncore_type *type, int old_cpu,
 static void uncore_change_context(struct intel_uncore_type **uncores,
 				  int old_cpu, int new_cpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (; *uncores; uncores++)
 		uncore_change_type_ctx(*uncores, old_cpu, new_cpu);
 }
@@ -1168,6 +1214,7 @@ static int uncore_event_cpu_online(unsigned int cpu)
 	struct intel_uncore_box *box;
 	int i, ret, pkg, target;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pkg = topology_logical_package_id(cpu);
 	ret = allocate_boxes(types, pkg, cpu);
 	if (ret)
@@ -1202,6 +1249,7 @@ static int __init type_pmu_register(struct intel_uncore_type *type)
 {
 	int i, ret;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (i = 0; i < type->num_boxes; i++) {
 		ret = uncore_pmu_register(&type->pmus[i]);
 		if (ret)
@@ -1215,6 +1263,7 @@ static int __init uncore_msr_pmus_register(void)
 	struct intel_uncore_type **types = uncore_msr_uncores;
 	int ret;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (; *types; types++) {
 		ret = type_pmu_register(*types);
 		if (ret)
@@ -1231,6 +1280,7 @@ static int __init uncore_cpu_init(void)
 	if (ret)
 		goto err;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	ret = uncore_msr_pmus_register();
 	if (ret)
 		goto err;
@@ -1351,27 +1401,41 @@ static int __init intel_uncore_init(void)
 
 	id = x86_match_cpu(intel_uncore_match);
 	if (!id)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENODEV;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (boot_cpu_has(X86_FEATURE_HYPERVISOR))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENODEV;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	max_packages = topology_max_packages();
 
 	uncore_init = (struct intel_uncore_init_fun *)id->driver_data;
 	if (uncore_init->pci_init) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pret = uncore_init->pci_init();
 		if (!pret)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			pret = uncore_pci_init();
+}
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (uncore_init->cpu_init) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		uncore_init->cpu_init();
 		cret = uncore_cpu_init();
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (cret && pret)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENODEV;
+}
 
 	/* Install hotplug callbacks to setup the targets for each package */
 	ret = cpuhp_setup_state(CPUHP_AP_PERF_X86_UNCORE_ONLINE,
@@ -1380,6 +1444,7 @@ static int __init intel_uncore_init(void)
 				uncore_event_cpu_offline);
 	if (ret)
 		goto err;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 
 err:
@@ -1391,6 +1456,7 @@ module_init(intel_uncore_init);
 
 static void __exit intel_uncore_exit(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	cpuhp_remove_state(CPUHP_AP_PERF_X86_UNCORE_ONLINE);
 	uncore_types_exit(uncore_msr_uncores);
 	uncore_pci_exit();
diff --git a/arch/x86/events/msr.c b/arch/x86/events/msr.c
index 14efaa0..599162b 100644
--- a/arch/x86/events/msr.c
+++ b/arch/x86/events/msr.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 #include <linux/perf_event.h>
 #include <asm/intel-family.h>
@@ -35,6 +37,7 @@ static bool test_intel(int idx)
 	    boot_cpu_data.x86 != 6)
 		return false;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	switch (boot_cpu_data.x86_model) {
 	case INTEL_FAM6_NEHALEM:
 	case INTEL_FAM6_NEHALEM_G:
@@ -73,7 +76,9 @@ static bool test_intel(int idx)
 	case INTEL_FAM6_XEON_PHI_KNL:
 	case INTEL_FAM6_XEON_PHI_KNM:
 		if (idx == PERF_MSR_SMI)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return true;
+}
 		break;
 
 	case INTEL_FAM6_SKYLAKE_MOBILE:
@@ -82,10 +87,13 @@ static bool test_intel(int idx)
 	case INTEL_FAM6_KABYLAKE_MOBILE:
 	case INTEL_FAM6_KABYLAKE_DESKTOP:
 		if (idx == PERF_MSR_SMI || idx == PERF_MSR_PPERF)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return true;
+}
 		break;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return false;
 }
 
@@ -143,7 +151,9 @@ static int msr_event_init(struct perf_event *event)
 	u64 cfg = event->attr.config;
 
 	if (event->attr.type != event->pmu->type)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOENT;
+}
 
 	if (cfg >= PERF_MSR_EVENT_MAX)
 		return -EINVAL;
@@ -173,7 +183,9 @@ static inline u64 msr_read_counter(struct perf_event *event)
 	u64 now;
 
 	if (event->hw.event_base)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		rdmsrl(event->hw.event_base, now);
+}
 	else
 		rdtscll(now);
 
@@ -209,16 +221,19 @@ static void msr_event_start(struct perf_event *event, int flags)
 
 static void msr_event_stop(struct perf_event *event, int flags)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	msr_event_update(event);
 }
 
 static void msr_event_del(struct perf_event *event, int flags)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	msr_event_stop(event, PERF_EF_UPDATE);
 }
 
 static int msr_event_add(struct perf_event *event, int flags)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (flags & PERF_EF_START)
 		msr_event_start(event, flags);
 
@@ -242,6 +257,7 @@ static int __init msr_init(void)
 	int i, j = 0;
 
 	if (!boot_cpu_has(X86_FEATURE_TSC)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_cont("no MSR PMU driver.\n");
 		return 0;
 	}
diff --git a/arch/x86/events/perf_event.h b/arch/x86/events/perf_event.h
index 8e4ea143..603fede 100644
--- a/arch/x86/events/perf_event.h
+++ b/arch/x86/events/perf_event.h
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * Performance events x86 architecture header
  *
diff --git a/arch/x86/kernel/acpi/boot.c b/arch/x86/kernel/acpi/boot.c
index 9c2a002..d80eab8 100644
--- a/arch/x86/kernel/acpi/boot.c
+++ b/arch/x86/kernel/acpi/boot.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  *  boot.c - Architecture-Specific Low-Level ACPI Boot Support
  *
@@ -122,7 +124,9 @@ void __init __iomem *__acpi_map_table(unsigned long phys, unsigned long size)
 {
 
 	if (!phys || !size)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 
 	return early_memremap(phys, size);
 }
@@ -130,7 +134,9 @@ void __init __iomem *__acpi_map_table(unsigned long phys, unsigned long size)
 void __init __acpi_unmap_table(void __iomem *map, unsigned long size)
 {
 	if (!map || !size)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	early_memunmap(map, size);
 }
@@ -141,10 +147,14 @@ static int __init acpi_parse_madt(struct acpi_table_header *table)
 	struct acpi_table_madt *madt = NULL;
 
 	if (!boot_cpu_has(X86_FEATURE_APIC))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	madt = (struct acpi_table_madt *)table;
 	if (!madt) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		printk(KERN_WARNING PREFIX "Unable to map MADT\n");
 		return -ENODEV;
 	}
@@ -176,11 +186,13 @@ static int acpi_register_lapic(int id, u32 acpiid, u8 enabled)
 	int cpu;
 
 	if (id >= MAX_LOCAL_APIC) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		printk(KERN_INFO PREFIX "skipped apicid that is too big\n");
 		return -EINVAL;
 	}
 
 	if (!enabled) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		++disabled_cpus;
 		return -EINVAL;
 	}
@@ -192,6 +204,7 @@ static int acpi_register_lapic(int id, u32 acpiid, u8 enabled)
 	if (cpu >= 0)
 		early_per_cpu(x86_cpu_to_acpiid, cpu) = acpiid;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return cpu;
 }
 
@@ -206,6 +219,7 @@ acpi_parse_x2apic(struct acpi_subtable_header *header, const unsigned long end)
 
 	processor = (struct acpi_madt_local_x2apic *)header;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (BAD_MADT_ENTRY(processor, end))
 		return -EINVAL;
 
@@ -241,13 +255,17 @@ acpi_parse_lapic(struct acpi_subtable_header * header, const unsigned long end)
 	processor = (struct acpi_madt_local_apic *)header;
 
 	if (BAD_MADT_ENTRY(processor, end))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	acpi_table_print_madt_entry(header);
 
 	/* Ignore invalid ID */
 	if (processor->id == 0xff)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	/*
 	 * We need to register disabled CPU as well to permit
@@ -270,6 +288,7 @@ acpi_parse_sapic(struct acpi_subtable_header *header, const unsigned long end)
 
 	processor = (struct acpi_madt_local_sapic *)header;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (BAD_MADT_ENTRY(processor, end))
 		return -EINVAL;
 
@@ -290,6 +309,7 @@ acpi_parse_lapic_addr_ovr(struct acpi_subtable_header * header,
 
 	lapic_addr_ovr = (struct acpi_madt_local_apic_override *)header;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (BAD_MADT_ENTRY(lapic_addr_ovr, end))
 		return -EINVAL;
 
@@ -308,6 +328,7 @@ acpi_parse_x2apic_nmi(struct acpi_subtable_header *header,
 
 	x2apic_nmi = (struct acpi_madt_local_x2apic_nmi *)header;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (BAD_MADT_ENTRY(x2apic_nmi, end))
 		return -EINVAL;
 
@@ -327,13 +348,18 @@ acpi_parse_lapic_nmi(struct acpi_subtable_header * header, const unsigned long e
 	lapic_nmi = (struct acpi_madt_local_apic_nmi *)header;
 
 	if (BAD_MADT_ENTRY(lapic_nmi, end))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	acpi_table_print_madt_entry(header);
 
 	if (lapic_nmi->lint != 1)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		printk(KERN_WARNING PREFIX "NMI not connected to LINT 1!\n");
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
@@ -352,6 +378,7 @@ static void __init mp_override_legacy_irq(u8 bus_irq, u8 polarity, u8 trigger,
 	 * Check bus_irq boundary.
 	 */
 	if (bus_irq >= NR_IRQS_LEGACY) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_warn("Invalid bus_irq %u for legacy override\n", bus_irq);
 		return;
 	}
@@ -362,10 +389,14 @@ static void __init mp_override_legacy_irq(u8 bus_irq, u8 polarity, u8 trigger,
 	 *      increase of timer interrupts!
 	 */
 	if ((bus_irq == 0) && (trigger == 3))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		trigger = 1;
+}
 
 	if (mp_register_ioapic_irq(bus_irq, polarity, trigger, gsi) < 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 	/*
 	 * Reset default identity mapping if gsi is also an legacy IRQ,
 	 * otherwise there will be more than one entry with the same GSI
@@ -388,7 +419,9 @@ static int mp_config_acpi_gsi(struct device *dev, u32 gsi, int trigger,
 	u8 pin;
 
 	if (!acpi_ioapic)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 	if (!dev || !dev_is_pci(dev))
 		return 0;
 
@@ -421,6 +454,7 @@ static int __init mp_register_ioapic_irq(u8 bus_irq, u8 polarity,
 	/* Convert 'gsi' to 'ioapic.pin'(INTIN#) */
 	ioapic = mp_find_ioapic(gsi);
 	if (ioapic < 0) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_warn("Failed to find ioapic for gsi : %u\n", gsi);
 		return ioapic;
 	}
@@ -452,7 +486,9 @@ acpi_parse_ioapic(struct acpi_subtable_header * header, const unsigned long end)
 	ioapic = (struct acpi_madt_io_apic *)header;
 
 	if (BAD_MADT_ENTRY(ioapic, end))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	acpi_table_print_madt_entry(header);
 
@@ -472,17 +508,25 @@ acpi_parse_ioapic(struct acpi_subtable_header * header, const unsigned long end)
 static void __init acpi_sci_ioapic_setup(u8 bus_irq, u16 polarity, u16 trigger, u32 gsi)
 {
 	if (trigger == 0)	/* compatible SCI trigger is level */
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		trigger = 3;
+}
 
 	if (polarity == 0)	/* compatible SCI polarity is low */
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		polarity = 3;
+}
 
 	/* Command-line over-ride via acpi_sci= */
 	if (acpi_sci_flags & ACPI_MADT_TRIGGER_MASK)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		trigger = (acpi_sci_flags & ACPI_MADT_TRIGGER_MASK) >> 2;
+}
 
 	if (acpi_sci_flags & ACPI_MADT_POLARITY_MASK)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		polarity = acpi_sci_flags & ACPI_MADT_POLARITY_MASK;
+}
 
 	if (bus_irq < NR_IRQS_LEGACY)
 		mp_override_legacy_irq(bus_irq, polarity, trigger, gsi);
@@ -508,7 +552,9 @@ acpi_parse_int_src_ovr(struct acpi_subtable_header * header,
 	intsrc = (struct acpi_madt_interrupt_override *)header;
 
 	if (BAD_MADT_ENTRY(intsrc, end))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	acpi_table_print_madt_entry(header);
 
@@ -522,12 +568,14 @@ acpi_parse_int_src_ovr(struct acpi_subtable_header * header,
 
 	if (intsrc->source_irq == 0) {
 		if (acpi_skip_timer_override) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			printk(PREFIX "BIOS IRQ0 override ignored.\n");
 			return 0;
 		}
 
 		if ((intsrc->global_irq == 2) && acpi_fix_pin2_polarity
 			&& (intsrc->inti_flags & ACPI_MADT_POLARITY_MASK)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			intsrc->inti_flags &= ~ACPI_MADT_POLARITY_MASK;
 			printk(PREFIX "BIOS IRQ0 pin2 override: forcing polarity to high active.\n");
 		}
@@ -548,6 +596,7 @@ acpi_parse_nmi_src(struct acpi_subtable_header * header, const unsigned long end
 
 	nmi_src = (struct acpi_madt_nmi_source *)header;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (BAD_MADT_ENTRY(nmi_src, end))
 		return -EINVAL;
 
@@ -615,6 +664,7 @@ int acpi_gsi_to_irq(u32 gsi, unsigned int *irqp)
 	int rc, irq, trigger, polarity;
 
 	if (acpi_irq_model == ACPI_IRQ_MODEL_PIC) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		*irqp = gsi;
 		return 0;
 	}
@@ -630,6 +680,7 @@ int acpi_gsi_to_irq(u32 gsi, unsigned int *irqp)
 		}
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return -1;
 }
 EXPORT_SYMBOL_GPL(acpi_gsi_to_irq);
@@ -642,6 +693,7 @@ int acpi_isa_irq_to_gsi(unsigned isa_irq, u32 *gsi)
 		return 0;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return -1;
 }
 
@@ -668,6 +720,7 @@ static int acpi_register_gsi_ioapic(struct device *dev, u32 gsi,
 	int node;
 	struct irq_alloc_info info;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	node = dev ? dev_to_node(dev) : NUMA_NO_NODE;
 	trigger = trigger == ACPI_EDGE_SENSITIVE ? 0 : 1;
 	polarity = polarity == ACPI_ACTIVE_HIGH ? 0 : 1;
@@ -693,7 +746,9 @@ static void acpi_unregister_gsi_ioapic(u32 gsi)
 	mutex_lock(&acpi_ioapic_lock);
 	irq = mp_map_gsi_to_irq(gsi, 0, NULL);
 	if (irq > 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		mp_unmap_irq(irq);
+}
 	mutex_unlock(&acpi_ioapic_lock);
 #endif
 }
@@ -721,6 +776,7 @@ EXPORT_SYMBOL_GPL(acpi_register_gsi);
 
 void acpi_unregister_gsi(u32 gsi)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (__acpi_unregister_gsi)
 		__acpi_unregister_gsi(gsi);
 }
@@ -749,6 +805,7 @@ static int acpi_map_cpu2node(acpi_handle handle, int cpu, int physid)
 
 	nid = acpi_get_node(handle);
 	if (nid != NUMA_NO_NODE) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		set_apicid_to_node(physid, nid);
 		numa_set_node(cpu, nid);
 	}
@@ -763,6 +820,7 @@ int acpi_map_cpu(acpi_handle handle, phys_cpuid_t physid, u32 acpi_id,
 
 	cpu = acpi_register_lapic(physid, acpi_id, ACPI_MADT_ENABLED);
 	if (cpu < 0) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_info(PREFIX "Unable to map lapic to logical cpu number\n");
 		return cpu;
 	}
@@ -809,6 +867,7 @@ int acpi_register_ioapic(acpi_handle handle, u64 phys_addr, u32 gsi_base)
 		status = acpi_evaluate_integer(handle, METHOD_NAME__UID,
 					       NULL, &uid);
 		if (ACPI_FAILURE(status)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			acpi_handle_warn(handle, "failed to get IOAPIC ID.\n");
 			return -EINVAL;
 		}
@@ -879,6 +938,7 @@ static int __init acpi_parse_hpet(struct acpi_table_header *table)
 	struct acpi_table_hpet *hpet_tbl = (struct acpi_table_hpet *)table;
 
 	if (hpet_tbl->address.space_id != ACPI_SPACE_MEM) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		printk(KERN_WARNING PREFIX "HPET timers must be located in "
 		       "memory.\n");
 		return -1;
@@ -892,6 +952,7 @@ static int __init acpi_parse_hpet(struct acpi_table_header *table)
 	 * want to allocate a resource there.
 	 */
 	if (!hpet_address) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		printk(KERN_WARNING PREFIX
 		       "HPET id: %#x base: %#lx is invalid\n",
 		       hpet_tbl->id, hpet_address);
@@ -904,7 +965,9 @@ static int __init acpi_parse_hpet(struct acpi_table_header *table)
 	 * some noise:
 	 */
 	if (hpet_address == 0xfed0000000000000UL) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (!hpet_force_user) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			printk(KERN_WARNING PREFIX "HPET id: %#x "
 			       "base: 0xfed0000000000000 is bogus\n "
 			       "try hpet=force on the kernel command line to "
@@ -912,6 +975,7 @@ static int __init acpi_parse_hpet(struct acpi_table_header *table)
 			hpet_address = 0;
 			return 0;
 		}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		printk(KERN_WARNING PREFIX
 		       "HPET id: %#x base: 0xfed0000000000000 fixed up "
 		       "to 0xfed00000.\n", hpet_tbl->id);
@@ -946,7 +1010,9 @@ static int __init acpi_parse_hpet(struct acpi_table_header *table)
 static __init int hpet_insert_resource(void)
 {
 	if (!hpet_res)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 1;
+}
 
 	return insert_resource(&iomem_resource, hpet_res);
 }
@@ -960,6 +1026,7 @@ late_initcall(hpet_insert_resource);
 static int __init acpi_parse_fadt(struct acpi_table_header *table)
 {
 	if (!(acpi_gbl_FADT.boot_flags & ACPI_FADT_LEGACY_DEVICES)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_debug("ACPI: no legacy devices present\n");
 		x86_platform.legacy.devices.pnpbios = 0;
 	}
@@ -967,11 +1034,13 @@ static int __init acpi_parse_fadt(struct acpi_table_header *table)
 	if (acpi_gbl_FADT.header.revision >= FADT2_REVISION_ID &&
 	    !(acpi_gbl_FADT.boot_flags & ACPI_FADT_8042) &&
 	    x86_platform.legacy.i8042 != X86_LEGACY_I8042_PLATFORM_ABSENT) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_debug("ACPI: i8042 controller is absent\n");
 		x86_platform.legacy.i8042 = X86_LEGACY_I8042_FIRMWARE_ABSENT;
 	}
 
 	if (acpi_gbl_FADT.boot_flags & ACPI_FADT_NO_CMOS_RTC) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_debug("ACPI: not registering RTC platform device\n");
 		x86_platform.legacy.rtc = 0;
 	}
@@ -984,6 +1053,7 @@ static int __init acpi_parse_fadt(struct acpi_table_header *table)
 		    ACPI_ADR_SPACE_SYSTEM_IO)
 			return 0;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pmtmr_ioport = acpi_gbl_FADT.xpm_timer_block.address;
 		/*
 		 * "X" fields are optional extensions to the original V1.0
@@ -991,7 +1061,9 @@ static int __init acpi_parse_fadt(struct acpi_table_header *table)
 		 * corresponding X field is zero.
 	 	 */
 		if (!pmtmr_ioport)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			pmtmr_ioport = acpi_gbl_FADT.pm_timer_block;
+}
 	} else {
 		/* FADT rev. 1 */
 		pmtmr_ioport = acpi_gbl_FADT.pm_timer_block;
@@ -1014,7 +1086,9 @@ static int __init early_acpi_parse_madt_lapic_addr_ovr(void)
 	int count;
 
 	if (!boot_cpu_has(X86_FEATURE_APIC))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENODEV;
+}
 
 	/*
 	 * Note that the LAPIC address is obtained from the MADT (32-bit value)
@@ -1024,6 +1098,7 @@ static int __init early_acpi_parse_madt_lapic_addr_ovr(void)
 	count = acpi_table_parse_madt(ACPI_MADT_TYPE_LOCAL_APIC_OVERRIDE,
 				      acpi_parse_lapic_addr_ovr, 0);
 	if (count < 0) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		printk(KERN_ERR PREFIX
 		       "Error parsing LAPIC address override entry\n");
 		return count;
@@ -1042,12 +1117,15 @@ static int __init acpi_parse_madt_lapic_entries(void)
 	struct acpi_subtable_proc madt_proc[2];
 
 	if (!boot_cpu_has(X86_FEATURE_APIC))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENODEV;
+}
 
 	count = acpi_table_parse_madt(ACPI_MADT_TYPE_LOCAL_SAPIC,
 				      acpi_parse_sapic, MAX_LOCAL_APIC);
 
 	if (!count) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		memset(madt_proc, 0, sizeof(madt_proc));
 		madt_proc[0].id = ACPI_MADT_TYPE_LOCAL_APIC;
 		madt_proc[0].handler = acpi_parse_lapic;
@@ -1057,6 +1135,7 @@ static int __init acpi_parse_madt_lapic_entries(void)
 				sizeof(struct acpi_table_madt),
 				madt_proc, ARRAY_SIZE(madt_proc), MAX_LOCAL_APIC);
 		if (ret < 0) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			printk(KERN_ERR PREFIX
 					"Error parsing LAPIC/X2APIC entries\n");
 			return ret;
@@ -1066,10 +1145,12 @@ static int __init acpi_parse_madt_lapic_entries(void)
 		x2count = madt_proc[1].count;
 	}
 	if (!count && !x2count) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		printk(KERN_ERR PREFIX "No LAPIC entries present\n");
 		/* TBD: Cleanup to allow fallback to MPS */
 		return -ENODEV;
 	} else if (count < 0 || x2count < 0) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		printk(KERN_ERR PREFIX "Error parsing LAPIC entry\n");
 		/* TBD: Cleanup to allow fallback to MPS */
 		return count;
@@ -1080,10 +1161,12 @@ static int __init acpi_parse_madt_lapic_entries(void)
 	count = acpi_table_parse_madt(ACPI_MADT_TYPE_LOCAL_APIC_NMI,
 				      acpi_parse_lapic_nmi, 0);
 	if (count < 0 || x2count < 0) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		printk(KERN_ERR PREFIX "Error parsing LAPIC NMI entry\n");
 		/* TBD: Cleanup to allow fallback to MPS */
 		return count;
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 #endif				/* CONFIG_X86_LOCAL_APIC */
@@ -1101,6 +1184,7 @@ static void __init mp_config_acpi_legacy_irqs(void)
 	mp_bus_id_to_type[MP_ISA_BUS] = MP_BUS_ISA;
 #endif
 	set_bit(MP_ISA_BUS, mp_bus_not_pci);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pr_debug("Bus #%d is ISA (nIRQs: %d)\n", MP_ISA_BUS, nr_legacy_irqs());
 
 	/*
@@ -1170,15 +1254,20 @@ static int __init acpi_parse_madt_ioapic_entries(void)
 	 * otherwise the system will stay in PIC mode
 	 */
 	if (acpi_disabled || acpi_noirq)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENODEV;
+}
 
 	if (!boot_cpu_has(X86_FEATURE_APIC))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENODEV;
+}
 
 	/*
 	 * if "noapic" boot option, don't look for IO-APICs
 	 */
 	if (skip_ioapic_setup) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		printk(KERN_INFO PREFIX "Skipping IOAPIC probe "
 		       "due to 'noapic' option.\n");
 		return -ENODEV;
@@ -1187,9 +1276,11 @@ static int __init acpi_parse_madt_ioapic_entries(void)
 	count = acpi_table_parse_madt(ACPI_MADT_TYPE_IO_APIC, acpi_parse_ioapic,
 				      MAX_IO_APICS);
 	if (!count) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		printk(KERN_ERR PREFIX "No IOAPIC entries present\n");
 		return -ENODEV;
 	} else if (count < 0) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		printk(KERN_ERR PREFIX "Error parsing IOAPIC entry\n");
 		return count;
 	}
@@ -1197,6 +1288,7 @@ static int __init acpi_parse_madt_ioapic_entries(void)
 	count = acpi_table_parse_madt(ACPI_MADT_TYPE_INTERRUPT_OVERRIDE,
 				      acpi_parse_int_src_ovr, nr_irqs);
 	if (count < 0) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		printk(KERN_ERR PREFIX
 		       "Error parsing interrupt source overrides entry\n");
 		/* TBD: Cleanup to allow fallback to MPS */
@@ -1208,8 +1300,10 @@ static int __init acpi_parse_madt_ioapic_entries(void)
 	 * pretend we got one so we can set the SCI flags.
 	 */
 	if (!acpi_sci_override_gsi)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		acpi_sci_ioapic_setup(acpi_gbl_FADT.sci_interrupt, 0, 0,
 				      acpi_gbl_FADT.sci_interrupt);
+}
 
 	/* Fill in identity legacy mappings where no override */
 	mp_config_acpi_legacy_irqs();
@@ -1217,11 +1311,13 @@ static int __init acpi_parse_madt_ioapic_entries(void)
 	count = acpi_table_parse_madt(ACPI_MADT_TYPE_NMI_SOURCE,
 				      acpi_parse_nmi_src, nr_irqs);
 	if (count < 0) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		printk(KERN_ERR PREFIX "Error parsing NMI SRC entry\n");
 		/* TBD: Cleanup to allow fallback to MPS */
 		return count;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 #else
@@ -1299,6 +1395,7 @@ static void __init acpi_process_madt(void)
  		 * Boot with "acpi=off" to use MPS on such a system.
  		 */
 		if (smp_found_config) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			printk(KERN_WARNING PREFIX
 				"No APIC-table, disabling MPS\n");
 			smp_found_config = 0;
@@ -1312,15 +1409,19 @@ static void __init acpi_process_madt(void)
 	if (acpi_lapic && acpi_ioapic)
 		printk(KERN_INFO "Using ACPI (MADT) for SMP configuration "
 		       "information\n");
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	else if (acpi_lapic)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		printk(KERN_INFO "Using ACPI for processor (LAPIC) "
 		       "configuration information\n");
+}
 #endif
 	return;
 }
 
 static int __init disable_acpi_irq(const struct dmi_system_id *d)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!acpi_force) {
 		printk(KERN_NOTICE "%s detected: force use of acpi=noirq\n",
 		       d->ident);
@@ -1331,6 +1432,7 @@ static int __init disable_acpi_irq(const struct dmi_system_id *d)
 
 static int __init disable_acpi_pci(const struct dmi_system_id *d)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!acpi_force) {
 		printk(KERN_NOTICE "%s detected: force use of pci=noacpi\n",
 		       d->ident);
@@ -1341,6 +1443,7 @@ static int __init disable_acpi_pci(const struct dmi_system_id *d)
 
 static int __init dmi_disable_acpi(const struct dmi_system_id *d)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!acpi_force) {
 		printk(KERN_NOTICE "%s detected: acpi off\n", d->ident);
 		disable_acpi();
@@ -1356,6 +1459,7 @@ static int __init dmi_disable_acpi(const struct dmi_system_id *d)
  */
 static int __init dmi_ignore_irq0_timer_override(const struct dmi_system_id *d)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!acpi_skip_timer_override) {
 		pr_notice("%s detected: Ignoring BIOS IRQ0 override\n",
 			d->ident);
@@ -1544,12 +1648,15 @@ void __init acpi_boot_table_init(void)
 	 * If acpi_disabled, bail out
 	 */
 	if (acpi_disabled)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	/*
 	 * Initialize the ACPI boot-time table parser.
 	 */
 	if (acpi_table_init()) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		disable_acpi();
 		return;
 	}
@@ -1560,9 +1667,12 @@ void __init acpi_boot_table_init(void)
 	 * blacklist may disable ACPI entirely
 	 */
 	if (acpi_blacklisted()) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (acpi_force) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			printk(KERN_WARNING PREFIX "acpi=force override\n");
 		} else {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			printk(KERN_WARNING PREFIX "Disabling ACPI support\n");
 			disable_acpi();
 			return;
@@ -1576,7 +1686,9 @@ int __init early_acpi_boot_init(void)
 	 * If acpi_disabled, bail out
 	 */
 	if (acpi_disabled)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 1;
+}
 
 	/*
 	 * Process the Multiple APIC Description Table (MADT), if present
@@ -1600,7 +1712,9 @@ int __init acpi_boot_init(void)
 	 * If acpi_disabled, bail out
 	 */
 	if (acpi_disabled)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 1;
+}
 
 	acpi_table_parse(ACPI_SIG_BOOT, acpi_parse_sbf);
 
@@ -1616,16 +1730,20 @@ int __init acpi_boot_init(void)
 
 	acpi_table_parse(ACPI_SIG_HPET, acpi_parse_hpet);
 	if (IS_ENABLED(CONFIG_ACPI_BGRT))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		acpi_table_parse(ACPI_SIG_BGRT, acpi_parse_bgrt);
+}
 
 	if (!acpi_noirq)
 		x86_init.pci.init = pci_acpi_init;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
 static int __init parse_acpi(char *arg)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!arg)
 		return -EINVAL;
 
@@ -1668,6 +1786,7 @@ early_param("acpi", parse_acpi);
 /* FIXME: Using pci= for an ACPI parameter is a travesty. */
 static int __init parse_pci(char *arg)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (arg && strcmp(arg, "noacpi") == 0)
 		acpi_disable_pci();
 	return 0;
@@ -1691,6 +1810,7 @@ int __init acpi_mps_check(void)
 #ifdef CONFIG_X86_IO_APIC
 static int __init parse_acpi_skip_timer_override(char *arg)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	acpi_skip_timer_override = 1;
 	return 0;
 }
@@ -1698,6 +1818,7 @@ early_param("acpi_skip_timer_override", parse_acpi_skip_timer_override);
 
 static int __init parse_acpi_use_timer_override(char *arg)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	acpi_use_timer_override = 1;
 	return 0;
 }
@@ -1706,6 +1827,7 @@ early_param("acpi_use_timer_override", parse_acpi_use_timer_override);
 
 static int __init setup_acpi_sci(char *s)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!s)
 		return -EINVAL;
 	if (!strcmp(s, "edge"))
@@ -1750,6 +1872,7 @@ int __acpi_release_global_lock(unsigned int *lock)
 
 void __init arch_reserve_mem_area(acpi_physical_address addr, size_t size)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	e820__range_add(addr, size, E820_TYPE_ACPI);
 	e820__update_table_print();
 }
diff --git a/arch/x86/kernel/acpi/cstate.c b/arch/x86/kernel/acpi/cstate.c
index dde437f..60454888 100644
--- a/arch/x86/kernel/acpi/cstate.c
+++ b/arch/x86/kernel/acpi/cstate.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * Copyright (C) 2005 Intel Corporation
  * 	Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
@@ -28,6 +30,7 @@
 void acpi_processor_power_init_bm_check(struct acpi_processor_flags *flags,
 					unsigned int cpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cpuinfo_x86 *c = &cpu_data(cpu);
 
 	flags->bm_check = 0;
@@ -88,6 +91,7 @@ static long acpi_processor_ffh_cstate_probe_cpu(void *_cx)
 	retval = 0;
 	/* If the HW does not support any sub-states in this C-state */
 	if (num_cstate_subtype == 0) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_warn(FW_BUG "ACPI MWAIT C-state 0x%x not supported by HW (0x%x)\n",
 				cx->address, edx_part);
 		retval = -1;
@@ -118,6 +122,7 @@ int acpi_processor_ffh_cstate_probe(unsigned int cpu,
 		struct acpi_processor_cx *cx, struct acpi_power_register *reg)
 {
 	struct cstate_entry *percpu_entry;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cpuinfo_x86 *c = &cpu_data(cpu);
 	long retval;
 
@@ -154,6 +159,7 @@ EXPORT_SYMBOL_GPL(acpi_processor_ffh_cstate_probe);
 
 void __cpuidle acpi_processor_ffh_cstate_enter(struct acpi_processor_cx *cx)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	unsigned int cpu = smp_processor_id();
 	struct cstate_entry *percpu_entry;
 
@@ -177,6 +183,7 @@ static int __init ffh_cstate_init(void)
 
 static void __exit ffh_cstate_exit(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	free_percpu(cpu_cstate_entry);
 	cpu_cstate_entry = NULL;
 }
diff --git a/arch/x86/kernel/alternative.c b/arch/x86/kernel/alternative.c
index b034826a..e44d524 100644
--- a/arch/x86/kernel/alternative.c
+++ b/arch/x86/kernel/alternative.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 #define pr_fmt(fmt) "SMP alternatives: " fmt
 
 #include <linux/module.h>
@@ -32,6 +34,7 @@ static int __initdata_or_module debug_alternative;
 
 static int __init debug_alt(char *str)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	debug_alternative = 1;
 	return 1;
 }
@@ -41,6 +44,7 @@ static int noreplace_smp;
 
 static int __init setup_noreplace_smp(char *str)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	noreplace_smp = 1;
 	return 1;
 }
@@ -210,8 +214,10 @@ void __init arch_init_ideal_nops(void)
 		    boot_cpu_data.x86_model != 0x26 &&
 		    boot_cpu_data.x86_model != 0x27 &&
 		    boot_cpu_data.x86_model < 0x30) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			ideal_nops = k8_nops;
 		} else if (boot_cpu_has(X86_FEATURE_NOPL)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			   ideal_nops = p6_nops;
 		} else {
 #ifdef CONFIG_X86_64
@@ -224,6 +230,7 @@ void __init arch_init_ideal_nops(void)
 
 	case X86_VENDOR_AMD:
 		if (boot_cpu_data.x86 > 0xf) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			ideal_nops = p6_nops;
 			return;
 		}
@@ -250,7 +257,9 @@ static void __init_or_module add_nops(void *insns, unsigned int len)
 	while (len > 0) {
 		unsigned int noplen = len;
 		if (noplen > ASM_NOP_MAX)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			noplen = ASM_NOP_MAX;
+}
 		memcpy(insns, ideal_nops[noplen], noplen);
 		insns += noplen;
 		len -= noplen;
@@ -277,7 +286,9 @@ recompute_jump(struct alt_instr *a, u8 *orig_insn, u8 *repl_insn, u8 *insnbuf)
 	int repl_len;
 
 	if (a->replacementlen != 5)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	o_dspl = *(s32 *)(insnbuf + 1);
 
@@ -337,7 +348,9 @@ static void __init_or_module noinline optimize_nops(struct alt_instr *a, u8 *ins
 
 	for (i = 0; i < a->padlen; i++) {
 		if (instr[i] != 0x90)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return;
+}
 	}
 
 	local_irq_save(flags);
@@ -435,6 +448,7 @@ static void alternatives_smp_lock(const s32 *start, const s32 *end,
 	const s32 *poff;
 
 	mutex_lock(&text_mutex);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (poff = start; poff < end; poff++) {
 		u8 *ptr = (u8 *)poff + *poff;
 
@@ -499,21 +513,25 @@ void __init_or_module alternatives_smp_module_add(struct module *mod,
 		/* Don't bother remembering, we'll never have to undo it. */
 		goto smp_unlock;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	smp = kzalloc(sizeof(*smp), GFP_KERNEL);
 	if (NULL == smp)
 		/* we'll run the (safe but slow) SMP code then ... */
 		goto unlock;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	smp->mod	= mod;
 	smp->name	= name;
 	smp->locks	= locks;
 	smp->locks_end	= locks_end;
 	smp->text	= text;
 	smp->text_end	= text_end;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	DPRINTK("locks %p -> %p, text %p -> %p, name %s\n",
 		smp->locks, smp->locks_end,
 		smp->text, smp->text_end, smp->name);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_add_tail(&smp->next, &smp_alt_modules);
 smp_unlock:
 	alternatives_smp_unlock(locks, locks_end, text, text_end);
@@ -526,6 +544,7 @@ void __init_or_module alternatives_smp_module_del(struct module *mod)
 	struct smp_alt_module *item;
 
 	mutex_lock(&smp_alt);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry(item, &smp_alt_modules, next) {
 		if (mod != item->mod)
 			continue;
@@ -566,6 +585,7 @@ int alternatives_text_reserved(void *start, void *end)
 	u8 *text_start = start;
 	u8 *text_end = end;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry(mod, &smp_alt_modules, next) {
 		if (mod->text > text_end || mod->text_end < text_start)
 			continue;
@@ -666,6 +686,7 @@ void *__init_or_module text_poke_early(void *addr, const void *opcode,
 {
 	unsigned long flags;
 	local_irq_save(flags);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	memcpy(addr, opcode, len);
 	local_irq_restore(flags);
 	/* Could also do a CLFLUSH here to speed up CPU recovery; but
@@ -694,6 +715,7 @@ void *text_poke(void *addr, const void *opcode, size_t len)
 	int i;
 
 	if (!core_kernel_text((unsigned long)addr)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pages[0] = vmalloc_to_page(addr);
 		pages[1] = vmalloc_to_page(addr + PAGE_SIZE);
 	} else {
@@ -706,6 +728,7 @@ void *text_poke(void *addr, const void *opcode, size_t len)
 	set_fixmap(FIX_TEXT_POKE0, page_to_phys(pages[0]));
 	if (pages[1])
 		set_fixmap(FIX_TEXT_POKE1, page_to_phys(pages[1]));
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	vaddr = (char *)fix_to_virt(FIX_TEXT_POKE0);
 	memcpy(&vaddr[(unsigned long)addr & ~PAGE_MASK], opcode, len);
 	clear_fixmap(FIX_TEXT_POKE0);
@@ -744,10 +767,14 @@ int poke_int3_handler(struct pt_regs *regs)
 	smp_rmb();
 
 	if (likely(!bp_patching_in_progress))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	if (user_mode(regs) || regs->ip != (unsigned long)bp_int3_addr)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	/* set up the specified breakpoint handler */
 	regs->ip = (unsigned long) bp_int3_handler;
diff --git a/arch/x86/kernel/amd_nb.c b/arch/x86/kernel/amd_nb.c
index c88e0b1..ea241e2 100644
--- a/arch/x86/kernel/amd_nb.c
+++ b/arch/x86/kernel/amd_nb.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * Shared support code for AMD K8 northbridges and derivates.
  * Copyright 2006 Andi Kleen, SUSE Labs. Subject to GPLv2.
@@ -66,6 +68,7 @@ static struct amd_northbridge_info amd_northbridges;
 
 u16 amd_nb_num(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return amd_northbridges.num;
 }
 EXPORT_SYMBOL_GPL(amd_nb_num);
@@ -78,6 +81,7 @@ EXPORT_SYMBOL_GPL(amd_nb_has_feature);
 
 struct amd_northbridge *node_to_amd_nb(int node)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return (node < amd_northbridges.num) ? &amd_northbridges.nb[node] : NULL;
 }
 EXPORT_SYMBOL_GPL(node_to_amd_nb);
@@ -101,6 +105,7 @@ static int __amd_smn_rw(u16 node, u32 address, u32 *value, bool write)
 	if (node >= amd_northbridges.num)
 		goto out;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	root = node_to_amd_nb(node)->root;
 	if (!root)
 		goto out;
@@ -128,12 +133,14 @@ static int __amd_smn_rw(u16 node, u32 address, u32 *value, bool write)
 
 int amd_smn_read(u16 node, u32 address, u32 *value)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return __amd_smn_rw(node, address, value, false);
 }
 EXPORT_SYMBOL_GPL(amd_smn_read);
 
 int amd_smn_write(u16 node, u32 address, u32 value)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return __amd_smn_rw(node, address, &value, true);
 }
 EXPORT_SYMBOL_GPL(amd_smn_write);
@@ -157,6 +164,7 @@ int amd_df_indirect_read(u16 node, u8 func, u16 reg, u8 instance_id, u32 *lo)
 	if (node >= amd_northbridges.num)
 		goto out;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	F4 = node_to_amd_nb(node)->link;
 	if (!F4)
 		goto out;
@@ -193,23 +201,33 @@ int amd_cache_northbridges(void)
 	struct pci_dev *root, *misc, *link;
 
 	if (amd_northbridges.num)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	misc = NULL;
 	while ((misc = next_northbridge(misc, amd_nb_misc_ids)) != NULL)
 		i++;
 
 	if (!i)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENODEV;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	nb = kcalloc(i, sizeof(struct amd_northbridge), GFP_KERNEL);
 	if (!nb)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	amd_northbridges.nb = nb;
 	amd_northbridges.num = i;
 
 	link = misc = root = NULL;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (i = 0; i != amd_northbridges.num; i++) {
 		node_to_amd_nb(i)->root = root =
 			next_northbridge(root, amd_root_ids);
@@ -219,14 +237,19 @@ int amd_cache_northbridges(void)
 			next_northbridge(link, amd_nb_link_ids);
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (amd_gart_present())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		amd_northbridges.flags |= AMD_NB_GART;
+}
 
 	/*
 	 * Check for L3 cache presence.
 	 */
 	if (!cpuid_edx(0x80000006))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	/*
 	 * Some CPU families support L3 Cache Index Disable. There are some
@@ -238,13 +261,19 @@ int amd_cache_northbridges(void)
 	     boot_cpu_data.x86_stepping >= 0x1))
 		amd_northbridges.flags |= AMD_NB_L3_INDEX_DISABLE;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (boot_cpu_data.x86 == 0x15)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		amd_northbridges.flags |= AMD_NB_L3_INDEX_DISABLE;
+}
 
 	/* L3 cache partitioning is supported on family 0x15 */
 	if (boot_cpu_data.x86 == 0x15)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		amd_northbridges.flags |= AMD_NB_L3_PARTITIONING;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 EXPORT_SYMBOL_GPL(amd_cache_northbridges);
@@ -259,6 +288,7 @@ bool __init early_is_amd_nb(u32 device)
 	u32 vendor = device & 0xffff;
 
 	device >>= 16;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (id = amd_nb_misc_ids; id->vendor; id++)
 		if (vendor == id->vendor && device == id->device)
 			return true;
@@ -272,7 +302,9 @@ struct resource *amd_get_mmconfig_range(struct resource *res)
 	unsigned int segn_busn_bits;
 
 	if (boot_cpu_data.x86_vendor != X86_VENDOR_AMD)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 
 	/* assume all cpus from fam10h have mmconfig */
 	if (boot_cpu_data.x86 < 0x10)
@@ -298,6 +330,7 @@ struct resource *amd_get_mmconfig_range(struct resource *res)
 
 int amd_get_subcaches(int cpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct pci_dev *link = node_to_amd_nb(amd_get_nb_id(cpu))->link;
 	unsigned int mask;
 
@@ -316,6 +349,7 @@ int amd_set_subcaches(int cpu, unsigned long mask)
 	unsigned int reg;
 	int cuid;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!amd_nb_has_feature(AMD_NB_L3_PARTITIONING) || mask > 0xf)
 		return -EINVAL;
 
@@ -354,18 +388,25 @@ static void amd_cache_gart(void)
 	u16 i;
 
 	if (!amd_nb_has_feature(AMD_NB_GART))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	flush_words = kmalloc_array(amd_northbridges.num, sizeof(u32), GFP_KERNEL);
 	if (!flush_words) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		amd_northbridges.flags &= ~AMD_NB_GART;
 		pr_notice("Cannot initialize GART flush words, GART support disabled\n");
 		return;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (i = 0; i != amd_northbridges.num; i++)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pci_read_config_dword(node_to_amd_nb(i)->misc, 0x9c, &flush_words[i]);
 }
+}
 
 void amd_flush_garts(void)
 {
@@ -374,7 +415,9 @@ void amd_flush_garts(void)
 	static DEFINE_SPINLOCK(gart_lock);
 
 	if (!amd_nb_has_feature(AMD_NB_GART))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	/*
 	 * Avoid races between AGP and IOMMU. In theory it's not needed
@@ -410,6 +453,7 @@ static void __fix_erratum_688(void *info)
 {
 #define MSR_AMD64_IC_CFG 0xC0011021
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	msr_set_bit(MSR_AMD64_IC_CFG, 3);
 	msr_set_bit(MSR_AMD64_IC_CFG, 14);
 }
@@ -423,19 +467,32 @@ static __init void fix_erratum_688(void)
 	if (boot_cpu_data.x86 != 0x14)
 		return;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!amd_northbridges.num)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	F4 = node_to_amd_nb(0)->link;
 	if (!F4)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (pci_read_config_dword(F4, 0x164, &val))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (val & BIT(2))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	on_each_cpu(__fix_erratum_688, NULL, 0);
 
 	pr_info("x86/cpu/AMD: CPU erratum 688 worked around\n");
diff --git a/arch/x86/kernel/apic/apic.c b/arch/x86/kernel/apic/apic.c
index 5942aa5..d01a8ca 100644
--- a/arch/x86/kernel/apic/apic.c
+++ b/arch/x86/kernel/apic/apic.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  *	Local APIC handling, local APIC timers
  *
@@ -150,6 +152,7 @@ static int force_enable_local_apic __initdata;
  */
 static int __init parse_lapic(char *arg)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (IS_ENABLED(CONFIG_X86_32) && !arg)
 		force_enable_local_apic = 1;
 	else if (arg && !strncmp(arg, "notscdeadline", 13))
@@ -162,6 +165,7 @@ early_param("lapic", parse_lapic);
 static int apic_calibrate_pmtmr __initdata;
 static __init int setup_apicpmtimer(char *s)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	apic_calibrate_pmtmr = 1;
 	notsc_setup(NULL);
 	return 0;
@@ -236,12 +240,14 @@ static int modern_apic(void)
  */
 static void __init apic_disable(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pr_info("APIC: switched to apic NOOP\n");
 	apic = &apic_noop;
 }
 
 void native_apic_wait_icr_idle(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	while (apic_read(APIC_ICR) & APIC_ICR_BUSY)
 		cpu_relax();
 }
@@ -253,6 +259,7 @@ u32 native_safe_apic_wait_icr_idle(void)
 
 	timeout = 0;
 	do {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		send_status = apic_read(APIC_ICR) & APIC_ICR_BUSY;
 		if (!send_status)
 			break;
@@ -267,6 +274,7 @@ void native_apic_icr_write(u32 low, u32 id)
 {
 	unsigned long flags;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	local_irq_save(flags);
 	apic_write(APIC_ICR2, SET_APIC_DEST_FIELD(id));
 	apic_write(APIC_ICR, low);
@@ -332,12 +340,19 @@ static void __setup_APIC_LVTT(unsigned int clocks, int oneshot, int irqen)
 
 	lvtt_value = LOCAL_TIMER_VECTOR;
 	if (!oneshot)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		lvtt_value |= APIC_LVT_TIMER_PERIODIC;
+}
 	else if (boot_cpu_has(X86_FEATURE_TSC_DEADLINE_TIMER))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		lvtt_value |= APIC_LVT_TIMER_TSCDEADLINE;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!lapic_is_integrated())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		lvtt_value |= SET_APIC_TIMER_BASE(APIC_TIMER_BASE_DIV);
+}
 
 	if (!irqen)
 		lvtt_value |= APIC_LVT_MASKED;
@@ -352,6 +367,7 @@ static void __setup_APIC_LVTT(unsigned int clocks, int oneshot, int irqen)
 		 */
 		asm volatile("mfence" : : : "memory");
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		printk_once(KERN_DEBUG "TSC deadline timer enabled\n");
 		return;
 	}
@@ -392,6 +408,7 @@ static atomic_t eilvt_offsets[APIC_EILVT_NR_MAX];
 
 static inline int eilvt_entry_is_changeable(unsigned int old, unsigned int new)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return (old & APIC_EILVT_MASKED)
 		|| (new == APIC_EILVT_MASKED)
 		|| ((new & ~APIC_EILVT_MASKED) == old);
@@ -402,7 +419,9 @@ static unsigned int reserve_eilvt_offset(int offset, unsigned int new)
 	unsigned int rsvd, vector;
 
 	if (offset >= APIC_EILVT_NR_MAX)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ~0;
+}
 
 	rsvd = atomic_read(&eilvt_offsets[offset]);
 	do {
@@ -437,6 +456,7 @@ int setup_APIC_eilvt(u8 offset, u8 vector, u8 msg_type, u8 mask)
 	reserved = reserve_eilvt_offset(offset, new);
 
 	if (reserved != new) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_err(FW_BUG "cpu %d, try to use APIC%lX (LVT offset %d) for "
 		       "vector 0x%x, but the register is already in use for "
 		       "vector 0x%x on another cpu\n",
@@ -484,7 +504,9 @@ static int lapic_timer_shutdown(struct clock_event_device *evt)
 
 	/* Lapic used as dummy for broadcast ? */
 	if (evt->features & CLOCK_EVT_FEAT_DUMMY)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	v = apic_read(APIC_LVTT);
 	v |= (APIC_LVT_MASKED | LOCAL_TIMER_VECTOR);
@@ -498,7 +520,9 @@ lapic_timer_set_periodic_oneshot(struct clock_event_device *evt, bool oneshot)
 {
 	/* Lapic used as dummy for broadcast ? */
 	if (evt->features & CLOCK_EVT_FEAT_DUMMY)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	__setup_APIC_LVTT(lapic_timer_frequency, oneshot, 1);
 	return 0;
@@ -553,6 +577,7 @@ static DEFINE_PER_CPU(struct clock_event_device, lapic_events);
 
 static u32 hsx_deadline_rev(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	switch (boot_cpu_data.x86_stepping) {
 	case 0x02: return 0x3a; /* EP */
 	case 0x04: return 0x0f; /* EX */
@@ -563,6 +588,7 @@ static u32 hsx_deadline_rev(void)
 
 static u32 bdx_deadline_rev(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	switch (boot_cpu_data.x86_stepping) {
 	case 0x02: return 0x00000011;
 	case 0x03: return 0x0700000e;
@@ -575,6 +601,7 @@ static u32 bdx_deadline_rev(void)
 
 static u32 skx_deadline_rev(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	switch (boot_cpu_data.x86_stepping) {
 	case 0x03: return 0x01000136;
 	case 0x04: return 0x02000014;
@@ -614,22 +641,31 @@ static void apic_check_deadline_errata(void)
 	    boot_cpu_has(X86_FEATURE_HYPERVISOR))
 		return;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	m = x86_match_cpu(deadline_match);
 	if (!m)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	/*
 	 * Function pointers will have the MSB set due to address layout,
 	 * immediate revisions will not.
 	 */
 	if ((long)m->driver_data < 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		rev = ((u32 (*)(void))(m->driver_data))();
+}
 	else
 		rev = (u32)m->driver_data;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (boot_cpu_data.microcode >= rev)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	setup_clear_cpu_cap(X86_FEATURE_TSC_DEADLINE_TIMER);
 	pr_err(FW_BUG "TSC_DEADLINE disabled due to Errata; "
 	       "please update microcode to version: 0x%x (or later)\n", rev);
@@ -644,15 +680,18 @@ static void setup_APIC_timer(void)
 	struct clock_event_device *levt = this_cpu_ptr(&lapic_events);
 
 	if (this_cpu_has(X86_FEATURE_ARAT)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		lapic_clockevent.features &= ~CLOCK_EVT_FEAT_C3STOP;
 		/* Make LAPIC timer preferrable over percpu HPET */
 		lapic_clockevent.rating = 150;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	memcpy(levt, &lapic_clockevent, sizeof(*levt));
 	levt->cpumask = cpumask_of(smp_processor_id());
 
 	if (this_cpu_has(X86_FEATURE_TSC_DEADLINE_TIMER)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		levt->name = "lapic-deadline";
 		levt->features &= ~(CLOCK_EVT_FEAT_PERIODIC |
 				    CLOCK_EVT_FEAT_DUMMY);
@@ -673,8 +712,11 @@ static void __lapic_update_tsc_freq(void *info)
 	struct clock_event_device *levt = this_cpu_ptr(&lapic_events);
 
 	if (!this_cpu_has(X86_FEATURE_TSC_DEADLINE_TIMER))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	clockevents_update_freq(levt, tsc_khz * (1000 / TSC_DIVISOR));
 }
 
@@ -727,7 +769,9 @@ static void __init lapic_cal_handler(struct clock_event_device *dev)
 	unsigned long pm = acpi_pm_read_early();
 
 	if (boot_cpu_has(X86_FEATURE_TSC))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		tsc = rdtsc();
+}
 
 	switch (lapic_cal_loops++) {
 	case 0:
@@ -764,16 +808,21 @@ calibrate_by_pmtimer(long deltapm, long *delta, long *deltatsc)
 
 	/* Check, if the PM timer is available */
 	if (!deltapm)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -1;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	mult = clocksource_hz2mult(PMTMR_TICKS_PER_SEC, 22);
 
 	if (deltapm > (pm_100ms - pm_thresh) &&
 	    deltapm < (pm_100ms + pm_thresh)) {
 		apic_printk(APIC_VERBOSE, "... PM-Timer result ok\n");
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	res = (((u64)deltapm) *  mult) >> 22;
 	do_div(res, 1000000);
 	pr_warning("APIC calibration not consistent "
@@ -788,14 +837,18 @@ calibrate_by_pmtimer(long deltapm, long *delta, long *deltatsc)
 
 	/* Correct the tsc counter value */
 	if (boot_cpu_has(X86_FEATURE_TSC)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		res = (((u64)(*deltatsc)) * pm_100ms);
 		do_div(res, deltapm);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		apic_printk(APIC_VERBOSE, "TSC delta adjusted to "
 					  "PM-Timer: %lu (%ld)\n",
 					(unsigned long)res, *deltatsc);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		*deltatsc = (long)res;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
@@ -814,10 +867,13 @@ static int __init calibrate_APIC_clock(void)
 	 */
 
 	if (boot_cpu_has(X86_FEATURE_TSC_DEADLINE_TIMER)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
 	} else if (lapic_timer_frequency) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		apic_printk(APIC_VERBOSE, "lapic timer already calibrated %d\n",
 				lapic_timer_frequency);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		lapic_clockevent.mult = div_sc(lapic_timer_frequency/APIC_DIVISOR,
 					TICK_NSEC, lapic_clockevent.shift);
 		lapic_clockevent.max_delta_ns =
@@ -899,7 +955,9 @@ static int __init calibrate_APIC_clock(void)
 	 * Do a sanity check on the APIC calibration result
 	 */
 	if (lapic_timer_frequency < (1000000 / HZ)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		local_irq_enable();
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_warning("APIC frequency too slow, disabling apic timer\n");
 		return -1;
 	}
@@ -911,6 +969,7 @@ static int __init calibrate_APIC_clock(void)
 	 * so lets try APIC timer based calibration
 	 */
 	if (!pm_referenced) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		apic_printk(APIC_VERBOSE, "... verify APIC timer\n");
 
 		/*
@@ -923,30 +982,37 @@ static int __init calibrate_APIC_clock(void)
 		/* Let the interrupts run */
 		local_irq_enable();
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		while (lapic_cal_loops <= LAPIC_CAL_LOOPS)
 			cpu_relax();
 
 		/* Stop the lapic timer */
 		local_irq_disable();
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		lapic_timer_shutdown(levt);
 
 		/* Jiffies delta */
 		deltaj = lapic_cal_j2 - lapic_cal_j1;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		apic_printk(APIC_VERBOSE, "... jiffies delta = %lu\n", deltaj);
 
 		/* Check, if the jiffies result is consistent */
 		if (deltaj >= LAPIC_CAL_LOOPS-2 && deltaj <= LAPIC_CAL_LOOPS+2)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			apic_printk(APIC_VERBOSE, "... jiffies result ok\n");
+}
 		else
 			levt->features |= CLOCK_EVT_FEAT_DUMMY;
 	}
 	local_irq_enable();
 
 	if (levt->features & CLOCK_EVT_FEAT_DUMMY) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_warning("APIC timer disabled due to verification failure\n");
 			return -1;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
@@ -964,19 +1030,25 @@ void __init setup_boot_APIC_clock(void)
 	 * broadcast mechanism is used. On UP systems simply ignore it.
 	 */
 	if (disable_apic_timer) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_info("Disabling APIC timer\n");
 		/* No broadcast on UP ! */
 		if (num_possible_cpus() > 1) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			lapic_clockevent.mult = 1;
 			setup_APIC_timer();
 		}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
 	}
 
 	if (calibrate_APIC_clock()) {
 		/* No broadcast on UP ! */
 		if (num_possible_cpus() > 1)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			setup_APIC_timer();
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
 	}
 
@@ -994,6 +1066,7 @@ void __init setup_boot_APIC_clock(void)
 
 void setup_secondary_APIC_clock(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	setup_APIC_timer();
 	amd_e400_c1e_apic_setup();
 }
@@ -1017,6 +1090,7 @@ static void local_apic_timer_interrupt(void)
 	 * spurious.
 	 */
 	if (!evt->event_handler) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_warning("Spurious LAPIC timer interrupt on cpu %d\n",
 			   smp_processor_id());
 		/* Switch it off */
@@ -1042,6 +1116,7 @@ static void local_apic_timer_interrupt(void)
  */
 __visible void __irq_entry smp_apic_timer_interrupt(struct pt_regs *regs)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct pt_regs *old_regs = set_irq_regs(regs);
 
 	/*
@@ -1063,6 +1138,7 @@ __visible void __irq_entry smp_apic_timer_interrupt(struct pt_regs *regs)
 
 int setup_profiling_timer(unsigned int multiplier)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return -EINVAL;
 }
 
@@ -1191,6 +1267,7 @@ void lapic_shutdown(void)
 {
 	unsigned long flags;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!boot_cpu_has(X86_FEATURE_APIC) && !apic_from_smp_config())
 		return;
 
@@ -1217,14 +1294,18 @@ void __init sync_Arb_IDs(void)
 	 * needed on AMD.
 	 */
 	if (modern_apic() || boot_cpu_data.x86_vendor == X86_VENDOR_AMD)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	/*
 	 * Wait for idle.
 	 */
 	apic_wait_icr_idle();
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	apic_printk(APIC_DEBUG, "Synchronizing Arb IDs.\n");
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	apic_write(APIC_ICR, APIC_DEST_ALLINC |
 			APIC_INT_LEVELTRIG | APIC_DM_INIT);
 }
@@ -1241,7 +1322,9 @@ void __init init_bsp_APIC(void)
 	 * through-I/O-APIC virtual wire mode might be active.
 	 */
 	if (smp_found_config || !boot_cpu_has(X86_FEATURE_APIC))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	/*
 	 * Do not trust the local APIC being empty at bootup.
@@ -1272,9 +1355,15 @@ void __init init_bsp_APIC(void)
 	apic_write(APIC_LVT0, APIC_DM_EXTINT);
 	value = APIC_DM_NMI;
 	if (!lapic_is_integrated())		/* 82489DX */
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		value |= APIC_LVT_LEVEL_TRIGGER;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (apic_extnmi == APIC_EXTNMI_NONE)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		value |= APIC_LVT_MASKED;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	apic_write(APIC_LVT1, value);
 }
 
@@ -1283,6 +1372,7 @@ static void lapic_setup_esr(void)
 	unsigned int oldvalue, value, maxlvt;
 
 	if (!lapic_is_integrated()) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_info("No ESR for 82489DX.\n");
 		return;
 	}
@@ -1314,10 +1404,12 @@ static void lapic_setup_esr(void)
 		apic_write(APIC_ESR, 0);
 	value = apic_read(APIC_ESR);
 	if (value != oldvalue)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		apic_printk(APIC_VERBOSE, "ESR value before enabling "
 			"vector: 0x%08x  after: 0x%08x\n",
 			oldvalue, value);
 }
+}
 
 /**
  * setup_local_APIC - setup the local APIC
@@ -1334,9 +1426,12 @@ void setup_local_APIC(void)
 	long long max_loops = cpu_khz ? cpu_khz : 1000000;
 
 	if (boot_cpu_has(X86_FEATURE_TSC))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		tsc = rdtsc();
+}
 
 	if (disable_apic) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		disable_ioapic_support();
 		return;
 	}
@@ -1398,6 +1493,7 @@ void setup_local_APIC(void)
 	 * for timer irq (vector 0x31). Issue an extra EOI to clear ISR.
 	 */
 	do {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		queued = 0;
 		for (i = APIC_ISR_NR - 1; i >= 0; i--)
 			queued |= apic_read(APIC_IRR + i*0x10);
@@ -1406,22 +1502,28 @@ void setup_local_APIC(void)
 			value = apic_read(APIC_ISR + i*0x10);
 			for (j = 31; j >= 0; j--) {
 				if (value & (1<<j)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 					ack_APIC_irq();
 					acked++;
 				}
 			}
 		}
 		if (acked > 256) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			printk(KERN_ERR "LAPIC pending interrupts after %d EOI\n",
 			       acked);
 			break;
 		}
 		if (queued) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			if (boot_cpu_has(X86_FEATURE_TSC) && cpu_khz) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				ntsc = rdtsc();
 				max_loops = (cpu_khz << 10) - (ntsc - tsc);
 			} else
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				max_loops--;
+}
 		}
 	} while (queued && max_loops > 0);
 	WARN_ON(max_loops <= 0);
@@ -1482,10 +1584,13 @@ void setup_local_APIC(void)
 	 */
 	value = apic_read(APIC_LVT0) & APIC_LVT_MASKED;
 	if (!cpu && (pic_mode || !value)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		value = APIC_DM_EXTINT;
 		apic_printk(APIC_VERBOSE, "enabled ExtINT on CPU#%d\n", cpu);
 	} else {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		value = APIC_DM_EXTINT | APIC_LVT_MASKED;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		apic_printk(APIC_VERBOSE, "masked ExtINT on CPU#%d\n", cpu);
 	}
 	apic_write(APIC_LVT0, value);
@@ -1499,14 +1604,19 @@ void setup_local_APIC(void)
 		value = APIC_DM_NMI;
 	else
 		value = APIC_DM_NMI | APIC_LVT_MASKED;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!lapic_is_integrated())		/* 82489DX */
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		value |= APIC_LVT_LEVEL_TRIGGER;
+}
 	apic_write(APIC_LVT1, value);
 
 #ifdef CONFIG_X86_MCE_INTEL
 	/* Recheck CMCI information after local APIC is up on CPU #0 */
 	if (!cpu)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		cmci_recheck();
+}
 #endif
 }
 
@@ -1532,6 +1642,7 @@ static void end_local_APIC_setup(void)
  */
 void apic_ap_setup(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	setup_local_APIC();
 	end_local_APIC_setup();
 }
@@ -1673,6 +1784,7 @@ void __init check_x2apic(void)
 #else /* CONFIG_X86_X2APIC */
 static int __init validate_x2apic(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!apic_is_x2apic_enabled())
 		return 0;
 	/*
@@ -1692,33 +1804,47 @@ void __init enable_IR_x2apic(void)
 	int ret, ir_stat;
 
 	if (skip_ioapic_setup) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_info("Not enabling interrupt remapping due to skipped IO-APIC setup\n");
 		return;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	ir_stat = irq_remapping_prepare();
 	if (ir_stat < 0 && !x2apic_supported())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	ret = save_ioapic_entries();
 	if (ret) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_info("Saving IO-APIC state failed: %d\n", ret);
 		return;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	local_irq_save(flags);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	legacy_pic->mask_all();
 	mask_ioapic_entries();
 
 	/* If irq_remapping_prepare() succeeded, try to enable it */
 	if (ir_stat >= 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ir_stat = irq_remapping_enable();
+}
 	/* ir_stat contains the remap mode or an error code */
 	try_to_enable_x2apic(ir_stat);
 
 	if (ir_stat < 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		restore_ioapic_entries();
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	legacy_pic->restore_mask();
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	local_irq_restore(flags);
 }
 
@@ -1731,6 +1857,7 @@ void __init enable_IR_x2apic(void)
  */
 static int __init detect_init_APIC(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!boot_cpu_has(X86_FEATURE_APIC)) {
 		pr_info("No local APIC present\n");
 		return -1;
@@ -1854,6 +1981,7 @@ void __init init_apic_mappings(void)
 	apic_check_deadline_errata();
 
 	if (x2apic_mode) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		boot_cpu_physical_apicid = read_apic_id();
 		return;
 	}
@@ -1871,7 +1999,9 @@ void __init init_apic_mappings(void)
 		 * address is already registered.
 		 */
 		if (!acpi_lapic && !smp_found_config)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			register_lapic_address(apic_phys);
+}
 	}
 
 	/*
@@ -1880,6 +2010,7 @@ void __init init_apic_mappings(void)
 	 */
 	new_apicid = read_apic_id();
 	if (boot_cpu_physical_apicid != new_apicid) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		boot_cpu_physical_apicid = new_apicid;
 		/*
 		 * yeah -- we lie about apic_version
@@ -1929,7 +2060,9 @@ __visible void __irq_entry smp_spurious_interrupt(struct pt_regs *regs)
 	 */
 	v = apic_read(APIC_ISR + ((vector & ~0x1f) >> 1));
 	if (v & (1 << (vector & 0x1f)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ack_APIC_irq();
+}
 
 	inc_irq_stat(irq_spurious_count);
 
@@ -1963,7 +2096,9 @@ __visible void __irq_entry smp_error_interrupt(struct pt_regs *regs)
 
 	/* First tickle the hardware, only then report what went on. -- REW */
 	if (lapic_get_maxlvt() > 3)	/* Due to the Pentium erratum 3AP. */
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		apic_write(APIC_ESR, 0);
+}
 	v = apic_read(APIC_ESR);
 	ack_APIC_irq();
 	atomic_inc(&irq_err_count);
@@ -2197,8 +2332,10 @@ int generic_processor_info(int apicid, int version)
 		/* Logical cpuid 0 is reserved for BSP. */
 		cpuid_to_apicid[0] = apicid;
 	} else {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		cpu = allocate_logical_cpuid(apicid);
 		if (cpu < 0) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			disabled_cpus++;
 			return -EINVAL;
 		}
@@ -2208,18 +2345,22 @@ int generic_processor_info(int apicid, int version)
 	 * Validate version
 	 */
 	if (version == 0x0) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_warning("BIOS bug: APIC version is 0 for CPU %d/0x%x, fixing up to 0x10\n",
 			   cpu, apicid);
 		version = 0x10;
 	}
 
 	if (version != boot_cpu_apic_version) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_warning("BIOS bug: APIC version mismatch, boot CPU: %x, CPU %d: version %x\n",
 			boot_cpu_apic_version, cpu, version);
 	}
 
 	if (apicid > max_physical_apicid)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		max_physical_apicid = apicid;
+}
 
 #if defined(CONFIG_SMP) || defined(CONFIG_X86_64)
 	early_per_cpu(x86_cpu_to_apicid, cpu) = apicid;
@@ -2248,6 +2389,7 @@ void default_init_apic_ldr(void)
 
 	apic_write(APIC_DFR, APIC_DFR_VALUE);
 	val = apic_read(APIC_LDR) & ~APIC_LDR_MASK;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	val |= SET_APIC_LOGICAL_ID(1UL << smp_processor_id());
 	apic_write(APIC_LDR, val);
 }
@@ -2256,6 +2398,7 @@ int default_cpu_mask_to_apicid(const struct cpumask *mask,
 			       struct irq_data *irqdata,
 			       unsigned int *apicid)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	unsigned int cpu = cpumask_first(mask);
 
 	if (cpu >= nr_cpu_ids)
@@ -2270,11 +2413,14 @@ int flat_cpu_mask_to_apicid(const struct cpumask *mask,
 			    unsigned int *apicid)
 
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cpumask *effmsk = irq_data_get_effective_affinity_mask(irqdata);
 	unsigned long cpu_mask = cpumask_bits(mask)[0] & APIC_ALL_CPUS;
 
 	if (!cpu_mask)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 	*apicid = (unsigned int)cpu_mask;
 	cpumask_bits(effmsk)[0] = cpu_mask;
 	return 0;
@@ -2290,6 +2436,7 @@ void __init apic_set_eoi_write(void (*eoi_write)(u32 reg, u32 v))
 {
 	struct apic **drv;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (drv = __apicdrivers; drv < __apicdrivers_end; drv++) {
 		/* Should happen once for each apic */
 		WARN_ON((*drv)->eoi_write == eoi_write);
@@ -2328,11 +2475,15 @@ int __init apic_bsp_setup(bool upmode)
 
 	connect_bsp_APIC();
 	if (upmode)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		apic_bsp_up_setup();
+}
 	setup_local_APIC();
 
 	if (x2apic_mode)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		id = apic_read(APIC_LDR);
+}
 	else
 		id = GET_APIC_LOGICAL_ID(apic_read(APIC_LDR));
 
@@ -2351,6 +2502,7 @@ int __init apic_bsp_setup(bool upmode)
  */
 int __init APIC_init_uniprocessor(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (disable_apic) {
 		pr_info("Apic disabled\n");
 		return -1;
@@ -2571,6 +2723,7 @@ static int multi;
 
 static int set_multi(const struct dmi_system_id *d)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (multi)
 		return 0;
 	pr_info("APIC: %s detected, Multi Chassis\n", d->ident);
@@ -2593,7 +2746,9 @@ static const struct dmi_system_id multi_dmi_table[] = {
 static void dmi_check_multi(void)
 {
 	if (multi_checked)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	dmi_check_system(multi_dmi_table);
 	multi_checked = 1;
@@ -2619,6 +2774,7 @@ int apic_is_clustered_box(void)
  */
 static int __init setup_disableapic(char *arg)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	disable_apic = 1;
 	setup_clear_cpu_cap(X86_FEATURE_APIC);
 	return 0;
@@ -2628,12 +2784,14 @@ early_param("disableapic", setup_disableapic);
 /* same as disableapic, for compatibility */
 static int __init setup_nolapic(char *arg)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return setup_disableapic(arg);
 }
 early_param("nolapic", setup_nolapic);
 
 static int __init parse_lapic_timer_c2_ok(char *arg)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	local_apic_timer_c2_ok = 1;
 	return 0;
 }
@@ -2641,6 +2799,7 @@ early_param("lapic_timer_c2_ok", parse_lapic_timer_c2_ok);
 
 static int __init parse_disable_apic_timer(char *arg)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	disable_apic_timer = 1;
 	return 0;
 }
@@ -2648,6 +2807,7 @@ early_param("noapictimer", parse_disable_apic_timer);
 
 static int __init parse_nolapic_timer(char *arg)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	disable_apic_timer = 1;
 	return 0;
 }
@@ -2655,6 +2815,7 @@ early_param("nolapic_timer", parse_nolapic_timer);
 
 static int __init apic_set_verbosity(char *arg)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!arg)  {
 #ifdef CONFIG_X86_64
 		skip_ioapic_setup = 0;
@@ -2680,7 +2841,9 @@ early_param("apic", apic_set_verbosity);
 static int __init lapic_insert_resource(void)
 {
 	if (!apic_phys)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -1;
+}
 
 	/* Put local APIC into the resource map. */
 	lapic_resource.start = apic_phys;
@@ -2698,6 +2861,7 @@ late_initcall(lapic_insert_resource);
 
 static int __init apic_set_disabled_cpu_apicid(char *arg)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!arg || !get_option(&arg, &disabled_cpu_apicid))
 		return -EINVAL;
 
@@ -2707,6 +2871,7 @@ early_param("disable_cpu_apicid", apic_set_disabled_cpu_apicid);
 
 static int __init apic_set_extnmi(char *arg)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!arg)
 		return -EINVAL;
 
diff --git a/arch/x86/kernel/apic/apic_flat_64.c b/arch/x86/kernel/apic/apic_flat_64.c
index dedd5a4..fb72a42 100644
--- a/arch/x86/kernel/apic/apic_flat_64.c
+++ b/arch/x86/kernel/apic/apic_flat_64.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * Copyright 2004 James Cleverdon, IBM.
  * Subject to the GNU Public License, v.2
@@ -73,6 +75,7 @@ static void
 flat_send_IPI_mask_allbutself(const struct cpumask *cpumask, int vector)
 {
 	unsigned long mask = cpumask_bits(cpumask)[0];
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	int cpu = smp_processor_id();
 
 	if (cpu < BITS_PER_LONG)
@@ -83,6 +86,7 @@ flat_send_IPI_mask_allbutself(const struct cpumask *cpumask, int vector)
 
 static void flat_send_IPI_allbutself(int vector)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	int cpu = smp_processor_id();
 #ifdef	CONFIG_HOTPLUG_CPU
 	int hotplug = 1;
@@ -106,6 +110,7 @@ static void flat_send_IPI_allbutself(int vector)
 
 static void flat_send_IPI_all(int vector)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (vector == NMI_VECTOR) {
 		flat_send_IPI_mask(cpu_online_mask, vector);
 	} else {
@@ -121,6 +126,7 @@ static unsigned int flat_get_apic_id(unsigned long x)
 
 static unsigned long set_apic_id(unsigned int id)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return (id & 0xFF) << 24;
 }
 
@@ -207,34 +213,42 @@ static int physflat_acpi_madt_oem_check(char *oem_id, char *oem_table_id)
 	 */
 	if (acpi_gbl_FADT.header.revision >= FADT2_REVISION_ID &&
 		(acpi_gbl_FADT.flags & ACPI_FADT_APIC_PHYSICAL)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		printk(KERN_DEBUG "system APIC only can use physical flat");
 		return 1;
 	}
 
 	if (!strncmp(oem_id, "IBM", 3) && !strncmp(oem_table_id, "EXA", 3)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		printk(KERN_DEBUG "IBM Summit detected, will use apic physical");
 		return 1;
 	}
 #endif
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
 static void physflat_send_IPI_allbutself(int vector)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	default_send_IPI_mask_allbutself_phys(cpu_online_mask, vector);
 }
 
 static void physflat_send_IPI_all(int vector)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	default_send_IPI_mask_sequence_phys(cpu_online_mask, vector);
 }
 
 static int physflat_probe(void)
 {
 	if (apic == &apic_physflat || num_possible_cpus() > 8)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 1;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
diff --git a/arch/x86/kernel/apic/htirq.c b/arch/x86/kernel/apic/htirq.c
index 56ccf93..3b9b3a3 100644
--- a/arch/x86/kernel/apic/htirq.c
+++ b/arch/x86/kernel/apic/htirq.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * Support Hypertransport IRQ
  *
@@ -47,6 +49,7 @@ ht_set_affinity(struct irq_data *data, const struct cpumask *mask, bool force)
 		write_ht_irq_msg(data->irq, &msg);
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return ret;
 }
 
@@ -69,6 +72,7 @@ static int htirq_domain_alloc(struct irq_domain *domain, unsigned int virq,
 	irq_hw_number_t hwirq;
 	int ret;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (nr_irqs > 1 || !info)
 		return -EINVAL;
 
@@ -105,6 +109,7 @@ static int htirq_domain_alloc(struct irq_domain *domain, unsigned int virq,
 static void htirq_domain_free(struct irq_domain *domain, unsigned int virq,
 			      unsigned int nr_irqs)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct irq_data *irq_data = irq_domain_get_irq_data(domain, virq);
 
 	BUG_ON(nr_irqs != 1);
@@ -155,7 +160,9 @@ void __init arch_init_htirq_domain(struct irq_domain *parent)
 	struct fwnode_handle *fn;
 
 	if (disable_apic)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	fn = irq_domain_alloc_named_fwnode("PCI-HT");
 	if (!fn)
@@ -179,7 +186,9 @@ int arch_setup_ht_irq(int idx, int pos, struct pci_dev *dev,
 	struct irq_alloc_info info;
 
 	if (!htirq_domain)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOSYS;
+}
 
 	init_irq_alloc_info(&info, NULL);
 	info.ht_idx = idx;
@@ -193,5 +202,6 @@ int arch_setup_ht_irq(int idx, int pos, struct pci_dev *dev,
 
 void arch_teardown_ht_irq(unsigned int irq)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	irq_domain_free_irqs(irq, 1);
 }
diff --git a/arch/x86/kernel/apic/hw_nmi.c b/arch/x86/kernel/apic/hw_nmi.c
index d1fc62a..71dc195 100644
--- a/arch/x86/kernel/apic/hw_nmi.c
+++ b/arch/x86/kernel/apic/hw_nmi.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 /*
  *  HW NMI watchdog support
@@ -30,17 +32,20 @@ u64 hw_nmi_get_sample_period(int watchdog_thresh)
 #ifdef arch_trigger_cpumask_backtrace
 static void nmi_raise_cpu_backtrace(cpumask_t *mask)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	apic->send_IPI_mask(mask, NMI_VECTOR);
 }
 
 void arch_trigger_cpumask_backtrace(const cpumask_t *mask, bool exclude_self)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	nmi_trigger_cpumask_backtrace(mask, exclude_self,
 				      nmi_raise_cpu_backtrace);
 }
 
 static int nmi_cpu_backtrace_handler(unsigned int cmd, struct pt_regs *regs)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (nmi_cpu_backtrace(regs))
 		return NMI_HANDLED;
 
diff --git a/arch/x86/kernel/apic/io_apic.c b/arch/x86/kernel/apic/io_apic.c
index 3b89b27..b526baf 100644
--- a/arch/x86/kernel/apic/io_apic.c
+++ b/arch/x86/kernel/apic/io_apic.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 /*
  *	Intel IO-APIC support for multi-Pentium hosts.
@@ -277,6 +279,7 @@ static __attribute_const__ struct io_apic __iomem *io_apic_base(int idx)
 
 static inline void io_apic_eoi(unsigned int apic, unsigned int vector)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct io_apic __iomem *io_apic = io_apic_base(apic);
 	writel(vector, &io_apic->eoi);
 }
@@ -343,6 +346,7 @@ static void ioapic_write_entry(int apic, int pin, struct IO_APIC_route_entry e)
 {
 	unsigned long flags;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	raw_spin_lock_irqsave(&ioapic_lock, flags);
 	__ioapic_write_entry(apic, pin, e);
 	raw_spin_unlock_irqrestore(&ioapic_lock, flags);
@@ -377,10 +381,13 @@ static int __add_pin_to_irq_node(struct mp_chip_data *data,
 	/* don't allow duplicates */
 	for_each_irq_pin(entry, data->irq_2_pin)
 		if (entry->apic == apic && entry->pin == pin)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return 0;
+}
 
 	entry = kzalloc_node(sizeof(struct irq_pin_list), GFP_ATOMIC, node);
 	if (!entry) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_err("can not alloc irq_pin_list (%d,%d,%d)\n",
 		       node, apic, pin);
 		return -ENOMEM;
@@ -396,6 +403,7 @@ static void __remove_pin_from_irq(struct mp_chip_data *data, int apic, int pin)
 {
 	struct irq_pin_list *tmp, *entry;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry_safe(entry, tmp, &data->irq_2_pin, list)
 		if (entry->apic == apic && entry->pin == pin) {
 			list_del(&entry->list);
@@ -408,8 +416,10 @@ static void add_pin_to_irq_node(struct mp_chip_data *data,
 				int node, int apic, int pin)
 {
 	if (__add_pin_to_irq_node(data, node, apic, pin))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		panic("IO-APIC: failed to add irq-pin. Can not proceed\n");
 }
+}
 
 /*
  * Reroute an IRQ to a different pin.
@@ -420,6 +430,7 @@ static void __init replace_pin_at_irq_node(struct mp_chip_data *data, int node,
 {
 	struct irq_pin_list *entry;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for_each_irq_pin(entry, data->irq_2_pin) {
 		if (entry->apic == oldapic && entry->pin == oldpin) {
 			entry->apic = newapic;
@@ -507,6 +518,7 @@ static void unmask_ioapic_irq(struct irq_data *irq_data)
  */
 static void __eoi_ioapic_pin(int apic, int pin, int vector)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (mpc_ioapic_ver(apic) >= 0x20) {
 		io_apic_eoi(apic, vector);
 	} else {
@@ -534,6 +546,7 @@ static void eoi_ioapic_pin(int vector, struct mp_chip_data *data)
 	unsigned long flags;
 	struct irq_pin_list *entry;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	raw_spin_lock_irqsave(&ioapic_lock, flags);
 	for_each_irq_pin(entry, data->irq_2_pin)
 		__eoi_ioapic_pin(entry->apic, entry->pin, vector);
@@ -547,13 +560,16 @@ static void clear_IO_APIC_pin(unsigned int apic, unsigned int pin)
 	/* Check delivery_mode to be sure we're not clearing an SMI pin */
 	entry = ioapic_read_entry(apic, pin);
 	if (entry.delivery_mode == dest_SMI)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	/*
 	 * Make sure the entry is masked and re-read the contents to check
 	 * if it is a level triggered pin and if the remote-IRR is set.
 	 */
 	if (entry.mask == IOAPIC_UNMASKED) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		entry.mask = IOAPIC_MASKED;
 		ioapic_write_entry(apic, pin, entry);
 		entry = ioapic_read_entry(apic, pin);
@@ -568,11 +584,15 @@ static void clear_IO_APIC_pin(unsigned int apic, unsigned int pin)
 		 * set to level.
 		 */
 		if (entry.trigger == IOAPIC_EDGE) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			entry.trigger = IOAPIC_LEVEL;
 			ioapic_write_entry(apic, pin, entry);
 		}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		raw_spin_lock_irqsave(&ioapic_lock, flags);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		__eoi_ioapic_pin(apic, pin, entry.vector);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		raw_spin_unlock_irqrestore(&ioapic_lock, flags);
 	}
 
@@ -583,9 +603,11 @@ static void clear_IO_APIC_pin(unsigned int apic, unsigned int pin)
 	ioapic_mask_entry(apic, pin);
 	entry = ioapic_read_entry(apic, pin);
 	if (entry.irr)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_err("Unable to reset IRR for apic: %d, pin :%d\n",
 		       mpc_ioapic_id(apic), pin);
 }
+}
 
 static void clear_IO_APIC (void)
 {
@@ -641,6 +663,7 @@ int save_ioapic_entries(void)
 	int apic, pin;
 	int err = 0;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for_each_ioapic(apic) {
 		if (!ioapics[apic].saved_registers) {
 			err = -ENOMEM;
@@ -662,6 +685,7 @@ void mask_ioapic_entries(void)
 {
 	int apic, pin;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for_each_ioapic(apic) {
 		if (!ioapics[apic].saved_registers)
 			continue;
@@ -685,6 +709,7 @@ int restore_ioapic_entries(void)
 {
 	int apic, pin;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for_each_ioapic(apic) {
 		if (!ioapics[apic].saved_registers)
 			continue;
@@ -710,6 +735,7 @@ static int find_irq_entry(int ioapic_idx, int pin, int type)
 		    mp_irqs[i].dstirq == pin)
 			return i;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return -1;
 }
 
@@ -729,6 +755,7 @@ static int __init find_isa_irq_pin(int irq, int type)
 
 			return mp_irqs[i].dstirq;
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return -1;
 }
 
@@ -748,11 +775,15 @@ static int __init find_isa_irq_apic(int irq, int type)
 	if (i < mp_irq_entries) {
 		int ioapic_idx;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		for_each_ioapic(ioapic_idx)
 			if (mpc_ioapic_id(ioapic_idx) == mp_irqs[i].dstapic)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				return ioapic_idx;
+}
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return -1;
 }
 
@@ -804,7 +835,9 @@ static int irq_polarity(int idx)
 	case 0:
 		/* conforms to spec, ie. bus-type dependent polarity */
 		if (test_bit(bus, mp_bus_not_pci))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return default_ISA_polarity(idx);
+}
 		else
 			return default_PCI_polarity(idx);
 	case 1:
@@ -833,6 +866,7 @@ static int eisa_irq_trigger(int idx, int bus, int trigger)
 #else
 static inline int eisa_irq_trigger(int idx, int bus, int trigger)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return trigger;
 }
 #endif
@@ -849,7 +883,9 @@ static int irq_trigger(int idx)
 	case 0:
 		/* conforms to spec, ie. bus-type dependent trigger mode */
 		if (test_bit(bus, mp_bus_not_pci))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			trigger = default_ISA_trigger(idx);
+}
 		else
 			trigger = default_PCI_trigger(idx);
 		/* Take EISA into account */
@@ -943,7 +979,9 @@ static bool mp_check_pin_attr(int irq, struct irq_alloc_info *info)
 	 */
 	if (irq < nr_legacy_irqs() && data->count == 1) {
 		if (info->ioapic_trigger != data->trigger)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			mp_register_handler(irq, info->ioapic_trigger);
+}
 		data->entry.trigger = data->trigger = info->ioapic_trigger;
 		data->entry.polarity = data->polarity = info->ioapic_polarity;
 	}
@@ -1009,7 +1047,9 @@ static int alloc_isa_irq_from_domain(struct irq_domain *domain,
 	 */
 	if (irq_data && irq_data->parent_data) {
 		if (!mp_check_pin_attr(irq, info))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -EBUSY;
+}
 		if (__add_pin_to_irq_node(irq_data->chip_data, node, ioapic,
 					  info->ioapic_pin))
 			return -ENOMEM;
@@ -1023,6 +1063,7 @@ static int alloc_isa_irq_from_domain(struct irq_domain *domain,
 		}
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return irq;
 }
 
@@ -1036,7 +1077,9 @@ static int mp_map_pin_to_irq(u32 gsi, int idx, int ioapic, int pin,
 	struct irq_domain *domain = mp_ioapic_irqdomain(ioapic);
 
 	if (!domain)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOSYS;
+}
 
 	if (idx >= 0 && test_bit(mp_irqs[idx].srcbus, mp_bus_not_pci)) {
 		irq = mp_irqs[idx].srcbusirq;
@@ -1046,9 +1089,12 @@ static int mp_map_pin_to_irq(u32 gsi, int idx, int ioapic, int pin,
 	mutex_lock(&ioapic_mutex);
 	if (!(flags & IOAPIC_MAP_ALLOC)) {
 		if (!legacy) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			irq = irq_find_mapping(domain, pin);
 			if (irq == 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				irq = -ENOENT;
+}
 		}
 	} else {
 		ioapic_copy_alloc_attr(&tmp, info, gsi, ioapic, pin);
@@ -1057,8 +1103,11 @@ static int mp_map_pin_to_irq(u32 gsi, int idx, int ioapic, int pin,
 							ioapic, pin, &tmp);
 		else if ((irq = irq_find_mapping(domain, pin)) == 0)
 			irq = alloc_irq_from_domain(domain, ioapic, gsi, &tmp);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		else if (!mp_check_pin_attr(irq, &tmp))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			irq = -EBUSY;
+}
 		if (irq >= 0) {
 			data = irq_get_chip_data(irq);
 			data->count++;
@@ -1071,13 +1120,16 @@ static int mp_map_pin_to_irq(u32 gsi, int idx, int ioapic, int pin,
 
 static int pin_2_irq(int idx, int ioapic, int pin, unsigned int flags)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	u32 gsi = mp_pin_to_gsi(ioapic, pin);
 
 	/*
 	 * Debugging check, we are in big trouble if this message pops up!
 	 */
 	if (mp_irqs[idx].dstirq != pin)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_err("broken BIOS or MPTABLE parser, ayiee!!\n");
+}
 
 #ifdef CONFIG_X86_32
 	/*
@@ -1108,18 +1160,23 @@ int mp_map_gsi_to_irq(u32 gsi, unsigned int flags, struct irq_alloc_info *info)
 
 	ioapic = mp_find_ioapic(gsi);
 	if (ioapic < 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENODEV;
+}
 
 	pin = mp_find_ioapic_pin(ioapic, gsi);
 	idx = find_irq_entry(ioapic, pin, mp_INT);
 	if ((flags & IOAPIC_MAP_CHECK) && idx < 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENODEV;
+}
 
 	return mp_map_pin_to_irq(gsi, idx, ioapic, pin, flags, info);
 }
 
 void mp_unmap_irq(int irq)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct irq_data *irq_data = irq_get_irq_data(irq);
 	struct mp_chip_data *data;
 
@@ -1144,6 +1201,7 @@ int IO_APIC_get_PCI_irq_vector(int bus, int slot, int pin)
 {
 	int irq, i, best_ioapic = -1, best_idx = -1;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	apic_printk(APIC_DEBUG,
 		    "querying PCI -> IRQ mapping bus:%d, slot:%d, pin:%d.\n",
 		    bus, slot, pin);
@@ -1222,6 +1280,7 @@ static void __init setup_IO_APIC_irqs(void)
 
 void ioapic_zap_locks(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	raw_spin_lock_init(&ioapic_lock);
 }
 
@@ -1233,6 +1292,7 @@ static void io_apic_print_entries(unsigned int apic, unsigned int nr_entries)
 	struct IR_IO_APIC_route_entry *ir_entry = (void *)&entry;
 
 	printk(KERN_DEBUG "IOAPIC %d:\n", apic);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (i = 0; i <= nr_entries; i++) {
 		entry = ioapic_read_entry(apic, i);
 		snprintf(buf, sizeof(buf),
@@ -1263,6 +1323,7 @@ static void __init print_IO_APIC(int ioapic_idx)
 	union IO_APIC_reg_03 reg_03;
 	unsigned long flags;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	raw_spin_lock_irqsave(&ioapic_lock, flags);
 	reg_00.raw = io_apic_read(ioapic_idx, 0);
 	reg_01.raw = io_apic_read(ioapic_idx, 1);
@@ -1317,6 +1378,7 @@ void __init print_IO_APICs(void)
 	unsigned int irq;
 
 	printk(KERN_DEBUG "number of MP IRQ sources: %d.\n", mp_irq_entries);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for_each_ioapic(ioapic_idx)
 		printk(KERN_DEBUG "number of IO-APIC #%d registers: %d.\n",
 		       mpc_ioapic_id(ioapic_idx),
@@ -1364,10 +1426,14 @@ void __init enable_IO_APIC(void)
 	int apic, pin;
 
 	if (skip_ioapic_setup)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		nr_ioapics = 0;
+}
 
 	if (!nr_legacy_irqs() || !nr_ioapics)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	for_each_ioapic_pin(apic, pin) {
 		/* See if any of the pins is in ExtINT mode */
@@ -1377,6 +1443,7 @@ void __init enable_IO_APIC(void)
 		 * I have found the pin where the i8259 is connected.
 		 */
 		if ((entry.mask == 0) && (entry.delivery_mode == dest_ExtINT)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			ioapic_i8259.apic = apic;
 			ioapic_i8259.pin  = pin;
 			goto found_i8259;
@@ -1392,6 +1459,7 @@ void __init enable_IO_APIC(void)
 	i8259_apic = find_isa_irq_apic(0, mp_ExtINT);
 	/* Trust the MP table if nothing is setup in the hardware */
 	if ((ioapic_i8259.pin == -1) && (i8259_pin >= 0)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		printk(KERN_WARNING "ExtINT not setup in hardware but reported by MP table\n");
 		ioapic_i8259.pin  = i8259_pin;
 		ioapic_i8259.apic = i8259_apic;
@@ -1400,6 +1468,7 @@ void __init enable_IO_APIC(void)
 	if (((ioapic_i8259.apic != i8259_apic) || (ioapic_i8259.pin != i8259_pin)) &&
 		(i8259_pin >= 0) && (ioapic_i8259.pin >= 0))
 	{
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		printk(KERN_WARNING "ExtINT in hardware and MP table differ\n");
 	}
 
@@ -1581,6 +1650,7 @@ int no_timer_check __initdata;
 
 static int __init notimercheck(char *s)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	no_timer_check = 1;
 	return 1;
 }
@@ -1600,7 +1670,9 @@ static int __init timer_irq_works(void)
 	unsigned long flags;
 
 	if (no_timer_check)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 1;
+}
 
 	local_save_flags(flags);
 	local_irq_enable();
@@ -1618,7 +1690,10 @@ static int __init timer_irq_works(void)
 
 	/* jiffies wrap? */
 	if (time_after(jiffies, t1 + 4))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 1;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
@@ -1653,7 +1728,9 @@ static unsigned int startup_ioapic_irq(struct irq_data *data)
 	if (irq < nr_legacy_irqs()) {
 		legacy_pic->mask(irq);
 		if (legacy_pic->irq_pending(irq))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			was_pending = 1;
+}
 	}
 	__unmask_ioapic(data->chip_data);
 	raw_spin_unlock_irqrestore(&ioapic_lock, flags);
@@ -1669,6 +1746,7 @@ static bool io_apic_level_ack_pending(struct mp_chip_data *data)
 	struct irq_pin_list *entry;
 	unsigned long flags;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	raw_spin_lock_irqsave(&ioapic_lock, flags);
 	for_each_irq_pin(entry, data->irq_2_pin) {
 		unsigned int reg;
@@ -1691,9 +1769,11 @@ static inline bool ioapic_irqd_mask(struct irq_data *data)
 {
 	/* If we are moving the irq we need to mask it */
 	if (unlikely(irqd_is_setaffinity_pending(data))) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		mask_ioapic_irq(data);
 		return true;
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return false;
 }
 
@@ -1727,7 +1807,10 @@ static inline void ioapic_irqd_unmask(struct irq_data *data, bool masked)
 		 * and you can go talk to the chipset vendor about it.
 		 */
 		if (!io_apic_level_ack_pending(data->chip_data))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			irq_move_masked_irq(data);
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		unmask_ioapic_irq(data);
 	}
 }
@@ -1800,6 +1883,7 @@ static void ioapic_ack_level(struct irq_data *irq_data)
 	 * at the cpu.
 	 */
 	if (!(v & (1 << (i & 0x1f)))) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		atomic_inc(&irq_mis_count);
 		eoi_ioapic_pin(cfg->vector, irq_data->chip_data);
 	}
@@ -1884,7 +1968,9 @@ static inline void init_IO_APIC_traps(void)
 			 * interrupt if we can..
 			 */
 			if (irq < nr_legacy_irqs())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				legacy_pic->make_irq(irq);
+}
 			else
 				/* Strange. Oh, well.. */
 				irq_set_chip(irq, &no_irq_chip);
@@ -1914,6 +2000,7 @@ static void unmask_lapic_irq(struct irq_data *data)
 
 static void ack_lapic_irq(struct irq_data *data)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	ack_APIC_irq();
 }
 
@@ -1926,6 +2013,7 @@ static struct irq_chip lapic_chip __read_mostly = {
 
 static void lapic_register_intr(int irq)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	irq_clear_status_flags(irq, IRQ_LEVEL);
 	irq_set_chip_and_handler_name(irq, &lapic_chip, handle_edge_irq,
 				      "edge");
@@ -1946,6 +2034,7 @@ static inline void __init unlock_ExtINT_logic(void)
 
 	pin  = find_isa_irq_pin(8, mp_INT);
 	if (pin == -1) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		WARN_ON_ONCE(1);
 		return;
 	}
@@ -1994,6 +2083,7 @@ static int disable_timer_pin_1 __initdata;
 /* Actually the next is obsolete, but keep it for paranoid reasons -AK */
 static int __init disable_timer_pin_setup(char *arg)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	disable_timer_pin_1 = 1;
 	return 0;
 }
@@ -2015,6 +2105,7 @@ static int mp_alloc_timer_irq(int ioapic, int pin)
 		mutex_unlock(&ioapic_mutex);
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return irq;
 }
 
@@ -2072,11 +2163,13 @@ static inline void __init check_timer(void)
 	 * 8259A.
 	 */
 	if (pin1 == -1) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		panic_if_irq_remap("BIOS bug: timer not connected to IO-APIC");
 		pin1 = pin2;
 		apic1 = apic2;
 		no_pin1 = 1;
 	} else if (pin2 == -1) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pin2 = pin1;
 		apic2 = apic1;
 	}
@@ -2084,6 +2177,7 @@ static inline void __init check_timer(void)
 	if (pin1 != -1) {
 		/* Ok, does IRQ0 through the IOAPIC work? */
 		if (no_pin1) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			mp_alloc_timer_irq(apic1, pin1);
 		} else {
 			/*
@@ -2094,24 +2188,35 @@ static inline void __init check_timer(void)
 			int idx;
 			idx = find_irq_entry(apic1, pin1, mp_INT);
 			if (idx != -1 && irq_trigger(idx))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				unmask_ioapic_irq(irq_get_irq_data(0));
+}
 		}
 		irq_domain_deactivate_irq(irq_data);
 		irq_domain_activate_irq(irq_data);
 		if (timer_irq_works()) {
 			if (disable_timer_pin_1 > 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				clear_IO_APIC_pin(0, pin1);
+}
 			goto out;
 		}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		panic_if_irq_remap("timer doesn't work through Interrupt-remapped IO-APIC");
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		local_irq_disable();
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		clear_IO_APIC_pin(apic1, pin1);
 		if (!no_pin1)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			apic_printk(APIC_QUIET, KERN_ERR "..MP-BIOS bug: "
 				    "8254 timer not connected to IO-APIC\n");
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		apic_printk(APIC_QUIET, KERN_INFO "...trying to set up timer "
 			    "(IRQ0) through the 8259A ...\n");
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		apic_printk(APIC_QUIET, KERN_INFO
 			    "..... (found apic %d pin %d) ...\n", apic2, pin2);
 		/*
@@ -2122,6 +2227,7 @@ static inline void __init check_timer(void)
 		irq_domain_activate_irq(irq_data);
 		legacy_pic->unmask(0);
 		if (timer_irq_works()) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			apic_printk(APIC_QUIET, KERN_INFO "....... works.\n");
 			goto out;
 		}
@@ -2129,30 +2235,40 @@ static inline void __init check_timer(void)
 		 * Cleanup, just in case ...
 		 */
 		local_irq_disable();
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		legacy_pic->mask(0);
 		clear_IO_APIC_pin(apic2, pin2);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		apic_printk(APIC_QUIET, KERN_INFO "....... failed.\n");
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	apic_printk(APIC_QUIET, KERN_INFO
 		    "...trying to set up timer as Virtual Wire IRQ...\n");
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lapic_register_intr(0);
 	apic_write(APIC_LVT0, APIC_DM_FIXED | cfg->vector);	/* Fixed mode */
 	legacy_pic->unmask(0);
 
 	if (timer_irq_works()) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		apic_printk(APIC_QUIET, KERN_INFO "..... works.\n");
 		goto out;
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	local_irq_disable();
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	legacy_pic->mask(0);
 	apic_write(APIC_LVT0, APIC_LVT_MASKED | APIC_DM_FIXED | cfg->vector);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	apic_printk(APIC_QUIET, KERN_INFO "..... failed.\n");
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	apic_printk(APIC_QUIET, KERN_INFO
 		    "...trying to set up timer as ExtINT IRQ...\n");
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	legacy_pic->init(0);
 	legacy_pic->make_irq(0);
 	apic_write(APIC_LVT0, APIC_DM_EXTINT);
@@ -2160,15 +2276,21 @@ static inline void __init check_timer(void)
 	unlock_ExtINT_logic();
 
 	if (timer_irq_works()) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		apic_printk(APIC_QUIET, KERN_INFO "..... works.\n");
 		goto out;
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	local_irq_disable();
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	apic_printk(APIC_QUIET, KERN_INFO "..... failed :(.\n");
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (apic_is_x2apic_enabled())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		apic_printk(APIC_QUIET, KERN_INFO
 			    "Perhaps problem with the pre-enabled x2apic mode\n"
 			    "Try booting with x2apic and interrupt-remapping disabled in the bios.\n");
+}
 	panic("IO-APIC + timer doesn't work!  Boot with apic=debug and send a "
 		"report.  Then try booting with the 'noapic' option.\n");
 out:
@@ -2206,7 +2328,9 @@ static int mp_irqdomain_create(int ioapic)
 	char *name = "IO-APIC";
 
 	if (cfg->type == IOAPIC_DOMAIN_INVALID)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	init_irq_alloc_info(&info, NULL);
 	info.type = X86_IRQ_ALLOC_TYPE_IOAPIC;
@@ -2219,11 +2343,14 @@ static int mp_irqdomain_create(int ioapic)
 
 	/* Handle device tree enumerated APICs proper */
 	if (cfg->dev) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		fn = of_node_to_fwnode(cfg->dev);
 	} else {
 		fn = irq_domain_alloc_named_id_fwnode(name, ioapic);
 		if (!fn)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -ENOMEM;
+}
 	}
 
 	ip->irqdomain = irq_domain_create_linear(fn, hwirqs, cfg->ops,
@@ -2234,7 +2361,9 @@ static int mp_irqdomain_create(int ioapic)
 		irq_domain_free_fwnode(fn);
 
 	if (!ip->irqdomain)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 
 	ip->irqdomain->parent = parent;
 
@@ -2243,11 +2372,13 @@ static int mp_irqdomain_create(int ioapic)
 		ioapic_dynirq_base = max(ioapic_dynirq_base,
 					 gsi_cfg->gsi_end + 1);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
 static void ioapic_destroy_irqdomain(int idx)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (ioapics[idx].irqdomain) {
 		irq_domain_remove(ioapics[idx].irqdomain);
 		ioapics[idx].irqdomain = NULL;
@@ -2259,7 +2390,9 @@ void __init setup_IO_APIC(void)
 	int ioapic;
 
 	if (skip_ioapic_setup || !nr_ioapics)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	io_apic_irqs = nr_legacy_irqs() ? ~PIC_IRQS : ~0UL;
 
@@ -2286,6 +2419,7 @@ static void resume_ioapic_id(int ioapic_idx)
 	unsigned long flags;
 	union IO_APIC_reg_00 reg_00;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	raw_spin_lock_irqsave(&ioapic_lock, flags);
 	reg_00.raw = io_apic_read(ioapic_idx, 0);
 	if (reg_00.bits.ID != mpc_ioapic_id(ioapic_idx)) {
@@ -2299,6 +2433,7 @@ static void ioapic_resume(void)
 {
 	int ioapic_idx;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for_each_ioapic_reverse(ioapic_idx)
 		resume_ioapic_id(ioapic_idx);
 
@@ -2443,20 +2578,28 @@ static u8 io_apic_unique_id(int idx, u8 id)
 
 	/* Hand out the requested id if available */
 	if (!test_bit(id, used))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return id;
+}
 
 	/*
 	 * Read the current id from the ioapic and keep it if
 	 * available.
 	 */
 	raw_spin_lock_irqsave(&ioapic_lock, flags);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	reg_00.raw = io_apic_read(idx, 0);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	raw_spin_unlock_irqrestore(&ioapic_lock, flags);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	new_id = reg_00.bits.ID;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!test_bit(new_id, used)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		apic_printk(APIC_VERBOSE, KERN_INFO
 			"IOAPIC[%d]: Using reg apic_id %d instead of %d\n",
 			 idx, new_id, id);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return new_id;
 	}
 
@@ -2465,13 +2608,17 @@ static u8 io_apic_unique_id(int idx, u8 id)
 	 */
 	new_id = find_first_zero_bit(used, 256);
 	reg_00.bits.ID = new_id;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	raw_spin_lock_irqsave(&ioapic_lock, flags);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	io_apic_write(idx, 0, reg_00.raw);
 	reg_00.raw = io_apic_read(idx, 0);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	raw_spin_unlock_irqrestore(&ioapic_lock, flags);
 	/* Sanity check */
 	BUG_ON(reg_00.bits.ID != new_id);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return new_id;
 }
 #endif
@@ -2493,19 +2640,27 @@ int acpi_get_override_irq(u32 gsi, int *trigger, int *polarity)
 	int ioapic, pin, idx;
 
 	if (skip_ioapic_setup)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -1;
+}
 
 	ioapic = mp_find_ioapic(gsi);
 	if (ioapic < 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -1;
+}
 
 	pin = mp_find_ioapic_pin(ioapic, gsi);
 	if (pin < 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -1;
+}
 
 	idx = find_irq_entry(ioapic, pin, mp_INT);
 	if (idx < 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -1;
+}
 
 	*trigger = irq_trigger(idx);
 	*polarity = irq_polarity(idx);
@@ -2527,7 +2682,9 @@ void __init setup_ioapic_dest(void)
 	struct irq_chip *chip;
 
 	if (skip_ioapic_setup == 1)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	for_each_ioapic_pin(ioapic, pin) {
 		irq_entry = find_irq_entry(ioapic, pin, mp_INT);
@@ -2550,6 +2707,7 @@ void __init setup_ioapic_dest(void)
 		else
 			mask = apic->target_cpus();
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		chip = irq_data_get_irq_chip(idata);
 		/* Might be lapic_chip for irq 0 */
 		if (chip->irq_set_affinity)
@@ -2571,8 +2729,11 @@ static struct resource * __init ioapic_setup_resources(void)
 	int i;
 
 	if (nr_ioapics == 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	n = IOAPIC_RESOURCE_NAME_SIZE + sizeof(struct resource);
 	n *= nr_ioapics;
 
@@ -2640,9 +2801,12 @@ void __init ioapic_insert_resources(void)
 	struct resource *r = ioapic_resources;
 
 	if (!r) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (nr_ioapics > 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			printk(KERN_ERR
 				"IO APIC resources couldn't be allocated.\n");
+}
 		return;
 	}
 
@@ -2657,15 +2821,21 @@ int mp_find_ioapic(u32 gsi)
 	int i;
 
 	if (nr_ioapics == 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -1;
+}
 
 	/* Find the IOAPIC that manages this GSI. */
 	for_each_ioapic(i) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		struct mp_ioapic_gsi *gsi_cfg = mp_ioapic_gsi_routing(i);
 		if (gsi >= gsi_cfg->gsi_base && gsi <= gsi_cfg->gsi_end)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return i;
+}
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	printk(KERN_ERR "ERROR: Unable to locate IOAPIC for GSI %d\n", gsi);
 	return -1;
 }
@@ -2675,11 +2845,16 @@ int mp_find_ioapic_pin(int ioapic, u32 gsi)
 	struct mp_ioapic_gsi *gsi_cfg;
 
 	if (WARN_ON(ioapic < 0))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -1;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	gsi_cfg = mp_ioapic_gsi_routing(ioapic);
 	if (WARN_ON(gsi > gsi_cfg->gsi_end))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -1;
+}
 
 	return gsi - gsi_cfg->gsi_base;
 }
@@ -2695,11 +2870,13 @@ static int bad_ioapic_register(int idx)
 	reg_02.raw = io_apic_read(idx, 2);
 
 	if (reg_00.raw == -1 && reg_01.raw == -1 && reg_02.raw == -1) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_warn("I/O APIC 0x%x registers return all ones, skipping!\n",
 			mpc_ioapic_addr(idx));
 		return 1;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
@@ -2709,8 +2886,11 @@ static int find_free_ioapic_entry(void)
 
 	for (idx = 0; idx < MAX_IO_APICS; idx++)
 		if (ioapics[idx].nr_registers == 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return idx;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return MAX_IO_APICS;
 }
 
@@ -2730,11 +2910,14 @@ int mp_register_ioapic(int id, u32 address, u32 gsi_base,
 	u32 gsi_end;
 
 	if (!address) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_warn("Bogus (zero) I/O APIC address found, skipping!\n");
 		return -EINVAL;
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for_each_ioapic(ioapic)
 		if (ioapics[ioapic].mp_config.apicaddr == address) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			pr_warn("address 0x%x conflicts with IOAPIC%d\n",
 				address, ioapic);
 			return -EEXIST;
@@ -2742,6 +2925,7 @@ int mp_register_ioapic(int id, u32 address, u32 gsi_base,
 
 	idx = find_free_ioapic_entry();
 	if (idx >= MAX_IO_APICS) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_warn("Max # of I/O APICs (%d) exceeded (found %d), skipping\n",
 			MAX_IO_APICS, idx);
 		return -ENOSPC;
@@ -2753,6 +2937,7 @@ int mp_register_ioapic(int id, u32 address, u32 gsi_base,
 
 	set_fixmap_nocache(FIX_IO_APIC_BASE_0 + idx, address);
 	if (bad_ioapic_register(idx)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		clear_fixmap(FIX_IO_APIC_BASE_0 + idx);
 		return -ENODEV;
 	}
@@ -2767,11 +2952,13 @@ int mp_register_ioapic(int id, u32 address, u32 gsi_base,
 	entries = io_apic_get_redir_entries(idx);
 	gsi_end = gsi_base + entries - 1;
 	for_each_ioapic(ioapic) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		gsi_cfg = mp_ioapic_gsi_routing(ioapic);
 		if ((gsi_base >= gsi_cfg->gsi_base &&
 		     gsi_base <= gsi_cfg->gsi_end) ||
 		    (gsi_end >= gsi_cfg->gsi_base &&
 		     gsi_end <= gsi_cfg->gsi_end)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			pr_warn("GSI range [%u-%u] for new IOAPIC conflicts with GSI[%u-%u]\n",
 				gsi_base, gsi_end,
 				gsi_cfg->gsi_base, gsi_cfg->gsi_end);
@@ -2779,6 +2966,7 @@ int mp_register_ioapic(int id, u32 address, u32 gsi_base,
 			return -ENOSPC;
 		}
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	gsi_cfg = mp_ioapic_gsi_routing(idx);
 	gsi_cfg->gsi_base = gsi_base;
 	gsi_cfg->gsi_end = gsi_end;
@@ -2792,10 +2980,13 @@ int mp_register_ioapic(int id, u32 address, u32 gsi_base,
 	 * we are still using bootmem allocator. So delay it to setup_IO_APIC().
 	 */
 	if (hotplug) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (mp_irqdomain_create(idx)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			clear_fixmap(FIX_IO_APIC_BASE_0 + idx);
 			return -ENOMEM;
 		}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		alloc_ioapic_saved_registers(idx);
 	}
 
@@ -2820,6 +3011,7 @@ int mp_unregister_ioapic(u32 gsi_base)
 	int ioapic, pin;
 	int found = 0;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for_each_ioapic(ioapic)
 		if (ioapics[ioapic].gsi_config.gsi_base == gsi_base) {
 			found = 1;
@@ -2861,6 +3053,7 @@ int mp_ioapic_registered(u32 gsi_base)
 {
 	int ioapic;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for_each_ioapic(ioapic)
 		if (ioapics[ioapic].gsi_config.gsi_base == gsi_base)
 			return 1;
@@ -2885,6 +3078,7 @@ static void mp_irqdomain_get_attr(u32 gsi, struct mp_chip_data *data,
 static void mp_setup_entry(struct irq_cfg *cfg, struct mp_chip_data *data,
 			   struct IO_APIC_route_entry *entry)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	memset(entry, 0, sizeof(*entry));
 	entry->delivery_mode = apic->irq_delivery_mode;
 	entry->dest_mode     = apic->irq_dest_mode;
@@ -2913,23 +3107,33 @@ int mp_irqdomain_alloc(struct irq_domain *domain, unsigned int virq,
 	unsigned long flags;
 
 	if (!info || nr_irqs > 1)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 	irq_data = irq_domain_get_irq_data(domain, virq);
 	if (!irq_data)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	ioapic = mp_irqdomain_ioapic_idx(domain);
 	pin = info->ioapic_pin;
 	if (irq_find_mapping(domain, (irq_hw_number_t)pin) > 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EEXIST;
+}
 
 	data = kzalloc(sizeof(*data), GFP_KERNEL);
 	if (!data)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 
 	info->ioapic_entry = &data->entry;
 	ret = irq_domain_alloc_irqs_parent(domain, virq, nr_irqs, info);
 	if (ret < 0) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		kfree(data);
 		return ret;
 	}
@@ -2957,6 +3161,7 @@ int mp_irqdomain_alloc(struct irq_domain *domain, unsigned int virq,
 		    ioapic, mpc_ioapic_id(ioapic), pin, cfg->vector,
 		    virq, data->trigger, data->polarity, cfg->dest_apicid);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
@@ -2966,6 +3171,7 @@ void mp_irqdomain_free(struct irq_domain *domain, unsigned int virq,
 	struct irq_data *irq_data;
 	struct mp_chip_data *data;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	BUG_ON(nr_irqs != 1);
 	irq_data = irq_domain_get_irq_data(domain, virq);
 	if (irq_data && irq_data->chip_data) {
diff --git a/arch/x86/kernel/apic/ipi.c b/arch/x86/kernel/apic/ipi.c
index 82f9244..de21cfe 100644
--- a/arch/x86/kernel/apic/ipi.c
+++ b/arch/x86/kernel/apic/ipi.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 #include <linux/cpumask.h>
 #include <linux/interrupt.h>
@@ -57,7 +59,9 @@ void __default_send_IPI_dest_field(unsigned int mask, int vector, unsigned int d
 	 * Wait for idle.
 	 */
 	if (unlikely(vector == NMI_VECTOR))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		safe_apic_wait_icr_idle();
+}
 	else
 		__xapic_wait_icr_idle();
 
@@ -82,6 +86,7 @@ void default_send_IPI_single_phys(int cpu, int vector)
 {
 	unsigned long flags;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	local_irq_save(flags);
 	__default_send_IPI_dest_field(per_cpu(x86_cpu_to_apicid, cpu),
 				      vector, APIC_DEST_PHYSICAL);
@@ -109,6 +114,7 @@ void default_send_IPI_mask_sequence_phys(const struct cpumask *mask, int vector)
 void default_send_IPI_mask_allbutself_phys(const struct cpumask *mask,
 						 int vector)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	unsigned int this_cpu = smp_processor_id();
 	unsigned int query_cpu;
 	unsigned long flags;
@@ -130,6 +136,7 @@ void default_send_IPI_mask_allbutself_phys(const struct cpumask *mask,
  */
 void default_send_IPI_single(int cpu, int vector)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	apic->send_IPI_mask(cpumask_of(cpu), vector);
 }
 
diff --git a/arch/x86/kernel/apic/msi.c b/arch/x86/kernel/apic/msi.c
index 9b18be7..de6b89e1 100644
--- a/arch/x86/kernel/apic/msi.c
+++ b/arch/x86/kernel/apic/msi.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * Support of MSI, HPET and DMAR interrupts.
  *
@@ -32,7 +34,9 @@ static void irq_msi_compose_msg(struct irq_data *data, struct msi_msg *msg)
 	msg->address_hi = MSI_ADDR_BASE_HI;
 
 	if (x2apic_enabled())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		msg->address_hi |= MSI_ADDR_EXT_DEST_ID(cfg->dest_apicid);
+}
 
 	msg->address_lo =
 		MSI_ADDR_BASE_LO |
@@ -80,13 +84,16 @@ int native_setup_msi_irqs(struct pci_dev *dev, int nvec, int type)
 	if (domain == NULL)
 		domain = msi_default_domain;
 	if (domain == NULL)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOSYS;
+}
 
 	return msi_domain_alloc_irqs(domain, &dev->dev, nvec);
 }
 
 void native_teardown_msi_irq(unsigned int irq)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	irq_domain_free_irqs(irq, 1);
 }
 
@@ -141,7 +148,9 @@ void __init arch_init_msi_domain(struct irq_domain *parent)
 	struct fwnode_handle *fn;
 
 	if (disable_apic)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	fn = irq_domain_alloc_named_fwnode("PCI-MSI");
 	if (fn) {
@@ -151,8 +160,10 @@ void __init arch_init_msi_domain(struct irq_domain *parent)
 		irq_domain_free_fwnode(fn);
 	}
 	if (!msi_default_domain)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_warn("failed to initialize irqdomain for MSI/MSI-x.\n");
 }
+}
 
 #ifdef CONFIG_IRQ_REMAP
 static struct irq_chip pci_msi_ir_controller = {
@@ -192,6 +203,7 @@ struct irq_domain *arch_create_remap_msi_irq_domain(struct irq_domain *parent,
 #ifdef CONFIG_DMAR_TABLE
 static void dmar_msi_write_msg(struct irq_data *data, struct msi_msg *msg)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	dmar_msi_write(data->irq, msg);
 }
 
@@ -210,6 +222,7 @@ static struct irq_chip dmar_msi_controller = {
 static irq_hw_number_t dmar_msi_get_hwirq(struct msi_domain_info *info,
 					  msi_alloc_info_t *arg)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return arg->dmar_id;
 }
 
@@ -217,6 +230,7 @@ static int dmar_msi_init(struct irq_domain *domain,
 			 struct msi_domain_info *info, unsigned int virq,
 			 irq_hw_number_t hwirq, msi_alloc_info_t *arg)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	irq_domain_set_info(domain, virq, arg->dmar_id, info->chip, NULL,
 			    handle_edge_irq, arg->dmar_data, "edge");
 
@@ -243,6 +257,7 @@ static struct irq_domain *dmar_get_irq_domain(void)
 	if (dmar_domain)
 		goto out;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	fn = irq_domain_alloc_named_fwnode("DMAR-MSI");
 	if (fn) {
 		dmar_domain = msi_create_irq_domain(fn, &dmar_msi_domain_info,
@@ -256,6 +271,7 @@ static struct irq_domain *dmar_get_irq_domain(void)
 
 int dmar_alloc_hwirq(int id, int node, void *arg)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct irq_domain *domain = dmar_get_irq_domain();
 	struct irq_alloc_info info;
 
@@ -272,6 +288,7 @@ int dmar_alloc_hwirq(int id, int node, void *arg)
 
 void dmar_free_hwirq(int irq)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	irq_domain_free_irqs(irq, 1);
 }
 #endif
@@ -282,6 +299,7 @@ void dmar_free_hwirq(int irq)
 #ifdef CONFIG_HPET_TIMER
 static inline int hpet_dev_id(struct irq_domain *domain)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct msi_domain_info *info = msi_get_domain_info(domain);
 
 	return (int)(long)info->data;
@@ -289,6 +307,7 @@ static inline int hpet_dev_id(struct irq_domain *domain)
 
 static void hpet_msi_write_msg(struct irq_data *data, struct msi_msg *msg)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	hpet_msi_write(irq_data_get_irq_handler_data(data), msg);
 }
 
@@ -307,6 +326,7 @@ static struct irq_chip hpet_msi_controller __ro_after_init = {
 static irq_hw_number_t hpet_msi_get_hwirq(struct msi_domain_info *info,
 					  msi_alloc_info_t *arg)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return arg->hpet_index;
 }
 
@@ -314,6 +334,7 @@ static int hpet_msi_init(struct irq_domain *domain,
 			 struct msi_domain_info *info, unsigned int virq,
 			 irq_hw_number_t hwirq, msi_alloc_info_t *arg)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	irq_set_status_flags(virq, IRQ_MOVE_PCNTXT);
 	irq_domain_set_info(domain, virq, arg->hpet_index, info->chip, NULL,
 			    handle_edge_irq, arg->hpet_data, "edge");
@@ -324,6 +345,7 @@ static int hpet_msi_init(struct irq_domain *domain,
 static void hpet_msi_free(struct irq_domain *domain,
 			  struct msi_domain_info *info, unsigned int virq)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	irq_clear_status_flags(virq, IRQ_MOVE_PCNTXT);
 }
 
@@ -346,11 +368,15 @@ struct irq_domain *hpet_create_irq_domain(int hpet_id)
 	struct fwnode_handle *fn;
 
 	if (x86_vector_domain == NULL)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 
 	domain_info = kzalloc(sizeof(*domain_info), GFP_KERNEL);
 	if (!domain_info)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 
 	*domain_info = hpet_msi_domain_info;
 	domain_info->data = (void *)(long)hpet_id;
@@ -367,6 +393,7 @@ struct irq_domain *hpet_create_irq_domain(int hpet_id)
 	fn = irq_domain_alloc_named_id_fwnode(hpet_msi_controller.name,
 					      hpet_id);
 	if (!fn) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		kfree(domain_info);
 		return NULL;
 	}
diff --git a/arch/x86/kernel/apic/probe_64.c b/arch/x86/kernel/apic/probe_64.c
index c303054..4c8e60e 100644
--- a/arch/x86/kernel/apic/probe_64.c
+++ b/arch/x86/kernel/apic/probe_64.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * Copyright 2004 James Cleverdon, IBM.
  * Subject to the GNU Public License, v.2
@@ -34,6 +36,7 @@ void __init default_setup_apic_routing(void)
 	for (drv = __apicdrivers; drv < __apicdrivers_end; drv++) {
 		if ((*drv)->probe && (*drv)->probe()) {
 			if (apic != *drv) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				apic = *drv;
 				pr_info("Switched APIC routing to %s.\n",
 					apic->name);
@@ -43,13 +46,16 @@ void __init default_setup_apic_routing(void)
 	}
 
 	if (x86_platform.apic_post_init)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		x86_platform.apic_post_init();
 }
+}
 
 /* Same for both flat and physical. */
 
 void apic_send_IPI_self(int vector)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	__default_send_IPI_shortcut(APIC_DEST_SELF, vector, APIC_DEST_PHYSICAL);
 }
 
@@ -60,12 +66,15 @@ int __init default_acpi_madt_oem_check(char *oem_id, char *oem_table_id)
 	for (drv = __apicdrivers; drv < __apicdrivers_end; drv++) {
 		if ((*drv)->acpi_madt_oem_check(oem_id, oem_table_id)) {
 			if (apic != *drv) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				apic = *drv;
 				pr_info("Setting APIC routing to %s.\n",
 					apic->name);
 			}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return 1;
 		}
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
diff --git a/arch/x86/kernel/apic/vector.c b/arch/x86/kernel/apic/vector.c
index 2ce1c70..62be683 100644
--- a/arch/x86/kernel/apic/vector.c
+++ b/arch/x86/kernel/apic/vector.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * Local APIC related interfaces to support IOAPIC, MSI, HT_IRQ etc.
  *
@@ -47,13 +49,16 @@ void lock_vector_lock(void)
 
 void unlock_vector_lock(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	raw_spin_unlock(&vector_lock);
 }
 
 static struct apic_chip_data *apic_chip_data(struct irq_data *irq_data)
 {
 	if (!irq_data)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 
 	while (irq_data->parent_data)
 		irq_data = irq_data->parent_data;
@@ -80,11 +85,14 @@ static struct apic_chip_data *alloc_apic_chip_data(int node)
 
 	data = kzalloc_node(sizeof(*data), GFP_KERNEL, node);
 	if (!data)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 	if (!zalloc_cpumask_var_node(&data->domain, GFP_KERNEL, node))
 		goto out_data;
 	if (!zalloc_cpumask_var_node(&data->old_domain, GFP_KERNEL, node))
 		goto out_domain;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return data;
 out_domain:
 	free_cpumask_var(data->domain);
@@ -95,6 +103,7 @@ static struct apic_chip_data *alloc_apic_chip_data(int node)
 
 static void free_apic_chip_data(struct apic_chip_data *data)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (data) {
 		free_cpumask_var(data->domain);
 		free_cpumask_var(data->old_domain);
@@ -167,6 +176,7 @@ static int __assign_irq_vector(int irq, struct apic_chip_data *d,
 next:
 		vector += 16;
 		if (vector >= FIRST_SYSTEM_VECTOR) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			offset = (offset + 1) % 16;
 			vector = FIRST_EXTERNAL_VECTOR + offset;
 		}
@@ -187,7 +197,9 @@ static int __assign_irq_vector(int irq, struct apic_chip_data *d,
 		current_offset = offset;
 		/* Schedule the old vector for cleanup on all cpus */
 		if (d->cfg.vector)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			cpumask_copy(d->old_domain, d->domain);
+}
 		for_each_cpu(new_cpu, vector_searchmask)
 			per_cpu(vector_irq, new_cpu)[vector] = irq_to_desc(irq);
 		goto update;
@@ -205,6 +217,7 @@ static int __assign_irq_vector(int irq, struct apic_chip_data *d,
 		cpu = cpumask_first_and(vector_cpumask, cpu_online_mask);
 		continue;
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return -ENOSPC;
 
 update:
@@ -229,6 +242,7 @@ static int __assign_irq_vector(int irq, struct apic_chip_data *d,
 	cpumask_and(vector_searchmask, vector_searchmask, mask);
 	BUG_ON(apic->cpu_mask_to_apicid(vector_searchmask, irqdata,
 					&d->cfg.dest_apicid));
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
@@ -251,10 +265,13 @@ static int assign_irq_vector_policy(int irq, int node,
 				    struct irq_data *irqdata)
 {
 	if (info && info->mask)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return assign_irq_vector(irq, data, info->mask, irqdata);
+}
 	if (node != NUMA_NO_NODE &&
 	    assign_irq_vector(irq, data, cpumask_of_node(node), irqdata) == 0)
 		return 0;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return assign_irq_vector(irq, data, apic->target_cpus(), irqdata);
 }
 
@@ -264,7 +281,9 @@ static void clear_irq_vector(int irq, struct apic_chip_data *data)
 	int cpu, vector;
 
 	if (!data->cfg.vector)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	vector = data->cfg.vector;
 	for_each_cpu_and(cpu, data->domain, cpu_online_mask)
@@ -297,6 +316,7 @@ static void clear_irq_vector(int irq, struct apic_chip_data *data)
 void init_irq_alloc_info(struct irq_alloc_info *info,
 			 const struct cpumask *mask)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	memset(info, 0, sizeof(*info));
 	info->mask = mask;
 }
@@ -317,6 +337,7 @@ static void x86_vector_free_irqs(struct irq_domain *domain,
 	unsigned long flags;
 	int i;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (i = 0; i < nr_irqs; i++) {
 		irq_data = irq_domain_get_irq_data(x86_vector_domain, virq + i);
 		if (irq_data && irq_data->chip_data) {
@@ -343,23 +364,31 @@ static int x86_vector_alloc_irqs(struct irq_domain *domain, unsigned int virq,
 	int i, err, node;
 
 	if (disable_apic)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENXIO;
+}
 
 	/* Currently vector allocator can't guarantee contiguous allocations */
 	if ((info->flags & X86_IRQ_ALLOC_CONTIGUOUS_VECTORS) && nr_irqs > 1)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOSYS;
+}
 
 	for (i = 0; i < nr_irqs; i++) {
 		irq_data = irq_domain_get_irq_data(domain, virq + i);
 		BUG_ON(!irq_data);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		node = irq_data_get_node(irq_data);
 #ifdef	CONFIG_X86_IO_APIC
 		if (virq + i < nr_legacy_irqs() && legacy_irq_data[virq + i])
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			data = legacy_irq_data[virq + i];
+}
 		else
 #endif
 			data = alloc_apic_chip_data(node);
 		if (!data) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			err = -ENOMEM;
 			goto error;
 		}
@@ -370,6 +399,7 @@ static int x86_vector_alloc_irqs(struct irq_domain *domain, unsigned int virq,
 		err = assign_irq_vector_policy(virq + i, node, data, info,
 					       irq_data);
 		if (err) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			irq_data->chip_data = NULL;
 			free_apic_chip_data(data);
 			goto error;
@@ -380,9 +410,12 @@ static int x86_vector_alloc_irqs(struct irq_domain *domain, unsigned int virq,
 		 * CPU. Mark the interrupt accordingly.
 		 */
 		if (!apic->irq_dest_mode)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			irqd_set_single_target(irq_data);
+}
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 
 error:
@@ -408,12 +441,16 @@ int __init arch_probe_nr_irqs(void)
 	 * for MSI and HT dyn irq
 	 */
 	if (gsi_top <= NR_IRQS_LEGACY)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		nr +=  8 * nr_cpu_ids;
+}
 	else
 		nr += gsi_top * 16;
 #endif
 	if (nr < nr_irqs)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		nr_irqs = nr;
+}
 
 	/*
 	 * We don't know if PIC is present at this point so we need to do
@@ -462,8 +499,11 @@ int __init arch_early_irq_init(void)
 	arch_init_msi_domain(x86_vector_domain);
 	arch_init_htirq_domain(x86_vector_domain);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	BUG_ON(!alloc_cpumask_var(&vector_cpumask, GFP_KERNEL));
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	BUG_ON(!alloc_cpumask_var(&vector_searchmask, GFP_KERNEL));
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	BUG_ON(!alloc_cpumask_var(&searched_cpumask, GFP_KERNEL));
 
 	return arch_early_ioapic_init();
@@ -505,6 +545,7 @@ void setup_vector_irq(int cpu)
 {
 	int irq;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lockdep_assert_held(&vector_lock);
 	/*
 	 * On most of the platforms, legacy PIC delivers the interrupts on the
@@ -547,10 +588,14 @@ static int apic_set_affinity(struct irq_data *irq_data,
 	int err, irq = irq_data->irq;
 
 	if (!IS_ENABLED(CONFIG_SMP))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EPERM;
+}
 
 	if (!cpumask_intersects(dest, cpu_online_mask))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	err = assign_irq_vector(irq, data, dest, irq_data);
 	return err ? err : IRQ_SET_MASK_OK;
@@ -566,6 +611,7 @@ static struct irq_chip lapic_controller = {
 #ifdef CONFIG_SMP
 static void __send_cleanup_vector(struct apic_chip_data *data)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	raw_spin_lock(&vector_lock);
 	cpumask_and(data->old_domain, data->old_domain, cpu_online_mask);
 	data->move_in_progress = 0;
@@ -578,6 +624,7 @@ void send_cleanup_vector(struct irq_cfg *cfg)
 {
 	struct apic_chip_data *data;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	data = container_of(cfg, struct apic_chip_data, cfg);
 	if (data->move_in_progress)
 		__send_cleanup_vector(data);
@@ -592,6 +639,7 @@ asmlinkage __visible void __irq_entry smp_irq_move_cleanup_interrupt(void)
 	/* Prevent vectors vanishing under us */
 	raw_spin_lock(&vector_lock);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	me = smp_processor_id();
 	for (vector = FIRST_EXTERNAL_VECTOR; vector < NR_VECTORS; vector++) {
 		struct apic_chip_data *data;
@@ -666,14 +714,21 @@ static void __irq_complete_move(struct irq_cfg *cfg, unsigned vector)
 	unsigned me;
 	struct apic_chip_data *data;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	data = container_of(cfg, struct apic_chip_data, cfg);
 	if (likely(!data->move_in_progress))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	me = smp_processor_id();
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (vector == data->cfg.vector && cpumask_test_cpu(me, data->domain))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		__send_cleanup_vector(data);
 }
+}
 
 void irq_complete_move(struct irq_cfg *cfg)
 {
@@ -702,7 +757,9 @@ void irq_force_complete_move(struct irq_desc *desc)
 	irqdata = irq_domain_get_irq_data(x86_vector_domain,
 					  irq_desc_get_irq(desc));
 	if (!irqdata)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	data = apic_chip_data(irqdata);
 	cfg = data ? &data->cfg : NULL;
@@ -799,6 +856,7 @@ static void __init print_APIC_field(int base)
 
 	printk(KERN_DEBUG);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (i = 0; i < 8; i++)
 		pr_cont("%08x", apic_read(base + i*0x10));
 
@@ -810,6 +868,7 @@ static void __init print_local_APIC(void *dummy)
 	unsigned int i, v, ver, maxlvt;
 	u64 icr;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pr_debug("printing local APIC contents on CPU#%d/%d:\n",
 		 smp_processor_id(), hard_smp_processor_id());
 	v = apic_read(APIC_ID);
@@ -917,7 +976,9 @@ static void __init print_local_APICs(int maxcpu)
 	int cpu;
 
 	if (!maxcpu)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	preempt_disable();
 	for_each_online_cpu(cpu) {
@@ -934,7 +995,9 @@ static void __init print_PIC(void)
 	unsigned long flags;
 
 	if (!nr_legacy_irqs())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	pr_debug("\nprinting PIC contents\n");
 
@@ -966,6 +1029,7 @@ static __init int setup_show_lapic(char *arg)
 	int num = -1;
 
 	if (strcmp(arg, "all") == 0) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		show_lapic = CONFIG_NR_CPUS;
 	} else {
 		get_option(&arg, &num);
@@ -980,14 +1044,20 @@ __setup("show_lapic=", setup_show_lapic);
 static int __init print_ICs(void)
 {
 	if (apic_verbosity == APIC_QUIET)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	print_PIC();
 
 	/* don't print out if apic is not there */
 	if (!boot_cpu_has(X86_FEATURE_APIC) && !apic_from_smp_config())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	print_local_APICs(show_lapic);
 	print_IO_APICs();
 
diff --git a/arch/x86/kernel/apic/x2apic_cluster.c b/arch/x86/kernel/apic/x2apic_cluster.c
index e216cf3..2740e7c 100644
--- a/arch/x86/kernel/apic/x2apic_cluster.c
+++ b/arch/x86/kernel/apic/x2apic_cluster.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 #include <linux/threads.h>
 #include <linux/cpumask.h>
diff --git a/arch/x86/kernel/apic/x2apic_phys.c b/arch/x86/kernel/apic/x2apic_phys.c
index b94d3532..87c2321 100644
--- a/arch/x86/kernel/apic/x2apic_phys.c
+++ b/arch/x86/kernel/apic/x2apic_phys.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 #include <linux/threads.h>
 #include <linux/cpumask.h>
diff --git a/arch/x86/kernel/audit_64.c b/arch/x86/kernel/audit_64.c
index e1efe44..f89eab1 100644
--- a/arch/x86/kernel/audit_64.c
+++ b/arch/x86/kernel/audit_64.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 #include <linux/init.h>
 #include <linux/types.h>
@@ -42,6 +44,7 @@ int audit_classify_syscall(int abi, unsigned syscall)
 {
 #ifdef CONFIG_IA32_EMULATION
 	extern int ia32_classify_syscall(unsigned);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (abi == AUDIT_ARCH_I386)
 		return ia32_classify_syscall(syscall);
 #endif
diff --git a/arch/x86/kernel/bootflag.c b/arch/x86/kernel/bootflag.c
index 3fed7ae..8487836 100644
--- a/arch/x86/kernel/bootflag.c
+++ b/arch/x86/kernel/bootflag.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 /*
  *	Implement 'Simple Boot Flag Specification 2.0'
@@ -25,6 +27,7 @@ static int __init parity(u8 v)
 	int x = 0;
 	int i;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (i = 0; i < 8; i++) {
 		x ^= (v & 1);
 		v >>= 1;
@@ -38,6 +41,7 @@ static void __init sbf_write(u8 v)
 	unsigned long flags;
 
 	if (sbf_port != -1) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		v &= ~SBF_PARITY;
 		if (!parity(v))
 			v |= SBF_PARITY;
@@ -57,7 +61,9 @@ static u8 __init sbf_read(void)
 	u8 v;
 
 	if (sbf_port == -1)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	spin_lock_irqsave(&rtc_lock, flags);
 	v = CMOS_READ(sbf_port);
@@ -68,6 +74,7 @@ static u8 __init sbf_read(void)
 
 static int __init sbf_value_valid(u8 v)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (v & SBF_RESERVED)		/* Reserved bits */
 		return 0;
 	if (!parity(v))
@@ -81,14 +88,19 @@ static int __init sbf_init(void)
 	u8 v;
 
 	if (sbf_port == -1)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	v = sbf_read();
 	if (!sbf_value_valid(v)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		printk(KERN_WARNING "Simple Boot Flag value 0x%x read from "
 			"CMOS RAM was invalid\n", v);
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	v &= ~SBF_RESERVED;
 	v &= ~SBF_BOOTING;
 	v &= ~SBF_DIAG;
diff --git a/arch/x86/kernel/cpu/amd.c b/arch/x86/kernel/cpu/amd.c
index e7d5a78..77f2416 100644
--- a/arch/x86/kernel/cpu/amd.c
+++ b/arch/x86/kernel/cpu/amd.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 #include <linux/export.h>
 #include <linux/bitops.h>
 #include <linux/elf.h>
@@ -37,6 +39,7 @@ static inline int rdmsrl_amd_safe(unsigned msr, unsigned long long *p)
 	u32 gprs[8] = { 0 };
 	int err;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WARN_ONCE((boot_cpu_data.x86 != 0xf),
 		  "%s should only be used on K8!\n", __func__);
 
@@ -54,6 +57,7 @@ static inline int wrmsrl_amd_safe(unsigned msr, unsigned long long val)
 {
 	u32 gprs[8] = { 0 };
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WARN_ONCE((boot_cpu_data.x86 != 0xf),
 		  "%s should only be used on K8!\n", __func__);
 
@@ -283,6 +287,7 @@ static int nearby_node(int apicid)
 {
 	int i, node;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (i = apicid - 1; i >= 0; i--) {
 		node = __apicid_to_node[i];
 		if (node != NUMA_NO_NODE && node_online(node))
@@ -308,7 +313,9 @@ static void legacy_fixup_core_id(struct cpuinfo_x86 *c)
 	u32 cus_per_node;
 
 	if (c->x86 >= 0x17)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	cus_per_node = c->x86_max_cores / nodes_per_socket;
 	c->cpu_core_id %= cus_per_node;
@@ -335,13 +342,19 @@ static void amd_get_topology(struct cpuinfo_x86 *c)
 		smp_num_siblings = ((ebx >> 8) & 0xff) + 1;
 
 		if (c->x86 == 0x15)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			c->cu_id = ebx & 0xff;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (c->x86 >= 0x17) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			c->cpu_core_id = ebx & 0xff;
 
 			if (smp_num_siblings > 1)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				c->x86_max_cores /= smp_num_siblings;
+}
 		}
 
 		/*
@@ -349,6 +362,7 @@ static void amd_get_topology(struct cpuinfo_x86 *c)
 		 * have an L3 cache by looking at the L3 cache CPUID leaf.
 		 */
 		if (cpuid_edx(0x80000006)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			if (c->x86 == 0x17) {
 				/*
 				 * LLC is at the core complex level.
@@ -366,11 +380,16 @@ static void amd_get_topology(struct cpuinfo_x86 *c)
 		rdmsrl(MSR_FAM10H_NODE_ID, value);
 		node_id = value & 7;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		per_cpu(cpu_llc_id, cpu) = node_id;
 	} else
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (nodes_per_socket > 1) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		set_cpu_cap(c, X86_FEATURE_AMD_DCM);
 		legacy_fixup_core_id(c);
 	}
@@ -410,6 +429,7 @@ EXPORT_SYMBOL_GPL(amd_get_nb_id);
 
 u32 amd_get_nodes_per_socket(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return nodes_per_socket;
 }
 EXPORT_SYMBOL_GPL(amd_get_nodes_per_socket);
@@ -472,7 +492,9 @@ static void early_init_amd_mc(struct cpuinfo_x86 *c)
 
 	/* Multi core CPU? */
 	if (c->extended_cpuid_level < 0x80000008)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	ecx = cpuid_ecx(0x80000008);
 
@@ -506,22 +528,28 @@ static void bsp_init_amd(struct cpuinfo_x86 *c)
 		if (!rdmsrl_safe(MSR_K8_TSEG_ADDR, &tseg)) {
 			unsigned long pfn = tseg >> PAGE_SHIFT;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			pr_debug("tseg: %010llx\n", tseg);
 			if (pfn_range_is_mapped(pfn, pfn + 1))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				set_memory_4k((unsigned long)__va(tseg), 1);
+}
 		}
 	}
 #endif
 
 	if (cpu_has(c, X86_FEATURE_CONSTANT_TSC)) {
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (c->x86 > 0x10 ||
 		    (c->x86 == 0x10 && c->x86_model >= 0x2)) {
 			u64 val;
 
 			rdmsrl(MSR_K7_HWCR, val);
 			if (!(val & BIT(24)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				pr_warn(FW_BUG "TSC doesn't count with P0 frequency!\n");
+}
 		}
 	}
 
@@ -541,7 +569,9 @@ static void bsp_init_amd(struct cpuinfo_x86 *c)
 	}
 
 	if (cpu_has(c, X86_FEATURE_MWAITX))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		use_mwaitx_delay();
+}
 
 	if (boot_cpu_has(X86_FEATURE_TOPOEXT)) {
 		u32 ecx;
@@ -569,13 +599,16 @@ static void early_init_amd(struct cpuinfo_x86 *c)
 	 * with P/T states and does not stop in deep C-states
 	 */
 	if (c->x86_power & (1 << 8)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		set_cpu_cap(c, X86_FEATURE_CONSTANT_TSC);
 		set_cpu_cap(c, X86_FEATURE_NONSTOP_TSC);
 	}
 
 	/* Bit 12 of 8000_0007 edx is accumulated power mechanism. */
 	if (c->x86_power & BIT(12))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		set_cpu_cap(c, X86_FEATURE_ACC_POWER);
+}
 
 #ifdef CONFIG_X86_64
 	set_cpu_cap(c, X86_FEATURE_SYSCALL32);
@@ -595,14 +628,18 @@ static void early_init_amd(struct cpuinfo_x86 *c)
 	 */
 	if (boot_cpu_has(X86_FEATURE_APIC)) {
 		if (c->x86 > 0x16)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			set_cpu_cap(c, X86_FEATURE_EXTD_APICID);
+}
 		else if (c->x86 >= 0xf) {
 			/* check CPU config space for extended APIC ID */
 			unsigned int val;
 
 			val = read_pci_config(0, 24, 0, 0x68);
 			if ((val >> 17 & 0x3) == 0x3)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				set_cpu_cap(c, X86_FEATURE_EXTD_APICID);
+}
 		}
 	}
 #endif
@@ -616,7 +653,9 @@ static void early_init_amd(struct cpuinfo_x86 *c)
 
 	/* F16h erratum 793, CVE-2013-6885 */
 	if (c->x86 == 0x16 && c->x86_model <= 0xf)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		msr_set_bit(MSR_AMD64_LS_CFG, 15);
+}
 
 	/*
 	 * Check whether the machine is affected by erratum 400. This is
@@ -625,7 +664,9 @@ static void early_init_amd(struct cpuinfo_x86 *c)
 	 * sets the X86_BUG_AMD_APIC_C1E bug depending on the MSR check.
 	 */
 	if (cpu_has_amd_erratum(c, amd_erratum_400))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		set_cpu_bug(c, X86_BUG_AMD_E400);
+}
 
 	/*
 	 * BIOS support is required for SME. If BIOS has enabled SME then
@@ -640,10 +681,14 @@ static void early_init_amd(struct cpuinfo_x86 *c)
 		/* Check if SME is enabled */
 		rdmsrl(MSR_K8_SYSCFG, msr);
 		if (msr & MSR_K8_SYSCFG_MEM_ENCRYPT) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			c->x86_phys_bits -= (cpuid_ebx(0x8000001f) >> 6) & 0x3f;
 			if (IS_ENABLED(CONFIG_X86_32))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				clear_cpu_cap(c, X86_FEATURE_SME);
+}
 		} else {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			clear_cpu_cap(c, X86_FEATURE_SME);
 		}
 	}
@@ -656,6 +701,7 @@ static void init_amd_k8(struct cpuinfo_x86 *c)
 
 	/* On C+ stepping K8 rep microcode works well for copy/memset */
 	level = cpuid_eax(1);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if ((level >= 0x0f48 && level < 0x0f50) || level >= 0x0f58)
 		set_cpu_cap(c, X86_FEATURE_REP_GOOD);
 
@@ -784,23 +830,35 @@ static void init_amd(struct cpuinfo_x86 *c)
 	clear_cpu_cap(c, 0*32+31);
 
 	if (c->x86 >= 0x10)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		set_cpu_cap(c, X86_FEATURE_REP_GOOD);
+}
 
 	/* get apicid instead of initial apic id from cpuid */
 	c->apicid = hard_smp_processor_id();
 
 	/* K6s reports MCEs but don't actually have all the MSRs */
 	if (c->x86 < 6)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		clear_cpu_cap(c, X86_FEATURE_MCE);
+}
 
 	switch (c->x86) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	case 4:    init_amd_k5(c); break;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	case 5:    init_amd_k6(c); break;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	case 6:	   init_amd_k7(c); break;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	case 0xf:  init_amd_k8(c); break;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	case 0x10: init_amd_gh(c); break;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	case 0x12: init_amd_ln(c); break;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	case 0x15: init_amd_bd(c); break;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	case 0x17: init_amd_zn(c); break;
 	}
 
@@ -809,7 +867,9 @@ static void init_amd(struct cpuinfo_x86 *c)
 	 * without a XSaveErPtr feature
 	 */
 	if ((c->x86 >= 6) && (!cpu_has(c, X86_FEATURE_XSAVEERPTR)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		set_cpu_bug(c, X86_BUG_FXSAVE_LEAK);
+}
 
 	cpu_detect_cache_sizes(c);
 
@@ -826,8 +886,11 @@ static void init_amd(struct cpuinfo_x86 *c)
 	init_amd_cacheinfo(c);
 
 	if (c->x86 >= 0xf)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		set_cpu_cap(c, X86_FEATURE_K8);
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (cpu_has(c, X86_FEATURE_XMM2)) {
 		unsigned long long val;
 		int ret;
@@ -862,17 +925,25 @@ static void init_amd(struct cpuinfo_x86 *c)
 	 * running in deep C states.
 	 */
 	if (c->x86 > 0x11)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		set_cpu_cap(c, X86_FEATURE_ARAT);
+}
 
 	/* 3DNow or LM implies PREFETCHW */
 	if (!cpu_has(c, X86_FEATURE_3DNOWPREFETCH))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (cpu_has(c, X86_FEATURE_3DNOW) || cpu_has(c, X86_FEATURE_LM))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			set_cpu_cap(c, X86_FEATURE_3DNOWPREFETCH);
+}
+}
 
 	/* AMD CPUs don't reset SS attributes on SYSRET, Xen does. */
 	if (!cpu_has(c, X86_FEATURE_XENPV))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		set_cpu_bug(c, X86_BUG_SYSRET_SS_ATTRS);
 }
+}
 
 #ifdef CONFIG_X86_32
 static unsigned int amd_size_cache(struct cpuinfo_x86 *c, unsigned int size)
@@ -899,9 +970,13 @@ static void cpu_detect_tlb_amd(struct cpuinfo_x86 *c)
 	if (c->x86 < 0xf)
 		return;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (c->extended_cpuid_level < 0x80000006)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	cpuid(0x80000006, &eax, &ebx, &ecx, &edx);
 
 	tlb_lld_4k[ENTRIES] = (ebx >> 16) & mask;
@@ -912,13 +987,16 @@ static void cpu_detect_tlb_amd(struct cpuinfo_x86 *c)
 	 * characteristics from the CPUID function 0x80000005 instead.
 	 */
 	if (c->x86 == 0xf) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		cpuid(0x80000005, &eax, &ebx, &ecx, &edx);
 		mask = 0xff;
 	}
 
 	/* Handle DTLB 2M and 4M sizes, fall back to L1 if L2 is disabled */
 	if (!((eax >> 16) & mask))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		tlb_lld_2m[ENTRIES] = (cpuid_eax(0x80000005) >> 16) & 0xff;
+}
 	else
 		tlb_lld_2m[ENTRIES] = (eax >> 16) & mask;
 
@@ -929,14 +1007,19 @@ static void cpu_detect_tlb_amd(struct cpuinfo_x86 *c)
 	if (!(eax & mask)) {
 		/* Erratum 658 */
 		if (c->x86 == 0x15 && c->x86_model <= 0x1f) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			tlb_lli_2m[ENTRIES] = 1024;
 		} else {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			cpuid(0x80000005, &eax, &ebx, &ecx, &edx);
 			tlb_lli_2m[ENTRIES] = eax & 0xff;
 		}
 	} else
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		tlb_lli_2m[ENTRIES] = eax & mask;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	tlb_lli_4m[ENTRIES] = tlb_lli_2m[ENTRIES] >> 1;
 }
 
@@ -1028,11 +1111,13 @@ static bool cpu_has_amd_erratum(struct cpuinfo_x86 *cpu, const int *erratum)
 		    (ms <= AMD_MODEL_RANGE_END(range)))
 			return true;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return false;
 }
 
 void set_dr_addr_mask(unsigned long mask, int dr)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!boot_cpu_has(X86_FEATURE_BPEXT))
 		return;
 
diff --git a/arch/x86/kernel/cpu/aperfmperf.c b/arch/x86/kernel/cpu/aperfmperf.c
index 7eba34d..96f5a6d 100644
--- a/arch/x86/kernel/cpu/aperfmperf.c
+++ b/arch/x86/kernel/cpu/aperfmperf.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * x86 APERF/MPERF KHz calculation for
  * /sys/.../cpufreq/scaling_cur_freq
@@ -39,6 +41,7 @@ static void aperfmperf_snapshot_khz(void *dummy)
 {
 	u64 aperf, aperf_delta;
 	u64 mperf, mperf_delta;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct aperfmperf_sample *s = this_cpu_ptr(&samples);
 	unsigned long flags;
 
@@ -65,6 +68,7 @@ static void aperfmperf_snapshot_khz(void *dummy)
 
 static bool aperfmperf_snapshot_cpu(int cpu, ktime_t now, bool wait)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	s64 time_delta = ktime_ms_delta(now, per_cpu(samples.time, cpu));
 
 	/* Don't bother re-computing within the cache threshold time. */
@@ -80,12 +84,18 @@ static bool aperfmperf_snapshot_cpu(int cpu, ktime_t now, bool wait)
 unsigned int aperfmperf_get_khz(int cpu)
 {
 	if (!cpu_khz)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	if (!static_cpu_has(X86_FEATURE_APERFMPERF))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	aperfmperf_snapshot_cpu(cpu, ktime_get(), true);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return per_cpu(samples.khz, cpu);
 }
 
@@ -96,21 +106,32 @@ void arch_freq_prepare_all(void)
 	int cpu;
 
 	if (!cpu_khz)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	if (!static_cpu_has(X86_FEATURE_APERFMPERF))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for_each_online_cpu(cpu)
 		if (!aperfmperf_snapshot_cpu(cpu, now, false))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			wait = true;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (wait)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		msleep(APERFMPERF_REFRESH_DELAY_MS);
 }
+}
 
 unsigned int arch_freq_get_on_cpu(int cpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!cpu_khz)
 		return 0;
 
diff --git a/arch/x86/kernel/cpu/bugs.c b/arch/x86/kernel/cpu/bugs.c
index d71c8b5..7d616f8 100644
--- a/arch/x86/kernel/cpu/bugs.c
+++ b/arch/x86/kernel/cpu/bugs.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 /*
  *  Copyright (C) 1994  Linus Torvalds
@@ -33,6 +35,7 @@ void __init check_bugs(void)
 	identify_boot_cpu();
 
 	if (!IS_ENABLED(CONFIG_SMP)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_info("CPU: ");
 		print_cpu_info(&boot_cpu_data);
 	}
@@ -118,23 +121,27 @@ static inline const char *spectre_v2_module_string(void) { return ""; }
 
 static void __init spec2_print_if_insecure(const char *reason)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (boot_cpu_has_bug(X86_BUG_SPECTRE_V2))
 		pr_info("%s selected on command line.\n", reason);
 }
 
 static void __init spec2_print_if_secure(const char *reason)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!boot_cpu_has_bug(X86_BUG_SPECTRE_V2))
 		pr_info("%s selected on command line.\n", reason);
 }
 
 static inline bool retp_compiler(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return __is_defined(RETPOLINE);
 }
 
 static inline bool match_option(const char *arg, int arglen, const char *opt)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	int len = strlen(opt);
 
 	return len == arglen && !strncmp(arg, opt, len);
@@ -160,50 +167,68 @@ static enum spectre_v2_mitigation_cmd __init spectre_v2_parse_cmdline(void)
 	enum spectre_v2_mitigation_cmd cmd = SPECTRE_V2_CMD_AUTO;
 
 	if (cmdline_find_option_bool(boot_command_line, "nospectre_v2"))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return SPECTRE_V2_CMD_NONE;
+}
 	else {
 		ret = cmdline_find_option(boot_command_line, "spectre_v2", arg, sizeof(arg));
 		if (ret < 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return SPECTRE_V2_CMD_AUTO;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		for (i = 0; i < ARRAY_SIZE(mitigation_options); i++) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			if (!match_option(arg, ret, mitigation_options[i].option))
 				continue;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			cmd = mitigation_options[i].cmd;
 			break;
 		}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (i >= ARRAY_SIZE(mitigation_options)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			pr_err("unknown option (%s). Switching to AUTO select\n", arg);
 			return SPECTRE_V2_CMD_AUTO;
 		}
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if ((cmd == SPECTRE_V2_CMD_RETPOLINE ||
 	     cmd == SPECTRE_V2_CMD_RETPOLINE_AMD ||
 	     cmd == SPECTRE_V2_CMD_RETPOLINE_GENERIC) &&
 	    !IS_ENABLED(CONFIG_RETPOLINE)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_err("%s selected but not compiled in. Switching to AUTO select\n", mitigation_options[i].option);
 		return SPECTRE_V2_CMD_AUTO;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (cmd == SPECTRE_V2_CMD_RETPOLINE_AMD &&
 	    boot_cpu_data.x86_vendor != X86_VENDOR_AMD) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_err("retpoline,amd selected but CPU is not AMD. Switching to AUTO select\n");
 		return SPECTRE_V2_CMD_AUTO;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (mitigation_options[i].secure)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		spec2_print_if_secure(mitigation_options[i].option);
+}
 	else
 		spec2_print_if_insecure(mitigation_options[i].option);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return cmd;
 }
 
 /* Check for Skylake-like CPUs (for RSB handling) */
 static bool __init is_skylake_era(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (boot_cpu_data.x86_vendor == X86_VENDOR_INTEL &&
 	    boot_cpu_data.x86 == 6) {
 		switch (boot_cpu_data.x86_model) {
@@ -253,6 +278,7 @@ static void __init spectre_v2_select_mitigation(void)
 			goto retpoline_auto;
 		break;
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pr_err("Spectre mitigation: kernel not compiled with retpoline; no mitigation available!");
 	return;
 
@@ -263,14 +289,18 @@ static void __init spectre_v2_select_mitigation(void)
 			pr_err("Spectre mitigation: LFENCE not serializing, switching to generic retpoline\n");
 			goto retpoline_generic;
 		}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		mode = retp_compiler() ? SPECTRE_V2_RETPOLINE_AMD :
 					 SPECTRE_V2_RETPOLINE_MINIMAL_AMD;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		setup_force_cpu_cap(X86_FEATURE_RETPOLINE_AMD);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		setup_force_cpu_cap(X86_FEATURE_RETPOLINE);
 	} else {
 	retpoline_generic:
 		mode = retp_compiler() ? SPECTRE_V2_RETPOLINE_GENERIC :
 					 SPECTRE_V2_RETPOLINE_MINIMAL;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		setup_force_cpu_cap(X86_FEATURE_RETPOLINE);
 	}
 
@@ -291,13 +321,16 @@ static void __init spectre_v2_select_mitigation(void)
 	 */
 	if ((!boot_cpu_has(X86_FEATURE_PTI) &&
 	     !boot_cpu_has(X86_FEATURE_SMEP)) || is_skylake_era()) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		setup_force_cpu_cap(X86_FEATURE_RSB_CTXSW);
 		pr_info("Spectre v2 mitigation: Filling RSB on context switch\n");
 	}
 
 	/* Initialize Indirect Branch Prediction Barrier if supported */
 	if (boot_cpu_has(X86_FEATURE_IBPB)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		setup_force_cpu_cap(X86_FEATURE_USE_IBPB);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_info("Spectre v2 mitigation: Enabling Indirect Branch Prediction Barrier\n");
 	}
 }
@@ -307,6 +340,7 @@ static void __init spectre_v2_select_mitigation(void)
 #ifdef CONFIG_SYSFS
 ssize_t cpu_show_meltdown(struct device *dev, struct device_attribute *attr, char *buf)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!boot_cpu_has_bug(X86_BUG_CPU_MELTDOWN))
 		return sprintf(buf, "Not affected\n");
 	if (boot_cpu_has(X86_FEATURE_PTI))
@@ -316,6 +350,7 @@ ssize_t cpu_show_meltdown(struct device *dev, struct device_attribute *attr, cha
 
 ssize_t cpu_show_spectre_v1(struct device *dev, struct device_attribute *attr, char *buf)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!boot_cpu_has_bug(X86_BUG_SPECTRE_V1))
 		return sprintf(buf, "Not affected\n");
 	return sprintf(buf, "Mitigation: __user pointer sanitization\n");
@@ -323,6 +358,7 @@ ssize_t cpu_show_spectre_v1(struct device *dev, struct device_attribute *attr, c
 
 ssize_t cpu_show_spectre_v2(struct device *dev, struct device_attribute *attr, char *buf)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!boot_cpu_has_bug(X86_BUG_SPECTRE_V2))
 		return sprintf(buf, "Not affected\n");
 
diff --git a/arch/x86/kernel/cpu/common.c b/arch/x86/kernel/cpu/common.c
index 651b7af..9a6b707 100644
--- a/arch/x86/kernel/cpu/common.c
+++ b/arch/x86/kernel/cpu/common.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 #include <linux/bootmem.h>
 #include <linux/linkage.h>
 #include <linux/bitops.h>
@@ -69,6 +71,7 @@ cpumask_var_t cpu_sibling_setup_mask;
 /* correctly size the local cpu masks */
 void __init setup_cpu_local_masks(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	alloc_bootmem_cpumask_var(&cpu_initialized_mask);
 	alloc_bootmem_cpumask_var(&cpu_callin_mask);
 	alloc_bootmem_cpumask_var(&cpu_callout_mask);
@@ -286,6 +289,7 @@ __setup("serialnumber", x86_serial_nr_setup);
 #else
 static inline int flag_is_changeable_p(u32 flag)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 1;
 }
 static inline void squash_the_stupid_serial_number(struct cpuinfo_x86 *c)
@@ -295,6 +299,7 @@ static inline void squash_the_stupid_serial_number(struct cpuinfo_x86 *c)
 
 static __init int setup_disable_smep(char *arg)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	setup_clear_cpu_cap(X86_FEATURE_SMEP);
 	/* Check for things that depend on SMEP being enabled: */
 	check_mpx_erratum(&boot_cpu_data);
@@ -305,11 +310,14 @@ __setup("nosmep", setup_disable_smep);
 static __always_inline void setup_smep(struct cpuinfo_x86 *c)
 {
 	if (cpu_has(c, X86_FEATURE_SMEP))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		cr4_set_bits(X86_CR4_SMEP);
 }
+}
 
 static __init int setup_disable_smap(char *arg)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	setup_clear_cpu_cap(X86_FEATURE_SMAP);
 	return 1;
 }
@@ -322,6 +330,7 @@ static __always_inline void setup_smap(struct cpuinfo_x86 *c)
 	/* This should have been cleared long ago */
 	BUG_ON(eflags & X86_EFLAGS_AC);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (cpu_has(c, X86_FEATURE_SMAP)) {
 #ifdef CONFIG_X86_SMAP
 		cr4_set_bits(X86_CR4_SMAP);
@@ -340,13 +349,21 @@ static __always_inline void setup_pku(struct cpuinfo_x86 *c)
 {
 	/* check the boot processor, plus compile options for PKU: */
 	if (!cpu_feature_enabled(X86_FEATURE_PKU))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 	/* checks the actual processor's cpuid bits: */
 	if (!cpu_has(c, X86_FEATURE_PKU))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (pku_disabled)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	cr4_set_bits(X86_CR4_PKE);
 	/*
 	 * Seting X86_CR4_PKE will cause the X86_FEATURE_OSPKE
@@ -415,10 +432,12 @@ static void filter_cpuid_features(struct cpuinfo_x86 *c, bool warn)
 		     (s32)df->level > (s32)c->cpuid_level))
 			continue;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		clear_cpu_cap(c, df->feature);
 		if (!warn)
 			continue;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_warn("CPU: CPU feature " X86_CAP_FMT " disabled, no CPUID level 0x%x\n",
 			x86_cap_flag(df->feature), df->level);
 	}
@@ -528,7 +547,9 @@ static void get_model_name(struct cpuinfo_x86 *c)
 	char *p, *q, *s;
 
 	if (c->extended_cpuid_level < 0x80000004)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	v = (unsigned int *)c->x86_model_id;
 	cpuid(0x80000002, &v[0], &v[1], &v[2], &v[3]);
@@ -545,7 +566,9 @@ static void get_model_name(struct cpuinfo_x86 *c)
 	while (*p) {
 		/* Note the last non-whitespace index */
 		if (!isspace(*p))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			s = q;
+}
 
 		*q++ = *p++;
 	}
@@ -560,6 +583,7 @@ void cpu_detect_cache_sizes(struct cpuinfo_x86 *c)
 	n = c->extended_cpuid_level;
 
 	if (n >= 0x80000005) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		cpuid(0x80000005, &dummy, &ebx, &ecx, &edx);
 		c->x86_cache_size = (ecx>>24) + (edx>>24);
 #ifdef CONFIG_X86_64
@@ -569,8 +593,11 @@ void cpu_detect_cache_sizes(struct cpuinfo_x86 *c)
 	}
 
 	if (n < 0x80000006)	/* Some chips just has a large L1. */
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	cpuid(0x80000006, &dummy, &ebx, &ecx, &edx);
 	l2size = ecx >> 16;
 
@@ -624,24 +651,32 @@ void detect_ht(struct cpuinfo_x86 *c)
 	if (!cpu_has(c, X86_FEATURE_HT))
 		return;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (cpu_has(c, X86_FEATURE_CMP_LEGACY))
 		goto out;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (cpu_has(c, X86_FEATURE_XTOPOLOGY))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	cpuid(1, &eax, &ebx, &ecx, &edx);
 
 	smp_num_siblings = (ebx & 0xff0000) >> 16;
 
 	if (smp_num_siblings == 1) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_info_once("CPU0: Hyper-Threading is disabled\n");
 		goto out;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (smp_num_siblings <= 1)
 		goto out;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	index_msb = get_count_order(smp_num_siblings);
 	c->phys_proc_id = apic->phys_pkg_id(c->initial_apicid, index_msb);
 
@@ -656,6 +691,7 @@ void detect_ht(struct cpuinfo_x86 *c)
 
 out:
 	if (!printed && (c->x86_max_cores * smp_num_siblings) > 1) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_info("CPU: Physical Processor ID: %d\n",
 			c->phys_proc_id);
 		pr_info("CPU: Processor Core ID: %d\n",
@@ -684,6 +720,7 @@ static void get_cpu_vendor(struct cpuinfo_x86 *c)
 		}
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pr_err_once("CPU: vendor_id '%s' unknown, using generic init.\n" \
 		    "CPU: Your system may be unstable.\n", v);
 
@@ -739,12 +776,15 @@ static void init_speculation_control(struct cpuinfo_x86 *c)
 	 * kernel. So set those accordingly from the Intel bits.
 	 */
 	if (cpu_has(c, X86_FEATURE_SPEC_CTRL)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		set_cpu_cap(c, X86_FEATURE_IBRS);
 		set_cpu_cap(c, X86_FEATURE_IBPB);
 	}
 	if (cpu_has(c, X86_FEATURE_INTEL_STIBP))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		set_cpu_cap(c, X86_FEATURE_STIBP);
 }
+}
 
 void get_cpu_cap(struct cpuinfo_x86 *c)
 {
@@ -752,6 +792,7 @@ void get_cpu_cap(struct cpuinfo_x86 *c)
 
 	/* Intel-defined flags: level 0x00000001 */
 	if (c->cpuid_level >= 0x00000001) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		cpuid(0x00000001, &eax, &ebx, &ecx, &edx);
 
 		c->x86_capability[CPUID_1_ECX] = ecx;
@@ -764,6 +805,7 @@ void get_cpu_cap(struct cpuinfo_x86 *c)
 
 	/* Additional Intel-defined flags: level 0x00000007 */
 	if (c->cpuid_level >= 0x00000007) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		cpuid_count(0x00000007, 0, &eax, &ebx, &ecx, &edx);
 		c->x86_capability[CPUID_7_0_EBX] = ebx;
 		c->x86_capability[CPUID_7_ECX] = ecx;
@@ -772,6 +814,7 @@ void get_cpu_cap(struct cpuinfo_x86 *c)
 
 	/* Extended state features: level 0x0000000d */
 	if (c->cpuid_level >= 0x0000000d) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		cpuid_count(0x0000000d, 1, &eax, &ebx, &ecx, &edx);
 
 		c->x86_capability[CPUID_D_1_EAX] = eax;
@@ -784,6 +827,7 @@ void get_cpu_cap(struct cpuinfo_x86 *c)
 		cpuid_count(0x0000000F, 0, &eax, &ebx, &ecx, &edx);
 		c->x86_capability[CPUID_F_0_EDX] = edx;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (cpu_has(c, X86_FEATURE_CQM_LLC)) {
 			/* will be overridden if occupancy monitoring exists */
 			c->x86_cache_max_rmid = ebx;
@@ -792,13 +836,16 @@ void get_cpu_cap(struct cpuinfo_x86 *c)
 			cpuid_count(0x0000000F, 1, &eax, &ebx, &ecx, &edx);
 			c->x86_capability[CPUID_F_1_EDX] = edx;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			if ((cpu_has(c, X86_FEATURE_CQM_OCCUP_LLC)) ||
 			      ((cpu_has(c, X86_FEATURE_CQM_MBM_TOTAL)) ||
 			       (cpu_has(c, X86_FEATURE_CQM_MBM_LOCAL)))) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				c->x86_cache_max_rmid = ecx;
 				c->x86_cache_occ_scale = ebx;
 			}
 		} else {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			c->x86_cache_max_rmid = -1;
 			c->x86_cache_occ_scale = -1;
 		}
@@ -810,6 +857,7 @@ void get_cpu_cap(struct cpuinfo_x86 *c)
 
 	if ((eax & 0xffff0000) == 0x80000000) {
 		if (eax >= 0x80000001) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			cpuid(0x80000001, &eax, &ebx, &ecx, &edx);
 
 			c->x86_capability[CPUID_8000_0001_ECX] = ecx;
@@ -818,6 +866,7 @@ void get_cpu_cap(struct cpuinfo_x86 *c)
 	}
 
 	if (c->extended_cpuid_level >= 0x80000007) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		cpuid(0x80000007, &eax, &ebx, &ecx, &edx);
 
 		c->x86_capability[CPUID_8000_0007_EBX] = ebx;
@@ -825,6 +874,7 @@ void get_cpu_cap(struct cpuinfo_x86 *c)
 	}
 
 	if (c->extended_cpuid_level >= 0x80000008) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		cpuid(0x80000008, &eax, &ebx, &ecx, &edx);
 
 		c->x86_virt_bits = (eax >> 8) & 0xff;
@@ -899,15 +949,23 @@ static bool __init cpu_vulnerable_to_meltdown(struct cpuinfo_x86 *c)
 	u64 ia32_cap = 0;
 
 	if (x86_match_cpu(cpu_no_meltdown))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return false;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (cpu_has(c, X86_FEATURE_ARCH_CAPABILITIES))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		rdmsrl(MSR_IA32_ARCH_CAPABILITIES, ia32_cap);
+}
 
 	/* Rogue Data Cache Load? No! */
 	if (ia32_cap & ARCH_CAP_RDCL_NO)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return false;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return true;
 }
 
@@ -941,6 +999,7 @@ static void __init early_identify_cpu(struct cpuinfo_x86 *c)
 		cpu_detect(c);
 		get_cpu_vendor(c);
 		get_cpu_cap(c);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		setup_force_cpu_cap(X86_FEATURE_CPUID);
 
 		if (this_cpu->c_early_init)
@@ -952,16 +1011,22 @@ static void __init early_identify_cpu(struct cpuinfo_x86 *c)
 		if (this_cpu->c_bsp_init)
 			this_cpu->c_bsp_init(c);
 	} else {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		identify_cpu_without_cpuid(c);
 		setup_clear_cpu_cap(X86_FEATURE_CPUID);
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	setup_force_cpu_cap(X86_FEATURE_ALWAYS);
 
 	if (!x86_match_cpu(cpu_no_speculation)) {
 		if (cpu_vulnerable_to_meltdown(c))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			setup_force_cpu_bug(X86_BUG_CPU_MELTDOWN);
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		setup_force_cpu_bug(X86_BUG_SPECTRE_V1);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		setup_force_cpu_bug(X86_BUG_SPECTRE_V2);
 	}
 
@@ -1051,7 +1116,9 @@ static void detect_null_seg_behavior(struct cpuinfo_x86 *c)
 	loadsegment(fs, 0);
 	rdmsrl(MSR_FS_BASE, tmp);
 	if (tmp != 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		set_cpu_bug(c, X86_BUG_NULL_SEG);
+}
 	wrmsrl(MSR_FS_BASE, old_base);
 #endif
 }
@@ -1061,11 +1128,15 @@ static void generic_identify(struct cpuinfo_x86 *c)
 	c->extended_cpuid_level = 0;
 
 	if (!have_cpuid_p())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		identify_cpu_without_cpuid(c);
+}
 
 	/* cyrix could have cpuid enabled via c_identify()*/
 	if (!have_cpuid_p())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	cpu_detect(c);
 
@@ -1184,7 +1255,9 @@ static void identify_cpu(struct cpuinfo_x86 *c)
 	generic_identify(c);
 
 	if (this_cpu->c_identify)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		this_cpu->c_identify(c);
+}
 
 	/* Clear/Set all flags overridden by options, after probe */
 	apply_forced_caps(c);
@@ -1226,7 +1299,9 @@ static void identify_cpu(struct cpuinfo_x86 *c)
 		const char *p;
 		p = table_lookup_model(c);
 		if (p)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			strcpy(c->x86_model_id, p);
+}
 		else
 			/* Last resort... */
 			sprintf(c->x86_model_id, "%02x/%02x",
@@ -1256,11 +1331,15 @@ static void identify_cpu(struct cpuinfo_x86 *c)
 	if (c != &boot_cpu_data) {
 		/* AND the already accumulated flags with these */
 		for (i = 0; i < NCAPINTS; i++)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			boot_cpu_data.x86_capability[i] &= c->x86_capability[i];
+}
 
 		/* OR, i.e. replicate the bug flags */
 		for (i = NCAPINTS; i < NCAPINTS + NBUGINTS; i++)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			c->x86_capability[i] |= boot_cpu_data.x86_capability[i];
+}
 	}
 
 	/* Init Machine Check Exception if available. */
@@ -1315,6 +1394,7 @@ void __init identify_boot_cpu(void)
 
 void identify_secondary_cpu(struct cpuinfo_x86 *c)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	BUG_ON(c == &boot_cpu_data);
 	identify_cpu(c);
 #ifdef CONFIG_X86_32
@@ -1326,6 +1406,7 @@ void identify_secondary_cpu(struct cpuinfo_x86 *c)
 
 static __init int setup_noclflush(char *arg)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	setup_clear_cpu_cap(X86_FEATURE_CLFLUSH);
 	setup_clear_cpu_cap(X86_FEATURE_CLFLUSHOPT);
 	return 1;
@@ -1339,8 +1420,11 @@ void print_cpu_info(struct cpuinfo_x86 *c)
 	if (c->x86_vendor < X86_VENDOR_NUM) {
 		vendor = this_cpu->c_vendor;
 	} else {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (c->cpuid_level >= 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			vendor = c->x86_vendor_id;
+}
 	}
 
 	if (vendor && !strstr(c->x86_model_id, vendor))
@@ -1366,6 +1450,7 @@ void print_cpu_info(struct cpuinfo_x86 *c)
  */
 static __init int setup_clearcpuid(char *arg)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 1;
 }
 __setup("clearcpuid=", setup_clearcpuid);
@@ -1403,7 +1488,9 @@ void syscall_init(void)
 
 	wrmsr(MSR_STAR, 0, (__USER32_CS << 16) | __KERNEL_CS);
 	if (static_cpu_has(X86_FEATURE_PTI))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		wrmsrl(MSR_LSTAR, SYSCALL64_entry_trampoline);
+}
 	else
 		wrmsrl(MSR_LSTAR, (unsigned long)entry_SYSCALL_64);
 
@@ -1442,6 +1529,7 @@ DEFINE_PER_CPU(int, debug_stack_usage);
 
 int is_debug_stack(unsigned long addr)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return __this_cpu_read(debug_stack_usage) ||
 		(addr <= __this_cpu_read(debug_stack_addr) &&
 		 addr > (__this_cpu_read(debug_stack_addr) - DEBUG_STKSZ));
@@ -1452,6 +1540,7 @@ DEFINE_PER_CPU(u32, debug_idt_ctr);
 
 void debug_stack_set_zero(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	this_cpu_inc(debug_idt_ctr);
 	load_current_idt();
 }
@@ -1459,6 +1548,7 @@ NOKPROBE_SYMBOL(debug_stack_set_zero);
 
 void debug_stack_reset(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (WARN_ON(!this_cpu_read(debug_idt_ctr)))
 		return;
 	if (this_cpu_dec_return(debug_idt_ctr) == 0)
@@ -1558,7 +1648,9 @@ void cpu_init(void)
 	cr4_init_shadow();
 
 	if (cpu)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		load_ucode_ap();
+}
 
 	t = &per_cpu(cpu_tss_rw, cpu);
 	oist = &per_cpu(orig_ist, cpu);
@@ -1569,8 +1661,10 @@ void cpu_init(void)
 		set_numa_node(early_cpu_to_node(cpu));
 #endif
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	me = current;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pr_debug("Initializing CPU#%d\n", cpu);
 
 	cr4_clear_bits(X86_CR4_VME|X86_CR4_PVI|X86_CR4_TSD|X86_CR4_DE);
@@ -1641,7 +1735,9 @@ void cpu_init(void)
 	fpu__init_cpu();
 
 	if (is_uv_system())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		uv_cpu_init();
+}
 
 	load_fixmap_gdt(cpu);
 }
@@ -1710,6 +1806,7 @@ void cpu_init(void)
 
 static void bsp_resume(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (this_cpu->c_bsp_resume)
 		this_cpu->c_bsp_resume(&boot_cpu_data);
 }
diff --git a/arch/x86/kernel/cpu/cpuid-deps.c b/arch/x86/kernel/cpu/cpuid-deps.c
index 904b0a3c4..042cf0d 100644
--- a/arch/x86/kernel/cpu/cpuid-deps.c
+++ b/arch/x86/kernel/cpu/cpuid-deps.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /* Declare dependencies between CPUIDs */
 #include <linux/kernel.h>
 #include <linux/init.h>
@@ -70,6 +72,7 @@ static inline void clear_feature(struct cpuinfo_x86 *c, unsigned int feature)
 	 * consistency. Cleanup all of it separately.
 	 */
 	if (!c) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		clear_cpu_cap(&boot_cpu_data, feature);
 		set_bit(feature, (unsigned long *)cpu_caps_cleared);
 	} else {
@@ -87,7 +90,9 @@ static void do_clear_cpu_cap(struct cpuinfo_x86 *c, unsigned int feature)
 	bool changed;
 
 	if (WARN_ON(feature >= MAX_FEATURE_BITS))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	clear_feature(c, feature);
 
@@ -97,13 +102,16 @@ static void do_clear_cpu_cap(struct cpuinfo_x86 *c, unsigned int feature)
 
 	/* Loop until we get a stable state. */
 	do {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		changed = false;
 		for (d = cpuid_deps; d->feature; d++) {
 			if (!test_bit(d->depends, disable))
 				continue;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			if (__test_and_set_bit(d->feature, disable))
 				continue;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			changed = true;
 			clear_feature(c, d->feature);
 		}
@@ -117,5 +125,6 @@ void clear_cpu_cap(struct cpuinfo_x86 *c, unsigned int feature)
 
 void setup_clear_cpu_cap(unsigned int feature)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	do_clear_cpu_cap(NULL, feature);
 }
diff --git a/arch/x86/kernel/cpu/hypervisor.c b/arch/x86/kernel/cpu/hypervisor.c
index bea8d3e..abba57c 100644
--- a/arch/x86/kernel/cpu/hypervisor.c
+++ b/arch/x86/kernel/cpu/hypervisor.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * Common hypervisor code
  *
diff --git a/arch/x86/kernel/cpu/intel_cacheinfo.c b/arch/x86/kernel/cpu/intel_cacheinfo.c
index 54d04d5..92013af 100644
--- a/arch/x86/kernel/cpu/intel_cacheinfo.c
+++ b/arch/x86/kernel/cpu/intel_cacheinfo.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 /*
  *	Routines to identify caches on Intel CPU.
@@ -247,7 +249,9 @@ amd_cpuid4(int leaf, union _cpuid4_leaf_eax *eax,
 		l1 = &l1i;
 	case 0:
 		if (!l1->val)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return;
+}
 		assoc = assocs[l1->assoc];
 		line_size = l1->line_size;
 		lines_per_tag = l1->lines_per_tag;
@@ -255,7 +259,9 @@ amd_cpuid4(int leaf, union _cpuid4_leaf_eax *eax,
 		break;
 	case 2:
 		if (!l2.val)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return;
+}
 		assoc = assocs[l2.assoc];
 		line_size = l2.line_size;
 		lines_per_tag = l2.lines_per_tag;
@@ -264,12 +270,17 @@ amd_cpuid4(int leaf, union _cpuid4_leaf_eax *eax,
 		break;
 	case 3:
 		if (!l3.val)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		assoc = assocs[l3.assoc];
 		line_size = l3.line_size;
 		lines_per_tag = l3.lines_per_tag;
 		size_in_kb = l3.size_encoded * 512;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (boot_cpu_has(X86_FEATURE_AMD_DCM)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			size_in_kb = size_in_kb >> 1;
 			assoc = assoc >> 1;
 		}
@@ -286,7 +297,9 @@ amd_cpuid4(int leaf, union _cpuid4_leaf_eax *eax,
 
 
 	if (assoc == 0xffff)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		eax->split.is_fully_associative = 1;
+}
 	ebx->split.coherency_line_size = line_size - 1;
 	ebx->split.ways_of_associativity = assoc - 1;
 	ebx->split.physical_line_partition = lines_per_tag - 1;
@@ -312,6 +325,7 @@ static void amd_calc_l3_indices(struct amd_northbridge *nb)
 	l3->subcaches[1] = sc1 = !(val & BIT(4));
 
 	if (boot_cpu_data.x86 == 0x15) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		l3->subcaches[0] = sc0 += !(val & BIT(1));
 		l3->subcaches[1] = sc1 += !(val & BIT(5));
 	}
@@ -337,7 +351,9 @@ static int amd_get_l3_disable_slot(struct amd_northbridge *nb, unsigned slot)
 
 	/* check whether this slot is activated already */
 	if (reg & (3UL << 30))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return reg & 0xfff;
+}
 
 	return -1;
 }
@@ -350,7 +366,9 @@ static ssize_t show_cache_disable(struct cacheinfo *this_leaf, char *buf,
 
 	index = amd_get_l3_disable_slot(nb, slot);
 	if (index >= 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return sprintf(buf, "%d\n", index);
+}
 
 	return sprintf(buf, "FREE\n");
 }
@@ -414,7 +432,9 @@ static int amd_set_l3_disable_slot(struct amd_northbridge *nb, int cpu,
 	/*  check if @slot is already used or the index is already disabled */
 	ret = amd_get_l3_disable_slot(nb, slot);
 	if (ret >= 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EEXIST;
+}
 
 	if (index > nb->l3_cache.indices)
 		return -EINVAL;
@@ -437,7 +457,9 @@ static ssize_t store_cache_disable(struct cacheinfo *this_leaf,
 	struct amd_northbridge *nb = this_leaf->priv;
 
 	if (!capable(CAP_SYS_ADMIN))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EPERM;
+}
 
 	cpu = cpumask_first(&this_leaf->shared_cpu_map);
 
@@ -469,6 +491,7 @@ STORE_CACHE_DISABLE(1)
 static ssize_t subcaches_show(struct device *dev,
 			      struct device_attribute *attr, char *buf)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cacheinfo *this_leaf = dev_get_drvdata(dev);
 	int cpu = cpumask_first(&this_leaf->shared_cpu_map);
 
@@ -479,6 +502,7 @@ static ssize_t subcaches_store(struct device *dev,
 			       struct device_attribute *attr,
 			       const char *buf, size_t count)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cacheinfo *this_leaf = dev_get_drvdata(dev);
 	int cpu = cpumask_first(&this_leaf->shared_cpu_map);
 	unsigned long val;
@@ -503,6 +527,7 @@ static umode_t
 cache_private_attrs_is_visible(struct kobject *kobj,
 			       struct attribute *attr, int unused)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct device *dev = kobj_to_dev(kobj);
 	struct cacheinfo *this_leaf = dev_get_drvdata(dev);
 	umode_t mode = attr->mode;
@@ -532,7 +557,9 @@ static void init_amd_l3_attrs(void)
 	static struct attribute **amd_l3_attrs;
 
 	if (amd_l3_attrs) /* already initialized */
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	if (amd_nb_has_feature(AMD_NB_L3_INDEX_DISABLE))
 		n += 2;
@@ -560,11 +587,17 @@ cache_get_priv_group(struct cacheinfo *this_leaf)
 	struct amd_northbridge *nb = this_leaf->priv;
 
 	if (this_leaf->level < 3 || !nb)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (nb && nb->l3_cache.indices)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		init_amd_l3_attrs();
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return &cache_private_group;
 }
 
@@ -574,13 +607,19 @@ static void amd_init_l3_cache(struct _cpuid4_info_regs *this_leaf, int index)
 
 	/* only for L3, and not in virtualized environments */
 	if (index < 3)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	node = amd_get_nb_id(smp_processor_id());
 	this_leaf->nb = node_to_amd_nb(node);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (this_leaf->nb && !this_leaf->nb->l3_cache.indices)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		amd_calc_l3_indices(this_leaf->nb);
 }
+}
 #else
 #define amd_init_l3_cache(x, y)
 #endif  /* CONFIG_AMD_NB && CONFIG_SYSFS */
@@ -595,17 +634,22 @@ cpuid4_cache_lookup_regs(int index, struct _cpuid4_info_regs *this_leaf)
 
 	if (boot_cpu_data.x86_vendor == X86_VENDOR_AMD) {
 		if (boot_cpu_has(X86_FEATURE_TOPOEXT))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			cpuid_count(0x8000001d, index, &eax.full,
 				    &ebx.full, &ecx.full, &edx);
+}
 		else
 			amd_cpuid4(index, &eax, &ebx, &ecx);
 		amd_init_l3_cache(this_leaf, index);
 	} else {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		cpuid_count(4, index, &eax.full, &ebx.full, &ecx.full, &edx);
 	}
 
 	if (eax.split.type == CTYPE_NULL)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EIO; /* better error ? */
+}
 
 	this_leaf->eax = eax;
 	this_leaf->ebx = ebx;
@@ -624,7 +668,9 @@ static int find_num_cache_leaves(struct cpuinfo_x86 *c)
 	int 			i = -1;
 
 	if (c->x86_vendor == X86_VENDOR_AMD)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		op = 0x8000001d;
+}
 	else
 		op = 4;
 
@@ -641,10 +687,13 @@ void init_amd_cacheinfo(struct cpuinfo_x86 *c)
 {
 
 	if (boot_cpu_has(X86_FEATURE_TOPOEXT)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		num_cache_leaves = find_num_cache_leaves(c);
 	} else if (c->extended_cpuid_level >= 0x80000006) {
 		if (cpuid_edx(0x80000006) & 0xf000)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			num_cache_leaves = 4;
+}
 		else
 			num_cache_leaves = 3;
 	}
@@ -817,14 +866,20 @@ static int __cache_amd_cpumap_setup(unsigned int cpu, int index,
 	 * to derive shared_cpu_map.
 	 */
 	if (index == 3) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		for_each_cpu(i, cpu_llc_shared_mask(cpu)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			this_cpu_ci = get_cpu_cacheinfo(i);
 			if (!this_cpu_ci->info_list)
 				continue;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			this_leaf = this_cpu_ci->info_list + index;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			for_each_cpu(sibling, cpu_llc_shared_mask(cpu)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				if (!cpu_online(sibling))
 					continue;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				cpumask_set_cpu(sibling,
 						&this_leaf->shared_cpu_map);
 			}
@@ -833,32 +888,45 @@ static int __cache_amd_cpumap_setup(unsigned int cpu, int index,
 		unsigned int apicid, nshared, first, last;
 
 		nshared = base->eax.split.num_threads_sharing + 1;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		apicid = cpu_data(cpu).apicid;
 		first = apicid - (apicid % nshared);
 		last = first + nshared - 1;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		for_each_online_cpu(i) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			this_cpu_ci = get_cpu_cacheinfo(i);
 			if (!this_cpu_ci->info_list)
 				continue;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			apicid = cpu_data(i).apicid;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			if ((apicid < first) || (apicid > last))
 				continue;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			this_leaf = this_cpu_ci->info_list + index;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			for_each_online_cpu(sibling) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				apicid = cpu_data(sibling).apicid;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				if ((apicid < first) || (apicid > last))
 					continue;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				cpumask_set_cpu(sibling,
 						&this_leaf->shared_cpu_map);
 			}
 		}
 	} else
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 1;
 }
 
@@ -873,7 +941,9 @@ static void __cache_cpumap_setup(unsigned int cpu, int index,
 
 	if (c->x86_vendor == X86_VENDOR_AMD) {
 		if (__cache_amd_cpumap_setup(cpu, index, base))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return;
+}
 	}
 
 	this_leaf = this_cpu_ci->info_list + index;
@@ -881,16 +951,23 @@ static void __cache_cpumap_setup(unsigned int cpu, int index,
 
 	cpumask_set_cpu(cpu, &this_leaf->shared_cpu_map);
 	if (num_threads_sharing == 1)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	index_msb = get_count_order(num_threads_sharing);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for_each_online_cpu(i)
 		if (cpu_data(i).apicid >> index_msb == c->apicid >> index_msb) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			struct cpu_cacheinfo *sib_cpu_ci = get_cpu_cacheinfo(i);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			if (i == cpu || !sib_cpu_ci->info_list)
 				continue;/* skip if itself or no cacheinfo */
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			sibling_leaf = sib_cpu_ci->info_list + index;
 			cpumask_set_cpu(i, &this_leaf->shared_cpu_map);
 			cpumask_set_cpu(cpu, &sibling_leaf->shared_cpu_map);
@@ -920,9 +997,13 @@ static int __init_cache_level(unsigned int cpu)
 	struct cpu_cacheinfo *this_cpu_ci = get_cpu_cacheinfo(cpu);
 
 	if (!num_cache_leaves)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOENT;
+}
 	if (!this_cpu_ci)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 	this_cpu_ci->num_levels = 3;
 	this_cpu_ci->num_leaves = num_cache_leaves;
 	return 0;
@@ -954,7 +1035,9 @@ static int __populate_cache_leaves(unsigned int cpu)
 	for (idx = 0; idx < this_cpu_ci->num_leaves; idx++) {
 		ret = cpuid4_cache_lookup_regs(idx, &id4_regs);
 		if (ret)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return ret;
+}
 		get_cache_id(cpu, &id4_regs);
 		ci_leaf_init(this_leaf++, &id4_regs);
 		__cache_cpumap_setup(cpu, idx, &id4_regs);
diff --git a/arch/x86/kernel/cpu/match.c b/arch/x86/kernel/cpu/match.c
index 3fed388..4b58732 100644
--- a/arch/x86/kernel/cpu/match.c
+++ b/arch/x86/kernel/cpu/match.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 #include <asm/cpu_device_id.h>
 #include <asm/cpufeature.h>
@@ -43,8 +45,10 @@ const struct x86_cpu_id *x86_match_cpu(const struct x86_cpu_id *match)
 			continue;
 		if (m->feature != X86_FEATURE_ANY && !cpu_has(c, m->feature))
 			continue;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return m;
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return NULL;
 }
 EXPORT_SYMBOL(x86_match_cpu);
diff --git a/arch/x86/kernel/cpu/microcode/core.c b/arch/x86/kernel/cpu/microcode/core.c
index e4fc595..f551cd1 100644
--- a/arch/x86/kernel/cpu/microcode/core.c
+++ b/arch/x86/kernel/cpu/microcode/core.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * CPU Microcode Update Driver for Linux
  *
@@ -93,6 +95,7 @@ static bool amd_check_current_patch_level(void)
 	u32 lvl, dummy, i;
 	u32 *levels;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	native_rdmsr(MSR_AMD64_PATCH_LEVEL, lvl, dummy);
 
 	if (IS_ENABLED(CONFIG_X86_32))
@@ -128,7 +131,9 @@ static bool __init check_loader_disabled_bsp(void)
 	 * that's good enough as they don't land on the BSP path anyway.
 	 */
 	if (native_cpuid_ecx(1) & BIT(31))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return *res;
+}
 
 	if (x86_cpuid_vendor() == X86_VENDOR_AMD) {
 		if (amd_check_current_patch_level())
@@ -149,6 +154,7 @@ bool get_builtin_firmware(struct cpio_data *cd, const char *name)
 #ifdef CONFIG_FW_LOADER
 	struct builtin_fw *b_fw;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (b_fw = __start_builtin_fw; b_fw != __end_builtin_fw; b_fw++) {
 		if (!strcmp(name, b_fw->name)) {
 			cd->size = b_fw->size;
@@ -166,19 +172,27 @@ void __init load_ucode_bsp(void)
 	bool intel = true;
 
 	if (!have_cpuid_p())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	cpuid_1_eax = native_cpuid_eax(1);
 
 	switch (x86_cpuid_vendor()) {
 	case X86_VENDOR_INTEL:
 		if (x86_family(cpuid_1_eax) < 6)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return;
+}
 		break;
 
 	case X86_VENDOR_AMD:
 		if (x86_family(cpuid_1_eax) < 0x10)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		intel = false;
 		break;
 
@@ -186,11 +200,17 @@ void __init load_ucode_bsp(void)
 		return;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (check_loader_disabled_bsp())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (intel)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		load_ucode_intel_bsp();
+}
 	else
 		load_ucode_amd_bsp(cpuid_1_eax);
 }
@@ -209,7 +229,9 @@ void load_ucode_ap(void)
 	unsigned int cpuid_1_eax;
 
 	if (check_loader_disabled_ap())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	cpuid_1_eax = native_cpuid_eax(1);
 
@@ -235,11 +257,15 @@ static int __init save_microcode_in_initrd(void)
 	switch (c->x86_vendor) {
 	case X86_VENDOR_INTEL:
 		if (c->x86 >= 6)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			ret = save_microcode_in_initrd_intel();
+}
 		break;
 	case X86_VENDOR_AMD:
 		if (c->x86 >= 0x10)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			ret = save_microcode_in_initrd_amd(cpuid_eax(1));
+}
 		break;
 	default:
 		break;
@@ -278,6 +304,7 @@ struct cpio_data find_microcode_in_initrd(const char *path, bool use_pa)
 	size |= boot_params.hdr.ramdisk_size;
 
 	if (size) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		start  = (unsigned long)boot_params.ext_ramdisk_image << 32;
 		start |= boot_params.hdr.ramdisk_image;
 
@@ -343,6 +370,7 @@ static void collect_cpu_info_local(void *arg)
 {
 	struct cpu_info_ctx *ctx = arg;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	ctx->err = microcode_ops->collect_cpu_info(smp_processor_id(),
 						   ctx->cpu_sig);
 }
@@ -354,7 +382,9 @@ static int collect_cpu_info_on_target(int cpu, struct cpu_signature *cpu_sig)
 
 	ret = smp_call_function_single(cpu, collect_cpu_info_local, &ctx, 1);
 	if (!ret)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ret = ctx.err;
+}
 
 	return ret;
 }
@@ -368,7 +398,9 @@ static int collect_cpu_info(int cpu)
 
 	ret = collect_cpu_info_on_target(cpu, &uci->cpu_sig);
 	if (!ret)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		uci->valid = 1;
+}
 
 	return ret;
 }
@@ -381,6 +413,7 @@ static void apply_microcode_local(void *arg)
 {
 	struct apply_microcode_ctx *ctx = arg;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	ctx->err = microcode_ops->apply_microcode(smp_processor_id());
 }
 
@@ -391,7 +424,9 @@ static int apply_microcode_on_target(int cpu)
 
 	ret = smp_call_function_single(cpu, apply_microcode_local, &ctx, 1);
 	if (!ret)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ret = ctx.err;
+}
 
 	return ret;
 }
@@ -402,6 +437,7 @@ static int do_microcode_update(const void __user *buf, size_t size)
 	int error = 0;
 	int cpu;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for_each_online_cpu(cpu) {
 		struct ucode_cpu_info *uci = ucode_cpu_info + cpu;
 		enum ucode_state ustate;
@@ -422,6 +458,7 @@ static int do_microcode_update(const void __user *buf, size_t size)
 
 static int microcode_open(struct inode *inode, struct file *file)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return capable(CAP_SYS_RAWIO) ? nonseekable_open(inode, file) : -EPERM;
 }
 
@@ -431,6 +468,7 @@ static ssize_t microcode_write(struct file *file, const char __user *buf,
 	ssize_t ret = -EINVAL;
 
 	if ((len >> PAGE_SHIFT) > totalram_pages) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_err("too much data (max %ld pages)\n", totalram_pages);
 		return ret;
 	}
@@ -470,6 +508,7 @@ static int __init microcode_dev_init(void)
 
 	error = misc_register(&microcode_dev);
 	if (error) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_err("can't misc_register on minor=%d\n", MICROCODE_MINOR);
 		return error;
 	}
@@ -479,6 +518,7 @@ static int __init microcode_dev_init(void)
 
 static void __exit microcode_dev_exit(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	misc_deregister(&microcode_dev);
 }
 #else
@@ -496,7 +536,9 @@ static int reload_for_cpu(int cpu)
 	int err = 0;
 
 	if (!uci->valid)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return err;
+}
 
 	ustate = microcode_ops->request_microcode_fw(cpu, &microcode_pdev->dev, true);
 	if (ustate == UCODE_OK)
@@ -517,7 +559,9 @@ static ssize_t reload_store(struct device *dev,
 
 	ret = kstrtoul(buf, 0, &val);
 	if (ret)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ret;
+}
 
 	if (val != 1)
 		return size;
@@ -577,12 +621,14 @@ static const struct attribute_group mc_attr_group = {
 
 static void microcode_fini_cpu(int cpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (microcode_ops->microcode_fini_cpu)
 		microcode_ops->microcode_fini_cpu(cpu);
 }
 
 static enum ucode_state microcode_resume_cpu(int cpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (apply_microcode_on_target(cpu))
 		return UCODE_ERROR;
 
@@ -597,7 +643,9 @@ static enum ucode_state microcode_init_cpu(int cpu, bool refresh_fw)
 	struct ucode_cpu_info *uci = ucode_cpu_info + cpu;
 
 	if (uci->valid)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return UCODE_OK;
+}
 
 	if (collect_cpu_info(cpu))
 		return UCODE_ERROR;
@@ -625,7 +673,9 @@ static enum ucode_state microcode_update_cpu(int cpu)
 	collect_cpu_info(cpu);
 
 	if (uci->valid)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return microcode_resume_cpu(cpu);
+}
 
 	return microcode_init_cpu(cpu, false);
 }
@@ -635,7 +685,9 @@ static int mc_device_add(struct device *dev, struct subsys_interface *sif)
 	int err, cpu = dev->id;
 
 	if (!cpu_online(cpu))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	pr_debug("CPU%d added\n", cpu);
 
@@ -654,7 +706,9 @@ static void mc_device_remove(struct device *dev, struct subsys_interface *sif)
 	int cpu = dev->id;
 
 	if (!cpu_online(cpu))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	pr_debug("CPU%d removed\n", cpu);
 	microcode_fini_cpu(cpu);
@@ -673,6 +727,7 @@ static struct subsys_interface mc_cpu_interface = {
  */
 static void mc_bp_resume(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	int cpu = smp_processor_id();
 	struct ucode_cpu_info *uci = ucode_cpu_info + cpu;
 
@@ -692,6 +747,7 @@ static int mc_cpu_online(unsigned int cpu)
 
 	dev = get_cpu_device(cpu);
 	microcode_update_cpu(cpu);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pr_debug("CPU%d added\n", cpu);
 
 	if (sysfs_create_group(&dev->kobj, &mc_attr_group))
@@ -706,6 +762,7 @@ static int mc_cpu_down_prep(unsigned int cpu)
 	dev = get_cpu_device(cpu);
 	/* Suspend is in progress, only remove the interface */
 	sysfs_remove_group(&dev->kobj, &mc_attr_group);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pr_debug("CPU%d removed\n", cpu);
 
 	return 0;
@@ -727,47 +784,69 @@ int __init microcode_init(void)
 	int error;
 
 	if (dis_ucode_ldr)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (c->x86_vendor == X86_VENDOR_INTEL)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		microcode_ops = init_intel_microcode();
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	else if (c->x86_vendor == X86_VENDOR_AMD)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		microcode_ops = init_amd_microcode();
+}
 	else
 		pr_err("no support for this CPU vendor\n");
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!microcode_ops)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENODEV;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	microcode_pdev = platform_device_register_simple("microcode", -1,
 							 NULL, 0);
 	if (IS_ERR(microcode_pdev))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return PTR_ERR(microcode_pdev);
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	get_online_cpus();
 	mutex_lock(&microcode_mutex);
 
 	error = subsys_interface_register(&mc_cpu_interface);
 	if (!error)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		perf_check_microcode();
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	mutex_unlock(&microcode_mutex);
 	put_online_cpus();
 
 	if (error)
 		goto out_pdev;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	error = sysfs_create_group(&cpu_subsys.dev_root->kobj,
 				   &cpu_root_microcode_group);
 
 	if (error) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_err("Error creating microcode group!\n");
 		goto out_driver;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	error = microcode_dev_init();
 	if (error)
 		goto out_ucode_group;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	register_syscore_ops(&mc_syscore_ops);
 	cpuhp_setup_state_nocalls(CPUHP_AP_ONLINE_DYN, "x86/microcode:online",
 				  mc_cpu_online, mc_cpu_down_prep);
diff --git a/arch/x86/kernel/cpu/mshyperv.c b/arch/x86/kernel/cpu/mshyperv.c
index 85eb5fc..219ffd7 100644
--- a/arch/x86/kernel/cpu/mshyperv.c
+++ b/arch/x86/kernel/cpu/mshyperv.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * HyperV  Detection code.
  *
diff --git a/arch/x86/kernel/cpu/mtrr/cleanup.c b/arch/x86/kernel/cpu/mtrr/cleanup.c
index 765afd5..be404a9 100644
--- a/arch/x86/kernel/cpu/mtrr/cleanup.c
+++ b/arch/x86/kernel/cpu/mtrr/cleanup.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * MTRR (Memory Type Range Register) cleanup
  *
@@ -70,6 +72,7 @@ x86_get_mtrr_mem_range(struct range *range, int nr_range,
 	mtrr_type type;
 	int i;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (i = 0; i < num_var_ranges; i++) {
 		type = range_state[i].type;
 		if (type != MTRR_TYPE_WRBACK)
@@ -805,6 +808,7 @@ int __init mtrr_cleanup(unsigned address_bits)
 #else
 int __init mtrr_cleanup(unsigned address_bits)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 #endif
@@ -813,6 +817,7 @@ static int disable_mtrr_trim;
 
 static int __init disable_mtrr_trim_setup(char *str)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	disable_mtrr_trim = 1;
 	return 0;
 }
@@ -832,12 +837,18 @@ int __init amd_special_default_mtrr(void)
 	u32 l, h;
 
 	if (boot_cpu_data.x86_vendor != X86_VENDOR_AMD)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 	if (boot_cpu_data.x86 < 0xf)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 	/* In case some hypervisor doesn't pass SYSCFG through: */
 	if (rdmsr_safe(MSR_K8_SYSCFG, &l, &h) < 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 	/*
 	 * Memory between 4GB and top of mem is forced WB by this magic bit.
 	 * Reserved before K8RevF, but should be zero there.
@@ -845,6 +856,7 @@ int __init amd_special_default_mtrr(void)
 	if ((l & (Tom2Enabled | Tom2ForceMemTypeWB)) ==
 		 (Tom2Enabled | Tom2ForceMemTypeWB))
 		return 1;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
@@ -887,16 +899,22 @@ int __init mtrr_trim_uncached_memory(unsigned long end_pfn)
 	 * support the Intel MTRR architecture:
 	 */
 	if (!is_cpu(INTEL) || disable_mtrr_trim)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	rdmsr(MSR_MTRRdefType, def, dummy);
 	def &= 0xff;
 	if (def != MTRR_TYPE_UNCACHABLE)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	/* Get it and store it aside: */
 	memset(range_state, 0, sizeof(range_state));
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (i = 0; i < num_var_ranges; i++) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		mtrr_if->get(i, &base, &size, &type);
 		range_state[i].base_pfn = base;
 		range_state[i].size_pfn = size;
@@ -905,83 +923,115 @@ int __init mtrr_trim_uncached_memory(unsigned long end_pfn)
 
 	/* Find highest cached pfn: */
 	for (i = 0; i < num_var_ranges; i++) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		type = range_state[i].type;
 		if (type != MTRR_TYPE_WRBACK)
 			continue;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		base = range_state[i].base_pfn;
 		size = range_state[i].size_pfn;
 		if (highest_pfn < base + size)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			highest_pfn = base + size;
+}
 	}
 
 	/* kvm/qemu doesn't have mtrr set right, don't trim them all: */
 	if (!highest_pfn) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_info("CPU MTRRs all blank - virtualized system.\n");
 		return 0;
 	}
 
 	/* Check entries number: */
 	memset(num, 0, sizeof(num));
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (i = 0; i < num_var_ranges; i++) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		type = range_state[i].type;
 		if (type >= MTRR_NUM_TYPES)
 			continue;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		size = range_state[i].size_pfn;
 		if (!size)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			type = MTRR_NUM_TYPES;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		num[type]++;
 	}
 
 	/* No entry for WB? */
 	if (!num[MTRR_TYPE_WRBACK])
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	/* Check if we only had WB and UC: */
 	if (num[MTRR_TYPE_WRBACK] + num[MTRR_TYPE_UNCACHABLE] !=
 		num_var_ranges - num[MTRR_NUM_TYPES])
 		return 0;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	memset(range, 0, sizeof(range));
 	nr_range = 0;
 	if (mtrr_tom2) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		range[nr_range].start = (1ULL<<(32 - PAGE_SHIFT));
 		range[nr_range].end = mtrr_tom2 >> PAGE_SHIFT;
 		if (highest_pfn < range[nr_range].end)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			highest_pfn = range[nr_range].end;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		nr_range++;
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	nr_range = x86_get_mtrr_mem_range(range, nr_range, 0, 0);
 
 	/* Check the head: */
 	total_trim_size = 0;
 	if (range[0].start)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		total_trim_size += real_trim_memory(0, range[0].start);
+}
 
 	/* Check the holes: */
 	for (i = 0; i < nr_range - 1; i++) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (range[i].end < range[i+1].start)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			total_trim_size += real_trim_memory(range[i].end,
 							    range[i+1].start);
+}
 	}
 
 	/* Check the top: */
 	i = nr_range - 1;
 	if (range[i].end < end_pfn)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		total_trim_size += real_trim_memory(range[i].end,
 							 end_pfn);
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (total_trim_size) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_warn("WARNING: BIOS bug: CPU MTRRs don't cover all of memory, losing %lluMB of RAM.\n",
 			total_trim_size >> 20);
 
 		if (!changed_by_mtrr_cleanup)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			WARN_ON(1);
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_info("update e820 for mtrr\n");
 		e820__update_table_print();
 
 		return 1;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
diff --git a/arch/x86/kernel/cpu/mtrr/generic.c b/arch/x86/kernel/cpu/mtrr/generic.c
index e12ee86..7acce6c 100644
--- a/arch/x86/kernel/cpu/mtrr/generic.c
+++ b/arch/x86/kernel/cpu/mtrr/generic.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * This only handles 32bit MTRR on 32bit hosts. This is strictly wrong
  * because MTRRs can span up to 40 bits (36bits on most modern x86)
@@ -53,8 +55,11 @@ static inline void k8_check_syscfg_dram_mod_en(void)
 	      (boot_cpu_data.x86 >= 0x0f)))
 		return;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rdmsr(MSR_K8_SYSCFG, lo, hi);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (lo & K8_MTRRFIXRANGE_DRAM_MODIFY) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_err(FW_WARN "MTRR: CPU %u: SYSCFG[MtrrFixDramModEn]"
 		       " not cleared by BIOS, clearing this bit\n",
 		       smp_processor_id());
@@ -81,6 +86,7 @@ static u64 get_mtrr_size(u64 mask)
  */
 static int check_type_overlap(u8 *prev, u8 *curr)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (*prev == MTRR_TYPE_UNCACHABLE || *curr == MTRR_TYPE_UNCACHABLE) {
 		*prev = MTRR_TYPE_UNCACHABLE;
 		*curr = MTRR_TYPE_UNCACHABLE;
@@ -121,7 +127,9 @@ static u8 mtrr_type_lookup_fixed(u64 start, u64 end)
 	int idx;
 
 	if (start >= 0x100000)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return MTRR_TYPE_INVALID;
+}
 
 	/* 0x0 - 0x7FFFF */
 	if (start < 0x80000) {
@@ -208,15 +216,20 @@ static u8 mtrr_type_lookup_variable(u64 start, u64 end, u64 *partial_end,
 			 * entries and the default type properly.
 			 */
 			if (start_state)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				*partial_end = base + get_mtrr_size(mask);
+}
 			else
 				*partial_end = base;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			if (unlikely(*partial_end <= start)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				WARN_ON(1);
 				*partial_end = start + PAGE_SIZE;
 			}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			end = *partial_end - 1; /* end is inclusive */
 			*repeat = 1;
 			*uniform = 0;
@@ -231,13 +244,18 @@ static u8 mtrr_type_lookup_variable(u64 start, u64 end, u64 *partial_end,
 			continue;
 		}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		*uniform = 0;
 		if (check_type_overlap(&prev_match, &curr_match))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return curr_match;
+}
 	}
 
 	if (prev_match != MTRR_TYPE_INVALID)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return prev_match;
+}
 
 	return mtrr_state.def_type;
 }
@@ -261,10 +279,14 @@ u8 mtrr_type_lookup(u64 start, u64 end, u8 *uniform)
 	u64 partial_end;
 
 	if (!mtrr_state_set)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return MTRR_TYPE_INVALID;
+}
 
 	if (!(mtrr_state.enabled & MTRR_STATE_MTRR_ENABLED))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return MTRR_TYPE_INVALID;
+}
 
 	/*
 	 * Look up the fixed ranges first, which take priority over
@@ -273,6 +295,7 @@ u8 mtrr_type_lookup(u64 start, u64 end, u8 *uniform)
 	if ((start < 0x100000) &&
 	    (mtrr_state.have_fixed) &&
 	    (mtrr_state.enabled & MTRR_STATE_MTRR_FIXED_ENABLED)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		is_uniform = 0;
 		type = mtrr_type_lookup_fixed(start, end);
 		goto out;
@@ -292,6 +315,7 @@ u8 mtrr_type_lookup(u64 start, u64 end, u8 *uniform)
 	 * that case here.
 	 */
 	while (repeat) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		prev_type = type;
 		start = partial_end;
 		is_uniform = 0;
@@ -303,7 +327,9 @@ u8 mtrr_type_lookup(u64 start, u64 end, u8 *uniform)
 	}
 
 	if (mtrr_tom2 && (start >= (1ULL<<32)) && (end < mtrr_tom2))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		type = MTRR_TYPE_WRBACK;
+}
 
 out:
 	*uniform = is_uniform;
@@ -349,6 +375,7 @@ static void get_fixed_ranges(mtrr_type *frs)
 
 void mtrr_save_fixed_ranges(void *info)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (boot_cpu_has(X86_FEATURE_MTRR))
 		get_fixed_ranges(mtrr_state.fixed_ranges);
 }
@@ -360,7 +387,9 @@ static mtrr_type __initdata last_fixed_type;
 static void __init print_fixed_last(void)
 {
 	if (!last_fixed_end)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	pr_debug("  %05X-%05X %s\n", last_fixed_start,
 		 last_fixed_end - 1, mtrr_attrib_to_str(last_fixed_type));
@@ -441,8 +470,10 @@ static void __init print_mtrr_state(void)
 			pr_debug("  %u disabled\n", i);
 	}
 	if (mtrr_tom2)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_debug("TOM2: %016llx aka %lldM\n", mtrr_tom2, mtrr_tom2>>20);
 }
+}
 
 /* PAT setup for BP. We need to go through sync steps here */
 void __init mtrr_bp_pat_init(void)
@@ -484,6 +515,7 @@ bool __init get_mtrr_state(void)
 
 		/* TOP_MEM2 */
 		rdmsr(MSR_K8_TOP_MEM2, low, high);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		mtrr_tom2 = high;
 		mtrr_tom2 <<= 32;
 		mtrr_tom2 |= low;
@@ -503,14 +535,26 @@ void __init mtrr_state_warn(void)
 	unsigned long mask = smp_changes_mask;
 
 	if (!mask)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (mask & MTRR_CHANGE_MASK_FIXED)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_warn("mtrr: your CPUs had inconsistent fixed MTRR settings\n");
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (mask & MTRR_CHANGE_MASK_VARIABLE)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_warn("mtrr: your CPUs had inconsistent variable MTRR settings\n");
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (mask & MTRR_CHANGE_MASK_DEFTYPE)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_warn("mtrr: your CPUs had inconsistent MTRRdefType settings\n");
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pr_info("mtrr: probably your BIOS does not setup all CPUs.\n");
 	pr_info("mtrr: corrected configuration.\n");
 }
@@ -523,6 +567,7 @@ void __init mtrr_state_warn(void)
 void mtrr_wrmsr(unsigned msr, unsigned a, unsigned b)
 {
 	if (wrmsr_safe(msr, a, b) < 0) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_err("MTRR: CPU %u: Writing MSR %x to %x:%x failed\n",
 			smp_processor_id(), msr, a, b);
 	}
@@ -542,6 +587,7 @@ static void set_fixed_range(int msr, bool *changed, unsigned int *msrwords)
 	rdmsr(msr, lo, hi);
 
 	if (lo != msrwords[0] || hi != msrwords[1]) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		mtrr_wrmsr(msr, msrwords[0], msrwords[1]);
 		*changed = true;
 	}
@@ -563,6 +609,7 @@ generic_get_free_region(unsigned long base, unsigned long size, int replace_reg)
 	int i, max;
 
 	max = num_var_ranges;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (replace_reg >= 0 && replace_reg < max)
 		return replace_reg;
 
@@ -664,6 +711,7 @@ static bool set_mtrr_var_ranges(unsigned int index, struct mtrr_var_range *vr)
 	    || (vr->base_hi & (size_and_mask >> (32 - PAGE_SHIFT))) !=
 		(hi & (size_and_mask >> (32 - PAGE_SHIFT)))) {
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		mtrr_wrmsr(MTRRphysBase_MSR(index), vr->base_lo, vr->base_hi);
 		changed = true;
 	}
@@ -673,6 +721,7 @@ static bool set_mtrr_var_ranges(unsigned int index, struct mtrr_var_range *vr)
 	if ((vr->mask_lo & 0xfffff800UL) != (lo & 0xfffff800UL)
 	    || (vr->mask_hi & (size_and_mask >> (32 - PAGE_SHIFT))) !=
 		(hi & (size_and_mask >> (32 - PAGE_SHIFT)))) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		mtrr_wrmsr(MTRRphysMask_MSR(index), vr->mask_lo, vr->mask_hi);
 		changed = true;
 	}
@@ -694,11 +743,15 @@ static unsigned long set_mtrr_state(void)
 
 	for (i = 0; i < num_var_ranges; i++) {
 		if (set_mtrr_var_ranges(i, &mtrr_state.var_ranges[i]))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			change_mask |= MTRR_CHANGE_MASK_VARIABLE;
+}
 	}
 
 	if (mtrr_state.have_fixed && set_fixed_ranges(mtrr_state.fixed_ranges))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		change_mask |= MTRR_CHANGE_MASK_FIXED;
+}
 
 	/*
 	 * Set_mtrr_restore restores the old value of MTRRdefType,
@@ -707,6 +760,7 @@ static unsigned long set_mtrr_state(void)
 	if ((deftype_lo & 0xff) != mtrr_state.def_type
 	    || ((deftype_lo & 0xc00) >> 10) != mtrr_state.enabled) {
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		deftype_lo = (deftype_lo & ~0xcff) | mtrr_state.def_type |
 			     (mtrr_state.enabled << 10);
 		change_mask |= MTRR_CHANGE_MASK_DEFTYPE;
@@ -751,6 +805,7 @@ static void prepare_set(void) __acquires(set_atomicity_lock)
 	}
 
 	/* Flush all TLBs via a mov %cr3, %reg; mov %reg, %cr3 */
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	count_vm_tlb_event(NR_TLB_LOCAL_FLUSH_ALL);
 	__flush_tlb();
 
@@ -777,6 +832,7 @@ static void post_set(void) __releases(set_atomicity_lock)
 	/* Restore value of CR4 */
 	if (boot_cpu_has(X86_FEATURE_PGE))
 		__write_cr4(cr4);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	raw_spin_unlock(&set_atomicity_lock);
 }
 
@@ -800,7 +856,9 @@ static void generic_set_all(void)
 	/* Use the atomic bitops to update the global mask */
 	for (count = 0; count < sizeof mask * 8; ++count) {
 		if (mask & 0x01)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			set_bit(count, &smp_changes_mask);
+}
 		mask >>= 1;
 	}
 
@@ -824,6 +882,7 @@ static void generic_set_mtrr(unsigned int reg, unsigned long base,
 
 	vr = &mtrr_state.var_ranges[reg];
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	local_irq_save(flags);
 	prepare_set();
 
@@ -890,12 +949,14 @@ int generic_validate_add_page(unsigned long base, unsigned long size,
 static int generic_have_wrcomb(void)
 {
 	unsigned long config, dummy;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rdmsr(MSR_MTRRcap, config, dummy);
 	return config & (1 << 10);
 }
 
 int positive_have_wrcomb(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 1;
 }
 
diff --git a/arch/x86/kernel/cpu/mtrr/if.c b/arch/x86/kernel/cpu/mtrr/if.c
index 558444b..d0fcb4c 100644
--- a/arch/x86/kernel/cpu/mtrr/if.c
+++ b/arch/x86/kernel/cpu/mtrr/if.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 #include <linux/capability.h>
 #include <linux/seq_file.h>
@@ -43,6 +45,7 @@ mtrr_file_add(unsigned long base, unsigned long size,
 
 	max = num_var_ranges;
 	if (fcount == NULL) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		fcount = kzalloc(max * sizeof *fcount, GFP_KERNEL);
 		if (!fcount)
 			return -ENOMEM;
@@ -68,6 +71,7 @@ mtrr_file_del(unsigned long base, unsigned long size,
 	int reg;
 
 	if (!page) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if ((base & (PAGE_SIZE - 1)) || (size & (PAGE_SIZE - 1)))
 			return -EINVAL;
 		base >>= PAGE_SHIFT;
@@ -102,7 +106,9 @@ mtrr_write(struct file *file, const char __user *buf, size_t len, loff_t * ppos)
 	size_t linelen;
 
 	if (!capable(CAP_SYS_ADMIN))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EPERM;
+}
 
 	memset(line, 0, LINE_SIZE);
 
@@ -366,6 +372,7 @@ static int mtrr_close(struct inode *ino, struct file *file)
 	int i, max;
 
 	if (fcount != NULL) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		max = num_var_ranges;
 		for (i = 0; i < max; ++i) {
 			while (fcount[i] > 0) {
@@ -383,6 +390,7 @@ static int mtrr_seq_show(struct seq_file *seq, void *offset);
 
 static int mtrr_open(struct inode *inode, struct file *file)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!mtrr_if)
 		return -EIO;
 	if (!mtrr_if->get)
@@ -409,6 +417,7 @@ static int mtrr_seq_show(struct seq_file *seq, void *offset)
 	unsigned long base, size;
 
 	max = num_var_ranges;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (i = 0; i < max; i++) {
 		mtrr_if->get(i, &base, &size, &type);
 		if (size == 0) {
diff --git a/arch/x86/kernel/cpu/mtrr/main.c b/arch/x86/kernel/cpu/mtrr/main.c
index 7468de4..b13ece0 100644
--- a/arch/x86/kernel/cpu/mtrr/main.c
+++ b/arch/x86/kernel/cpu/mtrr/main.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*  Generic MTRR (Memory Type Range Register) driver.
 
     Copyright (C) 1997-2000  Richard Gooch
@@ -81,6 +83,7 @@ static void set_mtrr(unsigned int reg, unsigned long base,
 
 void __init set_mtrr_ops(const struct mtrr_ops *ops)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (ops->vendor && ops->vendor < X86_VENDOR_NUM)
 		mtrr_ops[ops->vendor] = ops;
 }
@@ -126,10 +129,16 @@ static void __init set_num_var_ranges(void)
 
 	if (use_intel())
 		rdmsr(MSR_MTRRcap, config, dummy);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	else if (is_cpu(AMD))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		config = 2;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	else if (is_cpu(CYRIX) || is_cpu(CENTAUR))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		config = 8;
+}
 
 	num_var_ranges = config & 0xff;
 }
@@ -175,6 +184,7 @@ static int mtrr_rendezvous_handler(void *info)
 	 * set_all()).
 	 */
 	if (data->smp_reg != ~0U) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		mtrr_if->set(data->smp_reg, data->smp_base,
 			     data->smp_size, data->smp_type);
 	} else if (mtrr_aps_delayed_init || !cpu_online(smp_processor_id())) {
@@ -185,6 +195,7 @@ static int mtrr_rendezvous_handler(void *info)
 
 static inline int types_compatible(mtrr_type type1, mtrr_type type2)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return type1 == MTRR_TYPE_UNCACHABLE ||
 	       type2 == MTRR_TYPE_UNCACHABLE ||
 	       (type1 == MTRR_TYPE_WRTHROUGH && type2 == MTRR_TYPE_WRBACK) ||
@@ -305,7 +316,9 @@ int mtrr_add_page(unsigned long base, unsigned long size,
 	mtrr_type ltype;
 
 	if (!mtrr_enabled())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENXIO;
+}
 
 	error = mtrr_if->validate_add_page(base, size, type);
 	if (error)
@@ -406,6 +419,7 @@ int mtrr_add_page(unsigned long base, unsigned long size,
 
 static int mtrr_check(unsigned long base, unsigned long size)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if ((base & (PAGE_SIZE - 1)) || (size & (PAGE_SIZE - 1))) {
 		pr_warn("mtrr: size and base must be multiples of 4 kiB\n");
 		pr_debug("mtrr: size: 0x%lx  base: 0x%lx\n", size, base);
@@ -453,6 +467,7 @@ static int mtrr_check(unsigned long base, unsigned long size)
 int mtrr_add(unsigned long base, unsigned long size, unsigned int type,
 	     bool increment)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!mtrr_enabled())
 		return -ENODEV;
 	if (mtrr_check(base, size))
@@ -483,7 +498,9 @@ int mtrr_del_page(int reg, unsigned long base, unsigned long size)
 	int error = -EINVAL;
 
 	if (!mtrr_enabled())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENODEV;
+}
 
 	max = num_var_ranges;
 	/* No CPU hotplug when we change MTRR entries */
@@ -542,6 +559,7 @@ int mtrr_del_page(int reg, unsigned long base, unsigned long size)
  */
 int mtrr_del(int reg, unsigned long base, unsigned long size)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!mtrr_enabled())
 		return -ENODEV;
 	if (mtrr_check(base, size))
@@ -568,6 +586,7 @@ int arch_phys_wc_add(unsigned long base, unsigned long size)
 {
 	int ret;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (pat_enabled() || !mtrr_enabled())
 		return 0;  /* Success!  (We don't need to do anything.) */
 
@@ -592,6 +611,7 @@ EXPORT_SYMBOL(arch_phys_wc_add);
  */
 void arch_phys_wc_del(int handle)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (handle >= 1) {
 		WARN_ON(handle < MTRR_TO_PHYS_WC_OFFSET);
 		mtrr_del(handle - MTRR_TO_PHYS_WC_OFFSET, 0, 0);
@@ -612,6 +632,7 @@ EXPORT_SYMBOL(arch_phys_wc_del);
  */
 int arch_phys_wc_index(int handle)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (handle < MTRR_TO_PHYS_WC_OFFSET)
 		return -1;
 	else
@@ -648,6 +669,7 @@ static int mtrr_save(void)
 {
 	int i;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (i = 0; i < num_var_ranges; i++) {
 		mtrr_if->get(i, &mtrr_value[i].lbase,
 				&mtrr_value[i].lsize,
@@ -660,6 +682,7 @@ static void mtrr_restore(void)
 {
 	int i;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (i = 0; i < num_var_ranges; i++) {
 		if (mtrr_value[i].lsize) {
 			set_mtrr(i, mtrr_value[i].lbase,
@@ -728,6 +751,7 @@ void __init mtrr_bp_init(void)
 			phys_addr = 32;
 		}
 	} else {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		switch (boot_cpu_data.x86_vendor) {
 		case X86_VENDOR_AMD:
 			if (cpu_feature_enabled(X86_FEATURE_K6_MTRR)) {
@@ -739,6 +763,7 @@ void __init mtrr_bp_init(void)
 			break;
 		case X86_VENDOR_CENTAUR:
 			if (cpu_feature_enabled(X86_FEATURE_CENTAUR_MCR)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				mtrr_if = mtrr_ops[X86_VENDOR_CENTAUR];
 				size_or_mask = SIZE_OR_MASK_BITS(32);
 				size_and_mask = 0;
@@ -746,6 +771,7 @@ void __init mtrr_bp_init(void)
 			break;
 		case X86_VENDOR_CYRIX:
 			if (cpu_feature_enabled(X86_FEATURE_CYRIX_ARR)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				mtrr_if = mtrr_ops[X86_VENDOR_CYRIX];
 				size_or_mask = SIZE_OR_MASK_BITS(32);
 				size_and_mask = 0;
@@ -768,6 +794,7 @@ void __init mtrr_bp_init(void)
 				mtrr_bp_pat_init();
 
 			if (mtrr_cleanup(phys_addr)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				changed_by_mtrr_cleanup = 1;
 				mtrr_if->set_all();
 			}
@@ -775,6 +802,7 @@ void __init mtrr_bp_init(void)
 	}
 
 	if (!mtrr_enabled()) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_info("MTRR: Disabled\n");
 
 		/*
@@ -788,6 +816,7 @@ void __init mtrr_bp_init(void)
 
 void mtrr_ap_init(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!mtrr_enabled())
 		return;
 
@@ -817,7 +846,9 @@ void mtrr_save_state(void)
 	int first_cpu;
 
 	if (!mtrr_enabled())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	first_cpu = cpumask_first(cpu_online_mask);
 	smp_call_function_single(first_cpu, mtrr_save_fixed_ranges, NULL, 1);
@@ -826,9 +857,13 @@ void mtrr_save_state(void)
 void set_mtrr_aps_delayed_init(void)
 {
 	if (!mtrr_enabled())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 	if (!use_intel())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	mtrr_aps_delayed_init = true;
 }
@@ -839,7 +874,9 @@ void set_mtrr_aps_delayed_init(void)
 void mtrr_aps_init(void)
 {
 	if (!use_intel() || !mtrr_enabled())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	/*
 	 * Check if someone has requested the delay of AP MTRR initialization,
@@ -847,7 +884,9 @@ void mtrr_aps_init(void)
 	 * then we are done.
 	 */
 	if (!mtrr_aps_delayed_init)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	set_mtrr(~0U, 0, 0, 0);
 	mtrr_aps_delayed_init = false;
@@ -855,6 +894,7 @@ void mtrr_aps_init(void)
 
 void mtrr_bp_restore(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!use_intel() || !mtrr_enabled())
 		return;
 
@@ -864,11 +904,14 @@ void mtrr_bp_restore(void)
 static int __init mtrr_init_finialize(void)
 {
 	if (!mtrr_enabled())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	if (use_intel()) {
 		if (!changed_by_mtrr_cleanup)
 			mtrr_state_warn();
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
 	}
 
diff --git a/arch/x86/kernel/cpu/proc.c b/arch/x86/kernel/cpu/proc.c
index 2c8522a..cd05217 100644
--- a/arch/x86/kernel/cpu/proc.c
+++ b/arch/x86/kernel/cpu/proc.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 #include <linux/smp.h>
 #include <linux/timex.h>
@@ -77,7 +79,9 @@ static int show_cpuinfo(struct seq_file *m, void *v)
 	else
 		seq_puts(m, "stepping\t: unknown\n");
 	if (c->microcode)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		seq_printf(m, "microcode\t: 0x%x\n", c->microcode);
+}
 
 	if (cpu_has(c, X86_FEATURE_TSC)) {
 		unsigned int freq = aperfmperf_get_khz(cpu);
@@ -126,6 +130,7 @@ static int show_cpuinfo(struct seq_file *m, void *v)
 	seq_puts(m, "power management:");
 	for (i = 0; i < 32; i++) {
 		if (c->x86_power & (1 << i)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			if (i < ARRAY_SIZE(x86_power_flags) &&
 			    x86_power_flags[i])
 				seq_printf(m, "%s%s",
@@ -146,6 +151,7 @@ static void *c_start(struct seq_file *m, loff_t *pos)
 	*pos = cpumask_next(*pos - 1, cpu_online_mask);
 	if ((*pos) < nr_cpu_ids)
 		return &cpu_data(*pos);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return NULL;
 }
 
diff --git a/arch/x86/kernel/cpu/rdrand.c b/arch/x86/kernel/cpu/rdrand.c
index cfa97ff..1d587fa 100644
--- a/arch/x86/kernel/cpu/rdrand.c
+++ b/arch/x86/kernel/cpu/rdrand.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * This file is part of the Linux kernel.
  *
@@ -26,6 +28,7 @@
 
 static int __init x86_rdrand_setup(char *s)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	setup_clear_cpu_cap(X86_FEATURE_RDRAND);
 	setup_clear_cpu_cap(X86_FEATURE_RDSEED);
 	return 1;
@@ -48,9 +51,13 @@ void x86_init_rdrand(struct cpuinfo_x86 *c)
 	if (!cpu_has(c, X86_FEATURE_RDRAND))
 		return;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (i = 0; i < SANITY_CHECK_LOOPS; i++) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (!rdrand_long(&tmp)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			clear_cpu_cap(c, X86_FEATURE_RDRAND);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			pr_warn_once("rdrand: disabled\n");
 			return;
 		}
diff --git a/arch/x86/kernel/cpu/scattered.c b/arch/x86/kernel/cpu/scattered.c
index df11f5d..0edb18a 100644
--- a/arch/x86/kernel/cpu/scattered.c
+++ b/arch/x86/kernel/cpu/scattered.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  *	Routines to identify additional cpu features that are scattered in
  *	cpuid space.
@@ -51,7 +53,9 @@ void init_scattered_cpuid_features(struct cpuinfo_x86 *c)
 			    &regs[CPUID_EDX]);
 
 		if (regs[cb->reg] & (1 << cb->bit))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			set_cpu_cap(c, cb->feature);
+}
 	}
 }
 
@@ -61,6 +65,7 @@ u32 get_scattered_cpuid_leaf(unsigned int level, unsigned int sub_leaf,
 	const struct cpuid_bit *cb;
 	u32 cpuid_val = 0;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (cb = cpuid_bits; cb->feature; cb++) {
 
 		if (level > cb->level)
diff --git a/arch/x86/kernel/cpu/vmware.c b/arch/x86/kernel/cpu/vmware.c
index 8e00532..abc19dd 100644
--- a/arch/x86/kernel/cpu/vmware.c
+++ b/arch/x86/kernel/cpu/vmware.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * VMware Detection code.
  *
diff --git a/arch/x86/kernel/cpuid.c b/arch/x86/kernel/cpuid.c
index 0931a10..77ef256 100644
--- a/arch/x86/kernel/cpuid.c
+++ b/arch/x86/kernel/cpuid.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /* ----------------------------------------------------------------------- *
  *
  *   Copyright 2000-2008 H. Peter Anvin - All Rights Reserved
@@ -66,7 +68,9 @@ static ssize_t cpuid_read(struct file *file, char __user *buf,
 	int err = 0;
 
 	if (count % 16)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;	/* Invalid chunk size */
+}
 
 	for (; count; count -= 16) {
 		cmd.eax = pos;
@@ -92,6 +96,7 @@ static int cpuid_open(struct inode *inode, struct file *file)
 	struct cpuinfo_x86 *c;
 
 	cpu = iminor(file_inode(file));
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (cpu >= nr_cpu_ids || !cpu_online(cpu))
 		return -ENXIO;	/* No such CPU */
 
@@ -123,6 +128,7 @@ static int cpuid_device_create(unsigned int cpu)
 
 static int cpuid_device_destroy(unsigned int cpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	device_destroy(cpuid_class, MKDEV(CPUID_MAJOR, cpu));
 	return 0;
 }
@@ -138,12 +144,14 @@ static int __init cpuid_init(void)
 
 	if (__register_chrdev(CPUID_MAJOR, 0, NR_CPUS,
 			      "cpu/cpuid", &cpuid_fops)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		printk(KERN_ERR "cpuid: unable to get major %d for cpuid\n",
 		       CPUID_MAJOR);
 		return -EBUSY;
 	}
 	cpuid_class = class_create(THIS_MODULE, "cpuid");
 	if (IS_ERR(cpuid_class)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		err = PTR_ERR(cpuid_class);
 		goto out_chrdev;
 	}
@@ -167,6 +175,7 @@ module_init(cpuid_init);
 
 static void __exit cpuid_exit(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	cpuhp_remove_state(cpuhp_cpuid_state);
 	class_destroy(cpuid_class);
 	__unregister_chrdev(CPUID_MAJOR, 0, NR_CPUS, "cpu/cpuid");
diff --git a/arch/x86/kernel/e820.c b/arch/x86/kernel/e820.c
index 71c11ad..a336ba5 100644
--- a/arch/x86/kernel/e820.c
+++ b/arch/x86/kernel/e820.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * Low level x86 E820 memory map handling functions.
  *
@@ -84,8 +86,10 @@ bool e820__mapped_any(u64 start, u64 end, enum e820_type type)
 			continue;
 		if (entry->addr >= end || entry->addr + entry->size <= start)
 			continue;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 1;
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 EXPORT_SYMBOL_GPL(e820__mapped_any);
@@ -116,16 +120,21 @@ static struct e820_entry *__e820__mapped_all(u64 start, u64 end,
 		 * 'start' to the end of the region since it's ok until there
 		 */
 		if (entry->addr <= start)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			start = entry->addr + entry->size;
+}
 
 		/*
 		 * If 'start' is now at or beyond 'end', we're done, full
 		 * coverage of the desired range exists:
 		 */
 		if (start >= end)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return entry;
+}
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return NULL;
 }
 
@@ -142,6 +151,7 @@ bool __init e820__mapped_all(u64 start, u64 end, enum e820_type type)
  */
 int e820__get_entry_type(u64 start, u64 end)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct e820_entry *entry = __e820__mapped_all(start, end, 0);
 
 	return entry ? entry->type : -EINVAL;
@@ -155,6 +165,7 @@ static void __init __e820__range_add(struct e820_table *table, u64 start, u64 si
 	int x = table->nr_entries;
 
 	if (x >= ARRAY_SIZE(table->entries)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_err("e820: too many entries; ignoring [mem %#010llx-%#010llx]\n", start, start + size - 1);
 		return;
 	}
@@ -176,11 +187,15 @@ static void __init e820_print_type(enum e820_type type)
 	case E820_TYPE_RAM:		/* Fall through: */
 	case E820_TYPE_RESERVED_KERN:	pr_cont("usable");			break;
 	case E820_TYPE_RESERVED:	pr_cont("reserved");			break;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	case E820_TYPE_ACPI:		pr_cont("ACPI data");			break;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	case E820_TYPE_NVS:		pr_cont("ACPI NVS");			break;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	case E820_TYPE_UNUSABLE:	pr_cont("unusable");			break;
 	case E820_TYPE_PMEM:		/* Fall through: */
 	case E820_TYPE_PRAM:		pr_cont("persistent (type %u)", type);	break;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	default:			pr_cont("type %u", type);		break;
 	}
 }
@@ -300,14 +315,18 @@ int __init e820__update_table(struct e820_table *table)
 
 	/* If there's only one memory region, don't bother: */
 	if (table->nr_entries < 2)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -1;
+}
 
 	BUG_ON(table->nr_entries > max_nr_entries);
 
 	/* Bail out if we find any unreasonable addresses in the map: */
 	for (i = 0; i < table->nr_entries; i++) {
 		if (entries[i].addr + entries[i].size < entries[i].addr)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -1;
+}
 	}
 
 	/* Create pointers for initial change-point information (for sorting): */
@@ -327,6 +346,7 @@ int __init e820__update_table(struct e820_table *table)
 			change_point[chg_idx++]->entry	= &entries[i];
 		}
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	chg_nr = chg_idx;
 
 	/* Sort change-point list by memory addresses (low -> high): */
@@ -360,7 +380,9 @@ int __init e820__update_table(struct e820_table *table)
 		current_type = 0;
 		for (i = 0; i < overlap_entries; i++) {
 			if (overlap_list[i]->type > current_type)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				current_type = overlap_list[i]->type;
+}
 		}
 
 		/* Continue building up new map based on this information: */
@@ -378,6 +400,7 @@ int __init e820__update_table(struct e820_table *table)
 				new_entries[new_nr_entries].type = current_type;
 				last_addr = change_point[chg_idx]->addr;
 			}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			last_type = current_type;
 		}
 	}
@@ -401,13 +424,16 @@ static int __init __append_e820_table(struct boot_e820_entry *entries, u32 nr_en
 
 		/* Ignore the entry on 64-bit overflow: */
 		if (start > end && likely(size))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -1;
+}
 
 		e820__range_add(start, size, type);
 
 		entry++;
 		nr_entries--;
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
@@ -424,7 +450,9 @@ static int __init append_e820_table(struct boot_e820_entry *entries, u32 nr_entr
 {
 	/* Only one memory region (or negative)? Ignore it */
 	if (nr_entries < 2)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -1;
+}
 
 	return __append_e820_table(entries, nr_entries);
 }
@@ -439,7 +467,9 @@ __e820__range_update(struct e820_table *table, u64 start, u64 size, enum e820_ty
 	BUG_ON(old_type == new_type);
 
 	if (size > (ULLONG_MAX - start))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		size = ULLONG_MAX - start;
+}
 
 	end = start + size;
 	printk(KERN_DEBUG "e820: update [mem %#010Lx-%#010Lx] ", start, end - 1);
@@ -460,6 +490,7 @@ __e820__range_update(struct e820_table *table, u64 start, u64 size, enum e820_ty
 
 		/* Completely covered by new range? */
 		if (entry->addr >= start && entry_end <= end) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			entry->type = new_type;
 			real_updated_size += entry->size;
 			continue;
@@ -467,6 +498,7 @@ __e820__range_update(struct e820_table *table, u64 start, u64 size, enum e820_ty
 
 		/* New range is completely covered? */
 		if (entry->addr < start && entry_end > end) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			__e820__range_add(table, start, size, new_type);
 			__e820__range_add(table, end, entry_end - end, entry->type);
 			entry->size = start - entry->addr;
@@ -504,6 +536,7 @@ u64 __init e820__range_update(u64 start, u64 size, enum e820_type old_type, enum
 
 static u64 __init e820__range_update_kexec(u64 start, u64 size, enum e820_type old_type, enum e820_type  new_type)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return __e820__range_update(e820_table_kexec, start, size, old_type, new_type);
 }
 
@@ -515,7 +548,9 @@ u64 __init e820__range_remove(u64 start, u64 size, enum e820_type old_type, bool
 	u64 real_removed_size = 0;
 
 	if (size > (ULLONG_MAX - start))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		size = ULLONG_MAX - start;
+}
 
 	end = start + size;
 	printk(KERN_DEBUG "e820: remove [mem %#010Lx-%#010Lx] ", start, end - 1);
@@ -535,6 +570,7 @@ u64 __init e820__range_remove(u64 start, u64 size, enum e820_type old_type, bool
 
 		/* Completely covered? */
 		if (entry->addr >= start && entry_end <= end) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			real_removed_size += entry->size;
 			memset(entry, 0, sizeof(*entry));
 			continue;
@@ -542,6 +578,7 @@ u64 __init e820__range_remove(u64 start, u64 size, enum e820_type old_type, bool
 
 		/* Is the new range completely covered? */
 		if (entry->addr < start && entry_end > end) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			e820__range_add(end, entry_end - end, entry->type);
 			entry->size = start - entry->addr;
 			real_removed_size += size;
@@ -554,6 +591,7 @@ u64 __init e820__range_remove(u64 start, u64 size, enum e820_type old_type, bool
 		if (final_start >= final_end)
 			continue;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		real_removed_size += final_end - final_start;
 
 		/*
@@ -564,6 +602,7 @@ u64 __init e820__range_remove(u64 start, u64 size, enum e820_type old_type, bool
 		if (entry->addr < final_start)
 			continue;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		entry->addr = final_end;
 	}
 	return real_removed_size;
@@ -571,6 +610,7 @@ u64 __init e820__range_remove(u64 start, u64 size, enum e820_type old_type, bool
 
 void __init e820__update_table_print(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (e820__update_table(e820_table))
 		return;
 
@@ -580,6 +620,7 @@ void __init e820__update_table_print(void)
 
 static void __init e820__update_table_kexec(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	e820__update_table(e820_table_kexec);
 }
 
@@ -612,7 +653,9 @@ static int __init e820_search_gap(unsigned long *gapstart, unsigned long *gapsiz
 			}
 		}
 		if (start < last)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			last = start;
+}
 	}
 	return found;
 }
@@ -707,6 +750,7 @@ void __init e820__memory_setup_extended(u64 phys_addr, u32 data_len)
 	__append_e820_table(extmap, entries);
 	e820__update_table(e820_table);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	memcpy(e820_table_kexec, e820_table, sizeof(*e820_table_kexec));
 	memcpy(e820_table_firmware, e820_table, sizeof(*e820_table_firmware));
 
@@ -732,12 +776,17 @@ void __init e820__register_nosave_regions(unsigned long limit_pfn)
 		struct e820_entry *entry = &e820_table->entries[i];
 
 		if (pfn < PFN_UP(entry->addr))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			register_nosave_region(pfn, PFN_UP(entry->addr));
+}
 
 		pfn = PFN_DOWN(entry->addr + entry->size);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (entry->type != E820_TYPE_RAM && entry->type != E820_TYPE_RESERVED_KERN)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			register_nosave_region(PFN_UP(entry->addr), pfn);
+}
 
 		if (pfn >= limit_pfn)
 			break;
@@ -757,7 +806,9 @@ static int __init e820__register_nvs_regions(void)
 		struct e820_entry *entry = &e820_table->entries[i];
 
 		if (entry->type == E820_TYPE_NVS)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			acpi_nvs_register(entry->addr, entry->size);
+}
 	}
 
 	return 0;
@@ -779,6 +830,7 @@ u64 __init e820__memblock_alloc_reserved(u64 size, u64 align)
 
 	addr = __memblock_alloc_base(size, align, MEMBLOCK_ALLOC_ACCESSIBLE);
 	if (addr) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		e820__range_update_kexec(addr, size, E820_TYPE_RAM, E820_TYPE_RESERVED);
 		pr_info("e820: update e820_table_kexec for e820__memblock_alloc_reserved()\n");
 		e820__update_table_kexec();
@@ -820,15 +872,20 @@ static unsigned long __init e820_end_pfn(unsigned long limit_pfn, enum e820_type
 		if (start_pfn >= limit_pfn)
 			continue;
 		if (end_pfn > limit_pfn) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			last_pfn = limit_pfn;
 			break;
 		}
 		if (end_pfn > last_pfn)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			last_pfn = end_pfn;
+}
 	}
 
 	if (last_pfn > max_arch_pfn)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		last_pfn = max_arch_pfn;
+}
 
 	pr_info("e820: last_pfn = %#lx max_arch_pfn = %#lx\n",
 			 last_pfn, max_arch_pfn);
@@ -847,6 +904,7 @@ unsigned long __init e820__end_of_low_ram_pfn(void)
 
 static void __init early_panic(char *msg)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	early_printk(msg);
 	panic(msg);
 }
@@ -859,7 +917,9 @@ static int __init parse_memopt(char *p)
 	u64 mem_size;
 
 	if (!p)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	if (!strcmp(p, "nopentium")) {
 #ifdef CONFIG_X86_32
@@ -890,7 +950,9 @@ static int __init parse_memmap_one(char *p)
 	u64 start_at, mem_size;
 
 	if (!p)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	if (!strncmp(p, "exactmap", 8)) {
 #ifdef CONFIG_CRASH_DUMP
@@ -933,6 +995,7 @@ static int __init parse_memmap_one(char *p)
 
 static int __init parse_memmap_opt(char *str)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	while (str) {
 		char *k = strchr(str, ',');
 
@@ -959,9 +1022,13 @@ void __init e820__reserve_setup_data(void)
 
 	pa_data = boot_params.hdr.setup_data;
 	if (!pa_data)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	while (pa_data) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		data = early_memremap(pa_data, sizeof(*data));
 		e820__range_update(pa_data, sizeof(*data)+data->len, E820_TYPE_RAM, E820_TYPE_RESERVED_KERN);
 		e820__range_update_kexec(pa_data, sizeof(*data)+data->len, E820_TYPE_RAM, E820_TYPE_RESERVED_KERN);
@@ -969,6 +1036,7 @@ void __init e820__reserve_setup_data(void)
 		early_memunmap(data, sizeof(*data));
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	e820__update_table(e820_table);
 	e820__update_table(e820_table_kexec);
 
@@ -984,9 +1052,13 @@ void __init e820__reserve_setup_data(void)
 void __init e820__finish_early_params(void)
 {
 	if (userdef) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (e820__update_table(e820_table) < 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			early_panic("Invalid user supplied memory map");
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_info("e820: user-defined physical RAM map:\n");
 		e820__print_table("user");
 	}
@@ -997,12 +1069,18 @@ static const char *__init e820_type_to_string(struct e820_entry *entry)
 	switch (entry->type) {
 	case E820_TYPE_RESERVED_KERN:	/* Fall-through: */
 	case E820_TYPE_RAM:		return "System RAM";
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	case E820_TYPE_ACPI:		return "ACPI Tables";
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	case E820_TYPE_NVS:		return "ACPI Non-volatile Storage";
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	case E820_TYPE_UNUSABLE:	return "Unusable memory";
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	case E820_TYPE_PRAM:		return "Persistent Memory (legacy)";
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	case E820_TYPE_PMEM:		return "Persistent Memory";
 	case E820_TYPE_RESERVED:	return "Reserved";
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	default:			return "Unknown E820 type";
 	}
 }
@@ -1025,9 +1103,13 @@ static unsigned long __init e820_type_to_iomem_type(struct e820_entry *entry)
 static unsigned long __init e820_type_to_iores_desc(struct e820_entry *entry)
 {
 	switch (entry->type) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	case E820_TYPE_ACPI:		return IORES_DESC_ACPI_TABLES;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	case E820_TYPE_NVS:		return IORES_DESC_ACPI_NV_STORAGE;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	case E820_TYPE_PMEM:		return IORES_DESC_PERSISTENT_MEMORY;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	case E820_TYPE_PRAM:		return IORES_DESC_PERSISTENT_MEMORY_LEGACY;
 	case E820_TYPE_RESERVED_KERN:	/* Fall-through: */
 	case E820_TYPE_RAM:		/* Fall-through: */
@@ -1041,7 +1123,9 @@ static bool __init do_mark_busy(enum e820_type type, struct resource *res)
 {
 	/* this is the legacy bios/dos rom-shadow + mmio region */
 	if (res->start < (1ULL<<20))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return true;
+}
 
 	/*
 	 * Treat persistent memory like device memory, i.e. reserve it
@@ -1082,6 +1166,7 @@ void __init e820__reserve_resources(void)
 
 		end = entry->addr + entry->size - 1;
 		if (end != (resource_size_t)end) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			res++;
 			continue;
 		}
@@ -1120,11 +1205,15 @@ static unsigned long __init ram_alignment(resource_size_t pos)
 
 	/* To 64kB in the first megabyte */
 	if (!mb)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 64*1024;
+}
 
 	/* To 1MB in the first 16MB */
 	if (mb < 16)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 1024*1024;
+}
 
 	/* To 64MB for anything above that */
 	return 64*1024*1024;
@@ -1158,7 +1247,9 @@ void __init e820__reserve_resources_late(void)
 		start = entry->addr + entry->size;
 		end = round_up(start, ram_alignment(start)) - 1;
 		if (end > MAX_RESOURCE_SIZE)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			end = MAX_RESOURCE_SIZE;
+}
 		if (start >= end)
 			continue;
 
@@ -1185,13 +1276,16 @@ char *__init e820__memory_setup_default(void)
 
 		/* Compare results from other methods and take the one that gives more RAM: */
 		if (boot_params.alt_mem_k < boot_params.screen_info.ext_mem_k) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			mem_size = boot_params.screen_info.ext_mem_k;
 			who = "BIOS-88";
 		} else {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			mem_size = boot_params.alt_mem_k;
 			who = "BIOS-e801";
 		}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		e820_table->nr_entries = 0;
 		e820__range_add(0, LOWMEMSIZE(), E820_TYPE_RAM);
 		e820__range_add(HIGH_MEMORY, mem_size << 10, E820_TYPE_RAM);
diff --git a/arch/x86/kernel/early-quirks.c b/arch/x86/kernel/early-quirks.c
index c87560e..f3f2911 100644
--- a/arch/x86/kernel/early-quirks.c
+++ b/arch/x86/kernel/early-quirks.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 /* Various workarounds for chipset bugs.
    This code runs very early and can't use the regular PCI subsystem
@@ -41,6 +43,7 @@ static void __init fix_hypertransport_config(int num, int slot, int func)
 	 */
 	htcfg = read_pci_config(num, slot, func, 0x68);
 	if (htcfg & (1 << 18)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		printk(KERN_INFO "Detected use of extended apic ids "
 				 "on hypertransport bus\n");
 		if ((htcfg & (1 << 17)) == 0) {
@@ -74,6 +77,7 @@ static void __init via_bugs(int  num, int slot, int func)
 
 static int __init nvidia_hpet_check(struct acpi_table_header *header)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 #endif /* CONFIG_X86_IO_APIC */
@@ -139,7 +143,9 @@ static void __init ati_bugs(int num, int slot, int func)
 	u8  b;
 
 	if (acpi_use_timer_override)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	d = ati_ixp4x0_rev(num, slot, func);
 	if (d  < 0x82)
@@ -175,7 +181,9 @@ static void __init ati_bugs_contd(int num, int slot, int func)
 
 	rev = ati_sbx00_rev(num, slot, func);
 	if (rev >= 0x40)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		acpi_fix_pin2_polarity = 1;
+}
 
 	/*
 	 * SB600: revisions 0x11, 0x12, 0x13, 0x14, ...
@@ -225,7 +233,9 @@ static void __init intel_remapping_check(int num, int slot, int func)
 	 * revision 0x22 of device id 0x3405 has this problem.
 	 */
 	if (revision <= 0x13)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		set_irq_remapping_broken();
+}
 	else if (device == 0x3405 && revision == 0x22)
 		set_irq_remapping_broken();
 }
@@ -245,6 +255,7 @@ static void __init intel_remapping_check(int num, int slot, int func)
 
 static size_t __init i830_tseg_size(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	u8 esmramc = read_pci_config_byte(0, 0, 0, I830_ESMRAMC);
 
 	if (!(esmramc & TSEG_ENABLE))
@@ -258,6 +269,7 @@ static size_t __init i830_tseg_size(void)
 
 static size_t __init i845_tseg_size(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	u8 esmramc = read_pci_config_byte(0, 0, 0, I845_ESMRAMC);
 	u8 tseg_size = esmramc & I845_TSEG_SIZE_MASK;
 
@@ -275,6 +287,7 @@ static size_t __init i845_tseg_size(void)
 
 static size_t __init i85x_tseg_size(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	u8 esmramc = read_pci_config_byte(0, 0, 0, I85X_ESMRAMC);
 
 	if (!(esmramc & TSEG_ENABLE))
@@ -285,11 +298,13 @@ static size_t __init i85x_tseg_size(void)
 
 static size_t __init i830_mem_size(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return read_pci_config_byte(0, 0, 0, I830_DRB3) * MB(32);
 }
 
 static size_t __init i85x_mem_size(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return read_pci_config_byte(0, 0, 1, I85X_DRB3) * MB(32);
 }
 
@@ -300,18 +315,21 @@ static size_t __init i85x_mem_size(void)
 static phys_addr_t __init i830_stolen_base(int num, int slot, int func,
 					   size_t stolen_size)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return (phys_addr_t)i830_mem_size() - i830_tseg_size() - stolen_size;
 }
 
 static phys_addr_t __init i845_stolen_base(int num, int slot, int func,
 					   size_t stolen_size)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return (phys_addr_t)i830_mem_size() - i845_tseg_size() - stolen_size;
 }
 
 static phys_addr_t __init i85x_stolen_base(int num, int slot, int func,
 					   size_t stolen_size)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return (phys_addr_t)i85x_mem_size() - i85x_tseg_size() - stolen_size;
 }
 
@@ -349,6 +367,7 @@ static size_t __init i830_stolen_size(int num, int slot, int func)
 	gms = gmch_ctrl & I830_GMCH_GMS_MASK;
 
 	switch (gms) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	case I830_GMCH_GMS_STOLEN_512:	return KB(512);
 	case I830_GMCH_GMS_STOLEN_1024:	return MB(1);
 	case I830_GMCH_GMS_STOLEN_8192:	return MB(8);
@@ -370,6 +389,7 @@ static size_t __init gen3_stolen_size(int num, int slot, int func)
 	gms = gmch_ctrl & I855_GMCH_GMS_MASK;
 
 	switch (gms) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	case I855_GMCH_GMS_STOLEN_1M:	return MB(1);
 	case I855_GMCH_GMS_STOLEN_4M:	return MB(4);
 	case I855_GMCH_GMS_STOLEN_8M:	return MB(8);
@@ -426,7 +446,9 @@ static size_t __init chv_stolen_size(int num, int slot, int func)
 	 * 0x17 to 0x1d: 4MB increments start at 36MB
 	 */
 	if (gms < 0x11)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return (size_t)gms * MB(32);
+}
 	else if (gms < 0x17)
 		return (size_t)(gms - 0x11 + 2) * MB(4);
 	else
@@ -444,7 +466,9 @@ static size_t __init gen9_stolen_size(int num, int slot, int func)
 	/* 0x0  to 0xef: 32MB increments starting at 0MB */
 	/* 0xf0 to 0xfe: 4MB increments starting at 4MB */
 	if (gms < 0xf0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return (size_t)gms * MB(32);
+}
 	else
 		return (size_t)(gms - 0xf0 + 1) * MB(4);
 }
@@ -542,6 +566,7 @@ intel_graphics_stolen(int num, int slot, int func,
 	size = early_ops->stolen_size(num, slot, func);
 	base = early_ops->stolen_base(num, slot, func, size);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!size || !base)
 		return;
 
@@ -562,6 +587,7 @@ static void __init intel_graphics_quirks(int num, int slot, int func)
 
 	device = read_pci_config_16(num, slot, func, PCI_DEVICE_ID);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (i = 0; i < ARRAY_SIZE(intel_early_ids); i++) {
 		kernel_ulong_t driver_data = intel_early_ids[i].driver_data;
 
@@ -597,7 +623,9 @@ static void __init apple_airport_reset(int bus, int slot, int func)
 	int i;
 
 	if (!x86_apple_machine)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	/* Card may have been put into PCI_D3hot by grub quirk */
 	pmcsr = read_pci_config_16(bus, slot, func, BCM4331_PM_CAP + PCI_PM_CTRL);
@@ -711,7 +739,9 @@ static int __init check_dev_quirk(int num, int slot, int func)
 	class = read_pci_config_16(num, slot, func, PCI_CLASS_DEVICE);
 
 	if (class == 0xffff)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -1; /* no class, treat as single function */
+}
 
 	vendor = read_pci_config_16(num, slot, func, PCI_VENDOR_ID);
 
@@ -724,9 +754,11 @@ static int __init check_dev_quirk(int num, int slot, int func)
 			(early_qrk[i].device == device)) &&
 			(!((early_qrk[i].class ^ class) &
 			    early_qrk[i].class_mask))) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				if ((early_qrk[i].flags &
 				     QFLAG_DONE) != QFLAG_DONE)
 					early_qrk[i].f(num, slot, func);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				early_qrk[i].flags |= QFLAG_APPLIED;
 			}
 	}
@@ -735,13 +767,18 @@ static int __init check_dev_quirk(int num, int slot, int func)
 				    PCI_HEADER_TYPE);
 
 	if ((type & 0x7f) == PCI_HEADER_TYPE_BRIDGE) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		sec = read_pci_config_byte(num, slot, func, PCI_SECONDARY_BUS);
 		if (sec > num)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			early_pci_scan_bus(sec);
+}
 	}
 
 	if (!(type & 0x80))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -1;
+}
 
 	return 0;
 }
@@ -762,7 +799,9 @@ static void __init early_pci_scan_bus(int bus)
 void __init early_quirks(void)
 {
 	if (!early_pci_allowed())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	early_pci_scan_bus(0);
 }
diff --git a/arch/x86/kernel/ebda.c b/arch/x86/kernel/ebda.c
index 38e7d59..27ad239 100644
--- a/arch/x86/kernel/ebda.c
+++ b/arch/x86/kernel/ebda.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 #include <linux/kernel.h>
 #include <linux/init.h>
@@ -64,7 +66,9 @@ void __init reserve_bios_regions(void)
 	 * without our help.
 	 */
 	if (!x86_platform.legacy.reserve_bios_regions)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	/*
 	 * BIOS RAM size is encoded in kilobytes, convert it
@@ -80,7 +84,9 @@ void __init reserve_bios_regions(void)
 	 * don't trust it.
 	 */
 	if (bios_start < BIOS_START_MIN || bios_start > BIOS_START_MAX)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		bios_start = BIOS_START_MAX;
+}
 
 	/* Get the start address of the EBDA page: */
 	ebda_start = get_bios_ebda();
@@ -91,7 +97,9 @@ void __init reserve_bios_regions(void)
 	 * the BIOS region.
 	 */
 	if (ebda_start >= BIOS_START_MIN && ebda_start < bios_start)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		bios_start = ebda_start;
+}
 
 	/* Reserve all memory between bios_start and the 1MB mark: */
 	memblock_reserve(bios_start, 0x100000 - bios_start);
diff --git a/arch/x86/kernel/fpu/core.c b/arch/x86/kernel/fpu/core.c
index f92a659..73b5142 100644
--- a/arch/x86/kernel/fpu/core.c
+++ b/arch/x86/kernel/fpu/core.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  *  Copyright (C) 1994 Linus Torvalds
  *
@@ -43,23 +45,27 @@ DEFINE_PER_CPU(struct fpu *, fpu_fpregs_owner_ctx);
 
 static void kernel_fpu_disable(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WARN_ON_FPU(this_cpu_read(in_kernel_fpu));
 	this_cpu_write(in_kernel_fpu, true);
 }
 
 static void kernel_fpu_enable(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WARN_ON_FPU(!this_cpu_read(in_kernel_fpu));
 	this_cpu_write(in_kernel_fpu, false);
 }
 
 static bool kernel_fpu_disabled(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return this_cpu_read(in_kernel_fpu);
 }
 
 static bool interrupted_kernel_fpu_idle(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return !kernel_fpu_disabled();
 }
 
@@ -73,6 +79,7 @@ static bool interrupted_kernel_fpu_idle(void)
  */
 static bool interrupted_user_mode(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct pt_regs *regs = get_irq_regs();
 	return regs && user_mode(regs);
 }
@@ -86,6 +93,7 @@ static bool interrupted_user_mode(void)
  */
 bool irq_fpu_usable(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return !in_interrupt() ||
 		interrupted_user_mode() ||
 		interrupted_kernel_fpu_idle();
@@ -94,6 +102,7 @@ EXPORT_SYMBOL(irq_fpu_usable);
 
 void __kernel_fpu_begin(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct fpu *fpu = &current->thread.fpu;
 
 	WARN_ON_FPU(!irq_fpu_usable());
@@ -114,6 +123,7 @@ EXPORT_SYMBOL(__kernel_fpu_begin);
 
 void __kernel_fpu_end(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct fpu *fpu = &current->thread.fpu;
 
 	if (fpu->initialized)
@@ -125,6 +135,7 @@ EXPORT_SYMBOL(__kernel_fpu_end);
 
 void kernel_fpu_begin(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	preempt_disable();
 	__kernel_fpu_begin();
 }
@@ -132,6 +143,7 @@ EXPORT_SYMBOL_GPL(kernel_fpu_begin);
 
 void kernel_fpu_end(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	__kernel_fpu_end();
 	preempt_enable();
 }
@@ -144,6 +156,7 @@ EXPORT_SYMBOL_GPL(kernel_fpu_end);
  */
 void fpu__save(struct fpu *fpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WARN_ON_FPU(fpu != &current->thread.fpu);
 
 	preempt_disable();
@@ -163,6 +176,7 @@ EXPORT_SYMBOL_GPL(fpu__save);
  */
 static inline void fpstate_init_fstate(struct fregs_state *fp)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	fp->cwd = 0xffff037fu;
 	fp->swd = 0xffff0000u;
 	fp->twd = 0xffffffffu;
@@ -171,7 +185,9 @@ static inline void fpstate_init_fstate(struct fregs_state *fp)
 
 void fpstate_init(union fpregs_state *state)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!static_cpu_has(X86_FEATURE_FPU)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		fpstate_init_soft(&state->soft);
 		return;
 	}
@@ -179,9 +195,14 @@ void fpstate_init(union fpregs_state *state)
 	memset(state, 0, fpu_kernel_xstate_size);
 
 	if (static_cpu_has(X86_FEATURE_XSAVES))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		fpstate_init_xstate(&state->xsave);
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (static_cpu_has(X86_FEATURE_FXSR))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		fpstate_init_fxstate(&state->fxsave);
+}
 	else
 		fpstate_init_fstate(&state->fsave);
 }
@@ -192,7 +213,9 @@ int fpu__copy(struct fpu *dst_fpu, struct fpu *src_fpu)
 	dst_fpu->last_cpu = -1;
 
 	if (!src_fpu->initialized || !static_cpu_has(X86_FEATURE_FPU))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	WARN_ON_FPU(src_fpu != &current->thread.fpu);
 
@@ -210,6 +233,7 @@ int fpu__copy(struct fpu *dst_fpu, struct fpu *src_fpu)
 	 *   register contents so we have to copy them back. )
 	 */
 	if (!copy_fpregs_to_fpstate(dst_fpu)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		memcpy(&src_fpu->state, &dst_fpu->state, fpu_kernel_xstate_size);
 		copy_kernel_to_fpregs(&src_fpu->state);
 	}
@@ -256,6 +280,7 @@ EXPORT_SYMBOL_GPL(fpu__initialize);
  */
 void fpu__prepare_read(struct fpu *fpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (fpu == &current->thread.fpu) {
 		fpu__save(fpu);
 	} else {
@@ -316,6 +341,7 @@ void fpu__prepare_write(struct fpu *fpu)
  */
 void fpu__restore(struct fpu *fpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	fpu__initialize(fpu);
 
 	/* Avoid __kernel_fpu_begin() right after fpregs_activate() */
@@ -365,15 +391,20 @@ void fpu__drop(struct fpu *fpu)
 static inline void copy_init_fpstate_to_fpregs(void)
 {
 	if (use_xsave())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		copy_kernel_to_xregs(&init_fpstate.xsave, -1);
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	else if (static_cpu_has(X86_FEATURE_FXSR))
 		copy_kernel_to_fxregs(&init_fpstate.fxsave);
 	else
 		copy_kernel_to_fregs(&init_fpstate.fsave);
 
 	if (boot_cpu_has(X86_FEATURE_OSPKE))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		copy_init_pkru_to_fpregs();
 }
+}
 
 /*
  * Clear the FPU state back to init state.
diff --git a/arch/x86/kernel/fpu/init.c b/arch/x86/kernel/fpu/init.c
index 6abd835..26df599 100644
--- a/arch/x86/kernel/fpu/init.c
+++ b/arch/x86/kernel/fpu/init.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * x86 FPU boot time init code:
  */
@@ -18,17 +20,27 @@ static void fpu__init_cpu_generic(void)
 	unsigned long cr0;
 	unsigned long cr4_mask = 0;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (boot_cpu_has(X86_FEATURE_FXSR))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		cr4_mask |= X86_CR4_OSFXSR;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (boot_cpu_has(X86_FEATURE_XMM))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		cr4_mask |= X86_CR4_OSXMMEXCPT;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (cr4_mask)
 		cr4_set_bits(cr4_mask);
 
 	cr0 = read_cr0();
 	cr0 &= ~(X86_CR0_TS|X86_CR0_EM); /* clear TS and EM */
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!boot_cpu_has(X86_FEATURE_FPU))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		cr0 |= X86_CR0_EM;
+}
 	write_cr0(cr0);
 
 	/* Flush out any pending x87 state: */
@@ -64,6 +76,7 @@ static bool fpu__probe_without_cpuid(void)
 
 	pr_info("x86/fpu: Probing for FPU: FSW=0x%04hx FCW=0x%04hx\n", fsw, fcw);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return fsw == 0 && (fcw & 0x103f) == 0x003f;
 }
 
@@ -71,17 +84,23 @@ static void fpu__init_system_early_generic(struct cpuinfo_x86 *c)
 {
 	if (!boot_cpu_has(X86_FEATURE_CPUID) &&
 	    !test_bit(X86_FEATURE_FPU, (unsigned long *)cpu_caps_cleared)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (fpu__probe_without_cpuid())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			setup_force_cpu_cap(X86_FEATURE_FPU);
+}
 		else
 			setup_clear_cpu_cap(X86_FEATURE_FPU);
 	}
 
 #ifndef CONFIG_MATH_EMULATION
 	if (!test_cpu_cap(&boot_cpu_data, X86_FEATURE_FPU)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_emerg("x86/fpu: Giving up, no FPU found and no math emulation present\n");
 		for (;;)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			asm volatile("hlt");
+}
 	}
 #endif
 }
@@ -96,6 +115,7 @@ static void __init fpu__init_system_mxcsr(void)
 {
 	unsigned int mask = 0;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (boot_cpu_has(X86_FEATURE_FXSR)) {
 		/* Static because GCC does not get 16-byte stack alignment right: */
 		static struct fxregs_state fxregs __initdata;
@@ -110,7 +130,9 @@ static void __init fpu__init_system_mxcsr(void)
 		 * denormals-are-zero feature bit:
 		 */
 		if (mask == 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			mask = 0x0000ffbf;
+}
 	}
 	mxcsr_feature_mask &= mask;
 }
diff --git a/arch/x86/kernel/fpu/signal.c b/arch/x86/kernel/fpu/signal.c
index 23f1691..7db602d 100644
--- a/arch/x86/kernel/fpu/signal.c
+++ b/arch/x86/kernel/fpu/signal.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 /*
  * FPU signal frame handling routines.
@@ -29,7 +31,9 @@ static inline int check_for_xstate(struct fxregs_state __user *buf,
 	unsigned int magic2;
 
 	if (__copy_from_user(fx_sw, &buf->sw_reserved[0], sizeof(*fx_sw)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -1;
+}
 
 	/* Check for the first magic field and other error scenarios. */
 	if (fx_sw->magic1 != FP_XSTATE_MAGIC1 ||
@@ -56,6 +60,7 @@ static inline int check_for_xstate(struct fxregs_state __user *buf,
  */
 static inline int save_fsave_header(struct task_struct *tsk, void __user *buf)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (use_fxsr()) {
 		struct xregs_state *xsave = &tsk->thread.fpu.state.xsave;
 		struct user_i387_ia32_struct env;
@@ -89,8 +94,11 @@ static inline int save_xstate_epilog(void __user *buf, int ia32_frame)
 	err = __copy_to_user(&x->i387.sw_reserved, sw_bytes, sizeof(*sw_bytes));
 
 	if (!use_xsave())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return err;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	err |= __put_user(FP_XSTATE_MAGIC2,
 			  (__u32 *)(buf + fpu_user_xstate_size));
 
@@ -113,6 +121,7 @@ static inline int save_xstate_epilog(void __user *buf, int ia32_frame)
 	 */
 	xfeatures |= XFEATURE_MASK_FPSSE;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	err |= __put_user(xfeatures, (__u32 *)&x->header.xfeatures);
 
 	return err;
@@ -123,14 +132,19 @@ static inline int copy_fpregs_to_sigframe(struct xregs_state __user *buf)
 	int err;
 
 	if (use_xsave())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		err = copy_xregs_to_user(buf);
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	else if (use_fxsr())
 		err = copy_fxregs_to_user((struct fxregs_state __user *) buf);
 	else
 		err = copy_fregs_to_user((struct fregs_state __user *) buf);
 
 	if (unlikely(err) && __clear_user(buf, fpu_user_xstate_size))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		err = -EFAULT;
+}
 	return err;
 }
 
@@ -161,24 +175,34 @@ int copy_fpstate_to_sigframe(void __user *buf, void __user *buf_fx, int size)
 	struct task_struct *tsk = current;
 	int ia32_fxstate = (buf != buf_fx);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	ia32_fxstate &= (IS_ENABLED(CONFIG_X86_32) ||
 			 IS_ENABLED(CONFIG_IA32_EMULATION));
 
 	if (!access_ok(VERIFY_WRITE, buf, size))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EACCES;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!static_cpu_has(X86_FEATURE_FPU))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return fpregs_soft_get(current, NULL, 0,
 			sizeof(struct user_i387_ia32_struct), NULL,
 			(struct _fpstate_32 __user *) buf) ? -1 : 1;
+}
 
 	if (fpu->initialized || using_compacted_format()) {
 		/* Save the live register state to the user directly. */
 		if (copy_fpregs_to_sigframe(buf_fx))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -1;
+}
 		/* Update the thread's fxstate to save the fsave header. */
 		if (ia32_fxstate)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			copy_fxregs_to_kernel(fpu);
+}
 	} else {
 		/*
 		 * It is a *bug* if kernel uses compacted-format for xsave
@@ -187,22 +211,31 @@ int copy_fpstate_to_sigframe(void __user *buf, void __user *buf_fx, int size)
 		 * directly.
 		 */
 		if (boot_cpu_has(X86_FEATURE_XSAVES)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			WARN_ONCE(1, "x86/fpu: saving compacted-format xsave area to a signal frame!\n");
 			return -1;
 		}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		fpstate_sanitize_xstate(fpu);
 		if (__copy_to_user(buf_fx, xsave, fpu_user_xstate_size))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -1;
+}
 	}
 
 	/* Save the fsave header for the 32-bit frames. */
 	if ((ia32_fxstate || !use_fxsr()) && save_fsave_header(tsk, buf))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -1;
+}
 
 	if (use_fxsr() && save_xstate_epilog(buf_fx, ia32_fxstate))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -1;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
@@ -248,6 +281,7 @@ sanitize_restored_xstate(struct task_struct *tsk,
 static inline int copy_user_to_fpregs_zeroing(void __user *buf, u64 xbv, int fx_only)
 {
 	if (use_xsave()) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if ((unsigned long)buf % 64 || fx_only) {
 			u64 init_bv = xfeatures_mask & ~XFEATURE_MASK_FPSSE;
 			copy_kernel_to_xregs(&init_fpstate.xsave, init_bv);
@@ -255,14 +289,19 @@ static inline int copy_user_to_fpregs_zeroing(void __user *buf, u64 xbv, int fx_
 		} else {
 			u64 init_bv = xfeatures_mask & ~xbv;
 			if (unlikely(init_bv))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				copy_kernel_to_xregs(&init_fpstate.xsave, init_bv);
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return copy_user_to_xregs(buf, xbv);
 		}
 	} else if (use_fxsr()) {
 		return copy_user_to_fxregs(buf);
 	} else
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return copy_user_to_fregs(buf);
 }
+}
 
 static int __fpu__restore_sig(void __user *buf, void __user *buf_fx, int size)
 {
@@ -273,23 +312,30 @@ static int __fpu__restore_sig(void __user *buf, void __user *buf_fx, int size)
 	u64 xfeatures = 0;
 	int fx_only = 0;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	ia32_fxstate &= (IS_ENABLED(CONFIG_X86_32) ||
 			 IS_ENABLED(CONFIG_IA32_EMULATION));
 
 	if (!buf) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		fpu__clear(fpu);
 		return 0;
 	}
 
 	if (!access_ok(VERIFY_READ, buf, size))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EACCES;
+}
 
 	fpu__initialize(fpu);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!static_cpu_has(X86_FEATURE_FPU))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return fpregs_soft_set(current, NULL,
 				       0, sizeof(struct user_i387_ia32_struct),
 				       NULL, buf) != 0;
+}
 
 	if (use_xsave()) {
 		struct _fpx_sw_bytes fx_sw_user;
@@ -303,6 +349,7 @@ static int __fpu__restore_sig(void __user *buf, void __user *buf_fx, int size)
 			fx_only = 1;
 			trace_x86_fpu_xstate_check_failed(fpu);
 		} else {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			state_size = fx_sw_user.xstate_size;
 			xfeatures = fx_sw_user.xfeatures;
 		}
@@ -329,22 +376,31 @@ static int __fpu__restore_sig(void __user *buf, void __user *buf_fx, int size)
 		fpu__drop(fpu);
 
 		if (using_compacted_format()) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			err = copy_user_to_xstate(&fpu->state.xsave, buf_fx);
 		} else {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			err = __copy_from_user(&fpu->state.xsave, buf_fx, state_size);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			if (!err && state_size > offsetof(struct xregs_state, header))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				err = validate_xstate_header(&fpu->state.xsave.header);
+}
 		}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (err || __copy_from_user(&env, buf, sizeof(env))) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			fpstate_init(&fpu->state);
 			trace_x86_fpu_init_state(fpu);
 			err = -1;
 		} else {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			sanitize_restored_xstate(tsk, &env, xfeatures, fx_only);
 		}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		fpu->initialized = 1;
 		preempt_disable();
 		fpu__restore(fpu);
@@ -358,11 +414,13 @@ static int __fpu__restore_sig(void __user *buf, void __user *buf_fx, int size)
 		 */
 		user_fpu_begin();
 		if (copy_user_to_fpregs_zeroing(buf_fx, xfeatures, fx_only)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			fpu__clear(fpu);
 			return -1;
 		}
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
@@ -381,6 +439,7 @@ int fpu__restore_sig(void __user *buf, int ia32_frame)
 	int size = xstate_sigframe_size();
 
 	if (ia32_frame && use_fxsr()) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		buf_fx = buf + sizeof(struct fregs_state);
 		size += sizeof(struct fregs_state);
 	}
@@ -396,6 +455,7 @@ fpu__alloc_mathframe(unsigned long sp, int ia32_frame,
 
 	*buf_fx = sp = round_down(sp - frame_size, 64);
 	if (ia32_frame && use_fxsr()) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		frame_size += sizeof(struct fregs_state);
 		sp -= sizeof(struct fregs_state);
 	}
diff --git a/arch/x86/kernel/fpu/xstate.c b/arch/x86/kernel/fpu/xstate.c
index 87a57b7..23e56c0 100644
--- a/arch/x86/kernel/fpu/xstate.c
+++ b/arch/x86/kernel/fpu/xstate.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * xsave/xrstor support.
  *
@@ -72,6 +74,7 @@ unsigned int fpu_user_xstate_size;
  */
 void fpu__xstate_clear_all_cpu_caps(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	setup_clear_cpu_cap(X86_FEATURE_XSAVE);
 }
 
@@ -95,7 +98,9 @@ int cpu_has_xfeatures(u64 xfeatures_needed, const char **feature_name)
 		 * to users:
 		 */
 		if (xfeatures_missing)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			xfeatures_print = xfeatures_missing;
+}
 		else
 			xfeatures_print = xfeatures_needed;
 
@@ -107,8 +112,11 @@ int cpu_has_xfeatures(u64 xfeatures_needed, const char **feature_name)
 	}
 
 	if (xfeatures_missing)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 1;
 }
 EXPORT_SYMBOL_GPL(cpu_has_xfeatures);
@@ -131,6 +139,7 @@ static int xfeature_is_supervisor(int xfeature_nr)
 
 static int xfeature_is_user(int xfeature_nr)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return !xfeature_is_supervisor(xfeature_nr);
 }
 
@@ -156,7 +165,9 @@ void fpstate_sanitize_xstate(struct fpu *fpu)
 	u64 xfeatures;
 
 	if (!use_xsaveopt())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	xfeatures = fpu->state.xsave.header.xfeatures;
 
@@ -220,7 +231,9 @@ void fpstate_sanitize_xstate(struct fpu *fpu)
 void fpu__init_cpu_xstate(void)
 {
 	if (!boot_cpu_has(X86_FEATURE_XSAVE) || !xfeatures_mask)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 	/*
 	 * Make it clear that XSAVES supervisor states are not yet
 	 * implemented should anyone expect it to work by changing
@@ -242,6 +255,7 @@ void fpu__init_cpu_xstate(void)
  */
 static int xfeature_enabled(enum xfeature xfeature)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return !!(xfeatures_mask & (1UL << xfeature));
 }
 
@@ -265,6 +279,7 @@ static void __init setup_xstate_features(void)
 	xstate_offsets[1] = xstate_sizes[0];
 	xstate_sizes[1] = FIELD_SIZEOF(struct fxregs_state, xmm_space);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (i = FIRST_EXTENDED_XFEATURE; i < XFEATURE_MAX; i++) {
 		if (!xfeature_enabled(i))
 			continue;
@@ -295,14 +310,17 @@ static void __init print_xstate_feature(u64 xstate_mask)
 	const char *feature_name;
 
 	if (cpu_has_xfeatures(xstate_mask, &feature_name))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_info("x86/fpu: Supporting XSAVE feature 0x%03Lx: '%s'\n", xstate_mask, feature_name);
 }
+}
 
 /*
  * Print out all the supported xstate features:
  */
 static void __init print_xstate_features(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	print_xstate_feature(XFEATURE_MASK_FP);
 	print_xstate_feature(XFEATURE_MASK_SSE);
 	print_xstate_feature(XFEATURE_MASK_YMM);
@@ -331,6 +349,7 @@ static int xfeature_is_aligned(int xfeature_nr)
 {
 	u32 eax, ebx, ecx, edx;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	CHECK_XFEATURE(xfeature_nr);
 	cpuid_count(XSTATE_CPUID, xfeature_nr, &eax, &ebx, &ecx, &edx);
 	/*
@@ -359,6 +378,7 @@ static void __init setup_xstate_comp(void)
 	xstate_comp_offsets[0] = 0;
 	xstate_comp_offsets[1] = offsetof(struct fxregs_state, xmm_space);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!boot_cpu_has(X86_FEATURE_XSAVES)) {
 		for (i = FIRST_EXTENDED_XFEATURE; i < XFEATURE_MAX; i++) {
 			if (xfeature_enabled(i)) {
@@ -396,6 +416,7 @@ static void __init print_xstate_offset_size(void)
 {
 	int i;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (i = FIRST_EXTENDED_XFEATURE; i < XFEATURE_MAX; i++) {
 		if (!xfeature_enabled(i))
 			continue;
@@ -411,6 +432,7 @@ static void __init setup_init_fpu_buf(void)
 {
 	static int on_boot_cpu __initdata = 1;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WARN_ON_FPU(!on_boot_cpu);
 	on_boot_cpu = 0;
 
@@ -445,6 +467,7 @@ static int xfeature_uncompacted_offset(int xfeature_nr)
 	 * an error.
 	 */
 	if (XFEATURE_MASK_SUPERVISOR & (1 << xfeature_nr)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		WARN_ONCE(1, "No fixed offset for xstate %d\n", xfeature_nr);
 		return -1;
 	}
@@ -458,6 +481,7 @@ static int xfeature_size(int xfeature_nr)
 {
 	u32 eax, ebx, ecx, edx;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	CHECK_XFEATURE(xfeature_nr);
 	cpuid_count(XSTATE_CPUID, xfeature_nr, &eax, &ebx, &ecx, &edx);
 	return eax;
@@ -474,6 +498,7 @@ static int xfeature_size(int xfeature_nr)
  */
 int using_compacted_format(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return boot_cpu_has(X86_FEATURE_XSAVES);
 }
 
@@ -508,7 +533,9 @@ static void __xstate_dump_leaves(void)
 	static int should_dump = 1;
 
 	if (!should_dump)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 	should_dump = 0;
 	/*
 	 * Dump out a few leaves past the ones that we support
diff --git a/arch/x86/kernel/ftrace.c b/arch/x86/kernel/ftrace.c
index 01ebcb6..093ebd7 100644
--- a/arch/x86/kernel/ftrace.c
+++ b/arch/x86/kernel/ftrace.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 /*
  * Dynamic function tracing support.
diff --git a/arch/x86/kernel/head64.c b/arch/x86/kernel/head64.c
index 7ba5d81..98b3baf 100644
--- a/arch/x86/kernel/head64.c
+++ b/arch/x86/kernel/head64.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 /*
  *  prepare to run common code
@@ -43,6 +45,7 @@ pmdval_t early_pmd_flags = __PAGE_KERNEL_LARGE & ~(_PAGE_GLOBAL | _PAGE_NX);
 
 static void __head *fixup_pointer(void *ptr, unsigned long physaddr)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return ptr - (void *)_text + (void *)physaddr;
 }
 
@@ -179,6 +182,7 @@ unsigned long __startup_secondary_64(void)
 /* Wipe all early page tables except for the kernel symbol map */
 static void __init reset_early_page_tables(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	memset(early_top_pgt, 0, sizeof(pgd_t)*(PTRS_PER_PGD-1));
 	next_early_pgt = 0;
 	write_cr3(__sme_pa_nodebug(early_top_pgt));
@@ -195,7 +199,9 @@ int __init __early_make_pgtable(unsigned long address, pmdval_t pmd)
 
 	/* Invalid address or early pgt is done ?  */
 	if (physaddr >= MAXMEM || read_cr3_pa() != __pa_nodebug(early_top_pgt))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -1;
+}
 
 again:
 	pgd_p = &early_top_pgt[pgd_index(address)].pgd;
@@ -207,19 +213,28 @@ int __init __early_make_pgtable(unsigned long address, pmdval_t pmd)
 	 * range and we might end up looping forever...
 	 */
 	if (!IS_ENABLED(CONFIG_X86_5LEVEL))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		p4d_p = pgd_p;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	else if (pgd)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		p4d_p = (p4dval_t *)((pgd & PTE_PFN_MASK) + __START_KERNEL_map - phys_base);
+}
 	else {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (next_early_pgt >= EARLY_DYNAMIC_PAGE_TABLES) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			reset_early_page_tables();
 			goto again;
 		}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		p4d_p = (p4dval_t *)early_dynamic_pgts[next_early_pgt++];
 		memset(p4d_p, 0, sizeof(*p4d_p) * PTRS_PER_P4D);
 		*pgd_p = (pgdval_t)p4d_p - __START_KERNEL_map + phys_base + _KERNPG_TABLE;
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	p4d_p += p4d_index(address);
 	p4d = *p4d_p;
 
@@ -227,6 +242,7 @@ int __init __early_make_pgtable(unsigned long address, pmdval_t pmd)
 		pud_p = (pudval_t *)((p4d & PTE_PFN_MASK) + __START_KERNEL_map - phys_base);
 	else {
 		if (next_early_pgt >= EARLY_DYNAMIC_PAGE_TABLES) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			reset_early_page_tables();
 			goto again;
 		}
@@ -242,6 +258,7 @@ int __init __early_make_pgtable(unsigned long address, pmdval_t pmd)
 		pmd_p = (pmdval_t *)((pud & PTE_PFN_MASK) + __START_KERNEL_map - phys_base);
 	else {
 		if (next_early_pgt >= EARLY_DYNAMIC_PAGE_TABLES) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			reset_early_page_tables();
 			goto again;
 		}
@@ -293,11 +310,13 @@ static void __init copy_bootdata(char *real_mode_data)
 	 */
 	sme_map_bootdata(real_mode_data);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	memcpy(&boot_params, real_mode_data, sizeof boot_params);
 	sanitize_boot_params(&boot_params);
 	cmd_line_ptr = get_cmd_line_ptr();
 	if (cmd_line_ptr) {
 		command_line = __va(cmd_line_ptr);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		memcpy(boot_command_line, command_line, COMMAND_LINE_SIZE);
 	}
 
@@ -317,15 +336,23 @@ asmlinkage __visible void __init x86_64_start_kernel(char * real_mode_data)
 	 * area mappings. (these are purely build-time and produce no code)
 	 */
 	BUILD_BUG_ON(MODULES_VADDR < __START_KERNEL_map);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	BUILD_BUG_ON(MODULES_VADDR - __START_KERNEL_map < KERNEL_IMAGE_SIZE);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	BUILD_BUG_ON(MODULES_LEN + KERNEL_IMAGE_SIZE > 2*PUD_SIZE);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	BUILD_BUG_ON((__START_KERNEL_map & ~PMD_MASK) != 0);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	BUILD_BUG_ON((MODULES_VADDR & ~PMD_MASK) != 0);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	BUILD_BUG_ON(!(MODULES_VADDR > __START_KERNEL));
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	BUILD_BUG_ON(!(((MODULES_END - 1) & PGDIR_MASK) ==
 				(__START_KERNEL & PGDIR_MASK)));
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	BUILD_BUG_ON(__fix_to_virt(__end_of_fixed_addresses) <= MODULES_END);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	cr4_init_shadow();
 
 	/* Kill off the identity-map trampoline */
@@ -363,7 +390,9 @@ void __init x86_64_start_reservations(char *real_mode_data)
 {
 	/* version is always not zero if it is copied */
 	if (!boot_params.hdr.version)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		copy_bootdata(__va(real_mode_data));
+}
 
 	x86_early_init_platform_quirks();
 
diff --git a/arch/x86/kernel/hpet.c b/arch/x86/kernel/hpet.c
index 8ce4212..ef1343a 100644
--- a/arch/x86/kernel/hpet.c
+++ b/arch/x86/kernel/hpet.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 #include <linux/clocksource.h>
 #include <linux/clockchips.h>
 #include <linux/interrupt.h>
@@ -56,6 +58,7 @@ struct hpet_dev {
 
 static inline struct hpet_dev *EVT_TO_HPET_DEV(struct clock_event_device *evtdev)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return container_of(evtdev, struct hpet_dev, evt);
 }
 
@@ -80,6 +83,7 @@ static inline void hpet_set_mapping(void)
 
 static inline void hpet_clear_mapping(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	iounmap(hpet_virt_address);
 	hpet_virt_address = NULL;
 }
@@ -93,6 +97,7 @@ static bool hpet_verbose;
 
 static int __init hpet_setup(char *str)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	while (str) {
 		char *next = strchr(str, ',');
 
@@ -112,6 +117,7 @@ __setup("hpet=", hpet_setup);
 
 static int __init disable_hpet(char *str)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	boot_hpet_disable = true;
 	return 1;
 }
@@ -151,6 +157,7 @@ static void _hpet_print_config(const char *function, int line)
 	h = hpet_readl(HPET_COUNTER+4);
 	printk(KERN_INFO "hpet: COUNTER_l: 0x%x, COUNTER_h: 0x%x\n", l, h);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (i = 0; i < timers; i++) {
 		l = hpet_readl(HPET_Tn_CFG(i));
 		h = hpet_readl(HPET_Tn_CFG(i)+4);
@@ -231,6 +238,7 @@ static struct clock_event_device hpet_clockevent;
 
 static void hpet_stop_counter(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	u32 cfg = hpet_readl(HPET_CFG);
 	cfg &= ~HPET_CFG_ENABLE;
 	hpet_writel(cfg, HPET_CFG);
@@ -238,12 +246,14 @@ static void hpet_stop_counter(void)
 
 static void hpet_reset_counter(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	hpet_writel(0, HPET_COUNTER);
 	hpet_writel(0, HPET_COUNTER + 4);
 }
 
 static void hpet_start_counter(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	unsigned int cfg = hpet_readl(HPET_CFG);
 	cfg |= HPET_CFG_ENABLE;
 	hpet_writel(cfg, HPET_CFG);
@@ -258,17 +268,20 @@ static void hpet_restart_counter(void)
 
 static void hpet_resume_device(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	force_hpet_resume();
 }
 
 static void hpet_resume_counter(struct clocksource *cs)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	hpet_resume_device();
 	hpet_restart_counter();
 }
 
 static void hpet_enable_legacy_int(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	unsigned int cfg = hpet_readl(HPET_CFG);
 
 	cfg |= HPET_CFG_LEGACY;
@@ -347,6 +360,7 @@ static int hpet_shutdown(struct clock_event_device *evt, int timer)
 
 static int hpet_resume(struct clock_event_device *evt)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	hpet_enable_legacy_int();
 	hpet_print_config();
 	return 0;
@@ -386,6 +400,7 @@ static int hpet_next_event(unsigned long delta,
 	 */
 	res = (s32)(cnt - hpet_readl(HPET_COUNTER));
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return res < HPET_MIN_CYCLES ? -ETIME : 0;
 }
 
@@ -396,6 +411,7 @@ static int hpet_legacy_shutdown(struct clock_event_device *evt)
 
 static int hpet_legacy_set_oneshot(struct clock_event_device *evt)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return hpet_set_oneshot(evt, 0);
 }
 
@@ -406,12 +422,14 @@ static int hpet_legacy_set_periodic(struct clock_event_device *evt)
 
 static int hpet_legacy_resume(struct clock_event_device *evt)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return hpet_resume(evt);
 }
 
 static int hpet_legacy_next_event(unsigned long delta,
 			struct clock_event_device *evt)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return hpet_next_event(delta, evt, 0);
 }
 
@@ -442,6 +460,7 @@ static struct irq_domain *hpet_domain;
 
 void hpet_msi_unmask(struct irq_data *data)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct hpet_dev *hdev = irq_data_get_irq_handler_data(data);
 	unsigned int cfg;
 
@@ -453,6 +472,7 @@ void hpet_msi_unmask(struct irq_data *data)
 
 void hpet_msi_mask(struct irq_data *data)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct hpet_dev *hdev = irq_data_get_irq_handler_data(data);
 	unsigned int cfg;
 
@@ -464,12 +484,14 @@ void hpet_msi_mask(struct irq_data *data)
 
 void hpet_msi_write(struct hpet_dev *hdev, struct msi_msg *msg)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	hpet_writel(msg->data, HPET_Tn_ROUTE(hdev->num));
 	hpet_writel(msg->address_lo, HPET_Tn_ROUTE(hdev->num) + 4);
 }
 
 void hpet_msi_read(struct hpet_dev *hdev, struct msi_msg *msg)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	msg->data = hpet_readl(HPET_Tn_ROUTE(hdev->num));
 	msg->address_lo = hpet_readl(HPET_Tn_ROUTE(hdev->num) + 4);
 	msg->address_hi = 0;
@@ -477,6 +499,7 @@ void hpet_msi_read(struct hpet_dev *hdev, struct msi_msg *msg)
 
 static int hpet_msi_shutdown(struct clock_event_device *evt)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct hpet_dev *hdev = EVT_TO_HPET_DEV(evt);
 
 	return hpet_shutdown(evt, hdev->num);
@@ -484,6 +507,7 @@ static int hpet_msi_shutdown(struct clock_event_device *evt)
 
 static int hpet_msi_set_oneshot(struct clock_event_device *evt)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct hpet_dev *hdev = EVT_TO_HPET_DEV(evt);
 
 	return hpet_set_oneshot(evt, hdev->num);
@@ -491,6 +515,7 @@ static int hpet_msi_set_oneshot(struct clock_event_device *evt)
 
 static int hpet_msi_set_periodic(struct clock_event_device *evt)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct hpet_dev *hdev = EVT_TO_HPET_DEV(evt);
 
 	return hpet_set_periodic(evt, hdev->num);
@@ -498,6 +523,7 @@ static int hpet_msi_set_periodic(struct clock_event_device *evt)
 
 static int hpet_msi_resume(struct clock_event_device *evt)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct hpet_dev *hdev = EVT_TO_HPET_DEV(evt);
 	struct irq_data *data = irq_get_irq_data(hdev->irq);
 	struct msi_msg msg;
@@ -512,6 +538,7 @@ static int hpet_msi_resume(struct clock_event_device *evt)
 static int hpet_msi_next_event(unsigned long delta,
 				struct clock_event_device *evt)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct hpet_dev *hdev = EVT_TO_HPET_DEV(evt);
 	return hpet_next_event(delta, evt, hdev->num);
 }
@@ -522,6 +549,7 @@ static irqreturn_t hpet_interrupt_handler(int irq, void *data)
 	struct clock_event_device *hevt = &dev->evt;
 
 	if (!hevt->event_handler) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		printk(KERN_INFO "Spurious HPET timer interrupt on HPET timer %d\n",
 				dev->num);
 		return IRQ_HANDLED;
@@ -534,6 +562,7 @@ static irqreturn_t hpet_interrupt_handler(int irq, void *data)
 static int hpet_setup_irq(struct hpet_dev *dev)
 {
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (request_irq(dev->irq, hpet_interrupt_handler,
 			IRQF_TIMER | IRQF_NOBALANCING,
 			dev->name, dev))
@@ -554,6 +583,7 @@ static void init_one_hpet_msi_clockevent(struct hpet_dev *hdev, int cpu)
 {
 	struct clock_event_device *evt = &hdev->evt;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WARN_ON(cpu != smp_processor_id());
 	if (!(hdev->flags & HPET_DEV_VALID))
 		return;
@@ -596,10 +626,15 @@ static void hpet_msi_capability_lookup(unsigned int start_timer)
 	int i, irq;
 
 	if (hpet_msi_disable)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	if (boot_cpu_has(X86_FEATURE_ARAT))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	id = hpet_readl(HPET_ID);
 
 	num_timers = ((id & HPET_ID_NUMBER) >> HPET_ID_NUMBER_SHIFT);
@@ -608,11 +643,15 @@ static void hpet_msi_capability_lookup(unsigned int start_timer)
 
 	hpet_domain = hpet_create_irq_domain(hpet_blockid);
 	if (!hpet_domain)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	hpet_devs = kzalloc(sizeof(struct hpet_dev) * num_timers, GFP_KERNEL);
 	if (!hpet_devs)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	hpet_num_timers = num_timers;
 
@@ -624,9 +663,13 @@ static void hpet_msi_capability_lookup(unsigned int start_timer)
 		if (!(cfg & HPET_TN_FSB_CAP))
 			continue;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		hdev->flags = 0;
 		if (cfg & HPET_TN_PERIODIC_CAP)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			hdev->flags |= HPET_DEV_PERI_CAP;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		sprintf(hdev->name, "hpet%d", i);
 		hdev->num = i;
 
@@ -634,6 +677,7 @@ static void hpet_msi_capability_lookup(unsigned int start_timer)
 		if (irq <= 0)
 			continue;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		hdev->irq = irq;
 		hdev->flags |= HPET_DEV_FSB_CAP;
 		hdev->flags |= HPET_DEV_VALID;
@@ -652,7 +696,9 @@ static void hpet_reserve_msi_timers(struct hpet_data *hd)
 	int i;
 
 	if (!hpet_devs)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	for (i = 0; i < hpet_num_timers; i++) {
 		struct hpet_dev *hdev = &hpet_devs[i];
@@ -660,6 +706,7 @@ static void hpet_reserve_msi_timers(struct hpet_data *hd)
 		if (!(hdev->flags & HPET_DEV_VALID))
 			continue;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		hd->hd_irq[hdev->num] = hdev->irq;
 		hpet_reserve_timer(hd, hdev->num);
 	}
@@ -671,18 +718,23 @@ static struct hpet_dev *hpet_get_unused_timer(void)
 	int i;
 
 	if (!hpet_devs)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 
 	for (i = 0; i < hpet_num_timers; i++) {
 		struct hpet_dev *hdev = &hpet_devs[i];
 
 		if (!(hdev->flags & HPET_DEV_VALID))
 			continue;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (test_and_set_bit(HPET_DEV_USED_BIT,
 			(unsigned long *)&hdev->flags))
 			continue;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return hdev;
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return NULL;
 }
 
@@ -697,11 +749,14 @@ static void hpet_work(struct work_struct *w)
 	int cpu = smp_processor_id();
 	struct hpet_work_struct *hpet_work;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	hpet_work = container_of(w, struct hpet_work_struct, work.work);
 
 	hdev = hpet_get_unused_timer();
 	if (hdev)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		init_one_hpet_msi_clockevent(hdev, cpu);
+}
 
 	complete(&hpet_work->complete);
 }
@@ -721,6 +776,7 @@ static int hpet_cpuhp_online(unsigned int cpu)
 
 static int hpet_cpuhp_dead(unsigned int cpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct hpet_dev *hdev = per_cpu(cpu_hpet_dev, cpu);
 
 	if (!hdev)
@@ -792,13 +848,16 @@ static u64 read_hpet(struct clocksource *cs)
 	unsigned long flags;
 	union hpet_lock old, new;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	BUILD_BUG_ON(sizeof(union hpet_lock) != 8);
 
 	/*
 	 * Read HPET directly if in NMI.
 	 */
 	if (in_nmi())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return (u64)hpet_readl(HPET_COUNTER);
+}
 
 	/*
 	 * Read the current state of the lock and HPET value atomically.
@@ -810,6 +869,7 @@ static u64 read_hpet(struct clocksource *cs)
 
 	local_irq_save(flags);
 	if (arch_spin_trylock(&hpet.lock)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		new.value = hpet_readl(HPET_COUNTER);
 		/*
 		 * Use WRITE_ONCE() to prevent store tearing.
@@ -819,6 +879,7 @@ static u64 read_hpet(struct clocksource *cs)
 		local_irq_restore(flags);
 		return (u64)new.value;
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	local_irq_restore(flags);
 
 contended:
@@ -835,10 +896,14 @@ static u64 read_hpet(struct clocksource *cs)
 	 * to come along.
 	 */
 	do {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		cpu_relax();
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		new.lockval = READ_ONCE(hpet.lockval);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	} while ((new.value == old.value) && arch_spin_is_locked(&new.lock));
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return (u64)new.value;
 }
 #else
@@ -879,11 +944,13 @@ static int hpet_clocksource_register(void)
 	 * 1 GHz == 200us
 	 */
 	do {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		rep_nop();
 		now = rdtsc();
 	} while ((now - start) < 200000UL);
 
 	if (t1 == hpet_readl(HPET_COUNTER)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		printk(KERN_WARNING
 		       "HPET counter not counting. HPET disabled\n");
 		return -ENODEV;
@@ -905,7 +972,9 @@ int __init hpet_enable(void)
 	unsigned int i, last;
 
 	if (!is_hpet_capable())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	hpet_set_mapping();
 
@@ -928,7 +997,9 @@ int __init hpet_enable(void)
 	 * effects.
 	 */
 	for (i = 0; hpet_readl(HPET_CFG) == 0xFFFFFFFF; i++) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (i == 1000) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			printk(KERN_WARNING
 			       "HPET config register value = 0xFFFFFFFF. "
 			       "Disabling HPET\n");
@@ -965,6 +1036,7 @@ int __init hpet_enable(void)
 		goto out_nohpet;
 #endif
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	cfg = hpet_readl(HPET_CFG);
 	hpet_boot_cfg = kmalloc((last + 2) * sizeof(*hpet_boot_cfg),
 				GFP_KERNEL);
@@ -975,8 +1047,10 @@ int __init hpet_enable(void)
 	cfg &= ~(HPET_CFG_ENABLE | HPET_CFG_LEGACY);
 	hpet_writel(cfg, HPET_CFG);
 	if (cfg)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_warn("HPET: Unrecognized bits %#x set in global cfg\n",
 			cfg);
+}
 
 	for (i = 0; i <= last; ++i) {
 		cfg = hpet_readl(HPET_Tn_CFG(i));
@@ -988,8 +1062,10 @@ int __init hpet_enable(void)
 			 | HPET_TN_64BIT_CAP | HPET_TN_32BIT | HPET_TN_ROUTE
 			 | HPET_TN_FSB | HPET_TN_FSB_CAP);
 		if (cfg)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			pr_warn("HPET: Unrecognized bits %#x set in cfg#%u\n",
 				cfg, i);
+}
 	}
 	hpet_print_config();
 
@@ -1000,6 +1076,7 @@ int __init hpet_enable(void)
 		hpet_legacy_clockevent_register();
 		return 1;
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 
 out_nohpet:
@@ -1019,18 +1096,26 @@ static __init int hpet_late_init(void)
 	int ret;
 
 	if (boot_hpet_disable)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENODEV;
+}
 
 	if (!hpet_address) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (!force_hpet_address)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -ENODEV;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		hpet_address = force_hpet_address;
 		hpet_enable();
 	}
 
 	if (!hpet_virt_address)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENODEV;
+}
 
 	if (hpet_readl(HPET_ID) & HPET_ID_LEGSUP)
 		hpet_msi_capability_lookup(2);
@@ -1041,20 +1126,27 @@ static __init int hpet_late_init(void)
 	hpet_print_config();
 
 	if (hpet_msi_disable)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	if (boot_cpu_has(X86_FEATURE_ARAT))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	/* This notifier should be called after workqueue is ready */
 	ret = cpuhp_setup_state(CPUHP_AP_X86_HPET_ONLINE, "x86/hpet:online",
 				hpet_cpuhp_online, NULL);
 	if (ret)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ret;
+}
 	ret = cpuhp_setup_state(CPUHP_X86_HPET_DEAD, "x86/hpet:dead", NULL,
 				hpet_cpuhp_dead);
 	if (ret)
 		goto err_cpuhp;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 
 err_cpuhp:
@@ -1065,6 +1157,7 @@ fs_initcall(hpet_late_init);
 
 void hpet_disable(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (is_hpet_capable() && hpet_virt_address) {
 		unsigned int cfg = hpet_readl(HPET_CFG), id, last;
 
@@ -1139,9 +1232,13 @@ static inline int hpet_cnt_ahead(u32 c1, u32 c2)
 int hpet_register_irq_handler(rtc_irq_handler handler)
 {
 	if (!is_hpet_enabled())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENODEV;
+}
 	if (irq_handler)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EBUSY;
+}
 
 	irq_handler = handler;
 
@@ -1155,6 +1252,7 @@ EXPORT_SYMBOL_GPL(hpet_register_irq_handler);
  */
 void hpet_unregister_irq_handler(rtc_irq_handler handler)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!is_hpet_enabled())
 		return;
 
@@ -1175,7 +1273,9 @@ int hpet_rtc_timer_init(void)
 	unsigned long flags;
 
 	if (!is_hpet_enabled())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	if (!hpet_default_delta) {
 		uint64_t clc;
@@ -1209,6 +1309,7 @@ EXPORT_SYMBOL_GPL(hpet_rtc_timer_init);
 
 static void hpet_disable_rtc_channel(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	u32 cfg = hpet_readl(HPET_T1_CFG);
 	cfg &= ~HPET_TN_ENABLE;
 	hpet_writel(cfg, HPET_T1_CFG);
@@ -1222,12 +1323,15 @@ static void hpet_disable_rtc_channel(void)
 int hpet_mask_rtc_irq_bit(unsigned long bit_mask)
 {
 	if (!is_hpet_enabled())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	hpet_rtc_flags &= ~bit_mask;
 	if (unlikely(!hpet_rtc_flags))
 		hpet_disable_rtc_channel();
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 1;
 }
 EXPORT_SYMBOL_GPL(hpet_mask_rtc_irq_bit);
@@ -1237,16 +1341,21 @@ int hpet_set_rtc_irq_bit(unsigned long bit_mask)
 	unsigned long oldbits = hpet_rtc_flags;
 
 	if (!is_hpet_enabled())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	hpet_rtc_flags |= bit_mask;
 
 	if ((bit_mask & RTC_UIE) && !(oldbits & RTC_UIE))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		hpet_prev_update_sec = -1;
+}
 
 	if (!oldbits)
 		hpet_rtc_timer_init();
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 1;
 }
 EXPORT_SYMBOL_GPL(hpet_set_rtc_irq_bit);
@@ -1255,7 +1364,9 @@ int hpet_set_alarm_time(unsigned char hrs, unsigned char min,
 			unsigned char sec)
 {
 	if (!is_hpet_enabled())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	hpet_alarm_time.tm_hour = hrs;
 	hpet_alarm_time.tm_min = min;
@@ -1270,10 +1381,14 @@ int hpet_set_periodic_freq(unsigned long freq)
 	uint64_t clc;
 
 	if (!is_hpet_enabled())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	if (freq <= DEFAULT_RTC_INT_FREQ)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		hpet_pie_limit = DEFAULT_RTC_INT_FREQ / freq;
+}
 	else {
 		clc = (uint64_t) hpet_clockevent.mult * NSEC_PER_SEC;
 		do_div(clc, freq);
@@ -1281,12 +1396,14 @@ int hpet_set_periodic_freq(unsigned long freq)
 		hpet_pie_delta = clc;
 		hpet_pie_limit = 0;
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 1;
 }
 EXPORT_SYMBOL_GPL(hpet_set_periodic_freq);
 
 int hpet_rtc_dropped_irq(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return is_hpet_enabled();
 }
 EXPORT_SYMBOL_GPL(hpet_rtc_dropped_irq);
@@ -1316,7 +1433,9 @@ static void hpet_rtc_timer_reinit(void)
 
 	if (lost_ints) {
 		if (hpet_rtc_flags & RTC_PIE)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			hpet_pie_count += lost_ints;
+}
 		if (printk_ratelimit())
 			printk(KERN_WARNING "hpet1: lost %d rtc interrupts\n",
 				lost_ints);
@@ -1336,13 +1455,18 @@ irqreturn_t hpet_rtc_interrupt(int irq, void *dev_id)
 
 	if (hpet_rtc_flags & RTC_UIE &&
 	    curr_time.tm_sec != hpet_prev_update_sec) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (hpet_prev_update_sec >= 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			rtc_int_flag = RTC_UF;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		hpet_prev_update_sec = curr_time.tm_sec;
 	}
 
 	if (hpet_rtc_flags & RTC_PIE &&
 	    ++hpet_pie_count >= hpet_pie_limit) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		rtc_int_flag |= RTC_PF;
 		hpet_pie_count = 0;
 	}
diff --git a/arch/x86/kernel/hw_breakpoint.c b/arch/x86/kernel/hw_breakpoint.c
index 8771766..865f8c6 100644
--- a/arch/x86/kernel/hw_breakpoint.c
+++ b/arch/x86/kernel/hw_breakpoint.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * This program is free software; you can redistribute it and/or modify
  * it under the terms of the GNU General Public License as published by
@@ -77,6 +79,7 @@ __encode_dr7(int drnum, unsigned int len, unsigned int type)
  */
 unsigned long encode_dr7(int drnum, unsigned int len, unsigned int type)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return __encode_dr7(drnum, len, type) | DR_GLOBAL_SLOWDOWN;
 }
 
@@ -105,6 +108,7 @@ int decode_dr7(unsigned long dr7, int bpnum, unsigned *len, unsigned *type)
  */
 int arch_install_hw_breakpoint(struct perf_event *bp)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct arch_hw_breakpoint *info = counter_arch_bp(bp);
 	unsigned long *dr7;
 	int i;
@@ -145,6 +149,7 @@ int arch_install_hw_breakpoint(struct perf_event *bp)
  */
 void arch_uninstall_hw_breakpoint(struct perf_event *bp)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct arch_hw_breakpoint *info = counter_arch_bp(bp);
 	unsigned long *dr7;
 	int i;
@@ -236,6 +241,7 @@ int arch_bp_generic_fields(int x86_len, int x86_type,
 
 static int arch_build_bp_info(struct perf_event *bp)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct arch_hw_breakpoint *info = counter_arch_bp(bp);
 
 	info->address = bp->attr.bp_addr;
@@ -324,6 +330,7 @@ static int arch_build_bp_info(struct perf_event *bp)
  */
 int arch_validate_hwbkpt_settings(struct perf_event *bp)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct arch_hw_breakpoint *info = counter_arch_bp(bp);
 	unsigned int align;
 	int ret;
@@ -380,6 +387,7 @@ void aout_dump_debugregs(struct user *dump)
 	struct arch_hw_breakpoint *info;
 	struct thread_struct *thread = &current->thread;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (i = 0; i < HBP_NUM; i++) {
 		bp = thread->ptrace_bps[i];
 
@@ -419,6 +427,7 @@ void flush_ptrace_hw_breakpoint(struct task_struct *tsk)
 
 void hw_breakpoint_restore(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	set_debugreg(__this_cpu_read(cpu_debugreg[0]), 0);
 	set_debugreg(__this_cpu_read(cpu_debugreg[1]), 1);
 	set_debugreg(__this_cpu_read(cpu_debugreg[2]), 2);
@@ -457,7 +466,9 @@ static int hw_breakpoint_handler(struct die_args *args)
 
 	/* If it's a single step, TRAP bits are random */
 	if (dr6 & DR_STEP)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NOTIFY_DONE;
+}
 
 	/* Do an early return if no trap bits are set in DR6 */
 	if ((dr6 & DR_TRAP_BITS) == 0)
@@ -535,8 +546,11 @@ int hw_breakpoint_exceptions_notify(
 		struct notifier_block *unused, unsigned long val, void *data)
 {
 	if (val != DIE_DEBUG)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NOTIFY_DONE;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return hw_breakpoint_handler(data);
 }
 
diff --git a/arch/x86/kernel/i8237.c b/arch/x86/kernel/i8237.c
index 8eeaa81..e6b283a 100644
--- a/arch/x86/kernel/i8237.c
+++ b/arch/x86/kernel/i8237.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * 8237A DMA controller suspend functions.
  *
@@ -31,6 +33,7 @@ static void i8237A_resume(void)
 	dma_outb(0, DMA1_RESET_REG);
 	dma_outb(0, DMA2_RESET_REG);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (i = 0; i < 8; i++) {
 		set_dma_addr(i, 0x000000);
 		/* DMA count is a bit weird so this is not 0 */
diff --git a/arch/x86/kernel/i8259.c b/arch/x86/kernel/i8259.c
index 8f5cb2c..dcd39d5 100644
--- a/arch/x86/kernel/i8259.c
+++ b/arch/x86/kernel/i8259.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 #include <linux/linkage.h>
 #include <linux/errno.h>
@@ -70,6 +72,7 @@ static void mask_8259A_irq(unsigned int irq)
 
 static void disable_8259A_irq(struct irq_data *data)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	mask_8259A_irq(data->irq);
 }
 
@@ -81,7 +84,9 @@ static void unmask_8259A_irq(unsigned int irq)
 	raw_spin_lock_irqsave(&i8259A_lock, flags);
 	cached_irq_mask &= mask;
 	if (irq & 8)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		outb(cached_slave_mask, PIC_SLAVE_IMR);
+}
 	else
 		outb(cached_master_mask, PIC_MASTER_IMR);
 	raw_spin_unlock_irqrestore(&i8259A_lock, flags);
@@ -110,6 +115,7 @@ static int i8259A_irq_pending(unsigned int irq)
 
 static void make_8259A_irq(unsigned int irq)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	disable_irq_nosync(irq);
 	io_apic_irqs &= ~(1<<irq);
 	irq_set_chip_and_handler(irq, &i8259A_chip, handle_level_irq);
@@ -128,6 +134,7 @@ static inline int i8259A_irq_real(unsigned int irq)
 	int irqmask = 1<<irq;
 
 	if (irq < 8) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		outb(0x0B, PIC_MASTER_CMD);	/* ISR register */
 		value = inb(PIC_MASTER_CMD) & irqmask;
 		outb(0x0A, PIC_MASTER_CMD);	/* back to the IRR register */
@@ -173,6 +180,7 @@ static void mask_and_ack_8259A(struct irq_data *data)
 
 handle_real_irq:
 	if (irq & 8) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		inb(PIC_SLAVE_IMR);	/* DUMMY - (do we need this?) */
 		outb(cached_slave_mask, PIC_SLAVE_IMR);
 		/* 'Specific EOI' to slave */
@@ -180,6 +188,7 @@ static void mask_and_ack_8259A(struct irq_data *data)
 		 /* 'Specific EOI' to master-IRQ2 */
 		outb(0x60+PIC_CASCADE_IR, PIC_MASTER_CMD);
 	} else {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		inb(PIC_MASTER_IMR);	/* DUMMY - (do we need this?) */
 		outb(cached_master_mask, PIC_MASTER_IMR);
 		outb(0x60+irq, PIC_MASTER_CMD);	/* 'Specific EOI to master */
@@ -205,10 +214,12 @@ static void mask_and_ack_8259A(struct irq_data *data)
 		 * lets ACK and report it. [once per IRQ]
 		 */
 		if (!(spurious_irq_mask & irqmask)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			printk(KERN_DEBUG
 			       "spurious 8259A interrupt: IRQ%d.\n", irq);
 			spurious_irq_mask |= irqmask;
 		}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		atomic_inc(&irq_err_count);
 		/*
 		 * Theoretically we do not have to handle this IRQ,
@@ -233,6 +244,7 @@ static char irq_trigger[2];
  */
 static void restore_ELCR(char *trigger)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	outb(trigger[0], 0x4d0);
 	outb(trigger[1], 0x4d1);
 }
@@ -246,12 +258,14 @@ static void save_ELCR(char *trigger)
 
 static void i8259A_resume(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	init_8259A(i8259A_auto_eoi);
 	restore_ELCR(irq_trigger);
 }
 
 static int i8259A_suspend(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	save_ELCR(irq_trigger);
 	return 0;
 }
@@ -276,6 +290,7 @@ static void mask_8259A(void)
 {
 	unsigned long flags;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	raw_spin_lock_irqsave(&i8259A_lock, flags);
 
 	outb(0xff, PIC_MASTER_IMR);	/* mask all of 8259A-1 */
@@ -288,6 +303,7 @@ static void unmask_8259A(void)
 {
 	unsigned long flags;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	raw_spin_lock_irqsave(&i8259A_lock, flags);
 
 	outb(cached_master_mask, PIC_MASTER_IMR); /* restore master IRQ mask */
@@ -310,10 +326,12 @@ static int probe_8259A(void)
 	 */
 	raw_spin_lock_irqsave(&i8259A_lock, flags);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	outb(0xff, PIC_SLAVE_IMR);	/* mask all of 8259A-2 */
 	outb(probe_val, PIC_MASTER_IMR);
 	new_val = inb(PIC_MASTER_IMR);
 	if (new_val != probe_val) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		printk(KERN_INFO "Using NULL legacy PIC\n");
 		legacy_pic = &null_legacy_pic;
 	}
@@ -330,6 +348,7 @@ static void init_8259A(int auto_eoi)
 
 	raw_spin_lock_irqsave(&i8259A_lock, flags);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	outb(0xff, PIC_MASTER_IMR);	/* mask all of 8259A-1 */
 
 	/*
@@ -344,10 +363,13 @@ static void init_8259A(int auto_eoi)
 	outb_pic(1U << PIC_CASCADE_IR, PIC_MASTER_IMR);
 
 	if (auto_eoi)	/* master does Auto EOI */
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		outb_pic(MASTER_ICW4_DEFAULT | PIC_ICW4_AEOI, PIC_MASTER_IMR);
+}
 	else		/* master expects normal EOI */
 		outb_pic(MASTER_ICW4_DEFAULT, PIC_MASTER_IMR);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	outb_pic(0x11, PIC_SLAVE_CMD);	/* ICW1: select 8259A-2 init */
 
 	/* ICW2: 8259A-2 IR0-7 mapped to ISA_IRQ_VECTOR(8) */
@@ -385,10 +407,12 @@ static void legacy_pic_uint_noop(unsigned int unused) { };
 static void legacy_pic_int_noop(int unused) { };
 static int legacy_pic_irq_pending_noop(unsigned int irq)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 static int legacy_pic_probe(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
diff --git a/arch/x86/kernel/idt.c b/arch/x86/kernel/idt.c
index 236917b..b908ade 100644
--- a/arch/x86/kernel/idt.c
+++ b/arch/x86/kernel/idt.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * Interrupt descriptor table related code
  *
@@ -233,6 +235,7 @@ static void set_intr_gate(unsigned int n, const void *addr)
 
 	BUG_ON(n > 0xFF);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	memset(&data, 0, sizeof(data));
 	data.vector	= n;
 	data.addr	= addr;
@@ -295,6 +298,7 @@ void __init idt_setup_ist_traps(void)
  */
 void __init idt_setup_debugidt_traps(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	memcpy(&debug_idt_table, &idt_table, IDT_ENTRIES * 16);
 
 	idt_setup_from_table(debug_idt_table, dbg_idts, ARRAY_SIZE(dbg_idts), false);
@@ -356,6 +360,7 @@ void idt_invalidate(void *addr)
 
 void __init update_intr_gate(unsigned int n, const void *addr)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (WARN_ON_ONCE(!test_bit(n, used_vectors)))
 		return;
 	set_intr_gate(n, addr);
@@ -363,6 +368,7 @@ void __init update_intr_gate(unsigned int n, const void *addr)
 
 void alloc_intr_gate(unsigned int n, const void *addr)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	BUG_ON(n < FIRST_SYSTEM_VECTOR);
 	if (!test_and_set_bit(n, used_vectors))
 		set_intr_gate(n, addr);
diff --git a/arch/x86/kernel/io_delay.c b/arch/x86/kernel/io_delay.c
index 805b7a3..4f077f7 100644
--- a/arch/x86/kernel/io_delay.c
+++ b/arch/x86/kernel/io_delay.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 /*
  * I/O delay strategies for inb_p/outb_p
@@ -47,6 +49,7 @@ EXPORT_SYMBOL(native_io_delay);
 
 static int __init dmi_io_delay_0xed_port(const struct dmi_system_id *id)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (io_delay_type == CONFIG_IO_DELAY_TYPE_0X80) {
 		pr_notice("%s: using 0xed I/O delay port\n", id->ident);
 		io_delay_type = CONFIG_IO_DELAY_TYPE_0XED;
@@ -111,6 +114,7 @@ void __init io_delay_init(void)
 
 static int __init io_delay_param(char *s)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!s)
 		return -EINVAL;
 
diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index aa9d51e..e1e7dbb 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * Common interrupt code for 32 and 64 bit
  */
@@ -35,6 +37,7 @@ atomic_t irq_err_count;
  */
 void ack_bad_irq(unsigned int irq)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (printk_ratelimit())
 		pr_err("unexpected IRQ trap at vector %02x\n", irq);
 
@@ -59,6 +62,7 @@ int arch_show_interrupts(struct seq_file *p, int prec)
 	int j;
 
 	seq_printf(p, "%*s: ", prec, "NMI");
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for_each_online_cpu(j)
 		seq_printf(p, "%10u ", irq_stats(j)->__nmi_count);
 	seq_puts(p, "  Non-maskable interrupts\n");
@@ -181,7 +185,9 @@ u64 arch_irq_stat_cpu(unsigned int cpu)
 	sum += irq_stats(cpu)->apic_irq_work_irqs;
 	sum += irq_stats(cpu)->icr_read_retry_count;
 	if (x86_platform_ipi_callback)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		sum += irq_stats(cpu)->x86_platform_ipis;
+}
 #endif
 #ifdef CONFIG_SMP
 	sum += irq_stats(cpu)->irq_resched_count;
@@ -195,6 +201,7 @@ u64 arch_irq_stat_cpu(unsigned int cpu)
 #endif
 #ifdef CONFIG_X86_MCE
 	sum += per_cpu(mce_exception_count, cpu);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	sum += per_cpu(mce_poll_count, cpu);
 #endif
 	return sum;
@@ -214,6 +221,7 @@ u64 arch_irq_stat(void)
  */
 __visible unsigned int __irq_entry do_IRQ(struct pt_regs *regs)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct pt_regs *old_regs = set_irq_regs(regs);
 	struct irq_desc * desc;
 	/* high bit used in ret_from_ code  */
@@ -227,17 +235,21 @@ __visible unsigned int __irq_entry do_IRQ(struct pt_regs *regs)
 	desc = __this_cpu_read(vector_irq[vector]);
 
 	if (!handle_irq(desc, regs)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ack_APIC_irq();
 
 		if (desc != VECTOR_RETRIGGERED) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			pr_emerg_ratelimited("%s: %d.%d No irq handler for vector\n",
 					     __func__, smp_processor_id(),
 					     vector);
 		} else {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			__this_cpu_write(vector_irq[vector], VECTOR_UNUSED);
 		}
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	exiting_irq();
 
 	set_irq_regs(old_regs);
@@ -252,6 +264,7 @@ void (*x86_platform_ipi_callback)(void) = NULL;
  */
 __visible void __irq_entry smp_x86_platform_ipi(struct pt_regs *regs)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct pt_regs *old_regs = set_irq_regs(regs);
 
 	entering_ack_irq();
@@ -271,6 +284,7 @@ static void (*kvm_posted_intr_wakeup_handler)(void) = dummy_handler;
 
 void kvm_set_posted_intr_wakeup_handler(void (*handler)(void))
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (handler)
 		kvm_posted_intr_wakeup_handler = handler;
 	else
@@ -283,6 +297,7 @@ EXPORT_SYMBOL_GPL(kvm_set_posted_intr_wakeup_handler);
  */
 __visible void smp_kvm_posted_intr_ipi(struct pt_regs *regs)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct pt_regs *old_regs = set_irq_regs(regs);
 
 	entering_ack_irq();
@@ -296,6 +311,7 @@ __visible void smp_kvm_posted_intr_ipi(struct pt_regs *regs)
  */
 __visible void smp_kvm_posted_intr_wakeup_ipi(struct pt_regs *regs)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct pt_regs *old_regs = set_irq_regs(regs);
 
 	entering_ack_irq();
@@ -310,6 +326,7 @@ __visible void smp_kvm_posted_intr_wakeup_ipi(struct pt_regs *regs)
  */
 __visible void smp_kvm_posted_intr_nested_ipi(struct pt_regs *regs)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct pt_regs *old_regs = set_irq_regs(regs);
 
 	entering_ack_irq();
@@ -341,6 +358,7 @@ int check_irq_vectors_for_cpu_disable(void)
 	struct irq_data *data;
 	int cpu;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	this_cpu = smp_processor_id();
 	cpumask_copy(&online_new, cpu_online_mask);
 	cpumask_clear_cpu(this_cpu, &online_new);
diff --git a/arch/x86/kernel/irq_64.c b/arch/x86/kernel/irq_64.c
index d86e344..c3421a5 100644
--- a/arch/x86/kernel/irq_64.c
+++ b/arch/x86/kernel/irq_64.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 /*
  *	Copyright (C) 1992, 1998 Linus Torvalds, Ingo Molnar
@@ -39,7 +41,9 @@ static inline void stack_overflow_check(struct pt_regs *regs)
 	u64 curbase = (u64)task_stack_page(current);
 
 	if (user_mode(regs))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	if (regs->sp >= curbase + sizeof(struct pt_regs) + STACK_TOP_MARGIN &&
 	    regs->sp <= curbase + THREAD_SIZE)
@@ -69,10 +73,13 @@ static inline void stack_overflow_check(struct pt_regs *regs)
 
 bool handle_irq(struct irq_desc *desc, struct pt_regs *regs)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	stack_overflow_check(regs);
 
 	if (IS_ERR_OR_NULL(desc))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return false;
+}
 
 	generic_handle_irq_desc(desc);
 	return true;
diff --git a/arch/x86/kernel/irqinit.c b/arch/x86/kernel/irqinit.c
index 1e4094e..7c28216 100644
--- a/arch/x86/kernel/irqinit.c
+++ b/arch/x86/kernel/irqinit.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 #include <linux/linkage.h>
 #include <linux/errno.h>
@@ -96,7 +98,10 @@ void __init native_init_IRQ(void)
 	idt_setup_apic_and_irq_gates();
 
 	if (!acpi_ioapic && !of_ioapic && nr_legacy_irqs())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		setup_irq(2, &irq2);
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	irq_ctx_init(smp_processor_id());
 }
diff --git a/arch/x86/kernel/jump_label.c b/arch/x86/kernel/jump_label.c
index e56c95b..dd5af5a 100644
--- a/arch/x86/kernel/jump_label.c
+++ b/arch/x86/kernel/jump_label.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 /*
  * jump label x86 support
diff --git a/arch/x86/kernel/kdebugfs.c b/arch/x86/kernel/kdebugfs.c
index fd6f8fb..70ac434 100644
--- a/arch/x86/kernel/kdebugfs.c
+++ b/arch/x86/kernel/kdebugfs.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * Architecture specific debugfs files
  *
@@ -37,7 +39,9 @@ static ssize_t setup_data_read(struct file *file, char __user *user_buf,
 	u64 pa;
 
 	if (pos < 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	if (pos >= node->len)
 		return 0;
@@ -78,7 +82,9 @@ create_setup_data_node(struct dentry *parent, int no,
 	sprintf(buf, "%d", no);
 	d = debugfs_create_dir(buf, parent);
 	if (!d)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 
 	type = debugfs_create_x32("type", S_IRUGO, d, &node->type);
 	if (!type)
@@ -108,7 +114,9 @@ static int __init create_setup_data_nodes(struct dentry *parent)
 
 	d = debugfs_create_dir("setup_data", parent);
 	if (!d)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 
 	pa_data = boot_params.hdr.setup_data;
 
@@ -157,7 +165,9 @@ static int __init boot_params_kdebugfs_init(void)
 
 	dbp = debugfs_create_dir("boot_params", arch_debugfs_dir);
 	if (!dbp)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 
 	version = debugfs_create_x16("version", S_IRUGO, dbp,
 				     &boot_params.hdr.version);
@@ -191,7 +201,9 @@ static int __init arch_kdebugfs_init(void)
 
 	arch_debugfs_dir = debugfs_create_dir("x86", NULL);
 	if (!arch_debugfs_dir)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 
 #ifdef CONFIG_DEBUG_BOOT_PARAMS
 	error = boot_params_kdebugfs_init();
diff --git a/arch/x86/kernel/kprobes/core.c b/arch/x86/kernel/kprobes/core.c
index 0742491..5781b64 100644
--- a/arch/x86/kernel/kprobes/core.c
+++ b/arch/x86/kernel/kprobes/core.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  *  Kernel Probes (KProbes)
  *
diff --git a/arch/x86/kernel/ksysfs.c b/arch/x86/kernel/ksysfs.c
index 8c1cc08..8f4f75d 100644
--- a/arch/x86/kernel/ksysfs.c
+++ b/arch/x86/kernel/ksysfs.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * Architecture specific sysfs attributes in /sys/kernel
  *
@@ -23,6 +25,7 @@
 static ssize_t version_show(struct kobject *kobj,
 			    struct kobj_attribute *attr, char *buf)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return sprintf(buf, "0x%04x\n", boot_params.hdr.version);
 }
 
@@ -32,6 +35,7 @@ static ssize_t boot_params_data_read(struct file *fp, struct kobject *kobj,
 				     struct bin_attribute *bin_attr,
 				     char *buf, loff_t off, size_t count)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	memcpy(buf, (void *)&boot_params + off, count);
 	return count;
 }
@@ -74,6 +78,7 @@ static int get_setup_data_paddr(int nr, u64 *paddr)
 	struct setup_data *data;
 	u64 pa_data = boot_params.hdr.setup_data;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	while (pa_data) {
 		if (nr == i) {
 			*paddr = pa_data;
@@ -96,6 +101,7 @@ static int __init get_setup_data_size(int nr, size_t *size)
 	struct setup_data *data;
 	u64 pa_data = boot_params.hdr.setup_data;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	while (pa_data) {
 		data = memremap(pa_data, sizeof(*data), MEMREMAP_WB);
 		if (!data)
@@ -122,7 +128,9 @@ static ssize_t type_show(struct kobject *kobj,
 
 	ret = kobj_to_setup_data_nr(kobj, &nr);
 	if (ret)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ret;
+}
 
 	ret = get_setup_data_paddr(nr, &paddr);
 	if (ret)
@@ -149,7 +157,9 @@ static ssize_t setup_data_data_read(struct file *fp,
 
 	ret = kobj_to_setup_data_nr(kobj, &nr);
 	if (ret)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ret;
+}
 
 	ret = get_setup_data_paddr(nr, &paddr);
 	if (ret)
@@ -218,7 +228,9 @@ static int __init create_setup_data_node(struct kobject *parent,
 
 	kobj = kobject_create_and_add(name, parent);
 	if (!kobj)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 
 	ret = get_setup_data_size(nr, &size);
 	if (ret)
@@ -238,6 +250,7 @@ static int __init create_setup_data_node(struct kobject *parent,
 
 static void __init cleanup_setup_data_node(struct kobject *kobj)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	sysfs_remove_group(kobj, &setup_data_attr_group);
 	kobject_put(kobj);
 }
@@ -248,6 +261,7 @@ static int __init get_setup_data_total_num(u64 pa_data, int *nr)
 	struct setup_data *data;
 
 	*nr = 0;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	while (pa_data) {
 		*nr += 1;
 		data = memremap(pa_data, sizeof(*data), MEMREMAP_WB);
@@ -271,36 +285,49 @@ static int __init create_setup_data_nodes(struct kobject *parent)
 
 	pa_data = boot_params.hdr.setup_data;
 	if (!pa_data)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	setup_data_kobj = kobject_create_and_add("setup_data", parent);
 	if (!setup_data_kobj) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ret = -ENOMEM;
 		goto out;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	ret = get_setup_data_total_num(pa_data, &nr);
 	if (ret)
 		goto out_setup_data_kobj;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	kobjp = kmalloc(sizeof(*kobjp) * nr, GFP_KERNEL);
 	if (!kobjp) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ret = -ENOMEM;
 		goto out_setup_data_kobj;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (i = 0; i < nr; i++) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ret = create_setup_data_node(setup_data_kobj, kobjp + i, i);
 		if (ret)
 			goto out_clean_nodes;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	kfree(kobjp);
 	return 0;
 
 out_clean_nodes:
 	for (j = i - 1; j >= 0; j--)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		cleanup_setup_data_node(*(kobjp + j));
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	kfree(kobjp);
 out_setup_data_kobj:
 	kobject_put(setup_data_kobj);
@@ -316,6 +343,7 @@ static int __init boot_params_ksysfs_init(void)
 	boot_params_kobj = kobject_create_and_add("boot_params",
 						  kernel_kobj);
 	if (!boot_params_kobj) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ret = -ENOMEM;
 		goto out;
 	}
@@ -328,6 +356,7 @@ static int __init boot_params_ksysfs_init(void)
 	if (ret)
 		goto out_create_group;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 out_create_group:
 	sysfs_remove_group(boot_params_kobj, &boot_params_attr_group);
diff --git a/arch/x86/kernel/kvm.c b/arch/x86/kernel/kvm.c
index a94de09..c031ca4 100644
--- a/arch/x86/kernel/kvm.c
+++ b/arch/x86/kernel/kvm.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * KVM paravirt_ops implementation
  *
diff --git a/arch/x86/kernel/kvmclock.c b/arch/x86/kernel/kvmclock.c
index 5b609e2..9ff779e 100644
--- a/arch/x86/kernel/kvmclock.c
+++ b/arch/x86/kernel/kvmclock.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*  KVM paravirtual clock driver. A clocksource implementation
     Copyright (C) 2008 Glauber de Oliveira Costa, Red Hat Inc.
 
diff --git a/arch/x86/kernel/module.c b/arch/x86/kernel/module.c
index da0c160..23253e3 100644
--- a/arch/x86/kernel/module.c
+++ b/arch/x86/kernel/module.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*  Kernel module help for x86.
     Copyright (C) 2001 Rusty Russell.
 
@@ -82,14 +84,18 @@ void *module_alloc(unsigned long size)
 	void *p;
 
 	if (PAGE_ALIGN(size) > MODULES_LEN)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 
 	p = __vmalloc_node_range(size, MODULE_ALIGN,
 				    MODULES_VADDR + get_module_load_offset(),
 				    MODULES_END, GFP_KERNEL,
 				    PAGE_KERNEL_EXEC, 0, NUMA_NO_NODE,
 				    __builtin_return_address(0));
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (p && (kasan_module_alloc(p, size) < 0)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		vfree(p);
 		return NULL;
 	}
@@ -150,6 +156,7 @@ int apply_relocate_add(Elf64_Shdr *sechdrs,
 	void *loc;
 	u64 val;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	DEBUGP("Applying relocate section %u to %u\n",
 	       relsec, sechdrs[relsec].sh_info);
 	for (i = 0; i < sechdrs[relsec].sh_size / sizeof(*rel); i++) {
@@ -230,6 +237,7 @@ int module_finalize(const Elf_Ehdr *hdr,
 		*para = NULL, *orc = NULL, *orc_ip = NULL;
 	char *secstrings = (void *)hdr + sechdrs[hdr->e_shstrndx].sh_offset;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (s = sechdrs; s < sechdrs + hdr->e_shnum; s++) {
 		if (!strcmp(".text", secstrings + s->sh_name))
 			text = s;
@@ -275,5 +283,6 @@ int module_finalize(const Elf_Ehdr *hdr,
 
 void module_arch_cleanup(struct module *mod)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	alternatives_smp_module_del(mod);
 }
diff --git a/arch/x86/kernel/mpparse.c b/arch/x86/kernel/mpparse.c
index bc6bc66..c8fd7f8 100644
--- a/arch/x86/kernel/mpparse.c
+++ b/arch/x86/kernel/mpparse.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 /*
  *	Intel Multiprocessor Specification 1.1 and 1.4
@@ -48,6 +50,7 @@ static int __init mpf_checksum(unsigned char *mp, int len)
 
 int __init default_mpc_apic_id(struct mpc_cpu *m)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return m->apicid;
 }
 
@@ -57,6 +60,7 @@ static void __init MP_processor_info(struct mpc_cpu *m)
 	char *bootup_cpu = "";
 
 	if (!(m->cpuflag & CPU_ENABLED)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		disabled_cpus++;
 		return;
 	}
@@ -75,6 +79,7 @@ static void __init MP_processor_info(struct mpc_cpu *m)
 #ifdef CONFIG_X86_IO_APIC
 void __init default_mpc_oem_bus_info(struct mpc_bus *m, char *str)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	memcpy(str, m->bustype, 6);
 	str[6] = 0;
 	apic_printk(APIC_VERBOSE, "Bus #%d is %s\n", m->busid, str);
@@ -121,11 +126,14 @@ static void __init MP_ioapic_info(struct mpc_ioapic *m)
 	};
 
 	if (m->flags & MPC_APIC_USABLE)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		mp_register_ioapic(m->apicid, m->apicaddr, gsi_top, &cfg);
 }
+}
 
 static void __init print_mp_irq_info(struct mpc_intsrc *mp_irq)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	apic_printk(APIC_VERBOSE,
 		"Int: type %d, pol %d, trig %d, bus %02x, IRQ %02x, APIC ID %x, APIC INT %02x\n",
 		mp_irq->irqtype, mp_irq->irqflag & 3,
@@ -503,27 +511,38 @@ void __init default_get_smp_config(unsigned int early)
 	struct mpf_intel *mpf;
 
 	if (!smp_found_config)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	if (!mpf_found)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	if (acpi_lapic && early)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	/*
 	 * MPS doesn't support hyperthreading, aka only have
 	 * thread 0 apic id in MPS table
 	 */
 	if (acpi_lapic && acpi_ioapic)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	mpf = early_memremap(mpf_base, sizeof(*mpf));
 	if (!mpf) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_err("MPTABLE: error mapping MP table\n");
 		return;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pr_info("Intel MultiProcessor Specification v1.%d\n",
 		mpf->specification);
 #if defined(CONFIG_X86_LOCAL_APIC) && defined(CONFIG_X86_32)
@@ -539,6 +558,7 @@ void __init default_get_smp_config(unsigned int early)
 	 * Now see if we need to read further.
 	 */
 	if (mpf->feature1) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (early) {
 			/*
 			 * local APIC has default address
@@ -547,23 +567,32 @@ void __init default_get_smp_config(unsigned int early)
 			return;
 		}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_info("Default MP configuration #%d\n", mpf->feature1);
 		construct_default_ISA_mptable(mpf->feature1);
 
 	} else if (mpf->physptr) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (check_physptr(mpf, early)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			early_memunmap(mpf, sizeof(*mpf));
 			return;
 		}
 	} else
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		BUG();
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!early)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_info("Processors: %d\n", num_processors);
+}
 	/*
 	 * Only use the first configuration found.
 	 */
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	early_memunmap(mpf, sizeof(*mpf));
 }
 
@@ -580,6 +609,7 @@ static int __init smp_scan_config(unsigned long base, unsigned long length)
 
 	apic_printk(APIC_VERBOSE, "Scan for SMP in [mem %#010lx-%#010lx]\n",
 		    base, base + length - 1);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	BUILD_BUG_ON(sizeof(*mpf) != 16);
 
 	while (length > 0) {
@@ -603,6 +633,7 @@ static int __init smp_scan_config(unsigned long base, unsigned long length)
 			if (mpf->physptr)
 				smp_reserve_memory(mpf);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			ret = 1;
 		}
 		early_memunmap(bp, length);
@@ -649,10 +680,13 @@ void __init default_find_smp_config(void)
 	 * MP1.4 SPEC states to only scan first 1K of 4K EBDA.
 	 */
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	address = get_bios_ebda();
 	if (address)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		smp_scan_config(address, 0x400);
 }
+}
 
 #ifdef CONFIG_X86_IO_APIC
 static u8 __initdata irq_used[MAX_IRQ_SOURCES];
@@ -662,7 +696,9 @@ static int  __init get_MP_intsrc_index(struct mpc_intsrc *m)
 	int i;
 
 	if (m->irqtype != mp_INT)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	if (m->irqflag != 0x0f)
 		return 0;
@@ -700,6 +736,7 @@ static void __init check_irq_src(struct mpc_intsrc *m, int *nr_m_spare)
 {
 	int i;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	apic_printk(APIC_VERBOSE, "OLD ");
 	print_mp_irq_info(m);
 
@@ -727,6 +764,7 @@ static void __init check_irq_src(struct mpc_intsrc *m, int *nr_m_spare)
 static int __init
 check_slot(unsigned long mpc_new_phys, unsigned long mpc_new_length, int count)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!mpc_new_phys || count <= mpc_new_length) {
 		WARN(1, "update_mptable: No spare slots (length: %x)\n", count);
 		return -1;
diff --git a/arch/x86/kernel/msr.c b/arch/x86/kernel/msr.c
index ef68880..a365ef8 100644
--- a/arch/x86/kernel/msr.c
+++ b/arch/x86/kernel/msr.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /* ----------------------------------------------------------------------- *
  *
  *   Copyright 2000-2008 H. Peter Anvin - All Rights Reserved
@@ -57,7 +59,9 @@ static ssize_t msr_read(struct file *file, char __user *buf,
 	ssize_t bytes = 0;
 
 	if (count % 8)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;	/* Invalid chunk size */
+}
 
 	for (; count; count -= 8) {
 		err = rdmsr_safe_on_cpu(cpu, reg, &data[0], &data[1]);
@@ -85,7 +89,9 @@ static ssize_t msr_write(struct file *file, const char __user *buf,
 	ssize_t bytes = 0;
 
 	if (count % 8)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;	/* Invalid chunk size */
+}
 
 	for (; count; count -= 8) {
 		if (copy_from_user(&data, tmp, 8)) {
@@ -152,6 +158,7 @@ static long msr_ioctl(struct file *file, unsigned int ioc, unsigned long arg)
 
 static int msr_open(struct inode *inode, struct file *file)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	unsigned int cpu = iminor(file_inode(file));
 	struct cpuinfo_x86 *c;
 
@@ -192,6 +199,7 @@ static int msr_device_create(unsigned int cpu)
 
 static int msr_device_destroy(unsigned int cpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	device_destroy(msr_class, MKDEV(MSR_MAJOR, cpu));
 	return 0;
 }
@@ -206,11 +214,13 @@ static int __init msr_init(void)
 	int err;
 
 	if (__register_chrdev(MSR_MAJOR, 0, NR_CPUS, "cpu/msr", &msr_fops)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_err("unable to get major %d for msr\n", MSR_MAJOR);
 		return -EBUSY;
 	}
 	msr_class = class_create(THIS_MODULE, "msr");
 	if (IS_ERR(msr_class)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		err = PTR_ERR(msr_class);
 		goto out_chrdev;
 	}
@@ -233,6 +243,7 @@ module_init(msr_init);
 
 static void __exit msr_exit(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	cpuhp_remove_state(cpuhp_msr_state);
 	class_destroy(msr_class);
 	__unregister_chrdev(MSR_MAJOR, 0, NR_CPUS, "cpu/msr");
diff --git a/arch/x86/kernel/nmi.c b/arch/x86/kernel/nmi.c
index 35aafc9..265569d 100644
--- a/arch/x86/kernel/nmi.c
+++ b/arch/x86/kernel/nmi.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  *  Copyright (C) 1991, 1992  Linus Torvalds
  *  Copyright (C) 2000, 2001, 2002 Andi Kleen, SuSE Labs
@@ -84,6 +86,7 @@ static DEFINE_RAW_SPINLOCK(nmi_reason_lock);
 
 static int __init setup_unknown_nmi_panic(char *str)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	unknown_nmi_panic = 1;
 	return 1;
 }
@@ -103,6 +106,7 @@ fs_initcall(nmi_warning_debugfs);
 
 static void nmi_max_handler(struct irq_work *w)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct nmiaction *a = container_of(w, struct nmiaction, irq_work);
 	int remainder_ns, decimal_msecs;
 	u64 whole_msecs = ACCESS_ONCE(a->max_duration);
@@ -159,8 +163,11 @@ int __register_nmi_handler(unsigned int type, struct nmiaction *action)
 	unsigned long flags;
 
 	if (!action->handler)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	init_irq_work(&action->irq_work, nmi_max_handler);
 
 	raw_spin_lock_irqsave(&desc->lock, flags);
@@ -177,7 +184,9 @@ int __register_nmi_handler(unsigned int type, struct nmiaction *action)
 	 * event confuses some handlers (kdump uses this flag)
 	 */
 	if (action->flags & NMI_FLAG_FIRST)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		list_add_rcu(&action->list, &desc->head);
+}
 	else
 		list_add_tail_rcu(&action->list, &desc->head);
 	
@@ -192,6 +201,7 @@ void unregister_nmi_handler(unsigned int type, const char *name)
 	struct nmiaction *n;
 	unsigned long flags;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	raw_spin_lock_irqsave(&desc->lock, flags);
 
 	list_for_each_entry_rcu(n, &desc->head, list) {
@@ -240,7 +250,9 @@ io_check_error(unsigned char reason, struct pt_regs *regs)
 
 	/* check to see if anyone registered against these types of errors */
 	if (nmi_handle(NMI_IO_CHECK, regs))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	pr_emerg(
 	"NMI: IOCK error (debug interrupt?) for reason %02x on CPU %d.\n",
@@ -286,6 +298,7 @@ unknown_nmi_error(unsigned char reason, struct pt_regs *regs)
 	 */
 	handled = nmi_handle(NMI_UNKNOWN, regs);
 	if (handled) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		__this_cpu_add(nmi_stats.unknown, handled);
 		return;
 	}
@@ -494,6 +507,7 @@ do_nmi(struct pt_regs *regs, long error_code)
 {
 	if (this_cpu_read(nmi_state) != NMI_NOT_RUNNING) {
 		this_cpu_write(nmi_state, NMI_LATCHED);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
 	}
 	this_cpu_write(nmi_state, NMI_EXECUTING);
diff --git a/arch/x86/kernel/paravirt-spinlocks.c b/arch/x86/kernel/paravirt-spinlocks.c
index 71f2d11..d285eb0 100644
--- a/arch/x86/kernel/paravirt-spinlocks.c
+++ b/arch/x86/kernel/paravirt-spinlocks.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 /*
  * Split spinlock implementation out into its own file, so it can be
diff --git a/arch/x86/kernel/paravirt.c b/arch/x86/kernel/paravirt.c
index e1df9ef..6ffe703 100644
--- a/arch/x86/kernel/paravirt.c
+++ b/arch/x86/kernel/paravirt.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*  Paravirtualization interfaces
     Copyright (C) 2006 Rusty Russell IBM Corporation
 
diff --git a/arch/x86/kernel/paravirt_patch_64.c b/arch/x86/kernel/paravirt_patch_64.c
index 9edadab..1960c44 100644
--- a/arch/x86/kernel/paravirt_patch_64.c
+++ b/arch/x86/kernel/paravirt_patch_64.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 #include <asm/paravirt.h>
 #include <asm/asm-offsets.h>
diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index 599d746..bc2b05e 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 #include <linux/dma-mapping.h>
 #include <linux/dma-debug.h>
@@ -95,8 +97,10 @@ void *dma_generic_alloc_coherent(struct device *dev, size_t size,
 		page = dma_alloc_from_contiguous(dev, count, get_order(size),
 						 flag);
 		if (page) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			addr = phys_to_dma(dev, page_to_phys(page));
 			if (addr + size > dma_mask) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				dma_release_from_contiguous(dev, page, count);
 				page = NULL;
 			}
@@ -106,19 +110,26 @@ void *dma_generic_alloc_coherent(struct device *dev, size_t size,
 	if (!page)
 		page = alloc_pages_node(dev_to_node(dev), flag, get_order(size));
 	if (!page)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 
 	addr = phys_to_dma(dev, page_to_phys(page));
 	if (addr + size > dma_mask) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		__free_pages(page, get_order(size));
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (dma_mask < DMA_BIT_MASK(32) && !(flag & GFP_DMA)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			flag = (flag & ~GFP_DMA32) | GFP_DMA;
 			goto again;
 		}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	memset(page_address(page), 0, size);
 	*dma_addr = addr;
 	return page_address(page);
@@ -131,19 +142,25 @@ void dma_generic_free_coherent(struct device *dev, size_t size, void *vaddr,
 	struct page *page = virt_to_page(vaddr);
 
 	if (!dma_release_from_contiguous(dev, page, count))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		free_pages((unsigned long)vaddr, get_order(size));
 }
+}
 
 bool arch_dma_alloc_attrs(struct device **dev, gfp_t *gfp)
 {
 	if (!*dev)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		*dev = &x86_dma_fallback_dev;
+}
 
 	*gfp &= ~(__GFP_DMA | __GFP_HIGHMEM | __GFP_DMA32);
 	*gfp = dma_alloc_coherent_gfp_flags(*dev, *gfp);
 
 	if (!is_device_dma_capable(*dev))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return false;
+}
 	return true;
 
 }
@@ -155,6 +172,7 @@ EXPORT_SYMBOL(arch_dma_alloc_attrs);
  */
 static __init int iommu_setup(char *p)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	iommu_merge = 1;
 
 	if (!p)
@@ -221,6 +239,7 @@ int x86_dma_supported(struct device *dev, u64 mask)
 {
 #ifdef CONFIG_PCI
 	if (mask > 0xffffffff && forbid_dac > 0) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		dev_info(dev, "PCI: Disallowing DAC for device\n");
 		return 0;
 	}
@@ -230,7 +249,9 @@ int x86_dma_supported(struct device *dev, u64 mask)
 	   only work for pci_alloc_coherent.
 	   The caller just has to use GFP_DMA in this case. */
 	if (mask < DMA_BIT_MASK(24))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	/* Tell the device to use SAC when IOMMU force is on.  This
 	   allows the driver to use cheaper accesses in some cases.
@@ -245,10 +266,12 @@ int x86_dma_supported(struct device *dev, u64 mask)
 	   type. Normally this doesn't make any difference, but gives
 	   more gentle handling of IOMMU overflow. */
 	if (iommu_sac_force && (mask >= DMA_BIT_MASK(40))) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		dev_info(dev, "Force SAC with mask %Lx\n", mask);
 		return 0;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 1;
 }
 
@@ -277,6 +300,7 @@ rootfs_initcall(pci_iommu_init);
 
 static void via_no_dac(struct pci_dev *dev)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (forbid_dac == 0) {
 		dev_info(&dev->dev, "disabling DAC on VIA PCI bridge\n");
 		forbid_dac = 1;
diff --git a/arch/x86/kernel/pci-iommu_table.c b/arch/x86/kernel/pci-iommu_table.c
index 4dfd90a..68b5592 100644
--- a/arch/x86/kernel/pci-iommu_table.c
+++ b/arch/x86/kernel/pci-iommu_table.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 #include <linux/dma-mapping.h>
 #include <asm/iommu_table.h>
@@ -15,12 +17,17 @@ find_dependents_of(struct iommu_table_entry *start,
 	struct iommu_table_entry *p;
 
 	if (!q)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 
 	for (p = start; p < finish; p++)
 		if (p->detect == q->depend)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return p;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return NULL;
 }
 
diff --git a/arch/x86/kernel/pci-nommu.c b/arch/x86/kernel/pci-nommu.c
index b0caae2..85f2a76 100644
--- a/arch/x86/kernel/pci-nommu.c
+++ b/arch/x86/kernel/pci-nommu.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 /* Fallback functions when the main IOMMU code is not compiled in. This
    code is roughly equivalent to i386. */
@@ -18,13 +20,17 @@ static int
 check_addr(char *name, struct device *hwdev, dma_addr_t bus, size_t size)
 {
 	if (hwdev && !dma_capable(hwdev, bus, size)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (*hwdev->dma_mask >= DMA_BIT_MASK(32))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			printk(KERN_ERR
 			    "nommu_%s: overflow %Lx+%zu of device mask %Lx\n",
 				name, (long long)bus, size,
 				(long long)*hwdev->dma_mask);
+}
 		return 0;
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 1;
 }
 
@@ -33,6 +39,7 @@ static dma_addr_t nommu_map_page(struct device *dev, struct page *page,
 				 enum dma_data_direction dir,
 				 unsigned long attrs)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	dma_addr_t bus = phys_to_dma(dev, page_to_phys(page)) + offset;
 	WARN_ON(size == 0);
 	if (!check_addr("map_single", dev, bus, size))
@@ -69,9 +76,12 @@ static int nommu_map_sg(struct device *hwdev, struct scatterlist *sg,
 		BUG_ON(!sg_page(s));
 		s->dma_address = sg_phys(s);
 		if (!check_addr("map_sg", hwdev, s->dma_address, s->length))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return 0;
+}
 		s->dma_length = s->length;
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	flush_write_buffers();
 	return nents;
 }
@@ -80,6 +90,7 @@ static void nommu_sync_single_for_device(struct device *dev,
 			dma_addr_t addr, size_t size,
 			enum dma_data_direction dir)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	flush_write_buffers();
 }
 
@@ -88,11 +99,13 @@ static void nommu_sync_sg_for_device(struct device *dev,
 			struct scatterlist *sg, int nelems,
 			enum dma_data_direction dir)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	flush_write_buffers();
 }
 
 static int nommu_mapping_error(struct device *dev, dma_addr_t dma_addr)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return dma_addr == NOMMU_MAPPING_ERROR;
 }
 
diff --git a/arch/x86/kernel/pci-swiotlb.c b/arch/x86/kernel/pci-swiotlb.c
index 53bd05e..04b4a7e 100644
--- a/arch/x86/kernel/pci-swiotlb.c
+++ b/arch/x86/kernel/pci-swiotlb.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 /* Glue code to lib/swiotlb.c */
 
@@ -33,8 +35,11 @@ void *x86_swiotlb_alloc_coherent(struct device *hwdev, size_t size,
 	vaddr = dma_generic_alloc_coherent(hwdev, size, dma_handle, flags,
 					   attrs);
 	if (vaddr)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return vaddr;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return swiotlb_alloc_coherent(hwdev, size, dma_handle, flags);
 }
 
@@ -42,6 +47,7 @@ void x86_swiotlb_free_coherent(struct device *dev, size_t size,
 				      void *vaddr, dma_addr_t dma_addr,
 				      unsigned long attrs)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (is_swiotlb_buffer(dma_to_phys(dev, dma_addr)))
 		swiotlb_free_coherent(dev, size, vaddr, dma_addr);
 	else
@@ -72,7 +78,9 @@ static const struct dma_map_ops swiotlb_dma_ops = {
 int __init pci_swiotlb_detect_override(void)
 {
 	if (swiotlb_force == SWIOTLB_FORCE)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		swiotlb = 1;
+}
 
 	return swiotlb;
 }
@@ -99,7 +107,9 @@ int __init pci_swiotlb_detect_4gb(void)
 	 * the addressing range required for the encryption mask.
 	 */
 	if (sme_active())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		swiotlb = 1;
+}
 
 	return swiotlb;
 }
@@ -120,7 +130,9 @@ void __init pci_swiotlb_late_init(void)
 {
 	/* An IOMMU turned us off. */
 	if (!swiotlb)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		swiotlb_free();
+}
 	else {
 		printk(KERN_INFO "PCI-DMA: "
 		       "Using software bounce buffering for IO (SWIOTLB)\n");
diff --git a/arch/x86/kernel/pcspeaker.c b/arch/x86/kernel/pcspeaker.c
index da5190a..7ce21ab 100644
--- a/arch/x86/kernel/pcspeaker.c
+++ b/arch/x86/kernel/pcspeaker.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 #include <linux/platform_device.h>
 #include <linux/err.h>
diff --git a/arch/x86/kernel/platform-quirks.c b/arch/x86/kernel/platform-quirks.c
index 39a5929..3a110a0 100644
--- a/arch/x86/kernel/platform-quirks.c
+++ b/arch/x86/kernel/platform-quirks.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 #include <linux/kernel.h>
 #include <linux/init.h>
@@ -29,8 +31,10 @@ void __init x86_early_init_platform_quirks(void)
 	}
 
 	if (x86_platform.set_legacy_features)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		x86_platform.set_legacy_features();
 }
+}
 
 #if defined(CONFIG_PNPBIOS)
 bool __init arch_pnpbios_disabled(void)
diff --git a/arch/x86/kernel/probe_roms.c b/arch/x86/kernel/probe_roms.c
index ee02863..3a9fa3b 100644
--- a/arch/x86/kernel/probe_roms.c
+++ b/arch/x86/kernel/probe_roms.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 #include <linux/sched.h>
 #include <linux/mm.h>
@@ -83,6 +85,7 @@ static bool match_id(struct pci_dev *pdev, unsigned short vendor, unsigned short
 	struct pci_driver *drv = pdev->driver;
 	const struct pci_device_id *id;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (pdev->vendor == vendor && pdev->device == device)
 		return true;
 
@@ -99,6 +102,7 @@ static bool probe_list(struct pci_dev *pdev, unsigned short vendor,
 	unsigned short device;
 
 	do {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (probe_kernel_address(rom_list, device) != 0)
 			device = 0;
 
@@ -116,6 +120,7 @@ static struct resource *find_oprom(struct pci_dev *pdev)
 	struct resource *oprom = NULL;
 	int i;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (i = 0; i < ARRAY_SIZE(adapter_rom_resources); i++) {
 		struct resource *res = &adapter_rom_resources[i];
 		unsigned short offset, vendor, device, list, rev;
@@ -153,6 +158,7 @@ static struct resource *find_oprom(struct pci_dev *pdev)
 
 void __iomem *pci_map_biosrom(struct pci_dev *pdev)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct resource *oprom = find_oprom(pdev);
 
 	if (!oprom)
@@ -164,12 +170,14 @@ EXPORT_SYMBOL(pci_map_biosrom);
 
 void pci_unmap_biosrom(void __iomem *image)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	iounmap(image);
 }
 EXPORT_SYMBOL(pci_unmap_biosrom);
 
 size_t pci_biosrom_size(struct pci_dev *pdev)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct resource *oprom = find_oprom(pdev);
 
 	return oprom ? resource_size(oprom) : 0;
@@ -205,6 +213,7 @@ void __init probe_roms(void)
 	/* video rom */
 	upper = adapter_rom_resources[0].start;
 	for (start = video_rom_resource.start; start < upper; start += 2048) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		rom = isa_bus_to_virt(start);
 		if (!romsignature(rom))
 			continue;
@@ -227,7 +236,9 @@ void __init probe_roms(void)
 
 	start = (video_rom_resource.end + 1 + 2047) & ~2047UL;
 	if (start < upper)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		start = upper;
+}
 
 	/* system rom */
 	request_resource(&iomem_resource, &system_rom_resource);
@@ -236,8 +247,10 @@ void __init probe_roms(void)
 	/* check for extension rom (ignore length byte!) */
 	rom = isa_bus_to_virt(extension_rom_resource.start);
 	if (romsignature(rom)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		length = resource_size(&extension_rom_resource);
 		if (romchecksum(rom, length)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			request_resource(&iomem_resource, &extension_rom_resource);
 			upper = extension_rom_resource.start;
 		}
@@ -245,6 +258,7 @@ void __init probe_roms(void)
 
 	/* check for adapter roms on 2k boundaries */
 	for (i = 0; i < ARRAY_SIZE(adapter_rom_resources) && start < upper; start += 2048) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		rom = isa_bus_to_virt(start);
 		if (!romsignature(rom))
 			continue;
diff --git a/arch/x86/kernel/process.c b/arch/x86/kernel/process.c
index 8bd1d82..fb4bb7c 100644
--- a/arch/x86/kernel/process.c
+++ b/arch/x86/kernel/process.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 #define pr_fmt(fmt) KBUILD_MODNAME ": " fmt
 
@@ -111,6 +113,7 @@ void exit_thread(struct task_struct *tsk)
 	struct fpu *fpu = &t->fpu;
 
 	if (bp) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		struct tss_struct *tss = &per_cpu(cpu_tss_rw, get_cpu());
 
 		t->io_bitmap_ptr = NULL;
@@ -124,6 +127,7 @@ void exit_thread(struct task_struct *tsk)
 		kfree(bp);
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	free_vm86(t);
 
 	fpu__drop(fpu);
@@ -131,6 +135,7 @@ void exit_thread(struct task_struct *tsk)
 
 void flush_thread(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct task_struct *tsk = current;
 
 	flush_ptrace_hw_breakpoint(tsk);
@@ -141,6 +146,7 @@ void flush_thread(void)
 
 void disable_TSC(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	preempt_disable();
 	if (!test_and_set_thread_flag(TIF_NOTSC))
 		/*
@@ -153,6 +159,7 @@ void disable_TSC(void)
 
 static void enable_TSC(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	preempt_disable();
 	if (test_and_clear_thread_flag(TIF_NOTSC))
 		/*
@@ -168,7 +175,9 @@ int get_tsc_mode(unsigned long adr)
 	unsigned int val;
 
 	if (test_thread_flag(TIF_NOTSC))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		val = PR_TSC_SIGSEGV;
+}
 	else
 		val = PR_TSC_ENABLE;
 
@@ -177,6 +186,7 @@ int get_tsc_mode(unsigned long adr)
 
 int set_tsc_mode(unsigned int val)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (val == PR_TSC_SIGSEGV)
 		disable_TSC();
 	else if (val == PR_TSC_ENABLE)
@@ -193,6 +203,7 @@ static void set_cpuid_faulting(bool on)
 {
 	u64 msrval;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	msrval = this_cpu_read(msr_misc_features_shadow);
 	msrval &= ~MSR_MISC_FEATURES_ENABLES_CPUID_FAULT;
 	msrval |= (on << MSR_MISC_FEATURES_ENABLES_CPUID_FAULT_BIT);
@@ -202,6 +213,7 @@ static void set_cpuid_faulting(bool on)
 
 static void disable_cpuid(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	preempt_disable();
 	if (!test_and_set_thread_flag(TIF_NOCPUID)) {
 		/*
@@ -215,6 +227,7 @@ static void disable_cpuid(void)
 
 static void enable_cpuid(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	preempt_disable();
 	if (test_and_clear_thread_flag(TIF_NOCPUID)) {
 		/*
@@ -228,11 +241,13 @@ static void enable_cpuid(void)
 
 static int get_cpuid_mode(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return !test_thread_flag(TIF_NOCPUID);
 }
 
 static int set_cpuid_mode(struct task_struct *task, unsigned long cpuid_enabled)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!static_cpu_has(X86_FEATURE_CPUID_FAULT))
 		return -ENODEV;
 
@@ -251,14 +266,17 @@ void arch_setup_new_exec(void)
 {
 	/* If cpuid was previously disabled for this task, re-enable it. */
 	if (test_thread_flag(TIF_NOCPUID))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		enable_cpuid();
 }
+}
 
 static inline void switch_to_bitmap(struct tss_struct *tss,
 				    struct thread_struct *prev,
 				    struct thread_struct *next,
 				    unsigned long tifp, unsigned long tifn)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (tifn & _TIF_IO_BITMAP) {
 		/*
 		 * Copy the relevant range of the IO bitmap.
@@ -288,6 +306,7 @@ void __switch_to_xtra(struct task_struct *prev_p, struct task_struct *next_p,
 	prev = &prev_p->thread;
 	next = &next_p->thread;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	tifn = READ_ONCE(task_thread_info(next_p)->flags);
 	tifp = READ_ONCE(task_thread_info(prev_p)->flags);
 	switch_to_bitmap(tss, prev, next, tifp, tifn);
@@ -335,6 +354,7 @@ void arch_cpu_idle_enter(void)
 
 void arch_cpu_idle_dead(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	play_dead();
 }
 
@@ -372,6 +392,7 @@ bool xen_set_default_idle(void)
 
 void stop_this_cpu(void *dummy)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	local_irq_disable();
 	/*
 	 * Remove this CPU:
@@ -443,11 +464,17 @@ static void amd_e400_idle(void)
 static int prefer_mwait_c1_over_halt(const struct cpuinfo_x86 *c)
 {
 	if (c->x86_vendor != X86_VENDOR_INTEL)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!cpu_has(c, X86_FEATURE_MWAIT) || static_cpu_has_bug(X86_BUG_MONITOR))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 1;
 }
 
@@ -458,6 +485,7 @@ static int prefer_mwait_c1_over_halt(const struct cpuinfo_x86 *c)
  */
 static __cpuidle void mwait_idle(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!current_set_polling_and_test()) {
 		trace_cpu_idle_rcuidle(1, smp_processor_id());
 		if (this_cpu_has(X86_BUG_CLFLUSH_MONITOR)) {
@@ -482,15 +510,21 @@ void select_idle_routine(const struct cpuinfo_x86 *c)
 {
 #ifdef CONFIG_SMP
 	if (boot_option_idle_override == IDLE_POLL && smp_num_siblings > 1)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_warn_once("WARNING: polling idle and HT enabled, performance may degrade\n");
+}
 #endif
 	if (x86_idle || boot_option_idle_override == IDLE_POLL)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	if (boot_cpu_has_bug(X86_BUG_AMD_E400)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_info("using AMD E400 aware idle routine\n");
 		x86_idle = amd_e400_idle;
 	} else if (prefer_mwait_c1_over_halt(c)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_info("using mwait in idle threads\n");
 		x86_idle = mwait_idle;
 	} else
@@ -500,9 +534,13 @@ void select_idle_routine(const struct cpuinfo_x86 *c)
 void amd_e400_c1e_apic_setup(void)
 {
 	if (boot_cpu_has_bug(X86_BUG_AMD_APIC_C1E)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_info("Switch to broadcast mode on CPU%d\n", smp_processor_id());
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		local_irq_disable();
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		tick_broadcast_force();
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		local_irq_enable();
 	}
 }
@@ -512,7 +550,9 @@ void __init arch_post_acpi_subsys_init(void)
 	u32 lo, hi;
 
 	if (!boot_cpu_has_bug(X86_BUG_AMD_E400))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	/*
 	 * AMD E400 detection needs to happen after ACPI has been enabled. If
@@ -520,18 +560,27 @@ void __init arch_post_acpi_subsys_init(void)
 	 * MSR_K8_INT_PENDING_MSG.
 	 */
 	rdmsr(MSR_K8_INT_PENDING_MSG, lo, hi);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!(lo & K8_INTP_C1E_ACTIVE_MASK))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	boot_cpu_set_bug(X86_BUG_AMD_APIC_C1E);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!boot_cpu_has(X86_FEATURE_NONSTOP_TSC))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		mark_tsc_unstable("TSC halt in AMD C1E");
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pr_info("System has AMD C1E enabled\n");
 }
 
 static int __init idle_setup(char *str)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!str)
 		return -EINVAL;
 
@@ -588,10 +637,14 @@ unsigned long get_wchan(struct task_struct *p)
 	int count = 0;
 
 	if (!p || p == current || p->state == TASK_RUNNING)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	if (!try_get_task_stack(p))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	start = (unsigned long)task_stack_page(p);
 	if (!start)
@@ -617,6 +670,7 @@ unsigned long get_wchan(struct task_struct *p)
 	top -= 2 * sizeof(unsigned long);
 	bottom = start;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	sp = READ_ONCE(p->thread.sp);
 	if (sp < bottom || sp > top)
 		goto out;
@@ -625,12 +679,16 @@ unsigned long get_wchan(struct task_struct *p)
 	do {
 		if (fp < bottom || fp > top)
 			goto out;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ip = READ_ONCE_NOCHECK(*(unsigned long *)(fp + sizeof(unsigned long)));
 		if (!in_sched_functions(ip)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			ret = ip;
 			goto out;
 		}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		fp = READ_ONCE_NOCHECK(*(unsigned long *)fp);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	} while (count++ < 16 && p->state != TASK_RUNNING);
 
 out:
@@ -648,5 +706,6 @@ long do_arch_prctl_common(struct task_struct *task, int option,
 		return set_cpuid_mode(task, cpuid_enabled);
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return -EINVAL;
 }
diff --git a/arch/x86/kernel/process_64.c b/arch/x86/kernel/process_64.c
index 9eb448c..1a72fc9 100644
--- a/arch/x86/kernel/process_64.c
+++ b/arch/x86/kernel/process_64.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  *  Copyright (C) 1995  Linus Torvalds
  *
@@ -72,7 +74,9 @@ void __show_regs(struct pt_regs *regs, int all)
 	show_iret_regs(regs);
 
 	if (regs->orig_ax != -1)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_cont(" ORIG_RAX: %016lx\n", regs->orig_ax);
+}
 	else
 		pr_cont("\n");
 
@@ -134,13 +138,16 @@ void __show_regs(struct pt_regs *regs, int all)
 
 void release_thread(struct task_struct *dead_task)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (dead_task->mm) {
 #ifdef CONFIG_MODIFY_LDT_SYSCALL
 		if (dead_task->mm->context.ldt) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			pr_warn("WARNING: dead process %s still has LDT? <%p/%d>\n",
 				dead_task->comm,
 				dead_task->mm->context.ldt->entries,
 				dead_task->mm->context.ldt->nr_entries);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			BUG();
 		}
 #endif
@@ -191,7 +198,9 @@ static __always_inline void save_base_legacy(struct task_struct *prev_p,
 		 * saving the base isn't necessary.
 		 */
 		if (which == FS)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			prev_p->thread.fsbase = 0;
+}
 		else
 			prev_p->thread.gsbase = 0;
 	}
@@ -208,6 +217,7 @@ static __always_inline void save_fsgs(struct task_struct *task)
 static __always_inline void loadseg(enum which_selector which,
 				    unsigned short sel)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (which == FS)
 		loadsegment(fs, sel);
 	else
@@ -231,6 +241,7 @@ static __always_inline void load_seg_legacy(unsigned short prev_index,
 			 * the base.
 			 */
 			if (static_cpu_has_bug(X86_BUG_NULL_SEG)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				loadseg(which, __USER_DS);
 				loadseg(which, next_index);
 			} else {
@@ -247,11 +258,15 @@ static __always_inline void load_seg_legacy(unsigned short prev_index,
 				 * Intel-style CPUs.)
 				 */
 				if (likely(prev_index | next_index | prev_base))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 					loadseg(which, next_index);
+}
 			}
 		} else {
 			if (prev_index != next_index)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				loadseg(which, next_index);
+}
 			wrmsrl(which == FS ? MSR_FS_BASE : MSR_KERNEL_GS_BASE,
 			       next_base);
 		}
@@ -303,14 +318,18 @@ int copy_thread_tls(unsigned long clone_flags, unsigned long sp,
 	if (sp)
 		childregs->sp = sp;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	err = -ENOMEM;
 	if (unlikely(test_tsk_thread_flag(me, TIF_IO_BITMAP))) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		p->thread.io_bitmap_ptr = kmemdup(me->thread.io_bitmap_ptr,
 						  IO_BITMAP_BYTES, GFP_KERNEL);
 		if (!p->thread.io_bitmap_ptr) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			p->thread.io_bitmap_max = 0;
 			return -ENOMEM;
 		}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		set_tsk_thread_flag(p, TIF_IO_BITMAP);
 	}
 
@@ -320,21 +339,26 @@ int copy_thread_tls(unsigned long clone_flags, unsigned long sp,
 	if (clone_flags & CLONE_SETTLS) {
 #ifdef CONFIG_IA32_EMULATION
 		if (in_ia32_syscall())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			err = do_set_thread_area(p, -1,
 				(struct user_desc __user *)tls, 0);
+}
 		else
 #endif
 			err = do_arch_prctl_64(p, ARCH_SET_FS, tls);
 		if (err)
 			goto out;
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	err = 0;
 out:
 	if (err && p->thread.io_bitmap_ptr) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		kfree(p->thread.io_bitmap_ptr);
 		p->thread.io_bitmap_max = 0;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return err;
 }
 
@@ -401,6 +425,7 @@ __switch_to(struct task_struct *prev_p, struct task_struct *next_p)
 	int cpu = smp_processor_id();
 	struct tss_struct *tss = &per_cpu(cpu_tss_rw, cpu);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WARN_ON_ONCE(IS_ENABLED(CONFIG_DEBUG_ENTRY) &&
 		     this_cpu_read(irq_count) != -1);
 
@@ -444,11 +469,15 @@ __switch_to(struct task_struct *prev_p, struct task_struct *next_p)
 	 */
 	savesegment(es, prev->es);
 	if (unlikely(next->es | prev->es))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		loadsegment(es, next->es);
+}
 
 	savesegment(ds, prev->ds);
 	if (unlikely(next->ds | prev->ds))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		loadsegment(ds, next->ds);
+}
 
 	load_seg_legacy(prev->fsindex, prev->fsbase,
 			next->fsindex, next->fsbase, FS);
@@ -609,21 +638,28 @@ long do_arch_prctl_64(struct task_struct *task, int option, unsigned long arg2)
 	switch (option) {
 	case ARCH_SET_GS:
 		if (arg2 >= TASK_SIZE_MAX)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -EPERM;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		cpu = get_cpu();
 		task->thread.gsindex = 0;
 		task->thread.gsbase = arg2;
 		if (doit) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			load_gs_index(0);
 			ret = wrmsrl_safe(MSR_KERNEL_GS_BASE, arg2);
 		}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		put_cpu();
 		break;
 	case ARCH_SET_FS:
 		/* Not strictly needed for fs, but do it for symmetry
 		   with gs */
 		if (arg2 >= TASK_SIZE_MAX)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -EPERM;
+}
 		cpu = get_cpu();
 		task->thread.fsindex = 0;
 		task->thread.fsbase = arg2;
@@ -638,9 +674,12 @@ long do_arch_prctl_64(struct task_struct *task, int option, unsigned long arg2)
 		unsigned long base;
 
 		if (doit)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			rdmsrl(MSR_FS_BASE, base);
+}
 		else
 			base = task->thread.fsbase;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ret = put_user(base, (unsigned long __user *)arg2);
 		break;
 	}
@@ -648,9 +687,12 @@ long do_arch_prctl_64(struct task_struct *task, int option, unsigned long arg2)
 		unsigned long base;
 
 		if (doit)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			rdmsrl(MSR_KERNEL_GS_BASE, base);
+}
 		else
 			base = task->thread.gsbase;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ret = put_user(base, (unsigned long __user *)arg2);
 		break;
 	}
@@ -696,5 +738,6 @@ COMPAT_SYSCALL_DEFINE2(arch_prctl, int, option, unsigned long, arg2)
 
 unsigned long KSTK_ESP(struct task_struct *task)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return task_pt_regs(task)->sp;
 }
diff --git a/arch/x86/kernel/ptrace.c b/arch/x86/kernel/ptrace.c
index ed5c4cd..5d5886d 100644
--- a/arch/x86/kernel/ptrace.c
+++ b/arch/x86/kernel/ptrace.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /* By Ross Biro 1/23/92 */
 /*
  * Pentium III FXSR, SSE support
@@ -103,6 +105,7 @@ static const struct pt_regs_offset regoffset_table[] = {
 int regs_query_register_offset(const char *name)
 {
 	const struct pt_regs_offset *roff;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (roff = regoffset_table; roff->name != NULL; roff++)
 		if (!strcmp(roff->name, name))
 			return roff->offset;
@@ -119,6 +122,7 @@ int regs_query_register_offset(const char *name)
 const char *regs_query_register_name(unsigned int offset)
 {
 	const struct pt_regs_offset *roff;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (roff = regoffset_table; roff->name != NULL; roff++)
 		if (roff->offset == offset)
 			return roff->name;
@@ -145,6 +149,7 @@ const char *regs_query_register_name(unsigned int offset)
  */
 static inline bool invalid_selector(u16 value)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return unlikely(value != 0 && (value & SEGMENT_RPL_MASK) != USER_RPL);
 }
 
@@ -248,6 +253,7 @@ static int set_segment_reg(struct task_struct *task,
 
 static unsigned long *pt_regs_access(struct pt_regs *regs, unsigned long offset)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	BUILD_BUG_ON(offsetof(struct pt_regs, r15) != 0);
 	return &regs->r15 + (offset / sizeof(regs->r15));
 }
@@ -346,6 +352,7 @@ static int set_segment_reg(struct task_struct *task,
 
 static unsigned long get_flags(struct task_struct *task)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	unsigned long retval = task_pt_regs(task)->flags;
 
 	/*
@@ -359,6 +366,7 @@ static unsigned long get_flags(struct task_struct *task)
 
 static int set_flags(struct task_struct *task, unsigned long value)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct pt_regs *regs = task_pt_regs(task);
 
 	/*
@@ -379,6 +387,7 @@ static int set_flags(struct task_struct *task, unsigned long value)
 static int putreg(struct task_struct *child,
 		  unsigned long offset, unsigned long value)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	switch (offset) {
 	case offsetof(struct user_regs_struct, cs):
 	case offsetof(struct user_regs_struct, ds):
@@ -421,6 +430,7 @@ static int putreg(struct task_struct *child,
 
 static unsigned long getreg(struct task_struct *task, unsigned long offset)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	switch (offset) {
 	case offsetof(struct user_regs_struct, cs):
 	case offsetof(struct user_regs_struct, ds):
@@ -1374,6 +1384,7 @@ static void fill_sigtrap_info(struct task_struct *tsk,
 				int error_code, int si_code,
 				struct siginfo *info)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	tsk->thread.trap_nr = X86_TRAP_DB;
 	tsk->thread.error_code = error_code;
 
@@ -1387,6 +1398,7 @@ void user_single_step_siginfo(struct task_struct *tsk,
 				struct pt_regs *regs,
 				struct siginfo *info)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	fill_sigtrap_info(tsk, regs, 0, TRAP_BRKPT, info);
 }
 
diff --git a/arch/x86/kernel/quirks.c b/arch/x86/kernel/quirks.c
index 697a4ce..036ae9f 100644
--- a/arch/x86/kernel/quirks.c
+++ b/arch/x86/kernel/quirks.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 /*
  * This file contains work-arounds for x86 and x86_64 platform bugs.
@@ -21,7 +23,9 @@ static void quirk_intel_irqbalance(struct pci_dev *dev)
 	 * Disable SW irqbalance/affinity on those platforms.
 	 */
 	if (dev->revision > 0x9)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	/* enable access to config space*/
 	pci_read_config_byte(dev, 0xf4, &config);
@@ -73,7 +77,9 @@ static void ich_force_hpet_resume(void)
 	u32 val;
 
 	if (!force_hpet_address)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	BUG_ON(rcba_base == NULL);
 
@@ -99,6 +105,7 @@ static void ich_force_enable_hpet(struct pci_dev *dev)
 	u32 uninitialized_var(rcba);
 	int err = 0;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (hpet_address || force_hpet_address)
 		return;
 
@@ -179,6 +186,7 @@ static struct pci_dev *cached_dev;
 
 static void hpet_print_force_info(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	printk(KERN_INFO "HPET not enabled in BIOS. "
 	       "You might try hpet=force boot option\n");
 }
@@ -188,6 +196,7 @@ static void old_ich_force_hpet_resume(void)
 	u32 val;
 	u32 uninitialized_var(gen_cntl);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!force_hpet_address || !cached_dev)
 		return;
 
@@ -210,6 +219,7 @@ static void old_ich_force_enable_hpet(struct pci_dev *dev)
 	u32 val;
 	u32 uninitialized_var(gen_cntl);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (hpet_address || force_hpet_address)
 		return;
 
@@ -260,6 +270,7 @@ static void old_ich_force_enable_hpet(struct pci_dev *dev)
  */
 static void old_ich_force_enable_hpet_user(struct pci_dev *dev)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (hpet_force_user)
 		old_ich_force_enable_hpet(dev);
 }
@@ -284,6 +295,7 @@ static void vt8237_force_hpet_resume(void)
 {
 	u32 val;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!force_hpet_address || !cached_dev)
 		return;
 
@@ -301,6 +313,7 @@ static void vt8237_force_enable_hpet(struct pci_dev *dev)
 {
 	u32 uninitialized_var(val);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (hpet_address || force_hpet_address)
 		return;
 
@@ -350,6 +363,7 @@ DECLARE_PCI_FIXUP_HEADER(PCI_VENDOR_ID_VIA, PCI_DEVICE_ID_VIA_CX700,
 
 static void ati_force_hpet_resume(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pci_write_config_dword(cached_dev, 0x14, 0xfed00000);
 	printk(KERN_DEBUG "Force enabled HPET at resume\n");
 }
@@ -370,6 +384,7 @@ static u32 ati_ixp4x0_rev(struct pci_dev *dev)
 	d &= 0xff;
 	dev_printk(KERN_DEBUG, &dev->dev, "SB4X0 revision 0x%x\n", d);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WARN_ON_ONCE(err);
 
 	return d;
@@ -380,6 +395,7 @@ static void ati_force_enable_hpet(struct pci_dev *dev)
 	u32 d, val;
 	u8  b;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (hpet_address || force_hpet_address)
 		return;
 
@@ -424,6 +440,7 @@ DECLARE_PCI_FIXUP_HEADER(PCI_VENDOR_ID_ATI, PCI_DEVICE_ID_ATI_IXP400_SMBUS,
  */
 static void nvidia_force_hpet_resume(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pci_write_config_dword(cached_dev, 0x44, 0xfed00001);
 	printk(KERN_DEBUG "Force enabled HPET at resume\n");
 }
@@ -432,6 +449,7 @@ static void nvidia_force_enable_hpet(struct pci_dev *dev)
 {
 	u32 uninitialized_var(val);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (hpet_address || force_hpet_address)
 		return;
 
@@ -478,6 +496,7 @@ DECLARE_PCI_FIXUP_HEADER(PCI_VENDOR_ID_NVIDIA, 0x0367,
 
 void force_hpet_resume(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	switch (force_hpet_resume_type) {
 	case ICH_FORCE_HPET_RESUME:
 		ich_force_hpet_resume();
@@ -505,6 +524,7 @@ void force_hpet_resume(void)
  */
 static void e6xx_force_enable_hpet(struct pci_dev *dev)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (hpet_address || force_hpet_address)
 		return;
 
@@ -526,6 +546,7 @@ DECLARE_PCI_FIXUP_HEADER(PCI_VENDOR_ID_INTEL, PCI_DEVICE_ID_INTEL_E6XX_CU,
  */
 static void force_disable_hpet_msi(struct pci_dev *unused)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	hpet_msi_disable = true;
 }
 
@@ -546,7 +567,9 @@ static void quirk_amd_nb_node(struct pci_dev *dev)
 	devfn = PCI_DEVFN(PCI_SLOT(dev->devfn), 0);
 	nb_ht = pci_get_slot(dev->bus, devfn);
 	if (!nb_ht)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	pci_read_config_dword(nb_ht, 0x60, &val);
 	node = pcibus_to_node(dev->bus) | (val & 7);
@@ -613,6 +636,7 @@ static void amd_disable_seq_and_redirect_scrub(struct pci_dev *dev)
 	 */
 	pci_read_config_dword(dev, 0x58, &val);
 	if (val & 0x1F) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		val &= ~(0x1F);
 		pci_write_config_dword(dev, 0x58, val);
 	}
@@ -639,8 +663,10 @@ static void quirk_intel_brickland_xeon_ras_cap(struct pci_dev *pdev)
 	pci_read_config_dword(pdev, 0x84, &capid0);
 
 	if (capid0 & 0x10)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		static_branch_inc(&mcsafe_key);
 }
+}
 
 /* Skylake */
 static void quirk_intel_purley_xeon_ras_cap(struct pci_dev *pdev)
@@ -650,8 +676,10 @@ static void quirk_intel_purley_xeon_ras_cap(struct pci_dev *pdev)
 	pci_read_config_dword(pdev, 0x84, &capid0);
 
 	if ((capid0 & 0xc0) == 0xc0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		static_branch_inc(&mcsafe_key);
 }
+}
 DECLARE_PCI_FIXUP_EARLY(PCI_VENDOR_ID_INTEL, 0x0ec3, quirk_intel_brickland_xeon_ras_cap);
 DECLARE_PCI_FIXUP_EARLY(PCI_VENDOR_ID_INTEL, 0x2fc0, quirk_intel_brickland_xeon_ras_cap);
 DECLARE_PCI_FIXUP_EARLY(PCI_VENDOR_ID_INTEL, 0x6fc0, quirk_intel_brickland_xeon_ras_cap);
diff --git a/arch/x86/kernel/reboot.c b/arch/x86/kernel/reboot.c
index 2126b9d..6afa446 100644
--- a/arch/x86/kernel/reboot.c
+++ b/arch/x86/kernel/reboot.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 #define pr_fmt(fmt) KBUILD_MODNAME ": " fmt
 
@@ -59,6 +61,7 @@ bool port_cf9_safe = false;
  */
 static int __init set_acpi_reboot(const struct dmi_system_id *d)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (reboot_type != BOOT_ACPI) {
 		reboot_type = BOOT_ACPI;
 		pr_info("%s series board detected. Selecting %s-method for reboots.\n",
@@ -73,6 +76,7 @@ static int __init set_acpi_reboot(const struct dmi_system_id *d)
  */
 static int __init set_bios_reboot(const struct dmi_system_id *d)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (reboot_type != BOOT_BIOS) {
 		reboot_type = BOOT_BIOS;
 		pr_info("%s series board detected. Selecting %s-method for reboots.\n",
@@ -83,6 +87,7 @@ static int __init set_bios_reboot(const struct dmi_system_id *d)
 
 void __noreturn machine_real_restart(unsigned int type)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	local_irq_disable();
 
 	/*
@@ -134,6 +139,7 @@ STACK_FRAME_NON_STANDARD(machine_real_restart);
  */
 static int __init set_pci_reboot(const struct dmi_system_id *d)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (reboot_type != BOOT_CF9_FORCE) {
 		reboot_type = BOOT_CF9_FORCE;
 		pr_info("%s series board detected. Selecting %s-method for reboots.\n",
@@ -144,6 +150,7 @@ static int __init set_pci_reboot(const struct dmi_system_id *d)
 
 static int __init set_kbd_reboot(const struct dmi_system_id *d)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (reboot_type != BOOT_KBD) {
 		reboot_type = BOOT_KBD;
 		pr_info("%s series board detected. Selecting %s-method for reboot.\n",
@@ -470,7 +477,9 @@ static int __init reboot_init(void)
 	 * on the command line
 	 */
 	if (!reboot_default)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	/*
 	 * The DMI quirks table takes precedence. If no quirks entry
@@ -480,8 +489,11 @@ static int __init reboot_init(void)
 	rv = dmi_check_system(reboot_dmi_table);
 
 	if (!rv && efi_reboot_required() && !efi_runtime_disabled())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		reboot_type = BOOT_EFI;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 core_initcall(reboot_init);
@@ -490,6 +502,7 @@ static inline void kb_wait(void)
 {
 	int i;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (i = 0; i < 0x10000; i++) {
 		if ((inb(0x64) & 0x02) == 0)
 			break;
@@ -499,6 +512,7 @@ static inline void kb_wait(void)
 
 static void vmxoff_nmi(int cpu, struct pt_regs *regs)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	cpu_emergency_vmxoff();
 }
 
@@ -569,7 +583,9 @@ static void native_machine_emergency_restart(void)
 	unsigned short mode;
 
 	if (reboot_emergency)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		emergency_vmx_disable_all();
+}
 
 	tboot_shutdown(TB_SHUTDOWN_REBOOT);
 
@@ -692,12 +708,14 @@ void native_machine_shutdown(void)
 
 static void __machine_emergency_restart(int emergency)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	reboot_emergency = emergency;
 	machine_ops.emergency_restart();
 }
 
 static void native_machine_restart(char *__unused)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pr_notice("machine restart\n");
 
 	if (!reboot_force)
@@ -717,6 +735,7 @@ static void native_machine_halt(void)
 
 static void native_machine_power_off(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (pm_power_off) {
 		if (!reboot_force)
 			machine_shutdown();
@@ -739,32 +758,38 @@ struct machine_ops machine_ops __ro_after_init = {
 
 void machine_power_off(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	machine_ops.power_off();
 }
 
 void machine_shutdown(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	machine_ops.shutdown();
 }
 
 void machine_emergency_restart(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	__machine_emergency_restart(1);
 }
 
 void machine_restart(char *cmd)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	machine_ops.restart(cmd);
 }
 
 void machine_halt(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	machine_ops.halt();
 }
 
 #ifdef CONFIG_KEXEC_CORE
 void machine_crash_shutdown(struct pt_regs *regs)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	machine_ops.crash_shutdown(regs);
 }
 #endif
@@ -784,6 +809,7 @@ static int crash_nmi_callback(unsigned int val, struct pt_regs *regs)
 {
 	int cpu;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	cpu = raw_smp_processor_id();
 
 	/*
@@ -808,6 +834,7 @@ static int crash_nmi_callback(unsigned int val, struct pt_regs *regs)
 
 static void smp_send_nmi_allbutself(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	apic->send_IPI_allbutself(NMI_VECTOR);
 }
 
@@ -821,6 +848,7 @@ static void smp_send_nmi_allbutself(void)
 void nmi_shootdown_cpus(nmi_shootdown_cb callback)
 {
 	unsigned long msecs;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	local_irq_disable();
 
 	/* Make a note of crashing cpu. Will be used in NMI callback. */
@@ -860,6 +888,7 @@ void nmi_shootdown_cpus(nmi_shootdown_cb callback)
  */
 void run_crash_ipi_callback(struct pt_regs *regs)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (crash_ipi_issued)
 		crash_nmi_callback(0, regs);
 }
@@ -867,6 +896,7 @@ void run_crash_ipi_callback(struct pt_regs *regs)
 /* Override the weak function in kernel/panic.c */
 void nmi_panic_self_stop(struct pt_regs *regs)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	while (1) {
 		/* If no CPU is preparing crash dump, we simply loop here. */
 		run_crash_ipi_callback(regs);
diff --git a/arch/x86/kernel/rtc.c b/arch/x86/kernel/rtc.c
index 69ac9cb..1735ce9 100644
--- a/arch/x86/kernel/rtc.c
+++ b/arch/x86/kernel/rtc.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 /*
  * RTC related functions
@@ -47,6 +49,7 @@ int mach_set_rtc_mmss(const struct timespec *now)
 
 	rtc_time_to_tm(nowtime, &tm);
 	if (!rtc_valid_tm(&tm)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		retval = mc146818_set_time(&tm);
 		if (retval)
 			printk(KERN_ERR "%s: RTC write failed with error %d\n",
@@ -70,6 +73,7 @@ void mach_get_cmos_time(struct timespec *now)
 	 * which tells the caller that this RTC value is unusable.
 	 */
 	if (!pm_trace_rtc_valid()) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		now->tv_sec = now->tv_nsec = 0;
 		return;
 	}
@@ -98,11 +102,13 @@ void mach_get_cmos_time(struct timespec *now)
 		century = CMOS_READ(acpi_gbl_FADT.century);
 #endif
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	status = CMOS_READ(RTC_CONTROL);
 	WARN_ON_ONCE(RTC_ALWAYS_BCD && (status & RTC_DM_BINARY));
 
 	spin_unlock_irqrestore(&rtc_lock, flags);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (RTC_ALWAYS_BCD || !(status & RTC_DM_BINARY)) {
 		sec = bcd2bin(sec);
 		min = bcd2bin(min);
@@ -113,6 +119,7 @@ void mach_get_cmos_time(struct timespec *now)
 	}
 
 	if (century) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		century = bcd2bin(century);
 		year += century * 100;
 	} else
@@ -127,9 +134,12 @@ unsigned char rtc_cmos_read(unsigned char addr)
 {
 	unsigned char val;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lock_cmos_prefix(addr);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	outb(addr, RTC_PORT(0));
 	val = inb(RTC_PORT(1));
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lock_cmos_suffix(addr);
 
 	return val;
@@ -138,15 +148,19 @@ EXPORT_SYMBOL(rtc_cmos_read);
 
 void rtc_cmos_write(unsigned char val, unsigned char addr)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lock_cmos_prefix(addr);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	outb(addr, RTC_PORT(0));
 	outb(val, RTC_PORT(1));
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	lock_cmos_suffix(addr);
 }
 EXPORT_SYMBOL(rtc_cmos_write);
 
 int update_persistent_clock(struct timespec now)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return x86_platform.set_wallclock(&now);
 }
 
@@ -188,16 +202,22 @@ static __init int add_rtc_cmos(void)
 
 	pnp_for_each_dev(dev) {
 		for (id = dev->id; id; id = id->next) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			for (i = 0; i < ARRAY_SIZE(ids); i++) {
 				if (compare_pnp_id(id, ids[i]) != 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 					return 0;
+}
 			}
 		}
 	}
 #endif
 	if (!x86_platform.legacy.rtc)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENODEV;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	platform_device_register(&rtc_device);
 	dev_info(&rtc_device.dev,
 		 "registered platform RTC device (no PNP device found)\n");
diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index c54361a..671c7170 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  *  Copyright (C) 1995  Linus Torvalds
  *
@@ -139,6 +141,7 @@ unsigned long _brk_end = (unsigned long)__brk_base;
 #ifdef CONFIG_X86_64
 int default_cpu_present_to_apicid(int mps_cpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return __default_cpu_present_to_apicid(mps_cpu);
 }
 
@@ -380,9 +383,11 @@ static void __init reserve_initrd(void)
 
 	mapped_size = memblock_mem_size(max_pfn_mapped);
 	if (ramdisk_size >= (mapped_size>>1))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		panic("initrd too large to handle, "
 		       "disabling initrd (%lld needed, %lld available)\n",
 		       ramdisk_size, mapped_size>>1);
+}
 
 	printk(KERN_INFO "RAMDISK: [mem %#010llx-%#010llx]\n", ramdisk_image,
 			ramdisk_end - 1);
@@ -395,6 +400,7 @@ static void __init reserve_initrd(void)
 		return;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	relocate_initrd();
 
 	memblock_free(ramdisk_image, ramdisk_end - ramdisk_image);
@@ -437,6 +443,7 @@ static void __init parse_setup_data(void)
 		default:
 			break;
 		}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pa_data = pa_next;
 	}
 }
@@ -448,6 +455,7 @@ static void __init memblock_x86_reserve_range_setup_data(void)
 
 	pa_data = boot_params.hdr.setup_data;
 	while (pa_data) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		data = early_memremap(pa_data, sizeof(*data));
 		memblock_reserve(pa_data, sizeof(*data) + data->len);
 		pa_data = data->next;
@@ -540,6 +548,7 @@ static void __init reserve_crashkernel(void)
 
 	/* crashkernel=XM */
 	ret = parse_crashkernel(boot_command_line, total_mem, &crash_size, &crash_base);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (ret != 0 || crash_size <= 0) {
 		/* crashkernel=X,high */
 		ret = parse_crashkernel_high(boot_command_line, total_mem,
@@ -642,8 +651,10 @@ static __init void reserve_ibft_region(void)
 	addr = find_ibft_region(&size);
 
 	if (size)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		memblock_reserve(addr, size);
 }
+}
 
 static bool __init snb_gfx_workaround_needed(void)
 {
@@ -662,18 +673,29 @@ static bool __init snb_gfx_workaround_needed(void)
 
 	/* Assume no if something weird is going on with PCI */
 	if (!early_pci_allowed())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return false;
+}
 
 	vendor = read_pci_config_16(0, 2, 0, PCI_VENDOR_ID);
 	if (vendor != 0x8086)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return false;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	devid = read_pci_config_16(0, 2, 0, PCI_DEVICE_ID);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (i = 0; i < ARRAY_SIZE(snb_ids); i++)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (devid == snb_ids[i])
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return true;
+}
+}
 #endif
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return false;
 }
 
@@ -693,8 +715,11 @@ static void __init trim_snb_memory(void)
 	int i;
 
 	if (!snb_gfx_workaround_needed())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	printk(KERN_DEBUG "reserving inaccessible SNB gfx pages\n");
 
 	/*
@@ -704,9 +729,12 @@ static void __init trim_snb_memory(void)
 	memblock_reserve(0, 1<<20);
 	
 	for (i = 0; i < ARRAY_SIZE(bad_pages); i++) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (memblock_reserve(bad_pages[i], PAGE_SIZE))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			printk(KERN_WARNING "failed to reserve 0x%08lx\n",
 			       bad_pages[i]);
+}
 	}
 }
 
@@ -759,8 +787,11 @@ static void __init e820_add_kernel_range(void)
 	 * we will crash later anyways.
 	 */
 	if (e820__mapped_all(start, start + size, E820_TYPE_RAM))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pr_warn(".text .data .bss are not marked as E820_TYPE_RAM!\n");
 	e820__range_remove(start, size, E820_TYPE_RAM, 0);
 	e820__range_add(start, size, E820_TYPE_RAM);
@@ -773,7 +804,9 @@ static int __init parse_reservelow(char *p)
 	unsigned long long size;
 
 	if (!p)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	size = memparse(p, &p);
 
@@ -801,6 +834,7 @@ static void __init trim_low_memory_range(void)
 static int
 dump_kernel_offset(struct notifier_block *self, unsigned long v, void *p)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (kaslr_enabled()) {
 		pr_emerg("Kernel Offset: 0x%lx from 0x%lx (relocation range: 0x%lx-0x%lx)\n",
 			 kaslr_offset(),
@@ -820,14 +854,18 @@ static void __init simple_udelay_calibration(void)
 	unsigned long lpj;
 
 	if (!boot_cpu_has(X86_FEATURE_TSC))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	cpu_khz = x86_platform.calibrate_cpu();
 	tsc_khz = x86_platform.calibrate_tsc();
 
 	tsc_khz = tsc_khz ? : cpu_khz;
 	if (!tsc_khz)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	lpj = tsc_khz * 1000;
 	do_div(lpj, HZ);
@@ -908,6 +946,7 @@ void __init setup_arch(char **cmdline_p)
 	saved_video_mode = boot_params.hdr.vid_mode;
 	bootloader_type = boot_params.hdr.type_of_loader;
 	if ((bootloader_type >> 4) == 0xe) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		bootloader_type &= 0xf;
 		bootloader_type |= (boot_params.hdr.ext_loader_type+0x10) << 4;
 	}
@@ -922,9 +961,11 @@ void __init setup_arch(char **cmdline_p)
 #ifdef CONFIG_EFI
 	if (!strncmp((char *)&boot_params.efi_info.efi_loader_signature,
 		     EFI32_LOADER_SIGNATURE, 4)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		set_bit(EFI_BOOT, &efi.flags);
 	} else if (!strncmp((char *)&boot_params.efi_info.efi_loader_signature,
 		     EFI64_LOADER_SIGNATURE, 4)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		set_bit(EFI_BOOT, &efi.flags);
 		set_bit(EFI_64BIT, &efi.flags);
 	}
@@ -939,7 +980,9 @@ void __init setup_arch(char **cmdline_p)
 	copy_edd();
 
 	if (!boot_params.hdr.root_flags)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		root_mountflags &= ~MS_RDONLY;
+}
 	init_mm.start_code = (unsigned long) _text;
 	init_mm.end_code = (unsigned long) _etext;
 	init_mm.end_data = (unsigned long) _edata;
@@ -982,7 +1025,9 @@ void __init setup_arch(char **cmdline_p)
 	parse_early_param();
 
 	if (efi_enabled(EFI_BOOT))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		efi_memblock_x86_reserve_range();
+}
 #ifdef CONFIG_MEMORY_HOTPLUG
 	/*
 	 * Memory used by the kernel cannot be hot-removed because Linux
@@ -1021,14 +1066,18 @@ void __init setup_arch(char **cmdline_p)
 
 #ifdef CONFIG_PCI
 	if (pci_early_dump_regs)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		early_dump_pci_devices();
+}
 #endif
 
 	e820__reserve_setup_data();
 	e820__finish_early_params();
 
 	if (efi_enabled(EFI_BOOT))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		efi_init();
+}
 
 	dmi_scan_machine();
 	dmi_memdev_walk();
@@ -1072,7 +1121,9 @@ void __init setup_arch(char **cmdline_p)
 	/* update e820 for memory not covered by WB MTRRs */
 	mtrr_bp_init();
 	if (mtrr_trim_uncached_memory(max_pfn))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		max_pfn = e820__end_of_ram_pfn();
+}
 
 	max_possible_pfn = max_pfn;
 
@@ -1127,11 +1178,14 @@ void __init setup_arch(char **cmdline_p)
 	e820__memblock_setup();
 
 	if (!early_xdbc_setup_hardware())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		early_xdbc_register_console();
+}
 
 	reserve_bios_regions();
 
 	if (efi_enabled(EFI_MEMMAP)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		efi_fake_memmap();
 		efi_find_mirror();
 		efi_esrt_init();
@@ -1183,12 +1237,15 @@ void __init setup_arch(char **cmdline_p)
 
 #ifdef CONFIG_PROVIDE_OHCI1394_DMA_INIT
 	if (init_ohci1394_dma_early)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		init_ohci1394_dma_on_all_controllers();
+}
 #endif
 	/* Allocate bigger log buffer */
 	setup_log_buf(1);
 
 	if (efi_enabled(EFI_BOOT)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		switch (boot_params.secure_boot) {
 		case efi_secureboot_mode_disabled:
 			pr_info("Secure boot disabled\n");
@@ -1253,6 +1310,7 @@ void __init setup_arch(char **cmdline_p)
 			min(KERNEL_PGD_PTRS, KERNEL_PGD_BOUNDARY));
 #endif
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	tboot_probe();
 
 	map_vsyscall();
@@ -1314,7 +1372,9 @@ void __init setup_arch(char **cmdline_p)
 
 #ifdef CONFIG_EFI
 	if (efi_enabled(EFI_BOOT))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		efi_apply_memmap_quirks();
+}
 #endif
 
 	unwind_init();
@@ -1351,6 +1411,7 @@ __initcall(register_kernel_offset_dumper);
 
 void arch_show_smap(struct seq_file *m, struct vm_area_struct *vma)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!boot_cpu_has(X86_FEATURE_OSPKE))
 		return;
 
diff --git a/arch/x86/kernel/setup_percpu.c b/arch/x86/kernel/setup_percpu.c
index 497aa76..27fa7f4 100644
--- a/arch/x86/kernel/setup_percpu.c
+++ b/arch/x86/kernel/setup_percpu.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 #define pr_fmt(fmt) KBUILD_MODNAME ": " fmt
 
@@ -105,18 +107,24 @@ static void * __init pcpu_alloc_bootmem(unsigned int cpu, unsigned long size,
 	int node = early_cpu_to_node(cpu);
 	void *ptr;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!node_online(node) || !NODE_DATA(node)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ptr = __alloc_bootmem_nopanic(size, align, goal);
 		pr_info("cpu %d has no node %d or node-local memory\n",
 			cpu, node);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_debug("per cpu data for cpu%d %lu bytes at %016lx\n",
 			 cpu, size, __pa(ptr));
 	} else {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ptr = __alloc_bootmem_node_nopanic(NODE_DATA(node),
 						   size, align, goal);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_debug("per cpu data for cpu%d %lu bytes on node%d at %016lx\n",
 			 cpu, size, node, __pa(ptr));
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return ptr;
 #else
 	return __alloc_bootmem_nopanic(size, align, goal);
@@ -150,6 +158,7 @@ static int __init pcpu_cpu_distance(unsigned int from, unsigned int to)
 
 static void __init pcpup_populate_pte(unsigned long addr)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	populate_extra_pte(addr);
 }
 
@@ -205,15 +214,21 @@ void __init setup_per_cpu_areas(void)
 					    pcpu_cpu_distance,
 					    pcpu_fc_alloc, pcpu_fc_free);
 		if (rc < 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			pr_warning("%s allocator failed (%d), falling back to page size\n",
 				   pcpu_fc_names[pcpu_chosen_fc], rc);
+}
 	}
 	if (rc < 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		rc = pcpu_page_first_chunk(PERCPU_FIRST_CHUNK_RESERVE,
 					   pcpu_fc_alloc, pcpu_fc_free,
 					   pcpup_populate_pte);
+}
 	if (rc < 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		panic("cannot initialize percpu area (err=%d)", rc);
+}
 
 	/* alrighty, percpu areas up and running */
 	delta = (unsigned long)pcpu_base_addr - (unsigned long)__per_cpu_start;
diff --git a/arch/x86/kernel/signal.c b/arch/x86/kernel/signal.c
index 4cdc0b2..ad52320 100644
--- a/arch/x86/kernel/signal.c
+++ b/arch/x86/kernel/signal.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 /*
  *  Copyright (C) 1991, 1992  Linus Torvalds
@@ -277,7 +279,9 @@ get_sigframe(struct k_sigaction *ka, struct pt_regs *regs, size_t frame_size,
 	 * Return an always-bogus address instead so we will die with SIGSEGV.
 	 */
 	if (onsigstack && !likely(on_sig_stack(sp)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return (void __user *)-1L;
+}
 
 	/* save i387 and extended state */
 	if (fpu->initialized &&
@@ -445,7 +449,9 @@ static unsigned long frame_uc_flags(struct pt_regs *regs)
 	unsigned long flags;
 
 	if (boot_cpu_has(X86_FEATURE_XSAVE))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		flags = UC_FP_XSTATE | UC_SIGCONTEXT_SS;
+}
 	else
 		flags = UC_SIGCONTEXT_SS;
 
@@ -465,11 +471,15 @@ static int __setup_rt_frame(int sig, struct ksignal *ksig,
 	frame = get_sigframe(&ksig->ka, regs, sizeof(struct rt_sigframe), &fp);
 
 	if (!access_ok(VERIFY_WRITE, frame, sizeof(*frame)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EFAULT;
+}
 
 	if (ksig->ka.sa.sa_flags & SA_SIGINFO) {
 		if (copy_siginfo_to_user(&frame->info, &ksig->info))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -EFAULT;
+}
 	}
 
 	put_user_try {
@@ -493,7 +503,9 @@ static int __setup_rt_frame(int sig, struct ksignal *ksig,
 	err |= __copy_to_user(&frame->uc.uc_sigmask, set, sizeof(*set));
 
 	if (err)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EFAULT;
+}
 
 	/* Set up registers for signal handler */
 	regs->di = sig;
@@ -528,8 +540,11 @@ static int __setup_rt_frame(int sig, struct ksignal *ksig,
 	regs->cs = __USER_CS;
 
 	if (unlikely(regs->ss != __USER_DS))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		force_valid_ss(regs);
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 #endif /* CONFIG_X86_32 */
@@ -594,6 +609,7 @@ static int x32_setup_rt_frame(struct ksignal *ksig,
 	regs->ss = __USER_DS;
 #endif	/* CONFIG_X86_X32_ABI */
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
@@ -665,17 +681,20 @@ asmlinkage long sys_rt_sigreturn(void)
 
 static inline int is_ia32_compat_frame(struct ksignal *ksig)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return IS_ENABLED(CONFIG_IA32_EMULATION) &&
 		ksig->ka.sa.sa_flags & SA_IA32_ABI;
 }
 
 static inline int is_ia32_frame(struct ksignal *ksig)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return IS_ENABLED(CONFIG_X86_32) || is_ia32_compat_frame(ksig);
 }
 
 static inline int is_x32_frame(struct ksignal *ksig)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return IS_ENABLED(CONFIG_X86_X32_ABI) &&
 		ksig->ka.sa.sa_flags & SA_X32_ABI;
 }
@@ -689,11 +708,15 @@ setup_rt_frame(struct ksignal *ksig, struct pt_regs *regs)
 
 	/* Set up the stack frame */
 	if (is_ia32_frame(ksig)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (ksig->ka.sa.sa_flags & SA_SIGINFO)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return ia32_setup_rt_frame(usig, ksig, cset, regs);
+}
 		else
 			return ia32_setup_frame(usig, ksig, cset, regs);
 	} else if (is_x32_frame(ksig)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return x32_setup_rt_frame(ksig, cset, regs);
 	} else {
 		return __setup_rt_frame(ksig->sig, ksig, set, regs);
@@ -707,7 +730,9 @@ handle_signal(struct ksignal *ksig, struct pt_regs *regs)
 	struct fpu *fpu = &current->thread.fpu;
 
 	if (v8086_mode(regs))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		save_v86_state((struct kernel_vm86_regs *) regs, VM86_SIGNAL);
+}
 
 	/* Are we from a system call? */
 	if (syscall_get_nr(current, regs) >= 0) {
@@ -738,7 +763,9 @@ handle_signal(struct ksignal *ksig, struct pt_regs *regs)
 	 */
 	stepping = test_thread_flag(TIF_SINGLESTEP);
 	if (stepping)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		user_disable_single_step(current);
+}
 
 	failed = (setup_rt_frame(ksig, regs) < 0);
 	if (!failed) {
@@ -839,6 +866,7 @@ void do_signal(struct pt_regs *regs)
 
 void signal_fault(struct pt_regs *regs, void __user *frame, char *where)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct task_struct *me = current;
 
 	if (show_unhandled_signals && printk_ratelimit()) {
diff --git a/arch/x86/kernel/signal_compat.c b/arch/x86/kernel/signal_compat.c
index 8c6da1a..2263ea6 100644
--- a/arch/x86/kernel/signal_compat.c
+++ b/arch/x86/kernel/signal_compat.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 #include <linux/compat.h>
 #include <linux/uaccess.h>
@@ -101,16 +103,23 @@ void sigaction_compat_abi(struct k_sigaction *act, struct k_sigaction *oact)
 		oact->sa.sa_flags &= ~(SA_IA32_ABI | SA_X32_ABI);
 
 	if (!act)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	/* Don't let flags to be set from userspace */
 	act->sa.sa_flags &= ~(SA_IA32_ABI | SA_X32_ABI);
 
 	if (in_ia32_syscall())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		act->sa.sa_flags |= SA_IA32_ABI;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (in_x32_syscall())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		act->sa.sa_flags |= SA_X32_ABI;
 }
+}
 
 int __copy_siginfo_to_user32(compat_siginfo_t __user *to, const siginfo_t *from,
 		bool x32_ABI)
@@ -120,7 +129,9 @@ int __copy_siginfo_to_user32(compat_siginfo_t __user *to, const siginfo_t *from,
 	signal_compat_build_tests();
 
 	if (!access_ok(VERIFY_WRITE, to, sizeof(compat_siginfo_t)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EFAULT;
+}
 
 	put_user_try {
 		/* If you change siginfo_t structure, please make sure that
@@ -200,6 +211,7 @@ int __copy_siginfo_to_user32(compat_siginfo_t __user *to, const siginfo_t *from,
 /* from syscall's path, where we know the ABI */
 int copy_siginfo_to_user32(compat_siginfo_t __user *to, const siginfo_t *from)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return __copy_siginfo_to_user32(to, from, in_x32_syscall());
 }
 
@@ -209,7 +221,9 @@ int copy_siginfo_from_user32(siginfo_t *to, compat_siginfo_t __user *from)
 	u32 ptr32;
 
 	if (!access_ok(VERIFY_READ, from, sizeof(compat_siginfo_t)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EFAULT;
+}
 
 	get_user_try {
 		get_user_ex(to->si_signo, &from->si_signo);
diff --git a/arch/x86/kernel/smpboot.c b/arch/x86/kernel/smpboot.c
index 2651ca2..4c8c387 100644
--- a/arch/x86/kernel/smpboot.c
+++ b/arch/x86/kernel/smpboot.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
  /*
  *	x86 SMP booting functions
  *
@@ -125,6 +127,7 @@ static inline void smpboot_setup_warm_reset_vector(unsigned long start_eip)
 {
 	unsigned long flags;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_lock_irqsave(&rtc_lock, flags);
 	CMOS_WRITE(0xa, 0xf);
 	spin_unlock_irqrestore(&rtc_lock, flags);
@@ -281,16 +284,21 @@ int topology_update_package_map(unsigned int pkg, unsigned int cpu)
 
 	/* Called from early boot ? */
 	if (!physical_package_map)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	if (pkg >= max_physical_pkg_id)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	/* Set the logical package id */
 	if (test_and_set_bit(pkg, physical_package_map))
 		goto found;
 
 	if (logical_packages >= __max_logical_packages) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_warn("Package %u of CPU %u exceeds BIOS package data %u.\n",
 			logical_packages, cpu, __max_logical_packages);
 		return -ENOSPC;
@@ -298,6 +306,7 @@ int topology_update_package_map(unsigned int pkg, unsigned int cpu)
 
 	new = logical_packages++;
 	if (new != pkg) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_info("CPU %u Converting physical %u to logical package %u\n",
 			cpu, pkg, new);
 	}
@@ -315,6 +324,7 @@ int topology_update_package_map(unsigned int pkg, unsigned int cpu)
  */
 int topology_phys_to_logical_pkg(unsigned int phys_pkg)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (phys_pkg >= max_physical_pkg_id)
 		return -1;
 	return physical_to_logical_pkg[phys_pkg];
@@ -350,6 +360,7 @@ static void __init smp_init_package_map(struct cpuinfo_x86 *c, unsigned int cpu)
 	 */
 	ncpus = boot_cpu_data.x86_max_cores;
 	if (!ncpus) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_warn("x86_max_cores == zero !?!?");
 		ncpus = 1;
 	}
@@ -389,6 +400,7 @@ void __init smp_store_boot_cpu_info(void)
  */
 void smp_store_cpu_info(int id)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cpuinfo_x86 *c = &cpu_data(id);
 
 	*c = boot_cpu_data;
@@ -413,6 +425,7 @@ topology_sane(struct cpuinfo_x86 *c, struct cpuinfo_x86 *o, const char *name)
 {
 	int cpu1 = c->cpu_index, cpu2 = o->cpu_index;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return !WARN_ONCE(!topology_same_node(c, o),
 		"sched: CPU #%d's %s-sibling CPU #%d is not on the same node! "
 		"[node: %d != %d]. Ignoring dependency.\n",
@@ -427,6 +440,7 @@ do {									\
 
 static bool match_smt(struct cpuinfo_x86 *c, struct cpuinfo_x86 *o)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (boot_cpu_has(X86_FEATURE_TOPOEXT)) {
 		int cpu1 = c->cpu_index, cpu2 = o->cpu_index;
 
@@ -453,6 +467,7 @@ static bool match_llc(struct cpuinfo_x86 *c, struct cpuinfo_x86 *o)
 {
 	int cpu1 = c->cpu_index, cpu2 = o->cpu_index;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (per_cpu(cpu_llc_id, cpu1) != BAD_APICID &&
 	    per_cpu(cpu_llc_id, cpu1) == per_cpu(cpu_llc_id, cpu2))
 		return topology_sane(c, o, "llc");
@@ -467,6 +482,7 @@ static bool match_llc(struct cpuinfo_x86 *c, struct cpuinfo_x86 *o)
  */
 static bool match_die(struct cpuinfo_x86 *c, struct cpuinfo_x86 *o)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (c->phys_proc_id == o->phys_proc_id)
 		return true;
 	return false;
@@ -487,6 +503,7 @@ static int x86_core_flags(void)
 #ifdef CONFIG_SCHED_SMT
 static int x86_smt_flags(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return cpu_smt_flags() | x86_sched_itmt_flags();
 }
 #endif
@@ -537,14 +554,22 @@ void set_cpu_sibling_map(int cpu)
 		return;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for_each_cpu(i, cpu_sibling_setup_mask) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		o = &cpu_data(i);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if ((i == cpu) || (has_smt && match_smt(c, o)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			link_mask(topology_sibling_cpumask, cpu, i);
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if ((i == cpu) || (has_mp && match_llc(c, o)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			link_mask(cpu_llc_shared_mask, cpu, i);
+}
 
 	}
 
@@ -553,9 +578,12 @@ void set_cpu_sibling_map(int cpu)
 	 * topology_sibling_cpumask links to be set-up.
 	 */
 	for_each_cpu(i, cpu_sibling_setup_mask) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		o = &cpu_data(i);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if ((i == cpu) || (has_mp && match_die(c, o))) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			link_mask(topology_core_cpumask, cpu, i);
 
 			/*
@@ -575,18 +603,28 @@ void set_cpu_sibling_map(int cpu)
 				 * the other cpus in this package
 				 */
 				if (i != cpu)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 					cpu_data(i).booted_cores++;
+}
 			} else if (i != cpu && !c->booted_cores)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				c->booted_cores = cpu_data(i).booted_cores;
+}
 		}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (match_die(c, o) && !topology_same_node(c, o))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			x86_has_numa_in_package = true;
+}
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	threads = cpumask_weight(topology_sibling_cpumask(cpu));
 	if (threads > __max_smt_threads)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		__max_smt_threads = threads;
 }
+}
 
 /* maps the cpu to the sched domain representing multi-core */
 const struct cpumask *cpu_coregroup_mask(int cpu)
@@ -610,6 +648,7 @@ static void impress_friends(void)
 		bogosum/(500000/HZ),
 		(bogosum/(5000/HZ))%100);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pr_debug("Before bogocount - setting activated=1\n");
 }
 
@@ -622,6 +661,7 @@ void __inquire_remote_apic(int apicid)
 
 	pr_info("Inquiring remote APIC 0x%x...\n", apicid);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (i = 0; i < ARRAY_SIZE(regs); i++) {
 		pr_info("... APIC 0x%x %s: ", apicid, names[i]);
 
@@ -667,6 +707,7 @@ static unsigned int init_udelay = UINT_MAX;
 
 static int __init cpu_init_udelay(char *str)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	get_option(&str, &init_udelay);
 
 	return 0;
@@ -677,11 +718,14 @@ static void __init smp_quirk_init_udelay(void)
 {
 	/* if cmdline changed it from default, leave it alone */
 	if (init_udelay != UINT_MAX)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	/* if modern processor, use no delay */
 	if (((boot_cpu_data.x86_vendor == X86_VENDOR_INTEL) && (boot_cpu_data.x86 == 6)) ||
 	    ((boot_cpu_data.x86_vendor == X86_VENDOR_AMD) && (boot_cpu_data.x86 >= 0xF))) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		init_udelay = 0;
 		return;
 	}
@@ -705,6 +749,7 @@ wakeup_secondary_cpu_via_nmi(int apicid, unsigned long start_eip)
 	/* Kick the second */
 	apic_icr_write(APIC_DM_NMI | apic->dest_logical, apicid);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pr_debug("Waiting for send to finish...\n");
 	send_status = safe_apic_wait_icr_idle();
 
@@ -740,6 +785,7 @@ wakeup_secondary_cpu_via_init(int phys_apicid, unsigned long start_eip)
 	 * Be paranoid about clearing APIC errors.
 	 */
 	if (APIC_INTEGRATED(boot_cpu_apic_version)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (maxlvt > 3)		/* Due to the Pentium erratum 3AP.  */
 			apic_write(APIC_ESR, 0);
 		apic_read(APIC_ESR);
@@ -850,7 +896,9 @@ static void announce_cpu(int cpu, int apicid)
 	static int width, node_width;
 
 	if (!width)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		width = num_digits(num_possible_cpus()) + 1; /* + '#' sign */
+}
 
 	if (!node_width)
 		node_width = num_digits(num_possible_nodes()) + 1; /* + '#' */
@@ -883,6 +931,7 @@ static int wakeup_cpu0_nmi(unsigned int cmd, struct pt_regs *regs)
 {
 	int cpu;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	cpu = smp_processor_id();
 	if (cpu == 0 && !cpu_online(cpu) && enable_start_cpu0)
 		return NMI_HANDLED;
@@ -915,6 +964,7 @@ wakeup_cpu_via_init_nmi(int cpu, unsigned long start_ip, int apicid,
 	 * Wake up AP by INIT, INIT, STARTUP sequence.
 	 */
 	if (cpu) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		boot_error = wakeup_secondary_cpu_via_init(apicid, start_ip);
 		goto out;
 	}
@@ -994,6 +1044,7 @@ static int do_boot_cpu(int apicid, int cpu, struct task_struct *idle,
 
 	if (get_uv_system_type() != UV_NON_UNIQUE_APIC) {
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_debug("Setting warm reset code and vector.\n");
 
 		smpboot_setup_warm_reset_vector(start_ip);
@@ -1076,6 +1127,7 @@ static int do_boot_cpu(int apicid, int cpu, struct task_struct *idle,
 
 int native_cpu_up(unsigned int cpu, struct task_struct *tidle)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	int apicid = apic->cpu_present_to_apicid(cpu);
 	int cpu0_nmi_registered = 0;
 	unsigned long flags;
@@ -1152,6 +1204,7 @@ int native_cpu_up(unsigned int cpu, struct task_struct *tidle)
  */
 void arch_disable_smp_support(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	disable_ioapic_support();
 }
 
@@ -1162,6 +1215,7 @@ void arch_disable_smp_support(void)
  */
 static __init void disable_smp(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pr_info("SMP disabled\n");
 
 	disable_ioapic_support();
@@ -1218,6 +1272,7 @@ static int __init smp_sanity_check(unsigned max_cpus)
 #endif
 
 	if (!physid_isset(hard_smp_processor_id(), phys_cpu_present_map)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_warn("weird, boot CPU (#%d) not listed by the BIOS\n",
 			hard_smp_processor_id());
 
@@ -1229,6 +1284,7 @@ static int __init smp_sanity_check(unsigned max_cpus)
 	 * get out of here now!
 	 */
 	if (!smp_found_config && !acpi_lapic) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		preempt_enable();
 		pr_notice("SMP motherboard not detected\n");
 		return SMP_NO_CONFIG;
@@ -1239,6 +1295,7 @@ static int __init smp_sanity_check(unsigned max_cpus)
 	 * CPU too, but we do it for the sake of robustness anyway.
 	 */
 	if (!apic->check_phys_apicid_present(boot_cpu_physical_apicid)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_notice("weird, boot CPU (#%d) not listed by the BIOS\n",
 			  boot_cpu_physical_apicid);
 		physid_set(hard_smp_processor_id(), phys_cpu_present_map);
@@ -1250,11 +1307,14 @@ static int __init smp_sanity_check(unsigned max_cpus)
 	 */
 	if (APIC_INTEGRATED(boot_cpu_apic_version) &&
 	    !boot_cpu_has(X86_FEATURE_APIC)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (!disable_apic) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			pr_err("BIOS bug, local APIC #%d not detected!...\n",
 				boot_cpu_physical_apicid);
 			pr_err("... forcing use of dummy APIC emulation (tell your hw vendor)\n");
 		}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return SMP_NO_APIC;
 	}
 
@@ -1262,10 +1322,12 @@ static int __init smp_sanity_check(unsigned max_cpus)
 	 * If SMP should be disabled, then really disable it!
 	 */
 	if (!max_cpus) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_info("SMP mode deactivated\n");
 		return SMP_FORCE_UP;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return SMP_OK;
 }
 
@@ -1319,7 +1381,10 @@ void __init native_smp_prepare_cpus(unsigned int max_cpus)
 	case SMP_NO_CONFIG:
 		disable_smp();
 		if (APIC_init_uniprocessor())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			pr_notice("Local APIC not detected. Using dummy APIC emulation.\n");
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
 	case SMP_NO_APIC:
 		disable_smp();
@@ -1353,11 +1418,13 @@ void __init native_smp_prepare_cpus(unsigned int max_cpus)
 
 void arch_enable_nonboot_cpus_begin(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	set_mtrr_aps_delayed_init();
 }
 
 void arch_enable_nonboot_cpus_end(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	mtrr_aps_init();
 }
 
@@ -1375,11 +1442,15 @@ void __init native_smp_prepare_boot_cpu(void)
 
 void __init native_smp_cpus_done(unsigned int max_cpus)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pr_debug("Boot done\n");
 
 	if (x86_has_numa_in_package)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		set_sched_topology(x86_numa_in_package_topology);
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	nmi_selftest();
 	impress_friends();
 	setup_ioapic_dest();
@@ -1389,6 +1460,7 @@ void __init native_smp_cpus_done(unsigned int max_cpus)
 static int __initdata setup_possible_cpus = -1;
 static int __init _setup_possible_cpus(char *str)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	get_option(&str, &setup_possible_cpus);
 	return 0;
 }
@@ -1430,8 +1502,11 @@ __init void prefill_possible_map(void)
 				generic_processor_info(apicid, boot_cpu_apic_version);
 		}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (!num_processors)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			num_processors = 1;
+}
 	}
 
 	i = setup_max_cpus ?: 1;
@@ -1445,7 +1520,9 @@ __init void prefill_possible_map(void)
 			possible = i;
 #endif
 	} else
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		possible = setup_possible_cpus;
+}
 
 	total_cpus = max_t(int, possible, num_processors + disabled_cpus);
 
@@ -1484,6 +1561,7 @@ static void recompute_smt_state(void)
 	int max_threads, cpu;
 
 	max_threads = 0;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for_each_online_cpu (cpu) {
 		int threads = cpumask_weight(topology_sibling_cpumask(cpu));
 
@@ -1496,6 +1574,7 @@ static void recompute_smt_state(void)
 static void remove_siblinginfo(int cpu)
 {
 	int sibling;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct cpuinfo_x86 *c = &cpu_data(cpu);
 
 	for_each_cpu(sibling, topology_core_cpumask(cpu)) {
@@ -1522,6 +1601,7 @@ static void remove_siblinginfo(int cpu)
 
 static void remove_cpu_from_maps(int cpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	set_cpu_online(cpu, false);
 	cpumask_clear_cpu(cpu, cpu_callout_mask);
 	cpumask_clear_cpu(cpu, cpu_callin_mask);
@@ -1532,6 +1612,7 @@ static void remove_cpu_from_maps(int cpu)
 
 void cpu_disable_common(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	int cpu = smp_processor_id();
 
 	remove_siblinginfo(cpu);
@@ -1549,7 +1630,9 @@ int native_cpu_disable(void)
 
 	ret = check_irq_vectors_for_cpu_disable();
 	if (ret)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ret;
+}
 
 	clear_local_APIC();
 	cpu_disable_common();
@@ -1565,6 +1648,7 @@ int common_cpu_die(unsigned int cpu)
 
 	/* They ack this in play_dead() by setting CPU_DEAD */
 	if (cpu_wait_death(cpu, 5)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (system_state == SYSTEM_RUNNING)
 			pr_info("CPU %u is now offline\n", cpu);
 	} else {
@@ -1577,11 +1661,13 @@ int common_cpu_die(unsigned int cpu)
 
 void native_cpu_die(unsigned int cpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	common_cpu_die(cpu);
 }
 
 void play_dead_common(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	idle_task_exit();
 
 	/* Ack it */
@@ -1595,6 +1681,7 @@ void play_dead_common(void)
 
 static bool wakeup_cpu0(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (smp_processor_id() == 0 && enable_start_cpu0)
 		return true;
 
@@ -1613,6 +1700,7 @@ static inline void mwait_play_dead(void)
 	void *mwait_ptr;
 	int i;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!this_cpu_has(X86_FEATURE_MWAIT))
 		return;
 	if (!this_cpu_has(X86_FEATURE_CLFLUSH))
@@ -1675,6 +1763,7 @@ static inline void mwait_play_dead(void)
 
 void hlt_play_dead(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (__this_cpu_read(cpu_info.x86) >= 4)
 		wbinvd();
 
@@ -1690,6 +1779,7 @@ void hlt_play_dead(void)
 
 void native_play_dead(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	play_dead_common();
 	tboot_shutdown(TB_SHUTDOWN_WFS);
 
diff --git a/arch/x86/kernel/step.c b/arch/x86/kernel/step.c
index 60d2c37..1ba4b76 100644
--- a/arch/x86/kernel/step.c
+++ b/arch/x86/kernel/step.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 /*
  * x86 single-step support code, common to 32-bit and 64-bit.
@@ -16,6 +18,7 @@ unsigned long convert_ip_to_linear(struct task_struct *child, struct pt_regs *re
 	addr = regs->ip;
 	seg = regs->cs;
 	if (v8086_mode(regs)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		addr = (addr & 0xffff) + (seg << 4);
 		return addr;
 	}
@@ -34,22 +37,29 @@ unsigned long convert_ip_to_linear(struct task_struct *child, struct pt_regs *re
 		seg >>= 3;
 
 		mutex_lock(&child->mm->context.lock);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (unlikely(!child->mm->context.ldt ||
 			     seg >= child->mm->context.ldt->nr_entries))
 			addr = -1L; /* bogus selector, access would fault */
 		else {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			desc = &child->mm->context.ldt->entries[seg];
 			base = get_desc_base(desc);
 
 			/* 16-bit code segment? */
 			if (!desc->d)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				addr &= 0xffff;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			addr += base;
 		}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		mutex_unlock(&child->mm->context.lock);
 	}
 #endif
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return addr;
 }
 
@@ -61,6 +71,7 @@ static int is_setting_trap_flag(struct task_struct *child, struct pt_regs *regs)
 
 	copied = access_process_vm(child, addr, opcode, sizeof(opcode),
 			FOLL_FORCE);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (i = 0; i < copied; i++) {
 		switch (opcode[i]) {
 		/* popf and iret */
@@ -110,6 +121,7 @@ static int is_setting_trap_flag(struct task_struct *child, struct pt_regs *regs)
  */
 static int enable_single_step(struct task_struct *child)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct pt_regs *regs = task_pt_regs(child);
 	unsigned long oflags;
 
@@ -212,11 +224,13 @@ static void enable_step(struct task_struct *child, bool block)
 
 void user_enable_single_step(struct task_struct *child)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	enable_step(child, 0);
 }
 
 void user_enable_block_step(struct task_struct *child)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	enable_step(child, 1);
 }
 
@@ -226,12 +240,16 @@ void user_disable_single_step(struct task_struct *child)
 	 * Make sure block stepping (BTF) is disabled.
 	 */
 	if (test_tsk_thread_flag(child, TIF_BLOCKSTEP))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		set_task_blockstep(child, false);
+}
 
 	/* Always clear TIF_SINGLESTEP... */
 	clear_tsk_thread_flag(child, TIF_SINGLESTEP);
 
 	/* But touch TF only if it was set by us.. */
 	if (test_and_clear_tsk_thread_flag(child, TIF_FORCED_TF))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		task_pt_regs(child)->flags &= ~X86_EFLAGS_TF;
 }
+}
diff --git a/arch/x86/kernel/sys_x86_64.c b/arch/x86/kernel/sys_x86_64.c
index a63fe77..f048d44 100644
--- a/arch/x86/kernel/sys_x86_64.c
+++ b/arch/x86/kernel/sys_x86_64.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 #include <linux/errno.h>
 #include <linux/sched.h>
@@ -31,11 +33,17 @@ static unsigned long get_align_mask(void)
 {
 	/* handle 32- and 64-bit case with a single conditional */
 	if (va_align.flags < 0 || !(va_align.flags & (2 - mmap_is_ia32())))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!(current->flags & PF_RANDOMIZE))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return va_align.mask;
 }
 
@@ -118,12 +126,16 @@ static void find_start_end(unsigned long addr, unsigned long flags,
 		if (current->flags & PF_RANDOMIZE) {
 			*begin = randomize_page(*begin, 0x02000000);
 		}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	*begin	= get_mmap_base(1);
 	if (in_compat_syscall())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		*end = task_size_32bit();
+}
 	else
 		*end = task_size_64bit(addr > DEFAULT_MAP_WINDOW);
 }
@@ -139,15 +151,21 @@ arch_get_unmapped_area(struct file *filp, unsigned long addr,
 
 	addr = mpx_unmapped_area_check(addr, len, flags);
 	if (IS_ERR_VALUE(addr))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return addr;
+}
 
 	if (flags & MAP_FIXED)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return addr;
+}
 
 	find_start_end(addr, flags, &begin, &end);
 
 	if (len > end)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 
 	if (addr) {
 		addr = PAGE_ALIGN(addr);
@@ -164,6 +182,7 @@ arch_get_unmapped_area(struct file *filp, unsigned long addr,
 	info.align_mask = 0;
 	info.align_offset = pgoff << PAGE_SHIFT;
 	if (filp) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		info.align_mask = get_align_mask();
 		info.align_offset += get_align_bits();
 	}
@@ -182,14 +201,20 @@ arch_get_unmapped_area_topdown(struct file *filp, const unsigned long addr0,
 
 	addr = mpx_unmapped_area_check(addr, len, flags);
 	if (IS_ERR_VALUE(addr))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return addr;
+}
 
 	/* requested length too big for entire address space */
 	if (len > TASK_SIZE)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 
 	if (flags & MAP_FIXED)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return addr;
+}
 
 	/* for MAP_32BIT mappings we force the legacy mmap base */
 	if (!in_compat_syscall() && (flags & MAP_32BIT))
@@ -216,7 +241,9 @@ arch_get_unmapped_area_topdown(struct file *filp, const unsigned long addr0,
 	 * !in_compat_syscall() check to avoid high addresses for x32.
 	 */
 	if (addr > DEFAULT_MAP_WINDOW && !in_compat_syscall())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		info.high_limit += TASK_SIZE_MAX - DEFAULT_MAP_WINDOW;
+}
 
 	info.align_mask = 0;
 	info.align_offset = pgoff << PAGE_SHIFT;
@@ -226,7 +253,10 @@ arch_get_unmapped_area_topdown(struct file *filp, const unsigned long addr0,
 	}
 	addr = vm_unmapped_area(&info);
 	if (!(addr & ~PAGE_MASK))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return addr;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	VM_BUG_ON(addr != -ENOMEM);
 
 bottomup:
diff --git a/arch/x86/kernel/sysfb.c b/arch/x86/kernel/sysfb.c
index 160386e..4e0faba 100644
--- a/arch/x86/kernel/sysfb.c
+++ b/arch/x86/kernel/sysfb.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * Generic System Framebuffers on x86
  * Copyright (c) 2012-2013 David Herrmann <dh.herrmann@gmail.com>
@@ -52,16 +54,23 @@ static __init int sysfb_init(void)
 	/* try to create a simple-framebuffer device */
 	compatible = parse_mode(si, &mode);
 	if (compatible) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ret = create_simplefb(si, &mode);
 		if (!ret)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return 0;
+}
 	}
 
 	/* if the FB is incompatible, create a legacy framebuffer device */
 	if (si->orig_video_isVGA == VIDEO_TYPE_EFI)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		name = "efi-framebuffer";
+}
 	else if (si->orig_video_isVGA == VIDEO_TYPE_VLFB)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		name = "vesa-framebuffer";
+}
 	else
 		name = "platform-framebuffer";
 
diff --git a/arch/x86/kernel/sysfb_efi.c b/arch/x86/kernel/sysfb_efi.c
index 623965e..092b656 100644
--- a/arch/x86/kernel/sysfb_efi.c
+++ b/arch/x86/kernel/sysfb_efi.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * Generic System Framebuffers on x86
  * Copyright (c) 2012-2013 David Herrmann <dh.herrmann@gmail.com>
@@ -72,6 +74,7 @@ void efifb_setup_from_dmi(struct screen_info *si, const char *opt)
 {
 	int i;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (i = 0; i < M_UNKNOWN; i++) {
 		if (efifb_dmi_list[i].base != 0 &&
 		    !strcmp(opt, efifb_dmi_list[i].optname)) {
@@ -96,6 +99,7 @@ static int __init efifb_set_system(const struct dmi_system_id *id)
 {
 	struct efifb_dmi_info *info = id->driver_data;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (info->base == 0 && info->height == 0 && info->width == 0 &&
 	    info->stride == 0)
 		return 0;
diff --git a/arch/x86/kernel/time.c b/arch/x86/kernel/time.c
index 879af86..9484039 100644
--- a/arch/x86/kernel/time.c
+++ b/arch/x86/kernel/time.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 /*
  *  Copyright (c) 1991,1992,1995  Linus Torvalds
@@ -29,6 +31,7 @@ __visible volatile unsigned long jiffies __cacheline_aligned = INITIAL_JIFFIES;
 
 unsigned long profile_pc(struct pt_regs *regs)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	unsigned long pc = instruction_pointer(regs);
 
 	if (!user_mode(regs) && in_lock_functions(pc)) {
@@ -70,7 +73,9 @@ static struct irqaction irq0  = {
 static void __init setup_default_timer_irq(void)
 {
 	if (!nr_legacy_irqs())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 	setup_irq(0, &irq0);
 }
 
@@ -78,7 +83,9 @@ static void __init setup_default_timer_irq(void)
 void __init hpet_time_init(void)
 {
 	if (!hpet_enable())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		setup_pit_timer();
+}
 	setup_default_timer_irq();
 }
 
diff --git a/arch/x86/kernel/topology.c b/arch/x86/kernel/topology.c
index 12cbe2b..d5cda44 100644
--- a/arch/x86/kernel/topology.c
+++ b/arch/x86/kernel/topology.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * Populate sysfs with topology information
  *
@@ -43,6 +45,7 @@ static int cpu0_hotpluggable = 1;
 static int cpu0_hotpluggable;
 static int __init enable_cpu0_hotplug(char *str)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	cpu0_hotpluggable = 1;
 	return 1;
 }
@@ -130,14 +133,18 @@ int arch_register_cpu(int num)
 		 * interrupts only are able to be serviced by the BSP in PIC.
 		 */
 		for_each_active_irq(irq) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			if (!IO_APIC_IRQ(irq) && irq_has_action(irq)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				cpu0_hotpluggable = 0;
 				break;
 			}
 		}
 	}
 	if (num || cpu0_hotpluggable)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		per_cpu(cpu_devices, num).cpu.hotpluggable = 1;
+}
 
 	return register_cpu(&per_cpu(cpu_devices, num).cpu, num);
 }
@@ -145,6 +152,7 @@ EXPORT_SYMBOL(arch_register_cpu);
 
 void arch_unregister_cpu(int num)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	unregister_cpu(&per_cpu(cpu_devices, num).cpu);
 }
 EXPORT_SYMBOL(arch_unregister_cpu);
diff --git a/arch/x86/kernel/traps.c b/arch/x86/kernel/traps.c
index a66428dc..9dab902 100644
--- a/arch/x86/kernel/traps.c
+++ b/arch/x86/kernel/traps.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  *  Copyright (C) 1991, 1992  Linus Torvalds
  *  Copyright (C) 2000, 2001, 2002 Andi Kleen, SuSE Labs
@@ -81,6 +83,7 @@ static inline void cond_local_irq_enable(struct pt_regs *regs)
 
 static inline void cond_local_irq_disable(struct pt_regs *regs)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (regs->flags & X86_EFLAGS_IF)
 		local_irq_disable();
 }
@@ -93,6 +96,7 @@ static inline void cond_local_irq_disable(struct pt_regs *regs)
  */
 void ist_enter(struct pt_regs *regs)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (user_mode(regs)) {
 		RCU_LOCKDEP_WARN(!rcu_is_watching(), "entry code didn't wake RCU");
 	} else {
@@ -113,6 +117,7 @@ void ist_enter(struct pt_regs *regs)
 
 void ist_exit(struct pt_regs *regs)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	preempt_enable_no_resched();
 
 	if (!user_mode(regs))
@@ -134,6 +139,7 @@ void ist_exit(struct pt_regs *regs)
  */
 void ist_begin_non_atomic(struct pt_regs *regs)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	BUG_ON(!user_mode(regs));
 
 	/*
@@ -153,6 +159,7 @@ void ist_begin_non_atomic(struct pt_regs *regs)
  */
 void ist_end_non_atomic(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	preempt_disable();
 }
 
@@ -161,7 +168,9 @@ int is_valid_bugaddr(unsigned long addr)
 	unsigned short ud;
 
 	if (addr < TASK_SIZE_MAX)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	if (probe_kernel_address((unsigned short *)addr, ud))
 		return 0;
@@ -171,6 +180,7 @@ int is_valid_bugaddr(unsigned long addr)
 
 int fixup_bug(struct pt_regs *regs, int trapnr)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (trapnr != X86_TRAP_UD)
 		return 0;
 
@@ -191,28 +201,36 @@ static nokprobe_inline int
 do_trap_no_signal(struct task_struct *tsk, int trapnr, char *str,
 		  struct pt_regs *regs,	long error_code)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (v8086_mode(regs)) {
 		/*
 		 * Traps 0, 1, 3, 4, and 5 should be forwarded to vm86.
 		 * On nmi (interrupt 2), do_trap should not be called.
 		 */
 		if (trapnr < X86_TRAP_UD) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			if (!handle_vm86_trap((struct kernel_vm86_regs *) regs,
 						error_code, trapnr))
 				return 0;
 		}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -1;
 	}
 
 	if (!user_mode(regs)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (fixup_exception(regs, trapnr))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return 0;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		tsk->thread.error_code = error_code;
 		tsk->thread.trap_nr = trapnr;
 		die(str, regs, error_code);
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return -1;
 }
 
@@ -251,11 +269,14 @@ static void
 do_trap(int trapnr, int signr, char *str, struct pt_regs *regs,
 	long error_code, siginfo_t *info)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct task_struct *tsk = current;
 
 
 	if (!do_trap_no_signal(tsk, trapnr, str, regs, error_code))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 	/*
 	 * We want error_code and trap_nr set for userspace faults and
 	 * kernelspace faults which result in die(), but not
@@ -286,6 +307,7 @@ static void do_error_trap(struct pt_regs *regs, long error_code, char *str,
 {
 	siginfo_t info;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	RCU_LOCKDEP_WARN(!rcu_is_watching(), "entry code didn't wake RCU");
 
 	/*
@@ -293,7 +315,9 @@ static void do_error_trap(struct pt_regs *regs, long error_code, char *str,
 	 * notifier chain.
 	 */
 	if (!user_mode(regs) && fixup_bug(regs, trapnr))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	if (notify_die(DIE_TRAP, str, regs, error_code, trapnr, signr) !=
 			NOTIFY_STOP) {
@@ -455,6 +479,7 @@ dotraplinkage void do_bounds(struct pt_regs *regs, long error_code)
 	const struct mpx_bndcsr *bndcsr;
 	siginfo_t *info;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	RCU_LOCKDEP_WARN(!rcu_is_watching(), "entry code didn't wake RCU");
 	if (notify_die(DIE_TRAP, "bounds", regs, error_code,
 			X86_TRAP_BR, SIGSEGV) == NOTIFY_STOP)
@@ -533,6 +558,7 @@ do_general_protection(struct pt_regs *regs, long error_code)
 {
 	struct task_struct *tsk;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	RCU_LOCKDEP_WARN(!rcu_is_watching(), "entry code didn't wake RCU");
 	cond_local_irq_enable(regs);
 
@@ -584,9 +610,13 @@ dotraplinkage void notrace do_int3(struct pt_regs *regs, long error_code)
 		return;
 #endif
 	if (poke_int3_handler(regs))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	ist_enter(regs);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	RCU_LOCKDEP_WARN(!rcu_is_watching(), "entry code didn't wake RCU");
 #ifdef CONFIG_KGDB_LOW_LEVEL_TRAP
 	if (kgdb_ll_trap(DIE_INT3, "int3", regs, error_code, X86_TRAP_BP,
@@ -599,6 +629,7 @@ dotraplinkage void notrace do_int3(struct pt_regs *regs, long error_code)
 		goto exit;
 #endif
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (notify_die(DIE_INT3, "int3", regs, error_code, X86_TRAP_BP,
 			SIGTRAP) == NOTIFY_STOP)
 		goto exit;
@@ -658,6 +689,7 @@ struct bad_iret_stack *fixup_bad_iret(struct bad_iret_stack *s)
 	memmove(new_stack, s, offsetof(struct bad_iret_stack, regs.ip));
 
 	BUG_ON(!user_mode(&new_stack->regs));
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return new_stack;
 }
 NOKPROBE_SYMBOL(fixup_bad_iret);
@@ -712,6 +744,7 @@ static bool is_sysenter_singlestep(struct pt_regs *regs)
  */
 dotraplinkage void do_debug(struct pt_regs *regs, long error_code)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct task_struct *tsk = current;
 	int user_icebp = 0;
 	unsigned long dr6;
@@ -821,6 +854,7 @@ NOKPROBE_SYMBOL(do_debug);
  */
 static void math_error(struct pt_regs *regs, int error_code, int trapnr)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct task_struct *task = current;
 	struct fpu *fpu = &task->thread.fpu;
 	siginfo_t info;
@@ -862,6 +896,7 @@ static void math_error(struct pt_regs *regs, int error_code, int trapnr)
 
 dotraplinkage void do_coprocessor_error(struct pt_regs *regs, long error_code)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	RCU_LOCKDEP_WARN(!rcu_is_watching(), "entry code didn't wake RCU");
 	math_error(regs, error_code, X86_TRAP_MF);
 }
@@ -869,6 +904,7 @@ dotraplinkage void do_coprocessor_error(struct pt_regs *regs, long error_code)
 dotraplinkage void
 do_simd_coprocessor_error(struct pt_regs *regs, long error_code)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	RCU_LOCKDEP_WARN(!rcu_is_watching(), "entry code didn't wake RCU");
 	math_error(regs, error_code, X86_TRAP_XF);
 }
@@ -876,6 +912,7 @@ do_simd_coprocessor_error(struct pt_regs *regs, long error_code)
 dotraplinkage void
 do_spurious_interrupt_bug(struct pt_regs *regs, long error_code)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	cond_local_irq_enable(regs);
 }
 
@@ -884,6 +921,7 @@ do_device_not_available(struct pt_regs *regs, long error_code)
 {
 	unsigned long cr0;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	RCU_LOCKDEP_WARN(!rcu_is_watching(), "entry code didn't wake RCU");
 
 #ifdef CONFIG_MATH_EMULATION
diff --git a/arch/x86/kernel/tsc.c b/arch/x86/kernel/tsc.c
index 4750656..4195ca3 100644
--- a/arch/x86/kernel/tsc.c
+++ b/arch/x86/kernel/tsc.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 #define pr_fmt(fmt) KBUILD_MODNAME ": " fmt
 
 #include <linux/kernel.h>
@@ -192,6 +194,7 @@ static void set_cyc2ns_scale(unsigned long khz, int cpu, unsigned long long tsc_
 u64 native_sched_clock(void)
 {
 	if (static_branch_likely(&__use_tsc)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		u64 tsc_now = rdtsc();
 
 		/* return the value in ns */
@@ -216,6 +219,7 @@ u64 native_sched_clock(void)
  */
 u64 native_sched_clock_from_tsc(u64 tsc)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return cycles_2_ns(tsc);
 }
 
@@ -235,6 +239,7 @@ bool using_native_sched_clock(void)
 unsigned long long
 sched_clock(void) __attribute__((alias("native_sched_clock")));
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 bool using_native_sched_clock(void) { return true; }
 #endif
 
@@ -247,6 +252,7 @@ EXPORT_SYMBOL_GPL(check_tsc_unstable);
 #ifdef CONFIG_X86_TSC
 int __init notsc_setup(char *str)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pr_warn("Kernel compiled with CONFIG_X86_TSC, cannot disable TSC completely\n");
 	tsc_disabled = 1;
 	return 1;
@@ -269,6 +275,7 @@ static int no_sched_irq_time;
 
 static int __init tsc_setup(char *str)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!strcmp(str, "reliable"))
 		tsc_clocksource_reliable = 1;
 	if (!strncmp(str, "noirqtime", 9))
@@ -299,8 +306,11 @@ static u64 tsc_read_refs(u64 *p, int hpet)
 			*p = acpi_pm_read_early();
 		t2 = get_cycles();
 		if ((t2 - t1) < SMI_TRESHOLD)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return t2;
+}
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return ULLONG_MAX;
 }
 
@@ -328,6 +338,7 @@ static unsigned long calc_pmtimer_ref(u64 deltatsc, u64 pm1, u64 pm2)
 {
 	u64 tmp;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!pm1 && !pm2)
 		return ULONG_MAX;
 
@@ -385,9 +396,13 @@ static unsigned long pit_calibrate_tsc(u32 latch, unsigned long ms, int loopmin)
 		delta = t2 - tsc;
 		tsc = t2;
 		if ((unsigned long) delta < tscmin)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			tscmin = (unsigned int) delta;
+}
 		if ((unsigned long) delta > tscmax)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			tscmax = (unsigned int) delta;
+}
 		pitcnt++;
 	}
 
@@ -401,7 +416,9 @@ static unsigned long pit_calibrate_tsc(u32 latch, unsigned long ms, int loopmin)
 	 * then we got hit by an SMI as well.
 	 */
 	if (pitcnt < loopmin || tscmax > 10 * tscmin)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ULONG_MAX;
+}
 
 	/* Calculate the PIT value */
 	delta = t2 - t1;
@@ -459,6 +476,7 @@ static inline int pit_expect_msb(unsigned char val, u64 *tscp, unsigned long *de
 	for (count = 0; count < 50000; count++) {
 		if (!pit_verify_msb(val))
 			break;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		prev_tsc = tsc;
 		tsc = get_cycles();
 	}
@@ -579,22 +597,33 @@ unsigned long native_calibrate_tsc(void)
 	unsigned int crystal_khz;
 
 	if (boot_cpu_data.x86_vendor != X86_VENDOR_INTEL)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (boot_cpu_data.cpuid_level < 0x15)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	eax_denominator = ebx_numerator = ecx_hz = edx = 0;
 
 	/* CPUID 15H TSC/Crystal ratio, plus optionally Crystal Hz */
 	cpuid(0x15, &eax_denominator, &ebx_numerator, &ecx_hz, &edx);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (ebx_numerator == 0 || eax_denominator == 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	crystal_khz = ecx_hz / 1000;
 
 	if (crystal_khz == 0) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		switch (boot_cpu_data.x86_model) {
 		case INTEL_FAM6_SKYLAKE_MOBILE:
 		case INTEL_FAM6_SKYLAKE_DESKTOP:
@@ -611,8 +640,11 @@ unsigned long native_calibrate_tsc(void)
 		}
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (crystal_khz == 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 	/*
 	 * TSC frequency determined by CPUID is a "hardware reported"
 	 * frequency and is the most accurate one so far we have. This
@@ -625,8 +657,11 @@ unsigned long native_calibrate_tsc(void)
 	 * Mark TSC reliable so no watchdog on it.
 	 */
 	if (boot_cpu_data.x86_model == INTEL_FAM6_ATOM_GOLDMONT)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		setup_force_cpu_cap(X86_FEATURE_TSC_RELIABLE);
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return crystal_khz * ebx_numerator / eax_denominator;
 }
 
@@ -635,11 +670,17 @@ static unsigned long cpu_khz_from_cpuid(void)
 	unsigned int eax_base_mhz, ebx_max_mhz, ecx_bus_mhz, edx;
 
 	if (boot_cpu_data.x86_vendor != X86_VENDOR_INTEL)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (boot_cpu_data.cpuid_level < 0x16)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	eax_base_mhz = ebx_max_mhz = ecx_bus_mhz = edx = 0;
 
 	cpuid(0x16, &eax_base_mhz, &ebx_max_mhz, &ecx_bus_mhz, &edx);
@@ -659,17 +700,23 @@ unsigned long native_calibrate_cpu(void)
 
 	fast_calibrate = cpu_khz_from_cpuid();
 	if (fast_calibrate)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return fast_calibrate;
+}
 
 	fast_calibrate = cpu_khz_from_msr();
 	if (fast_calibrate)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return fast_calibrate;
+}
 
 	local_irq_save(flags);
 	fast_calibrate = quick_pit_calibrate();
 	local_irq_restore(flags);
 	if (fast_calibrate)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return fast_calibrate;
+}
 
 	/*
 	 * Run 5 calibration loops to get the lowest frequency value
@@ -746,6 +793,7 @@ unsigned long native_calibrate_cpu(void)
 		 * use the reference value, as it is more precise.
 		 */
 		if (delta >= 90 && delta <= 110) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			pr_info("PIT calibration matches %s. %d loops\n",
 				hpet ? "HPET" : "PMTIMER", i + 1);
 			return tsc_ref_min;
@@ -758,6 +806,7 @@ unsigned long native_calibrate_cpu(void)
 		 * the HPET/PMTIMER to make the result precise.
 		 */
 		if (i == 1 && tsc_pit_min == ULONG_MAX) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			latch = CAL2_LATCH;
 			ms = CAL2_MS;
 			loopmin = CAL2_PIT_LOOPS;
@@ -779,6 +828,7 @@ unsigned long native_calibrate_cpu(void)
 
 		/* The alternative source failed as well, disable TSC */
 		if (tsc_ref_min == ULONG_MAX) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			pr_warn("HPET/PMTIMER calibration failed\n");
 			return 0;
 		}
@@ -792,12 +842,14 @@ unsigned long native_calibrate_cpu(void)
 
 	/* We don't have an alternative source, use the PIT calibration value */
 	if (!hpet && !ref1 && !ref2) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_info("Using PIT calibration value\n");
 		return tsc_pit_min;
 	}
 
 	/* The alternative source failed, use the PIT calibration value */
 	if (tsc_ref_min == ULONG_MAX) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_warn("HPET/PMTIMER calibration failed. Using PIT calibration.\n");
 		return tsc_pit_min;
 	}
@@ -843,6 +895,7 @@ static unsigned long long cyc2ns_suspend;
 
 void tsc_save_sched_clock_state(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!sched_clock_stable())
 		return;
 
@@ -864,7 +917,9 @@ void tsc_restore_sched_clock_state(void)
 	int cpu;
 
 	if (!sched_clock_stable())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	local_irq_save(flags);
 
@@ -912,7 +967,9 @@ static int time_cpufreq_notifier(struct notifier_block *nb, unsigned long val,
 	lpj = &boot_cpu_data.loops_per_jiffy;
 #ifdef CONFIG_SMP
 	if (!(freq->flags & CPUFREQ_CONST_LOOPS))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		lpj = &cpu_data(freq->cpu).loops_per_jiffy;
+}
 #endif
 
 	if (!ref_freq) {
@@ -941,9 +998,13 @@ static struct notifier_block time_cpufreq_notifier_block = {
 static int __init cpufreq_register_tsc_scaling(void)
 {
 	if (!boot_cpu_has(X86_FEATURE_TSC))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 	if (boot_cpu_has(X86_FEATURE_CONSTANT_TSC))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 	cpufreq_register_notifier(&time_cpufreq_notifier_block,
 				CPUFREQ_TRANSITION_NOTIFIER);
 	return 0;
@@ -973,12 +1034,16 @@ static void detect_art(void)
 	    !boot_cpu_has(X86_FEATURE_TSC_ADJUST))
 		return;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	cpuid(ART_CPUID_LEAF, &art_to_tsc_denominator,
 	      &art_to_tsc_numerator, unused, unused+1);
 
 	if (art_to_tsc_denominator < ART_MIN_DENOMINATOR)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rdmsrl(MSR_IA32_TSC_ADJUST, art_to_tsc_offset);
 
 	/* Make this sticky over multiple CPU init calls */
@@ -992,6 +1057,7 @@ static struct clocksource clocksource_tsc;
 
 static void tsc_resume(struct clocksource *cs)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	tsc_verify_tsc_adjust(true);
 }
 
@@ -1018,6 +1084,7 @@ static u64 read_tsc(struct clocksource *cs)
 
 static void tsc_cs_mark_unstable(struct clocksource *cs)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (tsc_unstable)
 		return;
 
@@ -1031,7 +1098,9 @@ static void tsc_cs_mark_unstable(struct clocksource *cs)
 static void tsc_cs_tick_stable(struct clocksource *cs)
 {
 	if (tsc_unstable)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	if (using_native_sched_clock())
 		sched_clock_tick_stable();
@@ -1055,6 +1124,7 @@ static struct clocksource clocksource_tsc = {
 
 void mark_tsc_unstable(char *reason)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (tsc_unstable)
 		return;
 
@@ -1089,8 +1159,10 @@ static void __init check_system_tsc_reliable(void)
 	}
 #endif
 	if (boot_cpu_has(X86_FEATURE_TSC_RELIABLE))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		tsc_clocksource_reliable = 1;
 }
+}
 
 /*
  * Make an educated guess if the TSC is trustworthy and synchronized
@@ -1099,18 +1171,26 @@ static void __init check_system_tsc_reliable(void)
 int unsynchronized_tsc(void)
 {
 	if (!boot_cpu_has(X86_FEATURE_TSC) || tsc_unstable)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 1;
+}
 
 #ifdef CONFIG_SMP
 	if (apic_is_clustered_box())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 1;
+}
 #endif
 
 	if (boot_cpu_has(X86_FEATURE_CONSTANT_TSC))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	if (tsc_clocksource_reliable)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 	/*
 	 * Intel systems are normally all synchronized.
 	 * Exceptions must mark TSC as unstable:
@@ -1118,9 +1198,12 @@ int unsynchronized_tsc(void)
 	if (boot_cpu_data.x86_vendor != X86_VENDOR_INTEL) {
 		/* assume multi socket systems are not synchronized: */
 		if (num_possible_cpus() > 1)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return 1;
+}
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
@@ -1223,7 +1306,9 @@ static void tsc_refine_calibration_work(struct work_struct *work)
 
 out:
 	if (boot_cpu_has(X86_FEATURE_ART))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		art_related_clocksource = &clocksource_tsc;
+}
 	clocksource_register_khz(&clocksource_tsc, tsc_khz);
 }
 
@@ -1231,26 +1316,37 @@ static void tsc_refine_calibration_work(struct work_struct *work)
 static int __init init_tsc_clocksource(void)
 {
 	if (!boot_cpu_has(X86_FEATURE_TSC) || tsc_disabled > 0 || !tsc_khz)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	if (tsc_clocksource_reliable)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		clocksource_tsc.flags &= ~CLOCK_SOURCE_MUST_VERIFY;
+}
 	/* lower the rating if we already know its unstable: */
 	if (check_tsc_unstable()) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		clocksource_tsc.rating = 0;
 		clocksource_tsc.flags &= ~CLOCK_SOURCE_IS_CONTINUOUS;
 	}
 
 	if (boot_cpu_has(X86_FEATURE_NONSTOP_TSC_S3))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		clocksource_tsc.flags |= CLOCK_SOURCE_SUSPEND_NONSTOP;
+}
 
 	/*
 	 * When TSC frequency is known (retrieved via MSR or CPUID), we skip
 	 * the refined calibration and directly register it as a clocksource.
 	 */
 	if (boot_cpu_has(X86_FEATURE_TSC_KNOWN_FREQ)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (boot_cpu_has(X86_FEATURE_ART))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			art_related_clocksource = &clocksource_tsc;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		clocksource_register_khz(&clocksource_tsc, tsc_khz);
 		return 0;
 	}
@@ -1270,6 +1366,7 @@ void __init tsc_init(void)
 	int cpu;
 
 	if (!boot_cpu_has(X86_FEATURE_TSC)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		setup_clear_cpu_cap(X86_FEATURE_TSC_DEADLINE_TIMER);
 		return;
 	}
@@ -1284,10 +1381,14 @@ void __init tsc_init(void)
 	 */
 	if (tsc_khz == 0)
 		tsc_khz = cpu_khz;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	else if (abs(cpu_khz - tsc_khz) * 10 > tsc_khz)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		cpu_khz = tsc_khz;
+}
 
 	if (!tsc_khz) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		mark_tsc_unstable("could not calculate TSC khz");
 		setup_clear_cpu_cap(X86_FEATURE_TSC_DEADLINE_TIMER);
 		return;
@@ -1313,7 +1414,9 @@ void __init tsc_init(void)
 	}
 
 	if (tsc_disabled > 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	/* now allow native_sched_clock() to use rdtsc */
 
@@ -1321,7 +1424,9 @@ void __init tsc_init(void)
 	static_branch_enable(&__use_tsc);
 
 	if (!no_sched_irq_time)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		enable_sched_clock_irqtime();
+}
 
 	lpj = ((u64)tsc_khz * 1000);
 	do_div(lpj, HZ);
@@ -1332,7 +1437,9 @@ void __init tsc_init(void)
 	check_system_tsc_reliable();
 
 	if (unsynchronized_tsc())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		mark_tsc_unstable("TSCs unsynchronized");
+}
 
 	detect_art();
 }
@@ -1346,6 +1453,7 @@ void __init tsc_init(void)
  */
 unsigned long calibrate_delay_is_known(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	int sibling, cpu = smp_processor_id();
 	int constant_tsc = cpu_has(&cpu_data(cpu), X86_FEATURE_CONSTANT_TSC);
 	const struct cpumask *mask = topology_core_cpumask(cpu);
diff --git a/arch/x86/kernel/tsc_msr.c b/arch/x86/kernel/tsc_msr.c
index 19afdbd..83e0061 100644
--- a/arch/x86/kernel/tsc_msr.c
+++ b/arch/x86/kernel/tsc_msr.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * tsc_msr.c - TSC frequency enumeration via MSR
  *
@@ -49,6 +51,7 @@ static int match_cpu(u8 family, u8 model)
 {
 	int i;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (i = 0; i < ARRAY_SIZE(freq_desc_tables); i++) {
 		if ((family == freq_desc_tables[i].x86_family) &&
 			(model == freq_desc_tables[i].x86_model))
@@ -75,22 +78,33 @@ unsigned long cpu_khz_from_msr(void)
 	int cpu_index;
 
 	if (boot_cpu_data.x86_vendor != X86_VENDOR_INTEL)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	cpu_index = match_cpu(boot_cpu_data.x86, boot_cpu_data.x86_model);
 	if (cpu_index < 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (freq_desc_tables[cpu_index].msr_plat) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		rdmsr(MSR_PLATFORM_INFO, lo, hi);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ratio = (lo >> 8) & 0xff;
 	} else {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		rdmsr(MSR_IA32_PERF_STATUS, lo, hi);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ratio = (hi >> 8) & 0x1f;
 	}
 
 	/* Get FSB FREQ ID */
 	rdmsr(MSR_FSB_FREQ, lo, hi);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	freq_id = lo & 0x7;
 	freq = id_to_freq(cpu_index, freq_id);
 
@@ -119,5 +133,6 @@ unsigned long cpu_khz_from_msr(void)
 	 */
 	setup_force_cpu_cap(X86_FEATURE_TSC_RELIABLE);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return res;
 }
diff --git a/arch/x86/kernel/tsc_sync.c b/arch/x86/kernel/tsc_sync.c
index e76a988..7e3cd48 100644
--- a/arch/x86/kernel/tsc_sync.c
+++ b/arch/x86/kernel/tsc_sync.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 /*
  * check TSC synchronization.
@@ -37,22 +39,31 @@ void tsc_verify_tsc_adjust(bool resume)
 	s64 curval;
 
 	if (!boot_cpu_has(X86_FEATURE_TSC_ADJUST))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	/* Rate limit the MSR check */
 	if (!resume && time_before(jiffies, adj->nextcheck))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	adj->nextcheck = jiffies + HZ;
 
 	rdmsrl(MSR_IA32_TSC_ADJUST, curval);
 	if (adj->adjusted == curval)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	/* Restore the original value */
 	wrmsrl(MSR_IA32_TSC_ADJUST, adj->adjusted);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!adj->warned || resume) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_warn(FW_BUG "TSC ADJUST differs: CPU%u %lld --> %lld. Restoring\n",
 			smp_processor_id(), adj->adjusted, curval);
 		adj->warned = true;
@@ -111,8 +122,11 @@ bool tsc_store_and_check_tsc_adjust(bool bootcpu)
 	s64 bootval;
 
 	if (!boot_cpu_has(X86_FEATURE_TSC_ADJUST))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return false;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rdmsrl(MSR_IA32_TSC_ADJUST, bootval);
 	cur->bootval = bootval;
 	cur->nextcheck = jiffies + HZ;
@@ -126,20 +140,24 @@ bool tsc_store_and_check_tsc_adjust(bool bootcpu)
 	 * boot CPU topology_core_cpumask() might not be available yet.
 	 */
 	mask = topology_core_cpumask(cpu);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	refcpu = mask ? cpumask_any_but(mask, cpu) : nr_cpu_ids;
 
 	if (refcpu >= nr_cpu_ids) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		tsc_sanitize_first_cpu(cur, bootval, smp_processor_id(),
 				       bootcpu);
 		return false;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	ref = per_cpu_ptr(&tsc_adjust, refcpu);
 	/*
 	 * Compare the boot value and complain if it differs in the
 	 * package.
 	 */
 	if (bootval != ref->bootval) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_warn(FW_BUG "TSC ADJUST differs: Reference CPU%u: %lld CPU%u: %lld\n",
 			refcpu, ref->bootval, cpu, bootval);
 	}
@@ -150,6 +168,7 @@ bool tsc_store_and_check_tsc_adjust(bool bootcpu)
 	 * adjusted value.
 	 */
 	if (bootval != ref->adjusted) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_warn("TSC ADJUST synchronize: Reference CPU%u: %lld CPU%u: %lld\n",
 			refcpu, ref->adjusted, cpu, bootval);
 		cur->adjusted = ref->adjusted;
@@ -199,6 +218,7 @@ static cycles_t check_tsc_warp(unsigned int timeout)
 	end = start + (cycles_t) tsc_khz * timeout;
 	now = start;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (i = 0; ; i++) {
 		/*
 		 * We take the global lock, measure TSC, save the
@@ -264,6 +284,7 @@ static cycles_t check_tsc_warp(unsigned int timeout)
  */
 static inline unsigned int loop_timeout(int cpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return (cpumask_weight(topology_core_cpumask(cpu)) > 1) ? 2 : 20;
 }
 
@@ -280,7 +301,9 @@ void check_tsc_sync_source(int cpu)
 	 * synchronized or if we have no TSC.
 	 */
 	if (unsynchronized_tsc())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	/*
 	 * Set the maximum number of test runs to
@@ -363,6 +386,7 @@ void check_tsc_sync_source(int cpu)
  */
 void check_tsc_sync_target(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct tsc_adjust *cur = this_cpu_ptr(&tsc_adjust);
 	unsigned int cpu = smp_processor_id();
 	cycles_t cur_max_warp, gbl_max_warp;
diff --git a/arch/x86/kernel/unwind_orc.c b/arch/x86/kernel/unwind_orc.c
index be86a86..5ec739e 100644
--- a/arch/x86/kernel/unwind_orc.c
+++ b/arch/x86/kernel/unwind_orc.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 #include <linux/module.h>
 #include <linux/sort.h>
 #include <asm/ptrace.h>
@@ -35,7 +37,9 @@ static struct orc_entry *__orc_find(int *ip_table, struct orc_entry *u_table,
 	int *mid = first, *found = first;
 
 	if (!num_entries)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 
 	/*
 	 * Do a binary range search to find the rightmost duplicate of a given
@@ -47,6 +51,7 @@ static struct orc_entry *__orc_find(int *ip_table, struct orc_entry *u_table,
 		mid = first + ((last - first) / 2);
 
 		if (orc_ip(mid) <= ip) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			found = mid;
 			first = mid + 1;
 		} else
@@ -62,6 +67,7 @@ static struct orc_entry *orc_module_find(unsigned long ip)
 	struct module *mod;
 
 	mod = __module_address(ip);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!mod || !mod->arch.orc_unwind || !mod->arch.orc_unwind_ip)
 		return NULL;
 	return __orc_find(mod->arch.orc_unwind_ip, mod->arch.orc_unwind,
@@ -76,6 +82,7 @@ static struct orc_entry *orc_module_find(unsigned long ip)
 
 static struct orc_entry *orc_find(unsigned long ip)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!orc_init)
 		return NULL;
 
@@ -142,9 +149,13 @@ static int orc_sort_cmp(const void *_a, const void *_b)
 	unsigned long b_val = orc_ip(b);
 
 	if (a_val > b_val)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 1;
+}
 	if (a_val < b_val)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -1;
+}
 
 	/*
 	 * The "weak" section terminator entries need to always be on the left
@@ -164,6 +175,7 @@ void unwind_module_init(struct module *mod, void *_orc_ip, size_t orc_ip_size,
 	struct orc_entry *orc = _orc;
 	unsigned int num_entries = orc_ip_size / sizeof(int);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WARN_ON_ONCE(orc_ip_size % sizeof(int) != 0 ||
 		     orc_size % sizeof(*orc) != 0 ||
 		     num_entries != orc_size / sizeof(*orc));
diff --git a/arch/x86/kernel/uprobes.c b/arch/x86/kernel/uprobes.c
index 495c776..fdf3384 100644
--- a/arch/x86/kernel/uprobes.c
+++ b/arch/x86/kernel/uprobes.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * User-space Probes (UProbes) for x86
  *
@@ -270,6 +272,7 @@ static bool is_prefix_bad(struct insn *insn)
 {
 	int i;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (i = 0; i < insn->prefixes.nbytes; i++) {
 		switch (insn->prefixes.bytes[i]) {
 		case 0x26:	/* INAT_PFX_ES   */
@@ -290,6 +293,7 @@ static int uprobe_init_insn(struct arch_uprobe *auprobe, struct insn *insn, bool
 	insn_init(insn, auprobe->insn, sizeof(auprobe->insn), x86_64);
 	/* has the side-effect of processing the entire instruction */
 	insn_get_length(insn);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (WARN_ON_ONCE(!insn_complete(insn)))
 		return -ENOEXEC;
 
@@ -344,7 +348,9 @@ static void riprel_analyze(struct arch_uprobe *auprobe, struct insn *insn)
 	u8 reg2;
 
 	if (!insn_rip_relative(insn))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	/*
 	 * insn_rip_relative() would have decoded rex_prefix, vex_prefix, modrm.
@@ -461,6 +467,7 @@ static void riprel_analyze(struct arch_uprobe *auprobe, struct insn *insn)
 static inline unsigned long *
 scratch_reg(struct arch_uprobe *auprobe, struct pt_regs *regs)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (auprobe->defparam.fixups & UPROBE_FIX_RIP_SI)
 		return &regs->si;
 	if (auprobe->defparam.fixups & UPROBE_FIX_RIP_DI)
@@ -474,6 +481,7 @@ scratch_reg(struct arch_uprobe *auprobe, struct pt_regs *regs)
  */
 static void riprel_pre_xol(struct arch_uprobe *auprobe, struct pt_regs *regs)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (auprobe->defparam.fixups & UPROBE_FIX_RIP_MASK) {
 		struct uprobe_task *utask = current->utask;
 		unsigned long *sr = scratch_reg(auprobe, regs);
@@ -485,6 +493,7 @@ static void riprel_pre_xol(struct arch_uprobe *auprobe, struct pt_regs *regs)
 
 static void riprel_post_xol(struct arch_uprobe *auprobe, struct pt_regs *regs)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (auprobe->defparam.fixups & UPROBE_FIX_RIP_MASK) {
 		struct uprobe_task *utask = current->utask;
 		unsigned long *sr = scratch_reg(auprobe, regs);
@@ -516,17 +525,20 @@ struct uprobe_xol_ops {
 
 static inline int sizeof_long(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return in_ia32_syscall() ? 4 : 8;
 }
 
 static int default_pre_xol_op(struct arch_uprobe *auprobe, struct pt_regs *regs)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	riprel_pre_xol(auprobe, regs);
 	return 0;
 }
 
 static int push_ret_address(struct pt_regs *regs, unsigned long ip)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	unsigned long new_sp = regs->sp - sizeof_long();
 
 	if (copy_to_user((void __user *)new_sp, &ip, sizeof_long()))
@@ -555,6 +567,7 @@ static int push_ret_address(struct pt_regs *regs, unsigned long ip)
  */
 static int default_post_xol_op(struct arch_uprobe *auprobe, struct pt_regs *regs)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct uprobe_task *utask = current->utask;
 
 	riprel_post_xol(auprobe, regs);
@@ -575,6 +588,7 @@ static int default_post_xol_op(struct arch_uprobe *auprobe, struct pt_regs *regs
 
 static void default_abort_op(struct arch_uprobe *auprobe, struct pt_regs *regs)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	riprel_post_xol(auprobe, regs);
 }
 
@@ -586,6 +600,7 @@ static const struct uprobe_xol_ops default_xol_ops = {
 
 static bool branch_is_call(struct arch_uprobe *auprobe)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return auprobe->branch.opc1 == 0xe8;
 }
 
@@ -607,6 +622,7 @@ static bool branch_is_call(struct arch_uprobe *auprobe)
 
 static bool is_cond_jmp_opcode(u8 opcode)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	switch (opcode) {
 	#define DO(expr)	\
 		return true;
@@ -625,6 +641,7 @@ static bool check_jmp_cond(struct arch_uprobe *auprobe, struct pt_regs *regs)
 	switch (auprobe->branch.opc1) {
 	#define DO(expr)	\
 		return expr;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	CASE_COND
 	#undef	DO
 
@@ -664,6 +681,7 @@ static bool branch_emulate_op(struct arch_uprobe *auprobe, struct pt_regs *regs)
 
 static int branch_post_xol_op(struct arch_uprobe *auprobe, struct pt_regs *regs)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	BUG_ON(!branch_is_call(auprobe));
 	/*
 	 * We can only get here if branch_emulate_op() failed to push the ret
@@ -762,7 +780,9 @@ int arch_uprobe_analyze_insn(struct arch_uprobe *auprobe, struct mm_struct *mm,
 
 	ret = uprobe_init_insn(auprobe, &insn, is_64bit_mm(mm));
 	if (ret)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ret;
+}
 
 	ret = branch_setup_xol_ops(auprobe, &insn);
 	if (ret != -ENOSYS)
@@ -814,6 +834,7 @@ int arch_uprobe_analyze_insn(struct arch_uprobe *auprobe, struct mm_struct *mm,
  */
 int arch_uprobe_pre_xol(struct arch_uprobe *auprobe, struct pt_regs *regs)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct uprobe_task *utask = current->utask;
 
 	if (auprobe->ops->pre_xol) {
@@ -846,6 +867,7 @@ int arch_uprobe_pre_xol(struct arch_uprobe *auprobe, struct pt_regs *regs)
  */
 bool arch_uprobe_xol_was_trapped(struct task_struct *t)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (t->thread.trap_nr != UPROBE_TRAP_NR)
 		return true;
 
@@ -861,6 +883,7 @@ bool arch_uprobe_xol_was_trapped(struct task_struct *t)
  */
 int arch_uprobe_post_xol(struct arch_uprobe *auprobe, struct pt_regs *regs)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct uprobe_task *utask = current->utask;
 	bool send_sigtrap = utask->autask.saved_tf;
 	int err = 0;
@@ -905,23 +928,30 @@ int arch_uprobe_exception_notify(struct notifier_block *self, unsigned long val,
 
 	/* We are only interested in userspace traps */
 	if (regs && !user_mode(regs))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NOTIFY_DONE;
+}
 
 	switch (val) {
 	case DIE_INT3:
 		if (uprobe_pre_sstep_notifier(regs))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			ret = NOTIFY_STOP;
+}
 
 		break;
 
 	case DIE_DEBUG:
 		if (uprobe_post_sstep_notifier(regs))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			ret = NOTIFY_STOP;
+}
 
 	default:
 		break;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return ret;
 }
 
@@ -932,6 +962,7 @@ int arch_uprobe_exception_notify(struct notifier_block *self, unsigned long val,
  */
 void arch_uprobe_abort_xol(struct arch_uprobe *auprobe, struct pt_regs *regs)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct uprobe_task *utask = current->utask;
 
 	if (auprobe->ops->abort)
@@ -946,6 +977,7 @@ void arch_uprobe_abort_xol(struct arch_uprobe *auprobe, struct pt_regs *regs)
 
 static bool __skip_sstep(struct arch_uprobe *auprobe, struct pt_regs *regs)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (auprobe->ops->emulate)
 		return auprobe->ops->emulate(auprobe, regs);
 	return false;
@@ -953,6 +985,7 @@ static bool __skip_sstep(struct arch_uprobe *auprobe, struct pt_regs *regs)
 
 bool arch_uprobe_skip_sstep(struct arch_uprobe *auprobe, struct pt_regs *regs)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	bool ret = __skip_sstep(auprobe, regs);
 	if (ret && (regs->flags & X86_EFLAGS_TF))
 		send_sig(SIGTRAP, current, 0);
@@ -962,6 +995,7 @@ bool arch_uprobe_skip_sstep(struct arch_uprobe *auprobe, struct pt_regs *regs)
 unsigned long
 arch_uretprobe_hijack_return_addr(unsigned long trampoline_vaddr, struct pt_regs *regs)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	int rasize = sizeof_long(), nleft;
 	unsigned long orig_ret_vaddr = 0; /* clear high bits for 32-bit apps */
 
@@ -989,6 +1023,7 @@ arch_uretprobe_hijack_return_addr(unsigned long trampoline_vaddr, struct pt_regs
 bool arch_uretprobe_is_alive(struct return_instance *ret, enum rp_check ctx,
 				struct pt_regs *regs)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (ctx == RP_CHECK_CALL) /* sp was just decremented by "call" insn */
 		return regs->sp < ret->stack;
 	else
diff --git a/arch/x86/kernel/vsmp_64.c b/arch/x86/kernel/vsmp_64.c
index b034b1b..26bdc79 100644
--- a/arch/x86/kernel/vsmp_64.c
+++ b/arch/x86/kernel/vsmp_64.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * vSMPowered(tm) systems specific initialization
  * Copyright (C) 2005 ScaleMP Inc.
@@ -144,7 +146,9 @@ static void __init detect_vsmp_box(void)
 	is_vsmp = 0;
 
 	if (!early_pci_allowed())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	/* Check if we are running on a ScaleMP vSMPowered box */
 	if (read_pci_config(0, 0x1f, 0, PCI_VENDOR_ID) ==
@@ -155,8 +159,11 @@ static void __init detect_vsmp_box(void)
 static int is_vsmp_box(void)
 {
 	if (is_vsmp != -1)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return is_vsmp;
+}
 	else {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		WARN_ON_ONCE(1);
 		return 0;
 	}
@@ -184,7 +191,9 @@ static void __init vsmp_cap_cpus(void)
 	 * setup_max_cpus
 	 */
 	if (setup_max_cpus != NR_CPUS)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	/* Read the vSMP Foundation topology register */
 	cfg = read_pci_config(0, 0x1f, 0, PCI_BASE_ADDRESS_0);
@@ -208,6 +217,7 @@ static void __init vsmp_cap_cpus(void)
 
 static int apicid_phys_pkg_id(int initial_apic_id, int index_msb)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return hard_smp_processor_id() >> index_msb;
 }
 
@@ -218,6 +228,7 @@ static int apicid_phys_pkg_id(int initial_apic_id, int index_msb)
 static void fill_vector_allocation_domain(int cpu, struct cpumask *retmask,
 					  const struct cpumask *mask)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	cpumask_setall(retmask);
 }
 
@@ -234,8 +245,11 @@ void __init vsmp_init(void)
 {
 	detect_vsmp_box();
 	if (!is_vsmp_box())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	x86_platform.apic_post_init = vsmp_apic_post_init;
 
 	vsmp_cap_cpus();
diff --git a/arch/x86/kernel/x86_init.c b/arch/x86/kernel/x86_init.c
index 5b2d10c..d3a77c5 100644
--- a/arch/x86/kernel/x86_init.c
+++ b/arch/x86/kernel/x86_init.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * Copyright (C) 2009 Thomas Gleixner <tglx@linutronix.de>
  *
@@ -28,7 +30,8 @@ void x86_init_noop(void) { }
 void __init x86_init_uint_noop(unsigned int unused) { }
 int __init iommu_init_noop(void) { return 0; }
 void iommu_shutdown_noop(void) { }
-bool __init bool_x86_init_noop(void) { return false; }
+bool __init bool_x86_init_noop(void) { if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
+ return false; }
 void x86_op_int_noop(int cpu) { }
 
 /*
@@ -130,16 +133,19 @@ int arch_setup_msi_irqs(struct pci_dev *dev, int nvec, int type)
 
 void arch_teardown_msi_irqs(struct pci_dev *dev)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	x86_msi.teardown_msi_irqs(dev);
 }
 
 void arch_teardown_msi_irq(unsigned int irq)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	x86_msi.teardown_msi_irq(irq);
 }
 
 void arch_restore_msi_irqs(struct pci_dev *dev)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	x86_msi.restore_msi_irqs(dev);
 }
 #endif
diff --git a/arch/x86/lib/cmdline.c b/arch/x86/lib/cmdline.c
index 3261abb..e49816d 100644
--- a/arch/x86/lib/cmdline.c
+++ b/arch/x86/lib/cmdline.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * This file is part of the Linux kernel, and is made available under
  * the terms of the GNU General Public License version 2.
@@ -11,6 +13,7 @@
 
 static inline int myisspace(u8 c)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return c <= ' ';	/* Close enough approximation */
 }
 
@@ -39,7 +42,9 @@ __cmdline_find_option_bool(const char *cmdline, int max_cmdline_size,
 	} state = st_wordstart;
 
 	if (!cmdline)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -1;      /* No command line */
+}
 
 	/*
 	 * This 'pos' check ensures we do not overrun
@@ -52,10 +57,13 @@ __cmdline_find_option_bool(const char *cmdline, int max_cmdline_size,
 		switch (state) {
 		case st_wordstart:
 			if (!c)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				return 0;
+}
 			else if (myisspace(c))
 				break;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			state = st_wordcmp;
 			opptr = option;
 			wstart = pos;
@@ -70,7 +78,9 @@ __cmdline_find_option_bool(const char *cmdline, int max_cmdline_size,
 				 * we matched!
 				 */
 				if (!c || myisspace(c))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 					return wstart;
+}
 				/*
 				 * We hit the end of the option, but _not_
 				 * the end of a word on the cmdline.  Not
@@ -89,18 +99,24 @@ __cmdline_find_option_bool(const char *cmdline, int max_cmdline_size,
 				 */
 				break;
 			}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			state = st_wordskip;
 			/* fall through */
 
 		case st_wordskip:
 			if (!c)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				return 0;
+}
 			else if (myisspace(c))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				state = st_wordstart;
+}
 			break;
 		}
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;	/* Buffer overrun */
 }
 
@@ -134,7 +150,9 @@ __cmdline_find_option(const char *cmdline, int max_cmdline_size,
 	} state = st_wordstart;
 
 	if (!cmdline)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -1;      /* No command line */
+}
 
 	/*
 	 * This 'pos' check ensures we do not overrun
@@ -150,6 +168,7 @@ __cmdline_find_option(const char *cmdline, int max_cmdline_size,
 			if (myisspace(c))
 				break;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			state = st_wordcmp;
 			opptr = option;
 			/* fall through */
@@ -172,16 +191,20 @@ __cmdline_find_option(const char *cmdline, int max_cmdline_size,
 				 */
 				break;
 			}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			state = st_wordskip;
 			/* fall through */
 
 		case st_wordskip:
 			if (myisspace(c))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				state = st_wordstart;
+}
 			break;
 
 		case st_bufcpy:
 			if (myisspace(c)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				state = st_wordstart;
 			} else {
 				/*
@@ -190,7 +213,9 @@ __cmdline_find_option(const char *cmdline, int max_cmdline_size,
 				 * NULL terminator.
 				 */
 				if (++len < bufsize)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 					*bufptr++ = c;
+}
 			}
 			break;
 		}
@@ -199,6 +224,7 @@ __cmdline_find_option(const char *cmdline, int max_cmdline_size,
 	if (bufsize)
 		*bufptr = '\0';
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return len;
 }
 
diff --git a/arch/x86/lib/cpu.c b/arch/x86/lib/cpu.c
index 2dd1fe13..b83795f 100644
--- a/arch/x86/lib/cpu.c
+++ b/arch/x86/lib/cpu.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 #include <linux/types.h>
 #include <linux/export.h>
 
@@ -8,7 +10,9 @@ unsigned int x86_family(unsigned int sig)
 	x86 = (sig >> 8) & 0xf;
 
 	if (x86 == 0xf)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		x86 += (sig >> 20) & 0xff;
+}
 
 	return x86;
 }
diff --git a/arch/x86/lib/csum-partial_64.c b/arch/x86/lib/csum-partial_64.c
index 9baca3e..4570226 100644
--- a/arch/x86/lib/csum-partial_64.c
+++ b/arch/x86/lib/csum-partial_64.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 /*
  * arch/x86_64/lib/csum-partial.c
@@ -38,9 +40,12 @@ static unsigned do_csum(const unsigned char *buff, unsigned len)
 	unsigned long result = 0;
 
 	if (unlikely(len == 0))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return result; 
 	odd = 1 & (unsigned long) buff;
+}
 	if (unlikely(odd)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		result = *buff << 8;
 		len--;
 		buff++;
@@ -113,6 +118,7 @@ static unsigned do_csum(const unsigned char *buff, unsigned len)
 		result += *buff;
 	result = add32_with_carry(result>>32, result & 0xffffffff); 
 	if (unlikely(odd)) { 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		result = from32to16(result);
 		result = ((result >> 8) & 0xff) | ((result & 0xff) << 8);
 	}
@@ -144,6 +150,7 @@ EXPORT_SYMBOL(csum_partial);
  */
 __sum16 ip_compute_csum(const void *buff, int len)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return csum_fold(csum_partial(buff,len,0));
 }
 EXPORT_SYMBOL(ip_compute_csum);
diff --git a/arch/x86/lib/csum-wrappers_64.c b/arch/x86/lib/csum-wrappers_64.c
index 8bd5358..84a4388 100644
--- a/arch/x86/lib/csum-wrappers_64.c
+++ b/arch/x86/lib/csum-wrappers_64.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * Copyright 2002, 2003 Andi Kleen, SuSE Labs.
  * Subject to the GNU Public License v.2
@@ -39,12 +41,15 @@ csum_partial_copy_from_user(const void __user *src, void *dst,
 	 * addresses slowly too.
 	 */
 	if (unlikely((unsigned long)src & 6)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		while (((unsigned long)src & 6) && len >= 2) {
 			__u16 val16;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			if (__get_user(val16, (const __u16 __user *)src))
 				goto out_err;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			*(__u16 *)dst = val16;
 			isum = (__force __wsum)add32_with_carry(
 					(__force unsigned)isum, val16);
@@ -53,6 +58,7 @@ csum_partial_copy_from_user(const void __user *src, void *dst,
 			len -= 2;
 		}
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	stac();
 	isum = csum_partial_copy_generic((__force const void *)src,
 				dst, len, isum, errp, NULL);
@@ -60,6 +66,7 @@ csum_partial_copy_from_user(const void __user *src, void *dst,
 	if (unlikely(*errp))
 		goto out_err;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return isum;
 
 out_err:
@@ -87,6 +94,7 @@ csum_partial_copy_to_user(const void *src, void __user *dst,
 {
 	__wsum ret;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	might_sleep();
 
 	if (unlikely(!access_ok(VERIFY_WRITE, dst, len))) {
diff --git a/arch/x86/lib/delay.c b/arch/x86/lib/delay.c
index 4846eff..a31ef2be 100644
--- a/arch/x86/lib/delay.c
+++ b/arch/x86/lib/delay.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 /*
  *	Precise Delay Loops for i386
@@ -58,6 +60,7 @@ static void delay_tsc(unsigned long __loops)
 	cpu = smp_processor_id();
 	bclock = rdtsc_ordered();
 	for (;;) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		now = rdtsc_ordered();
 		if ((now - bclock) >= loops)
 			break;
@@ -77,7 +80,9 @@ static void delay_tsc(unsigned long __loops)
 		 * counter for this CPU.
 		 */
 		if (unlikely(cpu != smp_processor_id())) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			loops -= (now - bclock);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			cpu = smp_processor_id();
 			bclock = rdtsc_ordered();
 		}
@@ -99,7 +104,9 @@ static void delay_mwaitx(unsigned long __loops)
 	 * is a store on the memory monitored by MONITORX.
 	 */
 	if (loops == 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	start = rdtsc_ordered();
 
@@ -144,11 +151,13 @@ void use_tsc_delay(void)
 
 void use_mwaitx_delay(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	delay_fn = delay_mwaitx;
 }
 
 int read_current_timer(unsigned long *timer_val)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (delay_fn == delay_tsc) {
 		*timer_val = rdtsc();
 		return 0;
@@ -184,6 +193,7 @@ EXPORT_SYMBOL(__udelay);
 
 void __ndelay(unsigned long nsecs)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	__const_udelay(nsecs * 0x00005); /* 2**32 / 1000000000 (rounded up) */
 }
 EXPORT_SYMBOL(__ndelay);
diff --git a/arch/x86/lib/msr.c b/arch/x86/lib/msr.c
index 3bd905e..0c92385 100644
--- a/arch/x86/lib/msr.c
+++ b/arch/x86/lib/msr.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 #include <linux/export.h>
 #include <linux/percpu.h>
@@ -12,6 +14,7 @@ struct msr *msrs_alloc(void)
 
 	msrs = alloc_percpu(struct msr);
 	if (!msrs) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_warn("%s: error allocating msrs\n", __func__);
 		return NULL;
 	}
@@ -22,6 +25,7 @@ EXPORT_SYMBOL(msrs_alloc);
 
 void msrs_free(struct msr *msrs)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	free_percpu(msrs);
 }
 EXPORT_SYMBOL(msrs_free);
@@ -65,11 +69,15 @@ static inline int __flip_bit(u32 msr, u8 bit, bool set)
 	int err = -EINVAL;
 
 	if (bit > 63)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return err;
+}
 
 	err = msr_read(msr, &m);
 	if (err)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return err;
+}
 
 	m1 = m;
 	if (set)
@@ -78,11 +86,15 @@ static inline int __flip_bit(u32 msr, u8 bit, bool set)
 		m1.q &= ~BIT_64(bit);
 
 	if (m1.q == m.q)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	err = msr_write(msr, &m1);
 	if (err)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return err;
+}
 
 	return 1;
 }
@@ -110,12 +122,14 @@ int msr_set_bit(u32 msr, u8 bit)
  */
 int msr_clear_bit(u32 msr, u8 bit)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return __flip_bit(msr, bit, false);
 }
 
 #ifdef CONFIG_TRACEPOINTS
 void do_trace_write_msr(unsigned int msr, u64 val, int failed)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	trace_write_msr(msr, val, failed);
 }
 EXPORT_SYMBOL(do_trace_write_msr);
@@ -123,6 +137,7 @@ EXPORT_TRACEPOINT_SYMBOL(write_msr);
 
 void do_trace_read_msr(unsigned int msr, u64 val, int failed)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	trace_read_msr(msr, val, failed);
 }
 EXPORT_SYMBOL(do_trace_read_msr);
@@ -130,6 +145,7 @@ EXPORT_TRACEPOINT_SYMBOL(read_msr);
 
 void do_trace_rdpmc(unsigned counter, u64 val, int failed)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	trace_rdpmc(counter, val, failed);
 }
 EXPORT_SYMBOL(do_trace_rdpmc);
diff --git a/arch/x86/lib/usercopy_64.c b/arch/x86/lib/usercopy_64.c
index 75d3776..5014f42 100644
--- a/arch/x86/lib/usercopy_64.c
+++ b/arch/x86/lib/usercopy_64.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /* 
  * User address space access functions.
  *
@@ -51,6 +53,7 @@ unsigned long clear_user(void __user *to, unsigned long n)
 {
 	if (access_ok(VERIFY_WRITE, to, n))
 		return __clear_user(to, n);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return n;
 }
 EXPORT_SYMBOL(clear_user);
@@ -63,6 +66,7 @@ EXPORT_SYMBOL(clear_user);
 __visible unsigned long
 copy_user_handle_tail(char *to, char *from, unsigned len)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (; len; --len, to++) {
 		char c;
 
@@ -99,6 +103,7 @@ static void clean_cache_range(void *addr, size_t size)
 
 void arch_wb_cache_pmem(void *addr, size_t size)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	clean_cache_range(addr, size);
 }
 EXPORT_SYMBOL_GPL(arch_wb_cache_pmem);
@@ -117,6 +122,7 @@ long __copy_user_flushcache(void *dst, const void __user *src, unsigned size)
 	 *   - Require 4-byte alignment when size is 4 bytes.
 	 */
 	if (size < 8) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (!IS_ALIGNED(dest, 4) || size != 4)
 			clean_cache_range(dst, 1);
 	} else {
@@ -140,6 +146,7 @@ void memcpy_flushcache(void *_dst, const void *_src, size_t size)
 
 	/* cache copy and flush to align dest */
 	if (!IS_ALIGNED(dest, 8)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		unsigned len = min_t(unsigned, size, ALIGN(dest, 8) - dest);
 
 		memcpy((void *) dest, (void *) source, len);
@@ -201,6 +208,7 @@ EXPORT_SYMBOL_GPL(memcpy_flushcache);
 void memcpy_page_flushcache(char *to, struct page *page, size_t offset,
 		size_t len)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	char *from = kmap_atomic(page);
 
 	memcpy_flushcache(to, from + offset, len);
diff --git a/arch/x86/mm/cpu_entry_area.c b/arch/x86/mm/cpu_entry_area.c
index b9283cc..f9538e6 100644
--- a/arch/x86/mm/cpu_entry_area.c
+++ b/arch/x86/mm/cpu_entry_area.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 
 #include <linux/spinlock.h>
@@ -18,6 +20,7 @@ static DEFINE_PER_CPU_PAGE_ALIGNED(char, exception_stacks
 struct cpu_entry_area *get_cpu_entry_area(int cpu)
 {
 	unsigned long va = CPU_ENTRY_AREA_PER_CPU + cpu * CPU_ENTRY_AREA_SIZE;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	BUILD_BUG_ON(sizeof(struct cpu_entry_area) % PAGE_SIZE != 0);
 
 	return (struct cpu_entry_area *) va;
@@ -45,11 +48,16 @@ static void percpu_setup_debug_store(int cpu)
 	void *cea;
 
 	if (boot_cpu_data.x86_vendor != X86_VENDOR_INTEL)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	cea = &get_cpu_entry_area(cpu)->cpu_debug_store;
 	npages = sizeof(struct debug_store) / PAGE_SIZE;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	BUILD_BUG_ON(sizeof(struct debug_store) % PAGE_SIZE != 0);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	cea_map_percpu_pages(cea, &per_cpu(cpu_debug_store, cpu), npages,
 			     PAGE_KERNEL);
 
@@ -59,8 +67,11 @@ static void percpu_setup_debug_store(int cpu)
 	 * memory like debug store buffers.
 	 */
 	npages = sizeof(struct debug_store_buffers) / PAGE_SIZE;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (; npages; npages--, cea += PAGE_SIZE)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		cea_set_pte(cea, 0, PAGE_NONE);
+}
 #endif
 }
 
@@ -115,6 +126,7 @@ static void __init setup_cpu_entry_area(int cpu)
 	 */
 	BUILD_BUG_ON((offsetof(struct tss_struct, x86_tss) ^
 		      offsetofend(struct tss_struct, x86_tss)) & PAGE_MASK);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	BUILD_BUG_ON(sizeof(struct tss_struct) % PAGE_SIZE != 0);
 	cea_map_percpu_pages(&get_cpu_entry_area(cpu)->tss,
 			     &per_cpu(cpu_tss_rw, cpu),
@@ -126,6 +138,7 @@ static void __init setup_cpu_entry_area(int cpu)
 
 #ifdef CONFIG_X86_64
 	BUILD_BUG_ON(sizeof(exception_stacks) % PAGE_SIZE != 0);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	BUILD_BUG_ON(sizeof(exception_stacks) !=
 		     sizeof(((struct cpu_entry_area *)0)->exception_stacks));
 	cea_map_percpu_pages(&get_cpu_entry_area(cpu)->exception_stacks,
diff --git a/arch/x86/mm/extable.c b/arch/x86/mm/extable.c
index 9fe656c..d43ea20 100644
--- a/arch/x86/mm/extable.c
+++ b/arch/x86/mm/extable.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 #include <linux/extable.h>
 #include <linux/uaccess.h>
 #include <linux/sched/debug.h>
@@ -32,6 +34,7 @@ EXPORT_SYMBOL(ex_handler_default);
 bool ex_handler_fault(const struct exception_table_entry *fixup,
 		     struct pt_regs *regs, int trapnr)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	regs->ip = ex_fixup_addr(fixup);
 	regs->ax = trapnr;
 	return true;
@@ -98,6 +101,7 @@ EXPORT_SYMBOL(ex_handler_refcount);
 bool ex_handler_fprestore(const struct exception_table_entry *fixup,
 			  struct pt_regs *regs, int trapnr)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	regs->ip = ex_fixup_addr(fixup);
 
 	WARN_ONCE(1, "Bad FPU state detected at %pB, reinitializing FPU registers.",
@@ -121,6 +125,7 @@ EXPORT_SYMBOL(ex_handler_ext);
 bool ex_handler_rdmsr_unsafe(const struct exception_table_entry *fixup,
 			     struct pt_regs *regs, int trapnr)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (pr_warn_once("unchecked MSR access error: RDMSR from 0x%x at rIP: 0x%lx (%pF)\n",
 			 (unsigned int)regs->cx, regs->ip, (void *)regs->ip))
 		show_stack_regs(regs);
@@ -136,6 +141,7 @@ EXPORT_SYMBOL(ex_handler_rdmsr_unsafe);
 bool ex_handler_wrmsr_unsafe(const struct exception_table_entry *fixup,
 			     struct pt_regs *regs, int trapnr)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (pr_warn_once("unchecked MSR access error: WRMSR to 0x%x (tried to write 0x%08x%08x) at rIP: 0x%lx (%pF)\n",
 			 (unsigned int)regs->cx, (unsigned int)regs->dx,
 			 (unsigned int)regs->ax,  regs->ip, (void *)regs->ip))
@@ -150,6 +156,7 @@ EXPORT_SYMBOL(ex_handler_wrmsr_unsafe);
 bool ex_handler_clear_fs(const struct exception_table_entry *fixup,
 			 struct pt_regs *regs, int trapnr)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (static_cpu_has(X86_BUG_NULL_SEG))
 		asm volatile ("mov %0, %%fs" : : "rm" (__USER_DS));
 	asm volatile ("mov %0, %%fs" : : "rm" (0));
@@ -164,7 +171,9 @@ bool ex_has_fault_handler(unsigned long ip)
 
 	e = search_exception_tables(ip);
 	if (!e)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return false;
+}
 	handler = ex_fixup_handler(e);
 
 	return handler == ex_handler_fault;
@@ -191,8 +200,11 @@ int fixup_exception(struct pt_regs *regs, int trapnr)
 
 	e = search_exception_tables(regs->ip);
 	if (!e)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	handler = ex_fixup_handler(e);
 	return handler(e, regs, trapnr);
 }
diff --git a/arch/x86/mm/fault.c b/arch/x86/mm/fault.c
index 9150fe2..96a12c8 100644
--- a/arch/x86/mm/fault.c
+++ b/arch/x86/mm/fault.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 /*
  *  Copyright (C) 1995  Linus Torvalds
@@ -36,8 +38,13 @@ static nokprobe_inline int
 kmmio_fault(struct pt_regs *regs, unsigned long addr)
 {
 	if (unlikely(is_kmmio_active()))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (kmmio_handler(regs, addr) == 1)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -1;
+}
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
@@ -49,10 +56,13 @@ static nokprobe_inline int kprobes_fault(struct pt_regs *regs)
 	if (kprobes_built_in() && !user_mode(regs)) {
 		preempt_disable();
 		if (kprobe_running() && kprobe_fault_handler(regs, 14))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			ret = 1;
+}
 		preempt_enable();
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return ret;
 }
 
@@ -108,8 +118,11 @@ check_prefetch_opcode(struct pt_regs *regs, unsigned char *instr,
 	case 0x00:
 		/* Prefetch instruction is 0x0F0D or 0x0F18 */
 		if (probe_kernel_address(instr, opcode))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return 0;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		*prefetch = (instr_lo == 0xF) &&
 			(opcode == 0x0D || opcode == 0x18);
 		return 0;
@@ -130,13 +143,17 @@ is_prefetch(struct pt_regs *regs, unsigned long error_code, unsigned long addr)
 	 * do not ignore the fault:
 	 */
 	if (error_code & X86_PF_INSTR)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	instr = (void *)convert_ip_to_linear(current, regs);
 	max_instr = instr + 15;
 
 	if (user_mode(regs) && instr >= (unsigned char *)TASK_SIZE_MAX)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	while (instr < max_instr) {
 		unsigned char opcode;
@@ -177,11 +194,15 @@ static void fill_sig_info_pkey(int si_signo, int si_code, siginfo_t *info,
 {
 	/* This is effectively an #ifdef */
 	if (!boot_cpu_has(X86_FEATURE_OSPKE))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	/* Fault not from Protection Keys: nothing to do */
 	if ((si_code != SEGV_PKUERR) || (si_signo != SIGSEGV))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 	/*
 	 * force_sig_info_fault() is called from a number of
 	 * contexts, some of which have a VMA and some of which
@@ -190,6 +211,7 @@ static void fill_sig_info_pkey(int si_signo, int si_code, siginfo_t *info,
 	 * valid VMA.
 	 */
 	if (!pkey) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		WARN_ONCE(1, "PKU fault with no VMA passed in");
 		info->si_pkey = 0;
 		return;
@@ -214,9 +236,11 @@ force_sig_info_fault(int si_signo, int si_code, unsigned long address,
 	info.si_code	= si_code;
 	info.si_addr	= (void __user *)address;
 	if (fault & VM_FAULT_HWPOISON_LARGE)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		lsb = hstate_index_to_shift(VM_FAULT_GET_HINDEX(fault)); 
 	if (fault & VM_FAULT_HWPOISON)
 		lsb = PAGE_SHIFT;
+}
 	info.si_addr_lsb = lsb;
 
 	fill_sig_info_pkey(si_signo, si_code, &info, pkey);
@@ -425,7 +449,9 @@ static noinline int vmalloc_fault(unsigned long address)
 
 	/* Make sure we are in vmalloc area: */
 	if (!(address >= VMALLOC_START && address < VMALLOC_END))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -1;
+}
 
 	WARN_ON_ONCE(in_nmi());
 
@@ -437,10 +463,15 @@ static noinline int vmalloc_fault(unsigned long address)
 	pgd = (pgd_t *)__va(read_cr3_pa()) + pgd_index(address);
 	pgd_ref = pgd_offset_k(address);
 	if (pgd_none(*pgd_ref))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -1;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (pgd_none(*pgd)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		set_pgd(pgd, *pgd_ref);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		arch_flush_lazy_mmu_mode();
 	} else if (CONFIG_PGTABLE_LEVELS > 4) {
 		/*
@@ -457,10 +488,14 @@ static noinline int vmalloc_fault(unsigned long address)
 	p4d = p4d_offset(pgd, address);
 	p4d_ref = p4d_offset(pgd_ref, address);
 	if (p4d_none(*p4d_ref))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -1;
+}
 
 	if (p4d_none(*p4d)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		set_p4d(p4d, *p4d_ref);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		arch_flush_lazy_mmu_mode();
 	} else {
 		BUG_ON(p4d_pfn(*p4d) != p4d_pfn(*p4d_ref));
@@ -474,29 +509,44 @@ static noinline int vmalloc_fault(unsigned long address)
 	pud = pud_offset(p4d, address);
 	pud_ref = pud_offset(p4d_ref, address);
 	if (pud_none(*pud_ref))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -1;
+}
 
 	if (pud_none(*pud) || pud_pfn(*pud) != pud_pfn(*pud_ref))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		BUG();
+}
 
 	if (pud_huge(*pud))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	pmd = pmd_offset(pud, address);
 	pmd_ref = pmd_offset(pud_ref, address);
 	if (pmd_none(*pmd_ref))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -1;
+}
 
 	if (pmd_none(*pmd) || pmd_pfn(*pmd) != pmd_pfn(*pmd_ref))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		BUG();
+}
 
 	if (pmd_huge(*pmd))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	pte_ref = pte_offset_kernel(pmd_ref, address);
 	if (!pte_present(*pte_ref))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -1;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pte = pte_offset_kernel(pmd, address);
 
 	/*
@@ -505,8 +555,11 @@ static noinline int vmalloc_fault(unsigned long address)
 	 * that:
 	 */
 	if (!pte_present(*pte) || pte_pfn(*pte) != pte_pfn(*pte_ref))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		BUG();
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 NOKPROBE_SYMBOL(vmalloc_fault);
@@ -538,6 +591,7 @@ static int bad_address(void *p)
 
 static void dump_pagetable(unsigned long address)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pgd_t *base = __va(read_cr3_pa());
 	pgd_t *pgd = base + pgd_index(address);
 	p4d_t *p4d;
@@ -641,7 +695,9 @@ static int is_errata100(struct pt_regs *regs, unsigned long address)
 {
 #ifdef CONFIG_X86_64
 	if ((regs->cs == __USER32_CS || (regs->cs & (1<<2))) && (address >> 32))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 1;
+}
 #endif
 	return 0;
 }
@@ -675,6 +731,7 @@ static void
 show_fault_oops(struct pt_regs *regs, unsigned long error_code,
 		unsigned long address)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!oops_may_print())
 		return;
 
@@ -729,7 +786,9 @@ pgtable_bad(struct pt_regs *regs, unsigned long error_code,
 	tsk->thread.error_code	= error_code;
 
 	if (__die("Bad pagetable", regs, error_code))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		sig = 0;
+}
 
 	oops_end(flags, regs, sig);
 }
@@ -738,6 +797,7 @@ static noinline void
 no_context(struct pt_regs *regs, unsigned long error_code,
 	   unsigned long address, int signal, int si_code)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct task_struct *tsk = current;
 	unsigned long flags;
 	int sig;
@@ -750,7 +810,9 @@ no_context(struct pt_regs *regs, unsigned long error_code,
 		 * task context.
 		 */
 		if (in_interrupt())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return;
+}
 
 		/*
 		 * Per the above we're !in_interrupt(), aka. task context.
@@ -759,6 +821,7 @@ no_context(struct pt_regs *regs, unsigned long error_code,
 		 * faulting through the emulate_vsyscall() logic.
 		 */
 		if (current->thread.sig_on_uaccess_err && signal) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			tsk->thread.trap_nr = X86_TRAP_PF;
 			tsk->thread.error_code = error_code | X86_PF_USER;
 			tsk->thread.cr2 = address;
@@ -783,6 +846,7 @@ no_context(struct pt_regs *regs, unsigned long error_code,
 	if (is_vmalloc_addr((void *)address) &&
 	    (((unsigned long)tsk->stack - 1 - address < PAGE_SIZE) ||
 	     address - ((unsigned long)tsk->stack + THREAD_SIZE) < PAGE_SIZE)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		unsigned long stack = this_cpu_read(orig_ist.ist[DOUBLEFAULT_STACK]) - sizeof(void *);
 		/*
 		 * We're likely to be running with very little stack space
@@ -801,6 +865,7 @@ no_context(struct pt_regs *regs, unsigned long error_code,
 			      : "D" ("kernel stack overflow (page fault)"),
 				"S" (regs), "d" (address),
 				[stack] "rm" (stack));
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		unreachable();
 	}
 #endif
@@ -817,10 +882,15 @@ no_context(struct pt_regs *regs, unsigned long error_code,
 	 *   Hall of shame of CPU/BIOS bugs.
 	 */
 	if (is_prefetch(regs, error_code, address))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (is_errata93(regs, address))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	/*
 	 * Oops. The kernel tried to access some bad page. We'll have to
@@ -831,15 +901,20 @@ no_context(struct pt_regs *regs, unsigned long error_code,
 	show_fault_oops(regs, error_code, address);
 
 	if (task_stack_end_corrupted(tsk))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		printk(KERN_EMERG "Thread overran stack, or stack corrupted\n");
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	tsk->thread.cr2		= address;
 	tsk->thread.trap_nr	= X86_TRAP_PF;
 	tsk->thread.error_code	= error_code;
 
 	sig = SIGKILL;
 	if (__die("Oops", regs, error_code))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		sig = 0;
+}
 
 	/* Executive summary in case the body of the oops scrolled away */
 	printk(KERN_DEFAULT "CR2: %016lx\n", address);
@@ -856,10 +931,15 @@ show_signal_msg(struct pt_regs *regs, unsigned long error_code,
 		unsigned long address, struct task_struct *tsk)
 {
 	if (!unhandled_signal(tsk, SIGSEGV))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!printk_ratelimit())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	printk("%s%s[%d]: segfault at %lx ip %p sp %p error %lx",
 		task_pid_nr(tsk) > 1 ? KERN_INFO : KERN_EMERG,
@@ -875,6 +955,7 @@ static void
 __bad_area_nosemaphore(struct pt_regs *regs, unsigned long error_code,
 		       unsigned long address, u32 *pkey, int si_code)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct task_struct *tsk = current;
 
 	/* User mode accesses just cause a SIGSEGV */
@@ -889,10 +970,14 @@ __bad_area_nosemaphore(struct pt_regs *regs, unsigned long error_code,
 		 * from user space:
 		 */
 		if (is_prefetch(regs, error_code, address))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return;
+}
 
 		if (is_errata100(regs, address))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return;
+}
 
 #ifdef CONFIG_X86_64
 		/*
@@ -901,8 +986,11 @@ __bad_area_nosemaphore(struct pt_regs *regs, unsigned long error_code,
 		 */
 		if (unlikely((error_code & X86_PF_INSTR) &&
 			     ((address & ~0xfff) == VSYSCALL_ADDR))) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			if (emulate_vsyscall(regs, address))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				return;
+}
 		}
 #endif
 
@@ -912,7 +1000,9 @@ __bad_area_nosemaphore(struct pt_regs *regs, unsigned long error_code,
 		 * are always protection faults.
 		 */
 		if (address >= TASK_SIZE_MAX)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			error_code |= X86_PF_PROT;
+}
 
 		if (likely(show_unhandled_signals))
 			show_signal_msg(regs, error_code, address, tsk);
@@ -926,8 +1016,11 @@ __bad_area_nosemaphore(struct pt_regs *regs, unsigned long error_code,
 		return;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (is_f00f_bug(regs, address))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	no_context(regs, error_code, address, SIGSEGV, si_code);
 }
@@ -972,13 +1065,19 @@ static inline bool bad_area_access_from_pkeys(unsigned long error_code,
 	bool foreign = false;
 
 	if (!boot_cpu_has(X86_FEATURE_OSPKE))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return false;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (error_code & X86_PF_PK)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return true;
+}
 	/* this checks permission keys on the VMA: */
 	if (!arch_vma_access_permitted(vma, (error_code & X86_PF_WRITE),
 				       (error_code & X86_PF_INSTR), foreign))
 		return true;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return false;
 }
 
@@ -992,7 +1091,9 @@ bad_area_access_error(struct pt_regs *regs, unsigned long error_code,
 	 * if pkeys are compiled out.
 	 */
 	if (bad_area_access_from_pkeys(error_code, vma))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		__bad_area(regs, error_code, address, vma, SEGV_PKUERR);
+}
 	else
 		__bad_area(regs, error_code, address, vma, SEGV_ACCERR);
 }
@@ -1001,6 +1102,7 @@ static void
 do_sigbus(struct pt_regs *regs, unsigned long error_code, unsigned long address,
 	  u32 *pkey, unsigned int fault)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct task_struct *tsk = current;
 	int code = BUS_ADRERR;
 
@@ -1033,6 +1135,7 @@ static noinline void
 mm_fault_error(struct pt_regs *regs, unsigned long error_code,
 	       unsigned long address, u32 *pkey, unsigned int fault)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (fatal_signal_pending(current) && !(error_code & X86_PF_USER)) {
 		no_context(regs, error_code, address, 0, 0);
 		return;
@@ -1065,6 +1168,7 @@ mm_fault_error(struct pt_regs *regs, unsigned long error_code,
 
 static int spurious_fault_check(unsigned long error_code, pte_t *pte)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if ((error_code & X86_PF_WRITE) && !pte_write(*pte))
 		return 0;
 
@@ -1124,44 +1228,72 @@ spurious_fault(unsigned long error_code, unsigned long address)
 	    error_code != (X86_PF_INSTR | X86_PF_PROT))
 		return 0;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pgd = init_mm.pgd + pgd_index(address);
 	if (!pgd_present(*pgd))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	p4d = p4d_offset(pgd, address);
 	if (!p4d_present(*p4d))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (p4d_large(*p4d))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return spurious_fault_check(error_code, (pte_t *) p4d);
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pud = pud_offset(p4d, address);
 	if (!pud_present(*pud))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (pud_large(*pud))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return spurious_fault_check(error_code, (pte_t *) pud);
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pmd = pmd_offset(pud, address);
 	if (!pmd_present(*pmd))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (pmd_large(*pmd))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return spurious_fault_check(error_code, (pte_t *) pmd);
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pte = pte_offset_kernel(pmd, address);
 	if (!pte_present(*pte))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	ret = spurious_fault_check(error_code, pte);
 	if (!ret)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	/*
 	 * Make sure we have permissions in PMD.
 	 * If not, then there's a bug in the page tables:
 	 */
 	ret = spurious_fault_check(error_code, (pte_t *) pmd);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WARN_ONCE(!ret, "PMD has incorrect permission bits\n");
 
 	return ret;
@@ -1182,7 +1314,9 @@ access_error(unsigned long error_code, struct vm_area_struct *vma)
 	 * a follow-up action to resolve the fault, like a COW.
 	 */
 	if (error_code & X86_PF_PK)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 1;
+}
 
 	/*
 	 * Make sure to check the VMA so that we do not perform
@@ -1196,17 +1330,23 @@ access_error(unsigned long error_code, struct vm_area_struct *vma)
 	if (error_code & X86_PF_WRITE) {
 		/* write, present and write, not present: */
 		if (unlikely(!(vma->vm_flags & VM_WRITE)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return 1;
+}
 		return 0;
 	}
 
 	/* read, present: */
 	if (unlikely(error_code & X86_PF_PROT))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 1;
+}
 
 	/* read, not present: */
 	if (unlikely(!(vma->vm_flags & (VM_READ | VM_EXEC | VM_WRITE))))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 1;
+}
 
 	return 0;
 }
@@ -1218,18 +1358,30 @@ static int fault_in_kernel_space(unsigned long address)
 
 static inline bool smap_violation(int error_code, struct pt_regs *regs)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!IS_ENABLED(CONFIG_X86_SMAP))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return false;
+}
 
 	if (!static_cpu_has(X86_FEATURE_SMAP))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return false;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (error_code & X86_PF_USER)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return false;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!user_mode(regs) && (regs->flags & X86_EFLAGS_AC))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return false;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return true;
 }
 
@@ -1277,16 +1429,22 @@ __do_page_fault(struct pt_regs *regs, unsigned long error_code,
 	if (unlikely(fault_in_kernel_space(address))) {
 		if (!(error_code & (X86_PF_RSVD | X86_PF_USER | X86_PF_PROT))) {
 			if (vmalloc_fault(address) >= 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				return;
+}
 		}
 
 		/* Can handle a stale RO->RW TLB: */
 		if (spurious_fault(error_code, address))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return;
+}
 
 		/* kprobes don't want to hook the spurious faults: */
 		if (kprobes_fault(regs))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return;
+}
 		/*
 		 * Don't take the mm semaphore here. If we fixup a prefetch
 		 * fault we could otherwise deadlock:
@@ -1298,12 +1456,17 @@ __do_page_fault(struct pt_regs *regs, unsigned long error_code,
 
 	/* kprobes don't want to hook the spurious faults: */
 	if (unlikely(kprobes_fault(regs)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	if (unlikely(error_code & X86_PF_RSVD))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pgtable_bad(regs, error_code, address);
+}
 
 	if (unlikely(smap_violation(error_code, regs))) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		bad_area_nosemaphore(regs, error_code, address, NULL);
 		return;
 	}
@@ -1333,6 +1496,7 @@ __do_page_fault(struct pt_regs *regs, unsigned long error_code,
 			local_irq_enable();
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	perf_sw_event(PERF_COUNT_SW_PAGE_FAULTS, 1, regs, address);
 
 	if (error_code & X86_PF_WRITE)
@@ -1359,6 +1523,7 @@ __do_page_fault(struct pt_regs *regs, unsigned long error_code,
 	if (unlikely(!down_read_trylock(&mm->mmap_sem))) {
 		if (!(error_code & X86_PF_USER) &&
 		    !search_exception_tables(regs->ip)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			bad_area_nosemaphore(regs, error_code, address, NULL);
 			return;
 		}
@@ -1375,6 +1540,7 @@ __do_page_fault(struct pt_regs *regs, unsigned long error_code,
 
 	vma = find_vma(mm, address);
 	if (unlikely(!vma)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		bad_area(regs, error_code, address);
 		return;
 	}
@@ -1392,11 +1558,13 @@ __do_page_fault(struct pt_regs *regs, unsigned long error_code,
 		 * 32 pointers and then decrements %sp by 65535.)
 		 */
 		if (unlikely(address + 65536 + 32 * sizeof(unsigned long) < regs->sp)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			bad_area(regs, error_code, address);
 			return;
 		}
 	}
 	if (unlikely(expand_stack(vma, address))) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		bad_area(regs, error_code, address);
 		return;
 	}
@@ -1438,6 +1606,7 @@ __do_page_fault(struct pt_regs *regs, unsigned long error_code,
 	if (unlikely(fault & VM_FAULT_RETRY)) {
 		/* Retry at most once */
 		if (flags & FAULT_FLAG_ALLOW_RETRY) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			flags &= ~FAULT_FLAG_ALLOW_RETRY;
 			flags |= FAULT_FLAG_TRIED;
 			if (!fatal_signal_pending(tsk))
@@ -1446,7 +1615,9 @@ __do_page_fault(struct pt_regs *regs, unsigned long error_code,
 
 		/* User mode? Just return to handle the fatal exception */
 		if (flags & FAULT_FLAG_USER)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return;
+}
 
 		/* Not returning to user mode? Handle exceptions or die: */
 		no_context(regs, error_code, address, SIGBUS, BUS_ADRERR);
@@ -1455,6 +1626,7 @@ __do_page_fault(struct pt_regs *regs, unsigned long error_code,
 
 	up_read(&mm->mmap_sem);
 	if (unlikely(fault & VM_FAULT_ERROR)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		mm_fault_error(regs, error_code, address, &pkey, fault);
 		return;
 	}
@@ -1464,6 +1636,7 @@ __do_page_fault(struct pt_regs *regs, unsigned long error_code,
 	 * returned VM_FAULT_MAJOR, we account it as a major fault.
 	 */
 	if (major) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		tsk->maj_flt++;
 		perf_sw_event(PERF_COUNT_SW_PAGE_FAULTS_MAJ, 1, regs, address);
 	} else {
@@ -1471,6 +1644,7 @@ __do_page_fault(struct pt_regs *regs, unsigned long error_code,
 		perf_sw_event(PERF_COUNT_SW_PAGE_FAULTS_MIN, 1, regs, address);
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	check_v8086_mode(regs, address, tsk);
 }
 NOKPROBE_SYMBOL(__do_page_fault);
@@ -1479,6 +1653,7 @@ static nokprobe_inline void
 trace_page_fault_entries(unsigned long address, struct pt_regs *regs,
 			 unsigned long error_code)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (user_mode(regs))
 		trace_page_fault_user(address, regs, error_code);
 	else
@@ -1500,7 +1675,9 @@ do_page_fault(struct pt_regs *regs, unsigned long error_code)
 
 	prev_state = exception_enter();
 	if (trace_pagefault_enabled())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		trace_page_fault_entries(address, regs, error_code);
+}
 
 	__do_page_fault(regs, error_code, address);
 	exception_exit(prev_state);
diff --git a/arch/x86/mm/hugetlbpage.c b/arch/x86/mm/hugetlbpage.c
index 8ae0000..c54dfa0 100644
--- a/arch/x86/mm/hugetlbpage.c
+++ b/arch/x86/mm/hugetlbpage.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 /*
  * IA-32 Huge TLB Page Support for Kernel.
@@ -81,6 +83,7 @@ static unsigned long hugetlb_get_unmapped_area_bottomup(struct file *file,
 		unsigned long addr, unsigned long len,
 		unsigned long pgoff, unsigned long flags)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct hstate *h = hstate_file(file);
 	struct vm_unmapped_area_info info;
 
@@ -117,7 +120,9 @@ static unsigned long hugetlb_get_unmapped_area_topdown(struct file *file,
 	 * in the full address space.
 	 */
 	if (addr > DEFAULT_MAP_WINDOW && !in_compat_syscall())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		info.high_limit += TASK_SIZE_MAX - DEFAULT_MAP_WINDOW;
+}
 
 	info.align_mask = PAGE_MASK & ~huge_page_mask(h);
 	info.align_offset = 0;
@@ -130,9 +135,12 @@ static unsigned long hugetlb_get_unmapped_area_topdown(struct file *file,
 	 * allocations.
 	 */
 	if (addr & ~PAGE_MASK) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		VM_BUG_ON(addr != -ENOMEM);
 		info.flags = 0;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		info.low_limit = TASK_UNMAPPED_BASE;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		info.high_limit = TASK_SIZE_LOW;
 		addr = vm_unmapped_area(&info);
 	}
@@ -149,31 +157,46 @@ hugetlb_get_unmapped_area(struct file *file, unsigned long addr,
 	struct vm_area_struct *vma;
 
 	if (len & ~huge_page_mask(h))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	addr = mpx_unmapped_area_check(addr, len, flags);
 	if (IS_ERR_VALUE(addr))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return addr;
+}
 
 	if (len > TASK_SIZE)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 
 	if (flags & MAP_FIXED) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (prepare_hugepage_range(file, addr, len))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -EINVAL;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return addr;
 	}
 
 	if (addr) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		addr = ALIGN(addr, huge_page_size(h));
 		vma = find_vma(mm, addr);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (TASK_SIZE - len >= addr &&
 		    (!vma || addr + len <= vm_start_gap(vma)))
 			return addr;
 	}
 	if (mm->get_unmapped_area == arch_get_unmapped_area)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return hugetlb_get_unmapped_area_bottomup(file, addr, len,
 				pgoff, flags);
+}
 	else
 		return hugetlb_get_unmapped_area_topdown(file, addr, len,
 				pgoff, flags);
@@ -183,6 +206,7 @@ hugetlb_get_unmapped_area(struct file *file, unsigned long addr,
 #ifdef CONFIG_X86_64
 static __init int setup_hugepagesz(char *opt)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	unsigned long ps = memparse(opt, &opt);
 	if (ps == PMD_SIZE) {
 		hugetlb_add_hstate(PMD_SHIFT - PAGE_SHIFT);
diff --git a/arch/x86/mm/init.c b/arch/x86/mm/init.c
index 82f5252..adb1f09 100644
--- a/arch/x86/mm/init.c
+++ b/arch/x86/mm/init.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 #include <linux/gfp.h>
 #include <linux/initrd.h>
 #include <linux/ioport.h>
@@ -92,6 +94,7 @@ __ref void *alloc_low_pages(unsigned int num)
 	if (after_bootmem) {
 		unsigned int order;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		order = get_order((unsigned long)num << PAGE_SHIFT);
 		return (void *)__get_free_pages(GFP_ATOMIC | __GFP_ZERO, order);
 	}
@@ -99,15 +102,20 @@ __ref void *alloc_low_pages(unsigned int num)
 	if ((pgt_buf_end + num) > pgt_buf_top || !can_use_brk_pgt) {
 		unsigned long ret;
 		if (min_pfn_mapped >= max_pfn_mapped)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			panic("alloc_low_pages: ran out of memory");
+}
 		ret = memblock_find_in_range(min_pfn_mapped << PAGE_SHIFT,
 					max_pfn_mapped << PAGE_SHIFT,
 					PAGE_SIZE * num , PAGE_SIZE);
 		if (!ret)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			panic("alloc_low_pages: can not alloc memory");
+}
 		memblock_reserve(ret, PAGE_SIZE * num);
 		pfn = ret >> PAGE_SHIFT;
 	} else {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pfn = pgt_buf_end;
 		pgt_buf_end += num;
 		printk(KERN_DEBUG "BRK [%#010lx, %#010lx] PGTABLE\n",
@@ -192,6 +200,7 @@ static void __init probe_page_size_mask(void)
 
 	/* Enable 1 GB linear kernel mappings if available: */
 	if (direct_gbpages && boot_cpu_has(X86_FEATURE_GBPAGES)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		printk(KERN_INFO "Using GB pages for direct mapping\n");
 		page_size_mask |= 1 << PG_LEVEL_1G;
 	} else {
@@ -201,12 +210,18 @@ static void __init probe_page_size_mask(void)
 
 static void setup_pcid(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!IS_ENABLED(CONFIG_X86_64))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	if (!boot_cpu_has(X86_FEATURE_PCID))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (boot_cpu_has(X86_FEATURE_PGE)) {
 		/*
 		 * This can't be cr4_set_bits_and_update_boot() -- the
@@ -228,7 +243,9 @@ static void setup_pcid(void)
 		 * no INVPCID support at all.
 		 */
 		if (boot_cpu_has(X86_FEATURE_INVPCID))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			setup_force_cpu_cap(X86_FEATURE_INVPCID_SINGLE);
+}
 	} else {
 		/*
 		 * flush_tlb_all(), as currently implemented, won't work if
@@ -253,7 +270,9 @@ static int __meminit save_mr(struct map_range *mr, int nr_range,
 {
 	if (start_pfn < end_pfn) {
 		if (nr_range >= NR_RANGE_MR)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			panic("run out of range for init_memory_mapping\n");
+}
 		mr[nr_range].start = start_pfn<<PAGE_SHIFT;
 		mr[nr_range].end   = end_pfn<<PAGE_SHIFT;
 		mr[nr_range].page_size_mask = page_size_mask;
@@ -284,7 +303,9 @@ static void __ref adjust_range_page_size_mask(struct map_range *mr,
 #endif
 
 			if (memblock_is_region_memory(start, end - start))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				mr[i].page_size_mask |= 1<<PG_LEVEL_2M;
+}
 		}
 		if ((page_size_mask & (1<<PG_LEVEL_1G)) &&
 		    !(mr[i].page_size_mask & (1<<PG_LEVEL_1G))) {
@@ -292,7 +313,9 @@ static void __ref adjust_range_page_size_mask(struct map_range *mr,
 			unsigned long end = round_up(mr[i].end, PUD_SIZE);
 
 			if (memblock_is_region_memory(start, end - start))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				mr[i].page_size_mask |= 1<<PG_LEVEL_1G;
+}
 		}
 	}
 }
@@ -305,7 +328,9 @@ static const char *page_size_string(struct map_range *mr)
 	static const char str_4k[] = "4k";
 
 	if (mr->page_size_mask & (1<<PG_LEVEL_1G))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return str_1g;
+}
 	/*
 	 * 32-bit without PAE has a 4M large page size.
 	 * PG_LEVEL_2M is misnamed, but we can at least
@@ -349,7 +374,9 @@ static int __meminit split_mem_range(struct map_range *mr, int nr_range,
 	end_pfn = round_up(pfn, PFN_DOWN(PMD_SIZE));
 #endif
 	if (end_pfn > limit_pfn)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		end_pfn = limit_pfn;
+}
 	if (start_pfn < end_pfn) {
 		nr_range = save_mr(mr, nr_range, start_pfn, end_pfn, 0);
 		pfn = end_pfn;
@@ -362,7 +389,9 @@ static int __meminit split_mem_range(struct map_range *mr, int nr_range,
 #else /* CONFIG_X86_64 */
 	end_pfn = round_up(pfn, PFN_DOWN(PUD_SIZE));
 	if (end_pfn > round_down(limit_pfn, PFN_DOWN(PMD_SIZE)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		end_pfn = round_down(limit_pfn, PFN_DOWN(PMD_SIZE));
+}
 #endif
 
 	if (start_pfn < end_pfn) {
@@ -414,10 +443,13 @@ static int __meminit split_mem_range(struct map_range *mr, int nr_range,
 		nr_range--;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (i = 0; i < nr_range; i++)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_debug(" [mem %#010lx-%#010lx] page %s\n",
 				mr[i].start, mr[i].end - 1,
 				page_size_string(&mr[i]));
+}
 
 	return nr_range;
 }
@@ -447,6 +479,7 @@ bool pfn_range_is_mapped(unsigned long start_pfn, unsigned long end_pfn)
 		    (end_pfn <= pfn_mapped[i].end))
 			return true;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return false;
 }
 
@@ -462,6 +495,7 @@ unsigned long __ref init_memory_mapping(unsigned long start,
 	unsigned long ret = 0;
 	int nr_range, i;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pr_debug("init_memory_mapping: [mem %#010lx-%#010lx]\n",
 	       start, end - 1);
 
@@ -575,15 +609,21 @@ static void __init memory_map_top_down(unsigned long map_start,
 		if (last_start > step_size) {
 			start = round_down(last_start - 1, step_size);
 			if (start < map_start)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				start = map_start;
+}
 		} else
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			start = map_start;
+}
 		mapped_ram_size += init_range_memory_mapping(start,
 							last_start);
 		last_start = start;
 		min_pfn_mapped = last_start >> PAGE_SHIFT;
 		if (mapped_ram_size >= step_size)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			step_size = get_new_step_size(step_size);
+}
 	}
 
 	if (real_end < map_end)
@@ -706,6 +746,7 @@ void __init init_mem_mapping(void)
  */
 int devmem_is_allowed(unsigned long pagenr)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (page_is_ram(pagenr)) {
 		/*
 		 * For disallowed memory regions in the low 1MB range,
@@ -741,12 +782,15 @@ void free_init_pages(char *what, unsigned long begin, unsigned long end)
 	end_aligned   = end & PAGE_MASK;
 
 	if (WARN_ON(begin_aligned != begin || end_aligned != end)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		begin = begin_aligned;
 		end   = end_aligned;
 	}
 
 	if (begin >= end)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	/*
 	 * If debugging page accesses then do not free this memory but
@@ -754,6 +798,7 @@ void free_init_pages(char *what, unsigned long begin, unsigned long end)
 	 * create a kernel page fault:
 	 */
 	if (debug_pagealloc_enabled()) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_info("debug: unmapping init [mem %#010lx-%#010lx]\n",
 			begin, end - 1);
 		set_memory_np(begin, (end - begin) >> PAGE_SHIFT);
diff --git a/arch/x86/mm/init_64.c b/arch/x86/mm/init_64.c
index fe85d12..79510ac 100644
--- a/arch/x86/mm/init_64.c
+++ b/arch/x86/mm/init_64.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  *  linux/arch/x86_64/mm/init.c
  *
@@ -80,6 +82,7 @@ int force_personality32;
  */
 static int __init nonx32_setup(char *str)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!strcmp(str, "on"))
 		force_personality32 &= ~READ_IMPLIES_EXEC;
 	else if (!strcmp(str, "off"))
@@ -144,11 +147,13 @@ void sync_global_pgds(unsigned long start, unsigned long end)
 		 * handle synchonization on p4d level.
 		 */
 		BUILD_BUG_ON(pgd_none(*pgd_ref));
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		p4d_ref = p4d_offset(pgd_ref, addr);
 
 		if (p4d_none(*p4d_ref))
 			continue;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		spin_lock(&pgd_lock);
 		list_for_each_entry(page, &pgd_list, lru) {
 			pgd_t *pgd;
@@ -161,15 +166,23 @@ void sync_global_pgds(unsigned long start, unsigned long end)
 			pgt_lock = &pgd_page_get_mm(page)->page_table_lock;
 			spin_lock(pgt_lock);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			if (!p4d_none(*p4d_ref) && !p4d_none(*p4d))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				BUG_ON(p4d_page_vaddr(*p4d)
 				       != p4d_page_vaddr(*p4d_ref));
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			if (p4d_none(*p4d))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				set_p4d(p4d, *p4d_ref);
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			spin_unlock(pgt_lock);
 		}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		spin_unlock(&pgd_lock);
 	}
 }
@@ -184,7 +197,9 @@ static __ref void *spp_getpage(void)
 	void *ptr;
 
 	if (after_bootmem)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ptr = (void *) get_zeroed_page(GFP_ATOMIC);
+}
 	else
 		ptr = alloc_bootmem_pages(PAGE_SIZE);
 
@@ -193,6 +208,7 @@ static __ref void *spp_getpage(void)
 			after_bootmem ? "after bootmem" : "");
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pr_debug("spp_getpage %p\n", ptr);
 
 	return ptr;
@@ -200,6 +216,7 @@ static __ref void *spp_getpage(void)
 
 static p4d_t *fill_p4d(pgd_t *pgd, unsigned long vaddr)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (pgd_none(*pgd)) {
 		p4d_t *p4d = (p4d_t *)spp_getpage();
 		pgd_populate(&init_mm, pgd, p4d);
@@ -240,7 +257,9 @@ static pte_t *fill_pte(pmd_t *pmd, unsigned long vaddr)
 		pte_t *pte = (pte_t *) spp_getpage();
 		pmd_populate_kernel(&init_mm, pmd, pte);
 		if (pte != pte_offset_kernel(pmd, 0))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			printk(KERN_ERR "PAGETABLE BUG #03!\n");
+}
 	}
 	return pte_offset_kernel(pmd, vaddr);
 }
@@ -261,6 +280,7 @@ static void __set_pte_vaddr(pud_t *pud, unsigned long vaddr, pte_t new_pte)
 
 void set_pte_vaddr_p4d(p4d_t *p4d_page, unsigned long vaddr, pte_t new_pte)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	p4d_t *p4d = p4d_page + p4d_index(vaddr);
 	pud_t *pud = fill_pud(p4d, vaddr);
 
@@ -269,6 +289,7 @@ void set_pte_vaddr_p4d(p4d_t *p4d_page, unsigned long vaddr, pte_t new_pte)
 
 void set_pte_vaddr_pud(pud_t *pud_page, unsigned long vaddr, pte_t new_pte)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pud_t *pud = pud_page + pud_index(vaddr);
 
 	__set_pte_vaddr(pud, vaddr, new_pte);
@@ -279,15 +300,18 @@ void set_pte_vaddr(unsigned long vaddr, pte_t pteval)
 	pgd_t *pgd;
 	p4d_t *p4d_page;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pr_debug("set_pte_vaddr %lx to %lx\n", vaddr, native_pte_val(pteval));
 
 	pgd = pgd_offset_k(vaddr);
 	if (pgd_none(*pgd)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		printk(KERN_ERR
 			"PGD FIXMAP MISSING, it should be setup in head.S!\n");
 		return;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	p4d_page = p4d_offset(pgd, 0);
 	set_pte_vaddr_p4d(p4d_page, vaddr, pteval);
 }
@@ -326,6 +350,7 @@ static void __init __init_extra_mapping(unsigned long phys, unsigned long size,
 
 	pgprot_val(prot) = pgprot_val(PAGE_KERNEL_LARGE) |
 		pgprot_val(pgprot_4k_2_large(cachemode2pgprot(cache)));
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	BUG_ON((phys & ~PMD_MASK) || (size & ~PMD_MASK));
 	for (; size; phys += PMD_SIZE, size -= PMD_SIZE) {
 		pgd = pgd_offset_k((unsigned long)__va(phys));
@@ -354,11 +379,13 @@ static void __init __init_extra_mapping(unsigned long phys, unsigned long size,
 
 void __init init_extra_mapping_wb(unsigned long phys, unsigned long size)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	__init_extra_mapping(phys, size, _PAGE_CACHE_MODE_WB);
 }
 
 void __init init_extra_mapping_uc(unsigned long phys, unsigned long size)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	__init_extra_mapping(phys, size, _PAGE_CACHE_MODE_UC);
 }
 
@@ -388,7 +415,9 @@ void __init cleanup_highmap(void)
 	 *	arch/x86/xen/mmu.c:xen_setup_kernel_pagetable().
 	 */
 	if (max_pfn_mapped)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		vaddr_end = __START_KERNEL_map + (max_pfn_mapped << PAGE_SHIFT);
+}
 
 	for (; vaddr + PMD_SIZE - 1 < vaddr_end; pmd++, vaddr += PMD_SIZE) {
 		if (pmd_none(*pmd))
@@ -433,14 +462,20 @@ phys_pte_init(pte_t *pte_page, unsigned long paddr, unsigned long paddr_end,
 		 * these mappings are more intelligent.
 		 */
 		if (!pte_none(*pte)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			if (!after_bootmem)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				pages++;
+}
 			continue;
 		}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			pr_info("   pte=%p addr=%lx pte=%016lx\n", pte, paddr,
 				pfn_pte(paddr >> PAGE_SHIFT, PAGE_KERNEL).pte);
+}
 		pages++;
 		set_pte(pte, pfn_pte(paddr >> PAGE_SHIFT, prot));
 		paddr_last = (paddr & PAGE_MASK) + PAGE_SIZE;
@@ -483,6 +518,7 @@ phys_pmd_init(pmd_t *pmd_page, unsigned long paddr, unsigned long paddr_end,
 
 		if (!pmd_none(*pmd)) {
 			if (!pmd_large(*pmd)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				spin_lock(&init_mm.page_table_lock);
 				pte = (pte_t *)pmd_page_vaddr(*pmd);
 				paddr_last = phys_pte_init(pte, paddr,
@@ -503,11 +539,16 @@ phys_pmd_init(pmd_t *pmd_page, unsigned long paddr, unsigned long paddr_end,
 			 * attributes.
 			 */
 			if (page_size_mask & (1 << PG_LEVEL_2M)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				if (!after_bootmem)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 					pages++;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				paddr_last = paddr_next;
 				continue;
 			}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			new_prot = pte_pgprot(pte_clrhuge(*(pte_t *)pmd));
 		}
 
@@ -569,6 +610,7 @@ phys_pud_init(pud_t *pud_page, unsigned long paddr, unsigned long paddr_end,
 
 		if (!pud_none(*pud)) {
 			if (!pud_large(*pud)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				pmd = pmd_offset(pud, 0);
 				paddr_last = phys_pmd_init(pmd, paddr,
 							   paddr_end,
@@ -590,15 +632,21 @@ phys_pud_init(pud_t *pud_page, unsigned long paddr, unsigned long paddr_end,
 			 * attributes.
 			 */
 			if (page_size_mask & (1 << PG_LEVEL_1G)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				if (!after_bootmem)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 					pages++;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				paddr_last = paddr_next;
 				continue;
 			}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			prot = pte_pgprot(pte_clrhuge(*(pte_t *)pud));
 		}
 
 		if (page_size_mask & (1<<PG_LEVEL_1G)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			pages++;
 			spin_lock(&init_mm.page_table_lock);
 			set_pte((pte_t *)pud,
@@ -635,6 +683,7 @@ phys_p4d_init(p4d_t *p4d_page, unsigned long paddr, unsigned long paddr_end,
 	if (!IS_ENABLED(CONFIG_X86_5LEVEL))
 		return phys_pud_init((pud_t *) p4d_page, paddr, paddr_end, page_size_mask);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (; i < PTRS_PER_P4D; i++, paddr = paddr_next) {
 		p4d_t *p4d;
 		pud_t *pud;
@@ -644,6 +693,7 @@ phys_p4d_init(p4d_t *p4d_page, unsigned long paddr, unsigned long paddr_end,
 		paddr_next = (paddr & P4D_MASK) + P4D_SIZE;
 
 		if (paddr >= paddr_end) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			if (!after_bootmem &&
 			    !e820__mapped_any(paddr & P4D_MASK, paddr_next,
 					     E820_TYPE_RAM) &&
@@ -653,7 +703,9 @@ phys_p4d_init(p4d_t *p4d_page, unsigned long paddr, unsigned long paddr_end,
 			continue;
 		}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (!p4d_none(*p4d)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			pud = pud_offset(p4d, 0);
 			paddr_last = phys_pud_init(pud, paddr,
 					paddr_end,
@@ -662,6 +714,7 @@ phys_p4d_init(p4d_t *p4d_page, unsigned long paddr, unsigned long paddr_end,
 			continue;
 		}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pud = alloc_low_page();
 		paddr_last = phys_pud_init(pud, paddr, paddr_end,
 					   page_size_mask);
@@ -670,6 +723,7 @@ phys_p4d_init(p4d_t *p4d_page, unsigned long paddr, unsigned long paddr_end,
 		p4d_populate(&init_mm, p4d, pud);
 		spin_unlock(&init_mm.page_table_lock);
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	__flush_tlb_all();
 
 	return paddr_last;
@@ -713,9 +767,12 @@ kernel_physical_mapping_init(unsigned long paddr_start,
 
 		spin_lock(&init_mm.page_table_lock);
 		if (IS_ENABLED(CONFIG_X86_5LEVEL))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			pgd_populate(&init_mm, pgd, p4d);
+}
 		else
 			p4d_populate(&init_mm, p4d_offset(pgd, vaddr), (pud_t *) p4d);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		spin_unlock(&init_mm.page_table_lock);
 		pgd_changed = true;
 	}
@@ -748,7 +805,9 @@ void __init paging_init(void)
 	 */
 	node_clear_state(0, N_MEMORY);
 	if (N_MEMORY != N_NORMAL_MEMORY)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		node_clear_state(0, N_NORMAL_MEMORY);
+}
 
 	zone_sizes_init();
 }
@@ -1162,6 +1221,7 @@ static void __init register_page_bootmem_info(void)
 #ifdef CONFIG_NUMA
 	int i;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for_each_online_node(i)
 		register_page_bootmem_info_node(NODE_DATA(i));
 #endif
@@ -1194,7 +1254,9 @@ void set_kernel_text_rw(void)
 	unsigned long end = PFN_ALIGN(__stop___ex_table);
 
 	if (!kernel_set_to_readonly)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	pr_debug("Set kernel text: %lx - %lx for read write\n",
 		 start, end);
@@ -1213,7 +1275,9 @@ void set_kernel_text_ro(void)
 	unsigned long end = PFN_ALIGN(__stop___ex_table);
 
 	if (!kernel_set_to_readonly)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	pr_debug("Set kernel text: %lx - %lx for read only\n",
 		 start, end);
@@ -1269,6 +1333,7 @@ void mark_rodata_ro(void)
 			(unsigned long) __va(__pa_symbol(rodata_end)),
 			(unsigned long) __va(__pa_symbol(_sdata)));
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	debug_checkwx();
 }
 
@@ -1281,6 +1346,7 @@ int kern_addr_valid(unsigned long addr)
 	pmd_t *pmd;
 	pte_t *pte;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (above != 0 && above != -1UL)
 		return 0;
 
@@ -1319,7 +1385,9 @@ static unsigned long probe_memory_block_size(void)
 
 	/* if system is UV or has 64GB of RAM or more, use large blocks */
 	if (is_uv_system() || ((max_pfn << PAGE_SHIFT) >= (64UL << 30)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		bz = 2UL << 30; /* 2GB */
+}
 
 	pr_info("x86/mm: Memory block size: %ldMB\n", bz >> 20);
 
@@ -1358,15 +1426,21 @@ static int __meminit vmemmap_populate_hugepages(unsigned long start,
 
 		pgd = vmemmap_pgd_populate(addr, node);
 		if (!pgd)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -ENOMEM;
+}
 
 		p4d = vmemmap_p4d_populate(pgd, addr, node);
 		if (!p4d)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -ENOMEM;
+}
 
 		pud = vmemmap_pud_populate(p4d, addr, node);
 		if (!pud)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -ENOMEM;
+}
 
 		pmd = pmd_offset(pud, addr);
 		if (pmd_none(*pmd)) {
@@ -1382,9 +1456,12 @@ static int __meminit vmemmap_populate_hugepages(unsigned long start,
 
 				/* check to see if we have contiguous blocks */
 				if (p_end != p || node_start != node) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 					if (p_start)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 						pr_debug(" [%lx-%lx] PMD -> [%p-%p] on node %d\n",
 						       addr_start, addr_end-1, p_start, p_end-1, node_start);
+}
 					addr_start = addr;
 					node_start = node;
 					p_start = p;
@@ -1394,15 +1471,22 @@ static int __meminit vmemmap_populate_hugepages(unsigned long start,
 				p_end = p + PMD_SIZE;
 				continue;
 			} else if (altmap)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				return -ENOMEM; /* no fallback */
+}
 		} else if (pmd_large(*pmd)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			vmemmap_verify((pte_t *)pmd, node, addr, next);
 			continue;
 		}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_warn_once("vmemmap: falling back to regular page backing\n");
 		if (vmemmap_populate_basepages(addr, next, node))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return -ENOMEM;
+}
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
@@ -1413,12 +1497,16 @@ int __meminit vmemmap_populate(unsigned long start, unsigned long end, int node)
 
 	if (boot_cpu_has(X86_FEATURE_PSE))
 		err = vmemmap_populate_hugepages(start, end, node, altmap);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	else if (altmap) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_err_once("%s: no cpu support for altmap allocations\n",
 				__func__);
 		err = -ENOMEM;
 	} else
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		err = vmemmap_populate_basepages(start, end, node);
+}
 	if (!err)
 		sync_global_pgds(start, end - 1);
 	return err;
@@ -1495,6 +1583,7 @@ void register_page_bootmem_memmap(unsigned long section_nr,
 void __meminit vmemmap_populate_print_last(void)
 {
 	if (p_start) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_debug(" [%lx-%lx] PMD -> [%p-%p] on node %d\n",
 			addr_start, addr_end-1, p_start, p_end-1, node_start);
 		p_start = NULL;
diff --git a/arch/x86/mm/ioremap.c b/arch/x86/mm/ioremap.c
index 7bebdd0..86c8ab2 100644
--- a/arch/x86/mm/ioremap.c
+++ b/arch/x86/mm/ioremap.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * Re-map IO memory to kernel address space so that we can access it.
  * This is needed for high PCI addresses that aren't mapped in the
@@ -61,6 +63,7 @@ static int __ioremap_check_ram(unsigned long start_pfn, unsigned long nr_pages,
 {
 	unsigned long i;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (i = 0; i < nr_pages; ++i)
 		if (pfn_valid(start_pfn + i) &&
 		    !PageReserved(pfn_to_page(start_pfn + i)))
@@ -99,11 +102,15 @@ static void __iomem *__ioremap_caller(resource_size_t phys_addr,
 	/* Don't allow wraparound or zero size */
 	last_addr = phys_addr + size - 1;
 	if (!size || last_addr < phys_addr)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 
 	if (!phys_addr_valid(phys_addr)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		printk(KERN_WARNING "ioremap: invalid physical address %llx\n",
 		       (unsigned long long)phys_addr);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		WARN_ON_ONCE(1);
 		return NULL;
 	}
@@ -115,6 +122,7 @@ static void __iomem *__ioremap_caller(resource_size_t phys_addr,
 	last_pfn = last_addr >> PAGE_SHIFT;
 	if (walk_system_ram_range(pfn, last_pfn - pfn + 1, NULL,
 					  __ioremap_check_ram) == 1) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		WARN_ONCE(1, "ioremap on RAM at %pa - %pa\n",
 			  &phys_addr, &last_addr);
 		return NULL;
@@ -130,12 +138,14 @@ static void __iomem *__ioremap_caller(resource_size_t phys_addr,
 	retval = reserve_memtype(phys_addr, (u64)phys_addr + size,
 						pcm, &new_pcm);
 	if (retval) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		printk(KERN_ERR "ioremap reserve_memtype failed %d\n", retval);
 		return NULL;
 	}
 
 	if (pcm != new_pcm) {
 		if (!is_new_memtype_allowed(phys_addr, size, pcm, new_pcm)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			printk(KERN_ERR
 		"ioremap error for 0x%llx-0x%llx, requested 0x%x, got 0x%x\n",
 				(unsigned long long)phys_addr,
@@ -146,6 +156,7 @@ static void __iomem *__ioremap_caller(resource_size_t phys_addr,
 		pcm = new_pcm;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	prot = PAGE_KERNEL_IO;
 	switch (pcm) {
 	case _PAGE_CACHE_MODE_UC:
@@ -192,8 +203,11 @@ static void __iomem *__ioremap_caller(resource_size_t phys_addr,
 	 * tree.
 	 */
 	if (iomem_map_sanity_check(unaligned_phys_addr, unaligned_size))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_warn("caller %pS mapping multiple BARs\n", caller);
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return ret_addr;
 err_free_area:
 	free_vm_area(area);
@@ -334,7 +348,9 @@ void iounmap(volatile void __iomem *addr)
 	struct vm_struct *p, *o;
 
 	if ((void __force *)addr <= high_memory)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	/*
 	 * The PCI/ISA range special-casing was removed from __ioremap()
@@ -345,6 +361,7 @@ void iounmap(volatile void __iomem *addr)
 	 */
 	if ((void __force *)addr >= phys_to_virt(ISA_START_ADDRESS) &&
 	    (void __force *)addr < phys_to_virt(ISA_END_ADDRESS)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		WARN(1, "iounmap() called for ISA range not obtained using ioremap()\n");
 		return;
 	}
@@ -362,6 +379,7 @@ void iounmap(volatile void __iomem *addr)
 	p = find_vm_area((void __force *)addr);
 
 	if (!p) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		printk(KERN_ERR "iounmap: bad address %p\n", addr);
 		dump_stack();
 		return;
@@ -405,13 +423,16 @@ void *xlate_dev_mem_ptr(phys_addr_t phys)
 
 	/* Only add the offset on success and return NULL if memremap() failed */
 	if (vaddr)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		vaddr += offset;
+}
 
 	return vaddr;
 }
 
 void unxlate_dev_mem_ptr(phys_addr_t phys, void *addr)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	memunmap((void *)((unsigned long)addr & PAGE_MASK));
 }
 
@@ -435,7 +456,9 @@ static bool memremap_should_map_decrypted(resource_size_t phys_addr,
 	is_pmem = region_intersects(phys_addr, size, IORESOURCE_MEM,
 				    IORES_DESC_PERSISTENT_MEMORY);
 	if (is_pmem != REGION_DISJOINT)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return true;
+}
 
 	/*
 	 * Check if the non-volatile attribute is set for an EFI
@@ -478,7 +501,9 @@ static bool memremap_is_efi_data(resource_size_t phys_addr,
 
 	/* Check if the address is part of EFI boot/runtime data */
 	if (!efi_enabled(EFI_BOOT))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return false;
+}
 
 	paddr = boot_params.efi_info.efi_memmap_hi;
 	paddr <<= 32;
@@ -517,6 +542,7 @@ static bool memremap_is_setup_data(resource_size_t phys_addr,
 	u64 paddr, paddr_next;
 
 	paddr = boot_params.hdr.setup_data;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	while (paddr) {
 		unsigned int len;
 
@@ -551,6 +577,7 @@ static bool __init early_memremap_is_setup_data(resource_size_t phys_addr,
 	u64 paddr, paddr_next;
 
 	paddr = boot_params.hdr.setup_data;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	while (paddr) {
 		unsigned int len;
 
@@ -581,6 +608,7 @@ static bool __init early_memremap_is_setup_data(resource_size_t phys_addr,
 bool arch_memremap_can_ram_remap(resource_size_t phys_addr, unsigned long size,
 				 unsigned long flags)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!sme_active())
 		return true;
 
@@ -608,9 +636,11 @@ pgprot_t __init early_memremap_pgprot_adjust(resource_size_t phys_addr,
 					     unsigned long size,
 					     pgprot_t prot)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!sme_active())
 		return prot;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (early_memremap_is_setup_data(phys_addr, size) ||
 	    memremap_is_efi_data(phys_addr, size) ||
 	    memremap_should_map_decrypted(phys_addr, size))
@@ -618,11 +648,13 @@ pgprot_t __init early_memremap_pgprot_adjust(resource_size_t phys_addr,
 	else
 		prot = pgprot_encrypted(prot);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return prot;
 }
 
 bool phys_mem_access_encrypted(unsigned long phys_addr, unsigned long size)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return arch_memremap_can_ram_remap(phys_addr, size, 0);
 }
 
@@ -691,6 +723,7 @@ static inline pte_t * __init early_ioremap_pte(unsigned long addr)
 
 bool __init is_early_ioremap_ptep(pte_t *ptep)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return ptep >= &bm_pte[0] && ptep < &bm_pte[PAGE_SIZE/sizeof(pte_t)];
 }
 
@@ -719,6 +752,7 @@ void __init early_ioremap_init(void)
 		     != (__fix_to_virt(FIX_BTMAP_END) >> PMD_SHIFT));
 #undef __FIXADDR_TOP
 	if (pmd != early_ioremap_pmd(fix_to_virt(FIX_BTMAP_END))) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		WARN_ON(1);
 		printk(KERN_WARNING "pmd %p != %p\n",
 		       pmd, early_ioremap_pmd(fix_to_virt(FIX_BTMAP_END)));
@@ -740,9 +774,12 @@ void __init __early_set_fixmap(enum fixed_addresses idx,
 	pte_t *pte;
 
 	if (idx >= __end_of_fixed_addresses) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		BUG();
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pte = early_ioremap_pte(addr);
 
 	if (pgprot_val(flags))
diff --git a/arch/x86/mm/kaslr.c b/arch/x86/mm/kaslr.c
index aedebd2..54002b7 100644
--- a/arch/x86/mm/kaslr.c
+++ b/arch/x86/mm/kaslr.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 /*
  * This file implements KASLR memory randomization for x86_64. It randomizes
@@ -95,11 +97,15 @@ void __init kernel_randomize_memory(void)
 	 * limited....
 	 */
 	BUILD_BUG_ON(vaddr_start >= vaddr_end);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	BUILD_BUG_ON(vaddr_end != CPU_ENTRY_AREA_BASE);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	BUILD_BUG_ON(vaddr_end > __START_KERNEL_map);
 
 	if (!kaslr_memory_enabled())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	/*
 	 * Update Physical memory mapping to available and
@@ -130,7 +136,9 @@ void __init kernel_randomize_memory(void)
 		entropy = remain_entropy / (ARRAY_SIZE(kaslr_regions) - i);
 		prandom_bytes_state(&rand_state, &rand, sizeof(rand));
 		if (IS_ENABLED(CONFIG_X86_5LEVEL))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			entropy = (rand % (entropy + 1)) & P4D_MASK;
+}
 		else
 			entropy = (rand % (entropy + 1)) & PUD_MASK;
 		vaddr += entropy;
@@ -142,7 +150,9 @@ void __init kernel_randomize_memory(void)
 		 */
 		vaddr += get_padding(&kaslr_regions[i]);
 		if (IS_ENABLED(CONFIG_X86_5LEVEL))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			vaddr = round_up(vaddr + 1, P4D_SIZE);
+}
 		else
 			vaddr = round_up(vaddr + 1, PUD_SIZE);
 		remain_entropy -= entropy;
@@ -190,6 +200,7 @@ static void __meminit init_trampoline_p4d(void)
 	pgd = pgd_offset_k((unsigned long)__va(paddr));
 	p4d_page = (p4d_t *) pgd_page_vaddr(*pgd);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (i = p4d_index(paddr); i < PTRS_PER_P4D; i++, paddr = paddr_next) {
 		p4d_t *p4d, *p4d_tramp;
 		unsigned long vaddr = (unsigned long)__va(paddr);
@@ -213,12 +224,16 @@ void __meminit init_trampoline(void)
 {
 
 	if (!kaslr_memory_enabled()) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		init_trampoline_default();
 		return;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (IS_ENABLED(CONFIG_X86_5LEVEL))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		init_trampoline_p4d();
+}
 	else
 		init_trampoline_pud();
 }
diff --git a/arch/x86/mm/mm_internal.h b/arch/x86/mm/mm_internal.h
index 4e1f6e1..2725a83 100644
--- a/arch/x86/mm/mm_internal.h
+++ b/arch/x86/mm/mm_internal.h
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /* SPDX-License-Identifier: GPL-2.0 */
 #ifndef __X86_MM_INTERNAL_H
 #define __X86_MM_INTERNAL_H
diff --git a/arch/x86/mm/mmap.c b/arch/x86/mm/mmap.c
index a996798..82df5b6 100644
--- a/arch/x86/mm/mmap.c
+++ b/arch/x86/mm/mmap.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * Flexible mmap layout support
  *
@@ -44,6 +46,7 @@ unsigned long task_size_32bit(void)
 
 unsigned long task_size_64bit(int full_addr_space)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return full_addr_space ? TASK_SIZE_MAX : DEFAULT_MAP_WINDOW;
 }
 
@@ -71,7 +74,9 @@ static unsigned long stack_maxrandom_size(unsigned long task_size)
 static int mmap_is_legacy(void)
 {
 	if (current->personality & ADDR_COMPAT_LAYOUT)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 1;
+}
 
 	return sysctl_legacy_va_layout;
 }
@@ -79,7 +84,9 @@ static int mmap_is_legacy(void)
 static unsigned long arch_rnd(unsigned int rndbits)
 {
 	if (!(current->flags & PF_RANDOMIZE))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 	return (get_random_long() & ((1UL << rndbits) - 1)) << PAGE_SHIFT;
 }
 
@@ -90,13 +97,16 @@ unsigned long arch_mmap_rnd(void)
 
 static unsigned long mmap_base(unsigned long rnd, unsigned long task_size)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	unsigned long gap = rlimit(RLIMIT_STACK);
 	unsigned long pad = stack_maxrandom_size(task_size) + stack_guard_gap;
 	unsigned long gap_min, gap_max;
 
 	/* Values close to RLIM_INFINITY can overflow. */
 	if (gap + pad > gap)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		gap += pad;
+}
 
 	/*
 	 * Top of mmap area (just below the process stack).
@@ -106,9 +116,13 @@ static unsigned long mmap_base(unsigned long rnd, unsigned long task_size)
 	gap_max = (task_size / 6) * 5;
 
 	if (gap < gap_min)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		gap = gap_min;
+}
 	else if (gap > gap_max)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		gap = gap_max;
+}
 
 	return PAGE_ALIGN(task_size - gap - rnd);
 }
@@ -128,7 +142,9 @@ static void arch_pick_mmap_base(unsigned long *base, unsigned long *legacy_base,
 {
 	*legacy_base = mmap_legacy_base(random_factor, task_size);
 	if (mmap_is_legacy())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		*base = *legacy_base;
+}
 	else
 		*base = mmap_base(random_factor, task_size);
 }
@@ -136,7 +152,9 @@ static void arch_pick_mmap_base(unsigned long *base, unsigned long *legacy_base,
 void arch_pick_mmap_layout(struct mm_struct *mm)
 {
 	if (mmap_is_legacy())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		mm->get_unmapped_area = arch_get_unmapped_area;
+}
 	else
 		mm->get_unmapped_area = arch_get_unmapped_area_topdown;
 
@@ -161,6 +179,7 @@ unsigned long get_mmap_base(int is_legacy)
 
 #ifdef CONFIG_HAVE_ARCH_COMPAT_MMAP_BASES
 	if (in_compat_syscall()) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return is_legacy ? mm->mmap_compat_legacy_base
 				 : mm->mmap_compat_base;
 	}
@@ -170,7 +189,11 @@ unsigned long get_mmap_base(int is_legacy)
 
 const char *arch_vma_name(struct vm_area_struct *vma)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (vma->vm_flags & VM_MPX)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return "[mpx]";
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return NULL;
 }
diff --git a/arch/x86/mm/mmio-mod.c b/arch/x86/mm/mmio-mod.c
index 4d434dd..9f0d9a8 100644
--- a/arch/x86/mm/mmio-mod.c
+++ b/arch/x86/mm/mmio-mod.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * This program is free software; you can redistribute it and/or modify
  * it under the terms of the GNU General Public License as published by
diff --git a/arch/x86/mm/pageattr.c b/arch/x86/mm/pageattr.c
index 3ed9a08..c77b702 100644
--- a/arch/x86/mm/pageattr.c
+++ b/arch/x86/mm/pageattr.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * Copyright 2002 Andi Kleen, SuSE Labs.
  * Thanks to Ben LaHaise for precious feedback.
@@ -68,7 +70,9 @@ void update_page_count(int level, unsigned long pages)
 static void split_page_count(int level)
 {
 	if (direct_pages_count[level] == 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	direct_pages_count[level]--;
 	direct_pages_count[level - 1] += PTRS_PER_PTE;
@@ -86,9 +90,11 @@ void arch_report_meminfo(struct seq_file *m)
 			direct_pages_count[PG_LEVEL_2M] << 12);
 #endif
 	if (direct_gbpages)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		seq_printf(m, "DirectMap1G:    %8lu kB\n",
 			direct_pages_count[PG_LEVEL_1G] << 20);
 }
+}
 #else
 static inline void split_page_count(int level) { }
 #endif
@@ -139,7 +145,9 @@ void clflush_cache_range(void *vaddr, unsigned int size)
 	void *vend = vaddr + size;
 
 	if (p >= vend)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	mb();
 
@@ -152,6 +160,7 @@ EXPORT_SYMBOL_GPL(clflush_cache_range);
 
 void arch_invalidate_pmem(void *addr, size_t size)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	clflush_cache_range(addr, size);
 }
 EXPORT_SYMBOL_GPL(arch_invalidate_pmem);
@@ -166,12 +175,14 @@ static void __cpa_flush_all(void *arg)
 	 */
 	__flush_tlb_all();
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (cache && boot_cpu_data.x86 >= 4)
 		wbinvd();
 }
 
 static void cpa_flush_all(unsigned long cache)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	BUG_ON(irqs_disabled());
 
 	on_each_cpu(__cpa_flush_all, (void *) cache, 1);
@@ -207,13 +218,16 @@ static void cpa_flush_range(unsigned long start, int numpages, int cache)
 	 * cachelines:
 	 */
 	for (i = 0, addr = start; i < numpages; i++, addr += PAGE_SIZE) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pte_t *pte = lookup_address(addr, &level);
 
 		/*
 		 * Only flush present addresses:
 		 */
 		if (pte && (pte_val(*pte) & _PAGE_PRESENT))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			clflush_cache_range((void *) addr, PAGE_SIZE);
+}
 	}
 }
 
@@ -294,7 +308,9 @@ static inline pgprot_t static_protections(pgprot_t prot, unsigned long address,
 	 * 64bit we do not enforce !NX on the low mapping
 	 */
 	if (within(address, (unsigned long)_text, (unsigned long)_etext))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pgprot_val(forbidden) |= _PAGE_NX;
+}
 
 	/*
 	 * The .rodata section needs to be read-only. Using the pfn
@@ -360,31 +376,46 @@ pte_t *lookup_address_in_pgd(pgd_t *pgd, unsigned long address,
 	*level = PG_LEVEL_NONE;
 
 	if (pgd_none(*pgd))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	p4d = p4d_offset(pgd, address);
 	if (p4d_none(*p4d))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 
 	*level = PG_LEVEL_512G;
 	if (p4d_large(*p4d) || !p4d_present(*p4d))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return (pte_t *)p4d;
+}
 
 	pud = pud_offset(p4d, address);
 	if (pud_none(*pud))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 
 	*level = PG_LEVEL_1G;
 	if (pud_large(*pud) || !pud_present(*pud))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return (pte_t *)pud;
+}
 
 	pmd = pmd_offset(pud, address);
 	if (pmd_none(*pmd))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 
 	*level = PG_LEVEL_2M;
 	if (pmd_large(*pmd) || !pmd_present(*pmd))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return (pte_t *)pmd;
+}
 
 	*level = PG_LEVEL_4K;
 
@@ -409,8 +440,10 @@ static pte_t *_lookup_address_cpa(struct cpa_data *cpa, unsigned long address,
 				  unsigned int *level)
 {
         if (cpa->pgd)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return lookup_address_in_pgd(cpa->pgd + pgd_index(address),
 					       address, level);
+}
 
         return lookup_address(address, level);
 }
@@ -427,7 +460,9 @@ pmd_t *lookup_pmd_address(unsigned long address)
 
 	pgd = pgd_offset_k(address);
 	if (pgd_none(*pgd))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 
 	p4d = p4d_offset(pgd, address);
 	if (p4d_none(*p4d) || p4d_large(*p4d) || !p4d_present(*p4d))
@@ -523,8 +558,11 @@ try_preserve_large_page(pte_t *kpte, unsigned long address,
 	enum pg_level level;
 
 	if (cpa->force_split)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 1;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_lock(&pgd_lock);
 	/*
 	 * Check for races, another CPU might have split this page
@@ -619,6 +657,7 @@ try_preserve_large_page(pte_t *kpte, unsigned long address,
 	 * above:
 	 */
 	if (pgprot_val(new_prot) == pgprot_val(old_prot)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		do_split = 0;
 		goto out_unlock;
 	}
@@ -652,6 +691,7 @@ static int
 __split_large_page(struct cpa_data *cpa, pte_t *kpte, unsigned long address,
 		   struct page *base)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pte_t *pbase = (pte_t *)page_address(base);
 	unsigned long ref_pfn, pfn, pfninc = 1;
 	unsigned int i, level;
@@ -665,6 +705,7 @@ __split_large_page(struct cpa_data *cpa, pte_t *kpte, unsigned long address,
 	 */
 	tmp = _lookup_address_cpa(cpa, address, &level);
 	if (tmp != kpte) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		spin_unlock(&pgd_lock);
 		return 1;
 	}
@@ -690,7 +731,9 @@ __split_large_page(struct cpa_data *cpa, pte_t *kpte, unsigned long address,
 		 * even on a non present pmd.
 		 */
 		if (!(pgprot_val(ref_prot) & _PAGE_PRESENT))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			pgprot_val(ref_prot) &= ~_PAGE_PSE;
+}
 		break;
 
 	default:
@@ -752,16 +795,25 @@ static int split_large_page(struct cpa_data *cpa, pte_t *kpte,
 	struct page *base;
 
 	if (!debug_pagealloc_enabled())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		spin_unlock(&cpa_lock);
+}
 	base = alloc_pages(GFP_KERNEL, 0);
 	if (!debug_pagealloc_enabled())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		spin_lock(&cpa_lock);
+}
 	if (!base)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 
 	if (__split_large_page(cpa, kpte, address, base))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		__free_page(base);
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
@@ -769,6 +821,7 @@ static bool try_to_free_pte_page(pte_t *pte)
 {
 	int i;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (i = 0; i < PTRS_PER_PTE; i++)
 		if (!pte_none(pte[i]))
 			return false;
@@ -781,6 +834,7 @@ static bool try_to_free_pmd_page(pmd_t *pmd)
 {
 	int i;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (i = 0; i < PTRS_PER_PMD; i++)
 		if (!pmd_none(pmd[i]))
 			return false;
@@ -791,6 +845,7 @@ static bool try_to_free_pmd_page(pmd_t *pmd)
 
 static bool unmap_pte_range(pmd_t *pmd, unsigned long start, unsigned long end)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pte_t *pte = pte_offset_kernel(pmd, start);
 
 	while (start < end) {
@@ -810,6 +865,7 @@ static bool unmap_pte_range(pmd_t *pmd, unsigned long start, unsigned long end)
 static void __unmap_pmd_range(pud_t *pud, pmd_t *pmd,
 			      unsigned long start, unsigned long end)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (unmap_pte_range(pmd, start, end))
 		if (try_to_free_pmd_page((pmd_t *)pud_page_vaddr(*pud)))
 			pud_clear(pud);
@@ -817,6 +873,7 @@ static void __unmap_pmd_range(pud_t *pud, pmd_t *pmd,
 
 static void unmap_pmd_range(pud_t *pud, unsigned long start, unsigned long end)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pmd_t *pmd = pmd_offset(pud, start);
 
 	/*
@@ -861,6 +918,7 @@ static void unmap_pmd_range(pud_t *pud, unsigned long start, unsigned long end)
 
 static void unmap_pud_range(p4d_t *p4d, unsigned long start, unsigned long end)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pud_t *pud = pud_offset(p4d, start);
 
 	/*
@@ -904,6 +962,7 @@ static void unmap_pud_range(p4d_t *p4d, unsigned long start, unsigned long end)
 
 static int alloc_pte_page(pmd_t *pmd)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pte_t *pte = (pte_t *)get_zeroed_page(GFP_KERNEL);
 	if (!pte)
 		return -1;
@@ -914,6 +973,7 @@ static int alloc_pte_page(pmd_t *pmd)
 
 static int alloc_pmd_page(pud_t *pud)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pmd_t *pmd = (pmd_t *)get_zeroed_page(GFP_KERNEL);
 	if (!pmd)
 		return -1;
@@ -938,7 +998,9 @@ static void populate_pte(struct cpa_data *cpa,
 	 * support it.
 	 */
 	if (pgprot_val(pgprot) & _PAGE_PRESENT)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pgprot_val(pgprot) |= _PAGE_GLOBAL;
+}
 	else
 		pgprot_val(pgprot) &= ~_PAGE_GLOBAL;
 
@@ -968,6 +1030,7 @@ static long populate_pmd(struct cpa_data *cpa,
 		unsigned long pre_end = start + (num_pages << PAGE_SHIFT);
 		unsigned long next_page = (start + PMD_SIZE) & PMD_MASK;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pre_end   = min_t(unsigned long, pre_end, next_page);
 		cur_pages = (pre_end - start) >> PAGE_SHIFT;
 		cur_pages = min_t(unsigned int, num_pages, cur_pages);
@@ -1045,6 +1108,7 @@ static int populate_pud(struct cpa_data *cpa, unsigned long start, p4d_t *p4d,
 		unsigned long pre_end;
 		unsigned long next_page = (start + PUD_SIZE) & PUD_MASK;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pre_end   = min_t(unsigned long, end, next_page);
 		cur_pages = (pre_end - start) >> PAGE_SHIFT;
 		cur_pages = min_t(int, (int)cpa->numpages, cur_pages);
@@ -1120,6 +1184,7 @@ static int populate_pgd(struct cpa_data *cpa, unsigned long addr)
 	pgd_entry = cpa->pgd + pgd_index(addr);
 
 	if (pgd_none(*pgd_entry)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		p4d = (p4d_t *)get_zeroed_page(GFP_KERNEL);
 		if (!p4d)
 			return -1;
@@ -1161,6 +1226,7 @@ static int populate_pgd(struct cpa_data *cpa, unsigned long addr)
 static int __cpa_process_fault(struct cpa_data *cpa, unsigned long vaddr,
 			       int primary)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (cpa->pgd) {
 		/*
 		 * Right now, we only execute this code path when mapping
@@ -1209,20 +1275,29 @@ static int __change_page_attr(struct cpa_data *cpa, int primary)
 	if (cpa->flags & CPA_PAGES_ARRAY) {
 		struct page *page = cpa->pages[cpa->curpage];
 		if (unlikely(PageHighMem(page)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return 0;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		address = (unsigned long)page_address(page);
 	} else if (cpa->flags & CPA_ARRAY)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		address = cpa->vaddr[cpa->curpage];
+}
 	else
 		address = *cpa->vaddr;
 repeat:
 	kpte = _lookup_address_cpa(cpa, address, &level);
 	if (!kpte)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return __cpa_process_fault(cpa, address, primary);
+}
 
 	old_pte = *kpte;
 	if (pte_none(old_pte))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return __cpa_process_fault(cpa, address, primary);
+}
 
 	if (level == PG_LEVEL_4K) {
 		pte_t new_pte;
@@ -1257,6 +1332,7 @@ static int __change_page_attr(struct cpa_data *cpa, int primary)
 		 * Do we really change anything ?
 		 */
 		if (pte_val(old_pte) != pte_val(new_pte)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			set_pte_atomic(kpte, new_pte);
 			cpa->flags |= CPA_FLUSHTLB;
 		}
@@ -1275,7 +1351,9 @@ static int __change_page_attr(struct cpa_data *cpa, int primary)
 	 * try_large_page:
 	 */
 	if (do_split <= 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return do_split;
+}
 
 	/*
 	 * We have to split the large page:
@@ -1304,6 +1382,7 @@ static int __change_page_attr(struct cpa_data *cpa, int primary)
 		goto repeat;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return err;
 }
 
@@ -1317,7 +1396,9 @@ static int cpa_process_alias(struct cpa_data *cpa)
 	int ret;
 
 	if (!pfn_range_is_mapped(cpa->pfn, cpa->pfn + 1))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	/*
 	 * No need to redo, when the primary call touched the direct
@@ -1326,10 +1407,15 @@ static int cpa_process_alias(struct cpa_data *cpa)
 	if (cpa->flags & CPA_PAGES_ARRAY) {
 		struct page *page = cpa->pages[cpa->curpage];
 		if (unlikely(PageHighMem(page)))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return 0;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		vaddr = (unsigned long)page_address(page);
 	} else if (cpa->flags & CPA_ARRAY)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		vaddr = cpa->vaddr[cpa->curpage];
+}
 	else
 		vaddr = *cpa->vaddr;
 
@@ -1342,7 +1428,9 @@ static int cpa_process_alias(struct cpa_data *cpa)
 
 		ret = __change_page_attr_set_clr(&alias_cpa, 0);
 		if (ret)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return ret;
+}
 	}
 
 #ifdef CONFIG_X86_64
@@ -1368,6 +1456,7 @@ static int cpa_process_alias(struct cpa_data *cpa)
 	}
 #endif
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
@@ -1384,20 +1473,31 @@ static int __change_page_attr_set_clr(struct cpa_data *cpa, int checkalias)
 		cpa->numpages = numpages;
 		/* for array changes, we can't use large page */
 		if (cpa->flags & (CPA_ARRAY | CPA_PAGES_ARRAY))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			cpa->numpages = 1;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (!debug_pagealloc_enabled())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			spin_lock(&cpa_lock);
+}
 		ret = __change_page_attr(cpa, checkalias);
 		if (!debug_pagealloc_enabled())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			spin_unlock(&cpa_lock);
+}
 		if (ret)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return ret;
+}
 
 		if (checkalias) {
 			ret = cpa_process_alias(cpa);
 			if (ret)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				return ret;
+}
 		}
 
 		/*
@@ -1408,11 +1508,14 @@ static int __change_page_attr_set_clr(struct cpa_data *cpa, int checkalias)
 		BUG_ON(cpa->numpages > numpages || !cpa->numpages);
 		numpages -= cpa->numpages;
 		if (cpa->flags & (CPA_PAGES_ARRAY | CPA_ARRAY))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			cpa->curpage++;
+}
 		else
 			*cpa->vaddr += cpa->numpages * PAGE_SIZE;
 
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
@@ -1434,14 +1537,20 @@ static int change_page_attr_set_clr(unsigned long *addr, int numpages,
 	mask_set = canon_pgprot(mask_set);
 	mask_clr = canon_pgprot(mask_clr);
 	if (!pgprot_val(mask_set) && !pgprot_val(mask_clr) && !force_split)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	/* Ensure we are PAGE_SIZE aligned */
 	if (in_flag & CPA_ARRAY) {
 		int i;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		for (i = 0; i < numpages; i++) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			if (addr[i] & ~PAGE_MASK) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				addr[i] &= PAGE_MASK;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				WARN_ON_ONCE(1);
 			}
 		}
@@ -1451,6 +1560,7 @@ static int change_page_attr_set_clr(unsigned long *addr, int numpages,
 		 * No need to cehck in that case
 		 */
 		if (*addr & ~PAGE_MASK) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			*addr &= PAGE_MASK;
 			/*
 			 * People should not be passing in unaligned addresses:
@@ -1479,7 +1589,9 @@ static int change_page_attr_set_clr(unsigned long *addr, int numpages,
 	cpa.force_split = force_split;
 
 	if (in_flag & (CPA_ARRAY | CPA_PAGES_ARRAY))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		cpa.flags |= in_flag;
+}
 
 	/* No alias checking for _NX bit modifications */
 	checkalias = (pgprot_val(mask_set) | pgprot_val(mask_clr)) != _PAGE_NX;
@@ -1506,12 +1618,15 @@ static int change_page_attr_set_clr(unsigned long *addr, int numpages,
 	 */
 	if (!ret && boot_cpu_has(X86_FEATURE_CLFLUSH)) {
 		if (cpa.flags & (CPA_PAGES_ARRAY | CPA_ARRAY)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			cpa_flush_array(addr, numpages, cache,
 					cpa.flags, pages);
 		} else
 			cpa_flush_range(baddr, numpages, cache);
 	} else
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		cpa_flush_all(cache);
+}
 
 out:
 	return ret;
@@ -1534,6 +1649,7 @@ static inline int change_page_attr_clear(unsigned long *addr, int numpages,
 static inline int cpa_set_pages_array(struct page **pages, int numpages,
 				       pgprot_t mask)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return change_page_attr_set_clr(NULL, numpages, mask, __pgprot(0), 0,
 		CPA_PAGES_ARRAY, pages);
 }
@@ -1541,6 +1657,7 @@ static inline int cpa_set_pages_array(struct page **pages, int numpages,
 static inline int cpa_clear_pages_array(struct page **pages, int numpages,
 					 pgprot_t mask)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return change_page_attr_set_clr(NULL, numpages, __pgprot(0), mask, 0,
 		CPA_PAGES_ARRAY, pages);
 }
@@ -1570,6 +1687,7 @@ int set_memory_uc(unsigned long addr, int numpages)
 	if (ret)
 		goto out_err;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	ret = _set_memory_uc(addr, numpages);
 	if (ret)
 		goto out_free;
@@ -1590,6 +1708,7 @@ static int _set_memory_array(unsigned long *addr, int addrinarray,
 	int i, j;
 	int ret;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (i = 0; i < addrinarray; i++) {
 		ret = reserve_memtype(__pa(addr[i]), __pa(addr[i]) + PAGE_SIZE,
 					new_type, NULL);
@@ -1624,18 +1743,21 @@ static int _set_memory_array(unsigned long *addr, int addrinarray,
 
 int set_memory_array_uc(unsigned long *addr, int addrinarray)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return _set_memory_array(addr, addrinarray, _PAGE_CACHE_MODE_UC_MINUS);
 }
 EXPORT_SYMBOL(set_memory_array_uc);
 
 int set_memory_array_wc(unsigned long *addr, int addrinarray)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return _set_memory_array(addr, addrinarray, _PAGE_CACHE_MODE_WC);
 }
 EXPORT_SYMBOL(set_memory_array_wc);
 
 int set_memory_array_wt(unsigned long *addr, int addrinarray)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return _set_memory_array(addr, addrinarray, _PAGE_CACHE_MODE_WT);
 }
 EXPORT_SYMBOL_GPL(set_memory_array_wt);
@@ -1665,7 +1787,9 @@ int set_memory_wc(unsigned long addr, int numpages)
 	ret = reserve_memtype(__pa(addr), __pa(addr) + numpages * PAGE_SIZE,
 		_PAGE_CACHE_MODE_WC, NULL);
 	if (ret)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ret;
+}
 
 	ret = _set_memory_wc(addr, numpages);
 	if (ret)
@@ -1688,7 +1812,9 @@ int set_memory_wt(unsigned long addr, int numpages)
 	ret = reserve_memtype(__pa(addr), __pa(addr) + numpages * PAGE_SIZE,
 			      _PAGE_CACHE_MODE_WT, NULL);
 	if (ret)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ret;
+}
 
 	ret = _set_memory_wt(addr, numpages);
 	if (ret)
@@ -1711,7 +1837,9 @@ int set_memory_wb(unsigned long addr, int numpages)
 
 	ret = _set_memory_wb(addr, numpages);
 	if (ret)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ret;
+}
 
 	free_memtype(__pa(addr), __pa(addr) + numpages * PAGE_SIZE);
 	return 0;
@@ -1727,7 +1855,9 @@ int set_memory_array_wb(unsigned long *addr, int addrinarray)
 	ret = change_page_attr_clear(addr, addrinarray,
 				      __pgprot(_PAGE_CACHE_MASK), 1);
 	if (ret)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return ret;
+}
 
 	for (i = 0; i < addrinarray; i++)
 		free_memtype(__pa(addr[i]), __pa(addr[i]) + PAGE_SIZE);
@@ -1739,7 +1869,9 @@ EXPORT_SYMBOL(set_memory_array_wb);
 int set_memory_x(unsigned long addr, int numpages)
 {
 	if (!(__supported_pte_mask & _PAGE_NX))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	return change_page_attr_clear(&addr, numpages, __pgprot(_PAGE_NX), 0);
 }
@@ -1748,7 +1880,9 @@ EXPORT_SYMBOL(set_memory_x);
 int set_memory_nx(unsigned long addr, int numpages)
 {
 	if (!(__supported_pte_mask & _PAGE_NX))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	return change_page_attr_set(&addr, numpages, __pgprot(_PAGE_NX), 0);
 }
@@ -1766,6 +1900,7 @@ int set_memory_rw(unsigned long addr, int numpages)
 
 int set_memory_np(unsigned long addr, int numpages)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return change_page_attr_clear(&addr, numpages, __pgprot(_PAGE_PRESENT), 0);
 }
 
@@ -1783,7 +1918,9 @@ static int __set_memory_enc_dec(unsigned long addr, int numpages, bool enc)
 
 	/* Nothing to do if the SME is not active */
 	if (!sme_active())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	/* Should not be working on unaligned addresses */
 	if (WARN_ONCE(addr & ~PAGE_MASK, "misaligned address: %#lx\n", addr))
@@ -1829,6 +1966,7 @@ static int __set_memory_enc_dec(unsigned long addr, int numpages, bool enc)
 
 int set_memory_encrypted(unsigned long addr, int numpages)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return __set_memory_enc_dec(addr, numpages, true);
 }
 EXPORT_SYMBOL_GPL(set_memory_encrypted);
@@ -1841,6 +1979,7 @@ EXPORT_SYMBOL_GPL(set_memory_decrypted);
 
 int set_pages_uc(struct page *page, int numpages)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	unsigned long addr = (unsigned long)page_address(page);
 
 	return set_memory_uc(addr, numpages);
@@ -1857,6 +1996,7 @@ static int _set_pages_array(struct page **pages, int addrinarray,
 	int free_idx;
 	int ret;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (i = 0; i < addrinarray; i++) {
 		if (PageHighMem(pages[i]))
 			continue;
@@ -1895,24 +2035,28 @@ static int _set_pages_array(struct page **pages, int addrinarray,
 
 int set_pages_array_uc(struct page **pages, int addrinarray)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return _set_pages_array(pages, addrinarray, _PAGE_CACHE_MODE_UC_MINUS);
 }
 EXPORT_SYMBOL(set_pages_array_uc);
 
 int set_pages_array_wc(struct page **pages, int addrinarray)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return _set_pages_array(pages, addrinarray, _PAGE_CACHE_MODE_WC);
 }
 EXPORT_SYMBOL(set_pages_array_wc);
 
 int set_pages_array_wt(struct page **pages, int addrinarray)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return _set_pages_array(pages, addrinarray, _PAGE_CACHE_MODE_WT);
 }
 EXPORT_SYMBOL_GPL(set_pages_array_wt);
 
 int set_pages_wb(struct page *page, int numpages)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	unsigned long addr = (unsigned long)page_address(page);
 
 	return set_memory_wb(addr, numpages);
@@ -1930,7 +2074,9 @@ int set_pages_array_wb(struct page **pages, int addrinarray)
 	retval = cpa_clear_pages_array(pages, addrinarray,
 			__pgprot(_PAGE_CACHE_MASK));
 	if (retval)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return retval;
+}
 
 	for (i = 0; i < addrinarray; i++) {
 		if (PageHighMem(pages[i]))
@@ -1946,6 +2092,7 @@ EXPORT_SYMBOL(set_pages_array_wb);
 
 int set_pages_x(struct page *page, int numpages)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	unsigned long addr = (unsigned long)page_address(page);
 
 	return set_memory_x(addr, numpages);
@@ -1954,6 +2101,7 @@ EXPORT_SYMBOL(set_pages_x);
 
 int set_pages_nx(struct page *page, int numpages)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	unsigned long addr = (unsigned long)page_address(page);
 
 	return set_memory_nx(addr, numpages);
@@ -1962,6 +2110,7 @@ EXPORT_SYMBOL(set_pages_nx);
 
 int set_pages_ro(struct page *page, int numpages)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	unsigned long addr = (unsigned long)page_address(page);
 
 	return set_memory_ro(addr, numpages);
@@ -1969,6 +2118,7 @@ int set_pages_ro(struct page *page, int numpages)
 
 int set_pages_rw(struct page *page, int numpages)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	unsigned long addr = (unsigned long)page_address(page);
 
 	return set_memory_rw(addr, numpages);
@@ -2078,6 +2228,7 @@ int kernel_map_pages_in_pgd(pgd_t *pgd, u64 pfn, unsigned long address,
 	if (!(__supported_pte_mask & _PAGE_NX))
 		goto out;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!(page_flags & _PAGE_NX))
 		cpa.mask_clr = __pgprot(_PAGE_NX);
 
diff --git a/arch/x86/mm/pat.c b/arch/x86/mm/pat.c
index fe7d57a..527e733 100644
--- a/arch/x86/mm/pat.c
+++ b/arch/x86/mm/pat.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * Handle caching attributes in page tables (PAT)
  *
@@ -44,6 +46,7 @@ static bool __read_mostly init_cm_done;
 
 void pat_disable(const char *reason)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (pat_disabled)
 		return;
 
@@ -58,6 +61,7 @@ void pat_disable(const char *reason)
 
 static int __init nopat(char *str)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pat_disable("PAT support disabled.");
 	return 0;
 }
@@ -73,6 +77,7 @@ int pat_debug_enable;
 
 static int __init pat_debug_setup(char *str)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pat_debug_enable = 1;
 	return 0;
 }
@@ -104,11 +109,19 @@ static inline enum page_cache_mode get_page_memtype(struct page *pg)
 	unsigned long pg_flags = pg->flags & _PGMT_MASK;
 
 	if (pg_flags == _PGMT_WB)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return _PAGE_CACHE_MODE_WB;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	else if (pg_flags == _PGMT_WC)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return _PAGE_CACHE_MODE_WC;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	else if (pg_flags == _PGMT_UC_MINUS)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return _PAGE_CACHE_MODE_UC_MINUS;
+}
 	else
 		return _PAGE_CACHE_MODE_WT;
 }
@@ -169,15 +182,23 @@ static enum page_cache_mode pat_get_cache_mode(unsigned pat_val, char *msg)
 	char *cache_mode;
 
 	switch (pat_val) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	case PAT_UC:       cache = CM(UC);       cache_mode = "UC  "; break;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	case PAT_WC:       cache = CM(WC);       cache_mode = "WC  "; break;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	case PAT_WT:       cache = CM(WT);       cache_mode = "WT  "; break;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	case PAT_WP:       cache = CM(WP);       cache_mode = "WP  "; break;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	case PAT_WB:       cache = CM(WB);       cache_mode = "WB  "; break;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	case PAT_UC_MINUS: cache = CM(UC_MINUS); cache_mode = "UC- "; break;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	default:           cache = CM(WB);       cache_mode = "WB  "; break;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	memcpy(msg, cache_mode, 4);
 
 	return cache;
@@ -214,12 +235,14 @@ static void pat_bsp_init(u64 pat)
 	u64 tmp_pat;
 
 	if (!boot_cpu_has(X86_FEATURE_PAT)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pat_disable("PAT not supported by CPU.");
 		return;
 	}
 
 	rdmsrl(MSR_IA32_CR_PAT, tmp_pat);
 	if (!tmp_pat) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pat_disable("PAT MSR is 0, disabled.");
 		return;
 	}
@@ -248,8 +271,11 @@ void init_cache_modes(void)
 	u64 pat = 0;
 
 	if (init_cm_done)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (boot_cpu_has(X86_FEATURE_PAT)) {
 		/*
 		 * CPU supports PAT. Set PAT table to be consistent with
@@ -263,6 +289,7 @@ void init_cache_modes(void)
 		rdmsrl(MSR_IA32_CR_PAT, pat);
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!pat) {
 		/*
 		 * No PAT. Emulate the PAT table that corresponds to the two
@@ -286,6 +313,7 @@ void init_cache_modes(void)
 		      PAT(4, WB) | PAT(5, WT) | PAT(6, UC_MINUS) | PAT(7, UC);
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	__init_cache_modes(pat);
 }
 
@@ -305,7 +333,9 @@ void pat_init(void)
 	struct cpuinfo_x86 *c = &boot_cpu_data;
 
 	if (pat_disabled)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	if ((c->x86_vendor == X86_VENDOR_INTEL) &&
 	    (((c->x86 == 0x6) && (c->x86_model <= 0xd)) ||
@@ -394,7 +424,9 @@ static unsigned long pat_x_mtrr_type(u64 start, u64 end,
 
 		mtrr_type = mtrr_type_lookup(start, end, &uniform);
 		if (mtrr_type != MTRR_TYPE_WRBACK)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return _PAGE_CACHE_MODE_UC_MINUS;
+}
 
 		return _PAGE_CACHE_MODE_WB;
 	}
@@ -435,7 +467,9 @@ static int pat_pagerange_is_ram(resource_size_t start, resource_size_t end)
 	 * different e820 types(RAM/reserved/..)
 	 */
 	if (start_pfn < ISA_END_ADDRESS >> PAGE_SHIFT)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		start_pfn = ISA_END_ADDRESS >> PAGE_SHIFT;
+}
 
 	if (start_pfn < end_pfn) {
 		ret = walk_system_ram_range(start_pfn, end_pfn - start_pfn,
@@ -464,6 +498,7 @@ static int reserve_ram_pages_type(u64 start, u64 end,
 	u64 pfn;
 
 	if (req_type == _PAGE_CACHE_MODE_WP) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (new_type)
 			*new_type = _PAGE_CACHE_MODE_UC_MINUS;
 		return -EINVAL;
@@ -505,6 +540,7 @@ static int free_ram_pages_type(u64 start, u64 end)
 	struct page *page;
 	u64 pfn;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (pfn = (start >> PAGE_SHIFT); pfn < (end >> PAGE_SHIFT); ++pfn) {
 		page = pfn_to_page(pfn);
 		set_page_memtype(page, _PAGE_CACHE_MODE_WB);
@@ -538,7 +574,10 @@ int reserve_memtype(u64 start, u64 end, enum page_cache_mode req_type,
 	if (!pat_enabled()) {
 		/* This is identical to page table setting without PAT */
 		if (new_type)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			*new_type = req_type;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
 	}
 
@@ -546,6 +585,7 @@ int reserve_memtype(u64 start, u64 end, enum page_cache_mode req_type,
 	if (x86_platform.is_untracked_pat_range(start, end)) {
 		if (new_type)
 			*new_type = _PAGE_CACHE_MODE_WB;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
 	}
 
@@ -563,16 +603,20 @@ int reserve_memtype(u64 start, u64 end, enum page_cache_mode req_type,
 	is_range_ram = pat_pagerange_is_ram(start, end);
 	if (is_range_ram == 1) {
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		err = reserve_ram_pages_type(start, end, req_type, new_type);
 
 		return err;
 	} else if (is_range_ram < 0) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
 	}
 
 	new  = kzalloc(sizeof(struct memtype), GFP_KERNEL);
 	if (!new)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENOMEM;
+}
 
 	new->start	= start;
 	new->end	= end;
@@ -582,6 +626,7 @@ int reserve_memtype(u64 start, u64 end, enum page_cache_mode req_type,
 
 	err = rbt_memtype_check_insert(new, new_type);
 	if (err) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_info("x86/PAT: reserve_memtype failed [mem %#010Lx-%#010Lx], track %s, req %s\n",
 			start, end - 1,
 			cattr_name(new->type), cattr_name(req_type));
@@ -591,12 +636,14 @@ int reserve_memtype(u64 start, u64 end, enum page_cache_mode req_type,
 		return err;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_unlock(&memtype_lock);
 
 	dprintk("reserve_memtype added [mem %#010Lx-%#010Lx], track %s, req %s, ret %s\n",
 		start, end - 1, cattr_name(new->type), cattr_name(req_type),
 		new_type ? cattr_name(*new_type) : "-");
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return err;
 }
 
@@ -607,27 +654,35 @@ int free_memtype(u64 start, u64 end)
 	struct memtype *entry;
 
 	if (!pat_enabled())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	/* Low ISA region is always mapped WB. No need to track */
 	if (x86_platform.is_untracked_pat_range(start, end))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	is_range_ram = pat_pagerange_is_ram(start, end);
 	if (is_range_ram == 1) {
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		err = free_ram_pages_type(start, end);
 
 		return err;
 	} else if (is_range_ram < 0) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_lock(&memtype_lock);
 	entry = rbt_memtype_erase(start, end);
 	spin_unlock(&memtype_lock);
 
 	if (IS_ERR(entry)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_info("x86/PAT: %s:%d freeing invalid memtype [mem %#010Lx-%#010Lx]\n",
 			current->comm, current->pid, start, end - 1);
 		return -EINVAL;
@@ -637,6 +692,7 @@ int free_memtype(u64 start, u64 end)
 
 	dprintk("free_memtype request [mem %#010Lx-%#010Lx]\n", start, end - 1);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
@@ -656,7 +712,9 @@ static enum page_cache_mode lookup_memtype(u64 paddr)
 	struct memtype *entry;
 
 	if (x86_platform.is_untracked_pat_range(paddr, paddr + PAGE_SIZE))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return rettype;
+}
 
 	if (pat_pagerange_is_ram(paddr, paddr + PAGE_SIZE)) {
 		struct page *page;
@@ -665,14 +723,18 @@ static enum page_cache_mode lookup_memtype(u64 paddr)
 		return get_page_memtype(page);
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_lock(&memtype_lock);
 
 	entry = rbt_memtype_lookup(paddr);
 	if (entry != NULL)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		rettype = entry->type;
+}
 	else
 		rettype = _PAGE_CACHE_MODE_UC_MINUS;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_unlock(&memtype_lock);
 	return rettype;
 }
@@ -695,6 +757,7 @@ int io_reserve_memtype(resource_size_t start, resource_size_t end,
 	enum page_cache_mode new_type;
 	int ret;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WARN_ON_ONCE(iomem_map_sanity_check(start, size));
 
 	ret = reserve_memtype(start, end, req_type, &new_type);
@@ -724,6 +787,7 @@ int io_reserve_memtype(resource_size_t start, resource_size_t end,
  */
 void io_free_memtype(resource_size_t start, resource_size_t end)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	free_memtype(start, end);
 }
 
@@ -737,6 +801,7 @@ EXPORT_SYMBOL(arch_io_reserve_memtype_wc);
 
 void arch_io_free_memtype_wc(resource_size_t start, resource_size_t size)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	io_free_memtype(start, start + size);
 }
 EXPORT_SYMBOL(arch_io_free_memtype_wc);
@@ -744,6 +809,7 @@ EXPORT_SYMBOL(arch_io_free_memtype_wc);
 pgprot_t phys_mem_access_prot(struct file *file, unsigned long pfn,
 				unsigned long size, pgprot_t vma_prot)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!phys_mem_access_encrypted(pfn << PAGE_SHIFT, size))
 		vma_prot = pgprot_decrypted(vma_prot);
 
@@ -765,7 +831,9 @@ static inline int range_is_allowed(unsigned long pfn, unsigned long size)
 	u64 cursor = from;
 
 	if (!pat_enabled())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 1;
+}
 
 	while (cursor < to) {
 		if (!devmem_is_allowed(pfn))
@@ -783,7 +851,9 @@ int phys_mem_access_prot_allowed(struct file *file, unsigned long pfn,
 	enum page_cache_mode pcm = _PAGE_CACHE_MODE_WB;
 
 	if (!range_is_allowed(pfn, size))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	if (file->f_flags & O_DSYNC)
 		pcm = _PAGE_CACHE_MODE_UC_MINUS;
@@ -803,26 +873,33 @@ int kernel_map_sync_memtype(u64 base, unsigned long size,
 	unsigned long id_sz;
 
 	if (base > __pa(high_memory-1))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	/*
 	 * some areas in the middle of the kernel identity range
 	 * are not mapped, like the PCI space.
 	 */
 	if (!page_is_ram(base >> PAGE_SHIFT))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	id_sz = (__pa(high_memory-1) <= base + size) ?
 				__pa(high_memory) - base :
 				size;
 
 	if (ioremap_change_attr((unsigned long)__va(base), id_sz, pcm) < 0) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_info("x86/PAT: %s:%d ioremap_change_attr failed %s for [mem %#010Lx-%#010Lx]\n",
 			current->comm, current->pid,
 			cattr_name(pcm),
 			base, (unsigned long long)(base + size-1));
 		return -EINVAL;
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
@@ -847,6 +924,7 @@ static int reserve_pfn_range(u64 paddr, unsigned long size, pgprot_t *vma_prot,
 	 * the type requested matches the type of first page in the range.
 	 */
 	if (is_ram) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (!pat_enabled())
 			return 0;
 
@@ -907,8 +985,10 @@ static void free_pfn_range(u64 paddr, unsigned long size)
 
 	is_ram = pat_pagerange_is_ram(paddr, paddr + size);
 	if (is_ram == 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		free_memtype(paddr, paddr + size);
 }
+}
 
 /*
  * track_pfn_copy is called when vma that is covering the pfnmap gets
@@ -930,13 +1010,16 @@ int track_pfn_copy(struct vm_area_struct *vma)
 		 * starting address and protection from pte.
 		 */
 		if (follow_phys(vma, vma->vm_start, 0, &prot, &paddr)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			WARN_ON_ONCE(1);
 			return -EINVAL;
 		}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pgprot = __pgprot(prot);
 		return reserve_pfn_range(paddr, vma_size, &pgprot, 1);
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
@@ -991,7 +1074,9 @@ void track_pfn_insert(struct vm_area_struct *vma, pgprot_t *prot, pfn_t pfn)
 	enum page_cache_mode pcm;
 
 	if (!pat_enabled())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	/* Set prot based on lookup */
 	pcm = lookup_memtype(pfn_t_to_phys(pfn));
@@ -1015,18 +1100,25 @@ void untrack_pfn(struct vm_area_struct *vma, unsigned long pfn,
 
 	/* free the chunk starting from pfn or the whole chunk */
 	paddr = (resource_size_t)pfn << PAGE_SHIFT;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!paddr && !size) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (follow_phys(vma, vma->vm_start, 0, &prot, &paddr)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			WARN_ON_ONCE(1);
 			return;
 		}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		size = vma->vm_end - vma->vm_start;
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	free_pfn_range(paddr, size);
 	if (vma)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		vma->vm_flags &= ~VM_PAT;
 }
+}
 
 /*
  * untrack_pfn_moved is called, while mremapping a pfnmap for a new region,
@@ -1035,11 +1127,13 @@ void untrack_pfn(struct vm_area_struct *vma, unsigned long pfn,
  */
 void untrack_pfn_moved(struct vm_area_struct *vma)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	vma->vm_flags &= ~VM_PAT;
 }
 
 pgprot_t pgprot_writecombine(pgprot_t prot)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return __pgprot(pgprot_val(prot) |
 				cachemode2protval(_PAGE_CACHE_MODE_WC));
 }
@@ -1047,6 +1141,7 @@ EXPORT_SYMBOL_GPL(pgprot_writecombine);
 
 pgprot_t pgprot_writethrough(pgprot_t prot)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return __pgprot(pgprot_val(prot) |
 				cachemode2protval(_PAGE_CACHE_MODE_WT));
 }
@@ -1061,7 +1156,9 @@ static struct memtype *memtype_get_idx(loff_t pos)
 
 	print_entry  = kzalloc(sizeof(struct memtype), GFP_KERNEL);
 	if (!print_entry)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 
 	spin_lock(&memtype_lock);
 	ret = rbt_memtype_copy_nth_element(print_entry, pos);
@@ -1077,6 +1174,7 @@ static struct memtype *memtype_get_idx(loff_t pos)
 
 static void *memtype_seq_start(struct seq_file *seq, loff_t *pos)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (*pos == 0) {
 		++*pos;
 		seq_puts(seq, "PAT memtype list:\n");
@@ -1087,6 +1185,7 @@ static void *memtype_seq_start(struct seq_file *seq, loff_t *pos)
 
 static void *memtype_seq_next(struct seq_file *seq, void *v, loff_t *pos)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	++*pos;
 	return memtype_get_idx(*pos);
 }
@@ -1115,6 +1214,7 @@ static const struct seq_operations memtype_seq_ops = {
 
 static int memtype_seq_open(struct inode *inode, struct file *file)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return seq_open(file, &memtype_seq_ops);
 }
 
diff --git a/arch/x86/mm/pat_rbtree.c b/arch/x86/mm/pat_rbtree.c
index fa16036..0f92341 100644
--- a/arch/x86/mm/pat_rbtree.c
+++ b/arch/x86/mm/pat_rbtree.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 /*
  * Handle caching attributes in page tables (PAT)
@@ -39,8 +41,11 @@ static struct rb_root memtype_rbroot = RB_ROOT;
 static int is_node_overlap(struct memtype *node, u64 start, u64 end)
 {
 	if (node->start >= end || node->end <= start)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 1;
 }
 
@@ -48,9 +53,11 @@ static u64 get_subtree_max_end(struct rb_node *node)
 {
 	u64 ret = 0;
 	if (node) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		struct memtype *data = rb_entry(node, struct memtype, rb);
 		ret = data->subtree_max_end;
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return ret;
 }
 
@@ -60,11 +67,15 @@ static u64 compute_subtree_max_end(struct memtype *data)
 
 	child_max_end = get_subtree_max_end(data->rb.rb_right);
 	if (child_max_end > max_end)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		max_end = child_max_end;
+}
 
 	child_max_end = get_subtree_max_end(data->rb.rb_left);
 	if (child_max_end > max_end)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		max_end = child_max_end;
+}
 
 	return max_end;
 }
@@ -86,6 +97,7 @@ static struct memtype *memtype_rb_lowest_match(struct rb_root *root,
 			/* Lowest overlap if any must be on left side */
 			node = node->rb_left;
 		} else if (is_node_overlap(data, start, end)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			last_lower = data;
 			break;
 		} else if (start >= data->start) {
@@ -116,17 +128,22 @@ static struct memtype *memtype_rb_match(struct rb_root *root,
 		    (match->start == start) && (match->end == end))
 			return match;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if ((match_type == MEMTYPE_END_MATCH) &&
 		    (match->start < start) && (match->end == end))
 			return match;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		node = rb_next(&match->rb);
 		if (node)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			match = rb_entry(node, struct memtype, rb);
+}
 		else
 			match = NULL;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return NULL; /* Returns NULL if there is no match */
 }
 
@@ -167,6 +184,7 @@ static int memtype_rb_check_conflict(struct rb_root *root,
 	if (newtype)
 		*newtype = found_type;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 
 failure:
@@ -182,6 +200,7 @@ static void memtype_rb_insert(struct rb_root *root, struct memtype *newdata)
 	struct rb_node *parent = NULL;
 
 	while (*node) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		struct memtype *data = rb_entry(*node, struct memtype, rb);
 
 		parent = *node;
@@ -189,6 +208,7 @@ static void memtype_rb_insert(struct rb_root *root, struct memtype *newdata)
 			data->subtree_max_end = newdata->end;
 		if (newdata->start <= data->start)
 			node = &((*node)->rb_left);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		else if (newdata->start > data->start)
 			node = &((*node)->rb_right);
 	}
@@ -230,10 +250,13 @@ struct memtype *rbt_memtype_erase(u64 start, u64 end)
 	data = memtype_rb_match(&memtype_rbroot, start, end,
 				MEMTYPE_EXACT_MATCH);
 	if (!data) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		data = memtype_rb_match(&memtype_rbroot, start, end,
 					MEMTYPE_END_MATCH);
 		if (!data)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return ERR_PTR(-EINVAL);
+}
 	}
 
 	if (data->start == start) {
@@ -250,11 +273,13 @@ struct memtype *rbt_memtype_erase(u64 start, u64 end)
 		return NULL;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return data;
 }
 
 struct memtype *rbt_memtype_lookup(u64 addr)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return memtype_rb_lowest_match(&memtype_rbroot, addr, addr + PAGE_SIZE);
 }
 
@@ -265,6 +290,7 @@ int rbt_memtype_copy_nth_element(struct memtype *out, loff_t pos)
 	int i = 1;
 
 	node = rb_first(&memtype_rbroot);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	while (node && pos != i) {
 		node = rb_next(node);
 		i++;
diff --git a/arch/x86/mm/pgtable.c b/arch/x86/mm/pgtable.c
index 004abf9..484cacc 100644
--- a/arch/x86/mm/pgtable.c
+++ b/arch/x86/mm/pgtable.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 #include <linux/mm.h>
 #include <linux/gfp.h>
@@ -28,16 +30,21 @@ pgtable_t pte_alloc_one(struct mm_struct *mm, unsigned long address)
 
 	pte = alloc_pages(__userpte_alloc_gfp, 0);
 	if (!pte)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 	if (!pgtable_page_ctor(pte)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		__free_page(pte);
 		return NULL;
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return pte;
 }
 
 static int __init setup_userpte(char *arg)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!arg)
 		return -EINVAL;
 
@@ -113,12 +120,14 @@ static inline void pgd_list_del(pgd_t *pgd)
 
 static void pgd_set_mm(pgd_t *pgd, struct mm_struct *mm)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	BUILD_BUG_ON(sizeof(virt_to_page(pgd)->index) < sizeof(mm));
 	virt_to_page(pgd)->index = (pgoff_t)mm;
 }
 
 struct mm_struct *pgd_page_get_mm(struct page *page)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return (struct mm_struct *)page->index;
 }
 
@@ -144,9 +153,13 @@ static void pgd_ctor(struct mm_struct *mm, pgd_t *pgd)
 
 static void pgd_dtor(pgd_t *pgd)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (SHARED_KERNEL_PMD)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_lock(&pgd_lock);
 	pgd_list_del(pgd);
 	spin_unlock(&pgd_lock);
@@ -204,6 +217,7 @@ static void free_pmds(struct mm_struct *mm, pmd_t *pmds[])
 {
 	int i;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for(i = 0; i < PREALLOCATED_PMDS; i++)
 		if (pmds[i]) {
 			pgtable_pmd_page_dtor(virt_to_page(pmds[i]));
@@ -219,7 +233,9 @@ static int preallocate_pmds(struct mm_struct *mm, pmd_t *pmds[])
 	gfp_t gfp = PGALLOC_GFP;
 
 	if (mm == &init_mm)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		gfp &= ~__GFP_ACCOUNT;
+}
 
 	for(i = 0; i < PREALLOCATED_PMDS; i++) {
 		pmd_t *pmd = (pmd_t *)__get_free_page(gfp);
@@ -253,6 +269,7 @@ static void pgd_mop_up_pmds(struct mm_struct *mm, pgd_t *pgdp)
 {
 	int i;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for(i = 0; i < PREALLOCATED_PMDS; i++) {
 		pgd_t pgd = pgdp[i];
 
@@ -275,7 +292,9 @@ static void pgd_prepopulate_pmd(struct mm_struct *mm, pgd_t *pgd, pmd_t *pmds[])
 	int i;
 
 	if (PREALLOCATED_PMDS == 0) /* Work around gcc-3.4.x bug */
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	p4d = p4d_offset(pgd, 0);
 	pud = pud_offset(p4d, 0);
@@ -409,6 +428,7 @@ pgd_t *pgd_alloc(struct mm_struct *mm)
 
 void pgd_free(struct mm_struct *mm, pgd_t *pgd)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pgd_mop_up_pmds(mm, pgd);
 	pgd_dtor(pgd);
 	paravirt_pgd_free(mm, pgd);
@@ -483,8 +503,10 @@ int ptep_test_and_clear_young(struct vm_area_struct *vma,
 	int ret = 0;
 
 	if (pte_young(*ptep))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		ret = test_and_clear_bit(_PAGE_BIT_ACCESSED,
 					 (unsigned long *) &ptep->pte);
+}
 
 	return ret;
 }
@@ -573,7 +595,9 @@ void __native_set_fixmap(enum fixed_addresses idx, pte_t pte)
 	unsigned long address = __fix_to_virt(idx);
 
 	if (idx >= __end_of_fixed_addresses) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		BUG();
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
 	}
 	set_pte_vaddr(address, pte);
@@ -632,6 +656,7 @@ int pud_set_huge(pud_t *pud, phys_addr_t addr, pgprot_t prot)
 	u8 mtrr, uniform;
 
 	mtrr = mtrr_type_lookup(addr, addr + PUD_SIZE, &uniform);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if ((mtrr != MTRR_TYPE_INVALID) && (!uniform) &&
 	    (mtrr != MTRR_TYPE_WRBACK))
 		return 0;
@@ -659,6 +684,7 @@ int pmd_set_huge(pmd_t *pmd, phys_addr_t addr, pgprot_t prot)
 	mtrr = mtrr_type_lookup(addr, addr + PMD_SIZE, &uniform);
 	if ((mtrr != MTRR_TYPE_INVALID) && (!uniform) &&
 	    (mtrr != MTRR_TYPE_WRBACK)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_warn_once("%s: Cannot satisfy [mem %#010llx-%#010llx] with a huge-page mapping due to MTRR override.\n",
 			     __func__, addr, addr + PMD_SIZE);
 		return 0;
@@ -681,10 +707,12 @@ int pmd_set_huge(pmd_t *pmd, phys_addr_t addr, pgprot_t prot)
 int pud_clear_huge(pud_t *pud)
 {
 	if (pud_large(*pud)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pud_clear(pud);
 		return 1;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
@@ -696,10 +724,12 @@ int pud_clear_huge(pud_t *pud)
 int pmd_clear_huge(pmd_t *pmd)
 {
 	if (pmd_large(*pmd)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pmd_clear(pmd);
 		return 1;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 #endif	/* CONFIG_HAVE_ARCH_HUGE_VMAP */
diff --git a/arch/x86/mm/physaddr.c b/arch/x86/mm/physaddr.c
index 7f9acb6..8ea6671 100644
--- a/arch/x86/mm/physaddr.c
+++ b/arch/x86/mm/physaddr.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 #include <linux/bootmem.h>
 #include <linux/mmdebug.h>
@@ -52,13 +54,17 @@ bool __virt_addr_valid(unsigned long x)
 		x = y + phys_base;
 
 		if (y >= KERNEL_IMAGE_SIZE)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return false;
+}
 	} else {
 		x = y + (__START_KERNEL_map - PAGE_OFFSET);
 
 		/* carry flag will be set if starting x was >= PAGE_OFFSET */
 		if ((x > y) || !phys_addr_valid(x))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return false;
+}
 	}
 
 	return pfn_valid(x >> PAGE_SHIFT);
diff --git a/arch/x86/mm/physaddr.h b/arch/x86/mm/physaddr.h
index 9f6419c..2f31b71 100644
--- a/arch/x86/mm/physaddr.h
+++ b/arch/x86/mm/physaddr.h
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /* SPDX-License-Identifier: GPL-2.0 */
 #include <asm/processor.h>
 
diff --git a/arch/x86/mm/pkeys.c b/arch/x86/mm/pkeys.c
index d7bc0eea..1c7cff8 100644
--- a/arch/x86/mm/pkeys.c
+++ b/arch/x86/mm/pkeys.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * Intel Memory Protection Keys management
  * Copyright (c) 2015, Intel Corporation.
@@ -144,6 +146,7 @@ u32 init_pkru_value = PKRU_AD_KEY( 1) | PKRU_AD_KEY( 2) | PKRU_AD_KEY( 3) |
  */
 void copy_init_pkru_to_fpregs(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	u32 init_pkru_value_snapshot = READ_ONCE(init_pkru_value);
 	/*
 	 * Any write to PKRU takes it out of the XSAVE 'init
@@ -176,6 +179,7 @@ static ssize_t init_pkru_write_file(struct file *file,
 	ssize_t len;
 	u32 new_init_pkru;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	len = min(count, sizeof(buf) - 1);
 	if (copy_from_user(buf, user_buf, len))
 		return -EFAULT;
@@ -216,7 +220,9 @@ static __init int setup_init_pkru(char *opt)
 	u32 new_init_pkru;
 
 	if (kstrtouint(opt, 0, &new_init_pkru))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 1;
+}
 
 	WRITE_ONCE(init_pkru_value, new_init_pkru);
 
diff --git a/arch/x86/mm/pti.c b/arch/x86/mm/pti.c
index ce38f16..7c99f63 100644
--- a/arch/x86/mm/pti.c
+++ b/arch/x86/mm/pti.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * Copyright(c) 2017 Intel Corporation. All rights reserved.
  *
@@ -56,12 +58,14 @@
 
 static void __init pti_print_if_insecure(const char *reason)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (boot_cpu_has_bug(X86_BUG_CPU_MELTDOWN))
 		pr_info("%s\n", reason);
 }
 
 static void __init pti_print_if_secure(const char *reason)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!boot_cpu_has_bug(X86_BUG_CPU_MELTDOWN))
 		pr_info("%s\n", reason);
 }
@@ -72,32 +76,41 @@ void __init pti_check_boottime_disable(void)
 	int ret;
 
 	if (hypervisor_is_type(X86_HYPER_XEN_PV)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pti_print_if_insecure("disabled on XEN PV.");
 		return;
 	}
 
 	ret = cmdline_find_option(boot_command_line, "pti", arg, sizeof(arg));
 	if (ret > 0)  {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (ret == 3 && !strncmp(arg, "off", 3)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			pti_print_if_insecure("disabled on command line.");
 			return;
 		}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (ret == 2 && !strncmp(arg, "on", 2)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			pti_print_if_secure("force enabled on command line.");
 			goto enable;
 		}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (ret == 4 && !strncmp(arg, "auto", 4))
 			goto autosel;
 	}
 
 	if (cmdline_find_option_bool(boot_command_line, "nopti")) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pti_print_if_insecure("disabled on command line.");
 		return;
 	}
 
 autosel:
 	if (!boot_cpu_has_bug(X86_BUG_CPU_MELTDOWN))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 enable:
 	setup_force_cpu_cap(X86_FEATURE_PTI);
 }
@@ -151,6 +164,7 @@ pgd_t __pti_set_user_pgd(pgd_t *pgdp, pgd_t pgd)
  */
 static __init p4d_t *pti_user_pagetable_walk_p4d(unsigned long address)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pgd_t *pgd = kernel_to_user_pgdp(pgd_offset_k(address));
 	gfp_t gfp = (GFP_KERNEL | __GFP_NOTRACK | __GFP_ZERO);
 
@@ -183,6 +197,7 @@ static __init pmd_t *pti_user_pagetable_walk_pmd(unsigned long address)
 	p4d_t *p4d = pti_user_pagetable_walk_p4d(address);
 	pud_t *pud;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	BUILD_BUG_ON(p4d_large(*p4d) != 0);
 	if (p4d_none(*p4d)) {
 		unsigned long new_pud_page = __get_free_page(gfp);
@@ -227,6 +242,7 @@ static __init pte_t *pti_user_pagetable_walk_pte(unsigned long address)
 
 	/* We can't do anything sensible if we hit a large mapping. */
 	if (pmd_large(*pmd)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		WARN_ON(1);
 		return NULL;
 	}
@@ -253,6 +269,7 @@ static void __init pti_setup_vsyscall(void)
 	unsigned int level;
 
 	pte = lookup_address(VSYSCALL_ADDR, &level);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!pte || WARN_ON(level != PG_LEVEL_4K) || pte_none(*pte))
 		return;
 
@@ -328,6 +345,7 @@ static void __init pti_clone_p4d(unsigned long addr)
  */
 static void __init pti_clone_user_shared(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pti_clone_p4d(CPU_ENTRY_AREA_BASE);
 }
 
@@ -346,6 +364,7 @@ static void __init pti_setup_espfix64(void)
  */
 static void __init pti_clone_entry_text(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pti_clone_pmds((unsigned long) __entry_text_start,
 			(unsigned long) __irqentry_text_end,
 		       _PAGE_RW | _PAGE_GLOBAL);
@@ -357,8 +376,11 @@ static void __init pti_clone_entry_text(void)
 void __init pti_init(void)
 {
 	if (!static_cpu_has(X86_FEATURE_PTI))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pr_info("enabled\n");
 
 	pti_clone_user_shared();
diff --git a/arch/x86/mm/setup_nx.c b/arch/x86/mm/setup_nx.c
index adb3c57..57f2829 100644
--- a/arch/x86/mm/setup_nx.c
+++ b/arch/x86/mm/setup_nx.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 #include <linux/spinlock.h>
 #include <linux/errno.h>
@@ -19,6 +21,7 @@ static int disable_nx;
  */
 static int __init noexec_setup(char *str)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!str)
 		return -EINVAL;
 	if (!strncmp(str, "on", 2)) {
@@ -42,11 +45,13 @@ void x86_configure_nx(void)
 void __init x86_report_nx(void)
 {
 	if (!boot_cpu_has(X86_FEATURE_NX)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		printk(KERN_NOTICE "Notice: NX (Execute Disable) protection "
 		       "missing in CPU!\n");
 	} else {
 #if defined(CONFIG_X86_64) || defined(CONFIG_X86_PAE)
 		if (disable_nx) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			printk(KERN_INFO "NX (Execute Disable) protection: "
 			       "disabled by kernel command line option\n");
 		} else {
diff --git a/arch/x86/mm/tlb.c b/arch/x86/mm/tlb.c
index 0c93643..73951c9 100644
--- a/arch/x86/mm/tlb.c
+++ b/arch/x86/mm/tlb.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 #include <linux/init.h>
 
 #include <linux/mm.h>
@@ -75,15 +77,22 @@ static void choose_new_asid(struct mm_struct *next, u64 next_tlb_gen,
 		return;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (this_cpu_read(cpu_tlbstate.invalidate_other))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		clear_asid_other();
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (asid = 0; asid < TLB_NR_DYN_ASIDS; asid++) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (this_cpu_read(cpu_tlbstate.ctxs[asid].ctx_id) !=
 		    next->context.ctx_id)
 			continue;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		*new_asid = asid;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		*need_flush = (this_cpu_read(cpu_tlbstate.ctxs[asid].tlb_gen) <
 			       next_tlb_gen);
 		return;
@@ -95,9 +104,12 @@ static void choose_new_asid(struct mm_struct *next, u64 next_tlb_gen,
 	 */
 	*new_asid = this_cpu_add_return(cpu_tlbstate.next_asid, 1) - 1;
 	if (*new_asid >= TLB_NR_DYN_ASIDS) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		*new_asid = 0;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		this_cpu_write(cpu_tlbstate.next_asid, 1);
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	*need_flush = true;
 }
 
@@ -109,6 +121,7 @@ static void load_new_mm_cr3(pgd_t *pgdir, u16 new_asid, bool need_flush)
 		invalidate_user_asid(new_asid);
 		new_mm_cr3 = build_cr3(pgdir, new_asid);
 	} else {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		new_mm_cr3 = build_cr3_noflush(pgdir, new_asid);
 	}
 
@@ -122,6 +135,7 @@ static void load_new_mm_cr3(pgd_t *pgdir, u16 new_asid, bool need_flush)
 
 void leave_mm(int cpu)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	struct mm_struct *loaded_mm = this_cpu_read(cpu_tlbstate.loaded_mm);
 
 	/*
@@ -158,6 +172,7 @@ static void sync_current_stack_to_mm(struct mm_struct *mm)
 	pgd_t *pgd = pgd_offset(mm, sp);
 
 	if (CONFIG_PGTABLE_LEVELS > 4) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (unlikely(pgd_none(*pgd))) {
 			pgd_t *pgd_ref = pgd_offset_k(sp);
 
@@ -199,7 +214,9 @@ void switch_mm_irqs_off(struct mm_struct *prev, struct mm_struct *next,
 
 	/* We don't want flush_tlb_func_* to run concurrently with us. */
 	if (IS_ENABLED(CONFIG_PROVE_LOCKING))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		WARN_ON_ONCE(!irqs_disabled());
+}
 
 	/*
 	 * Verify that CR3 is what we think it is.  This will catch
@@ -230,6 +247,7 @@ void switch_mm_irqs_off(struct mm_struct *prev, struct mm_struct *next,
 	this_cpu_write(cpu_tlbstate.is_lazy, false);
 
 	if (real_prev == next) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		VM_WARN_ON(this_cpu_read(cpu_tlbstate.ctxs[prev_asid].ctx_id) !=
 			   next->context.ctx_id);
 
@@ -244,6 +262,7 @@ void switch_mm_irqs_off(struct mm_struct *prev, struct mm_struct *next,
 				 !cpumask_test_cpu(cpu, mm_cpumask(next))))
 			cpumask_set_cpu(cpu, mm_cpumask(next));
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
 	} else {
 		u16 new_asid;
@@ -270,6 +289,7 @@ void switch_mm_irqs_off(struct mm_struct *prev, struct mm_struct *next,
 		    get_dumpable(tsk->mm) != SUID_DUMP_USER)
 			indirect_branch_prediction_barrier();
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (IS_ENABLED(CONFIG_VMAP_STACK)) {
 			/*
 			 * If our current stack is in vmalloc space and isn't
@@ -346,7 +366,9 @@ void switch_mm_irqs_off(struct mm_struct *prev, struct mm_struct *next,
 void enter_lazy_tlb(struct mm_struct *mm, struct task_struct *tsk)
 {
 	if (this_cpu_read(cpu_tlbstate.loaded_mm) == &init_mm)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	if (tlb_defer_switch_to_init_mm()) {
 		/*
@@ -360,6 +382,7 @@ void enter_lazy_tlb(struct mm_struct *mm, struct task_struct *tsk)
 		 */
 		this_cpu_write(cpu_tlbstate.is_lazy, true);
 	} else {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		switch_mm(NULL, &init_mm, NULL);
 	}
 }
@@ -437,8 +460,11 @@ static void flush_tlb_func_common(const struct flush_tlb_info *f,
 	VM_WARN_ON(!irqs_disabled());
 
 	if (unlikely(loaded_mm == &init_mm))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	VM_WARN_ON(this_cpu_read(cpu_tlbstate.ctxs[loaded_mm_asid].ctx_id) !=
 		   loaded_mm->context.ctx_id);
 
@@ -516,14 +542,19 @@ static void flush_tlb_func_common(const struct flush_tlb_info *f,
 			__flush_tlb_one_user(addr);
 			addr += PAGE_SIZE;
 		}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (local)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			count_vm_tlb_events(NR_TLB_LOCAL_FLUSH_ONE, nr_pages);
+}
 		trace_tlb_flush(reason, nr_pages);
 	} else {
 		/* Full flush. */
 		local_flush_tlb();
 		if (local)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			count_vm_tlb_event(NR_TLB_LOCAL_FLUSH_ALL);
+}
 		trace_tlb_flush(reason, TLB_FLUSH_ALL);
 	}
 
@@ -542,6 +573,7 @@ static void flush_tlb_func_remote(void *info)
 {
 	const struct flush_tlb_info *f = info;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	inc_irq_stat(irq_tlb_count);
 
 	if (f->mm && f->mm != this_cpu_read(cpu_tlbstate.loaded_mm))
@@ -554,6 +586,7 @@ static void flush_tlb_func_remote(void *info)
 void native_flush_tlb_others(const struct cpumask *cpumask,
 			     const struct flush_tlb_info *info)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	count_vm_tlb_event(NR_TLB_REMOTE_FLUSH);
 	if (info->end == TLB_FLUSH_ALL)
 		trace_tlb_flush(TLB_REMOTE_SEND_IPI, TLB_FLUSH_ALL);
@@ -628,6 +661,7 @@ void flush_tlb_mm_range(struct mm_struct *mm, unsigned long start,
 	}
 
 	if (mm == this_cpu_read(cpu_tlbstate.loaded_mm)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		VM_WARN_ON(irqs_disabled());
 		local_irq_disable();
 		flush_tlb_func_local(&info, TLB_LOCAL_MM_SHOOTDOWN);
@@ -635,7 +669,9 @@ void flush_tlb_mm_range(struct mm_struct *mm, unsigned long start,
 	}
 
 	if (cpumask_any_but(mm_cpumask(mm), cpu) < nr_cpu_ids)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		flush_tlb_others(mm_cpumask(mm), &info);
+}
 
 	put_cpu();
 }
@@ -643,12 +679,14 @@ void flush_tlb_mm_range(struct mm_struct *mm, unsigned long start,
 
 static void do_flush_tlb_all(void *info)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	count_vm_tlb_event(NR_TLB_REMOTE_FLUSH_RECEIVED);
 	__flush_tlb_all();
 }
 
 void flush_tlb_all(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	count_vm_tlb_event(NR_TLB_REMOTE_FLUSH);
 	on_each_cpu(do_flush_tlb_all, NULL, 1);
 }
@@ -686,6 +724,7 @@ void arch_tlbbatch_flush(struct arch_tlbflush_unmap_batch *batch)
 		.end = TLB_FLUSH_ALL,
 	};
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	int cpu = get_cpu();
 
 	if (cpumask_test_cpu(cpu, &batch->cpumask)) {
@@ -720,6 +759,7 @@ static ssize_t tlbflush_write_file(struct file *file,
 	ssize_t len;
 	int ceiling;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	len = min(count, sizeof(buf) - 1);
 	if (copy_from_user(buf, user_buf, len))
 		return -EFAULT;
diff --git a/arch/x86/net/bpf_jit_comp.c b/arch/x86/net/bpf_jit_comp.c
index 0554e8a..57b2178 100644
--- a/arch/x86/net/bpf_jit_comp.c
+++ b/arch/x86/net/bpf_jit_comp.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /* bpf_jit_comp.c : BPF JIT compiler
  *
  * Copyright (C) 2011-2013 Eric Dumazet (eric.dumazet@gmail.com)
diff --git a/arch/x86/oprofile/init.c b/arch/x86/oprofile/init.c
index 9e138d0..7bc9842 100644
--- a/arch/x86/oprofile/init.c
+++ b/arch/x86/oprofile/init.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /**
  * @file init.c
  *
diff --git a/arch/x86/oprofile/nmi_int.c b/arch/x86/oprofile/nmi_int.c
index abff76b..4953589 100644
--- a/arch/x86/oprofile/nmi_int.c
+++ b/arch/x86/oprofile/nmi_int.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /**
  * @file nmi_int.c
  *
diff --git a/arch/x86/oprofile/op_model_amd.c b/arch/x86/oprofile/op_model_amd.c
index 660a83c..fdd23ed 100644
--- a/arch/x86/oprofile/op_model_amd.c
+++ b/arch/x86/oprofile/op_model_amd.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * @file op_model_amd.c
  * athlon / K7 / K8 / Family 10h model-specific MSR operations
diff --git a/arch/x86/pci/acpi.c b/arch/x86/pci/acpi.c
index 7df49c4..96a5f62 100644
--- a/arch/x86/pci/acpi.c
+++ b/arch/x86/pci/acpi.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 #include <linux/pci.h>
 #include <linux/acpi.h>
@@ -24,18 +26,21 @@ static bool pci_ignore_seg = false;
 
 static int __init set_use_crs(const struct dmi_system_id *id)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pci_use_crs = true;
 	return 0;
 }
 
 static int __init set_nouse_crs(const struct dmi_system_id *id)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pci_use_crs = false;
 	return 0;
 }
 
 static int __init set_ignore_seg(const struct dmi_system_id *id)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	printk(KERN_INFO "PCI: %s detected: ignoring ACPI _SEG\n", id->ident);
 	pci_ignore_seg = true;
 	return 0;
@@ -143,8 +148,11 @@ void __init pci_acpi_crs_quirks(void)
 	int year;
 
 	if (dmi_get_date(DMI_BIOS_DATE, &year, NULL, NULL) && year < 2008) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (iomem_resource.end <= 0xffffffff)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			pci_use_crs = false;
+}
 	}
 
 	dmi_check_system(pci_crs_quirks);
@@ -154,9 +162,13 @@ void __init pci_acpi_crs_quirks(void)
 	 * takes precedence over anything we figured out above.
 	 */
 	if (pci_probe & PCI_ROOT_NO_CRS)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pci_use_crs = false;
+}
 	else if (pci_probe & PCI_USE__CRS)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pci_use_crs = true;
+}
 
 	printk(KERN_INFO "PCI: %s host bridge windows from ACPI; "
 	       "if necessary, use \"pci=%s\" and report a bug\n",
@@ -167,6 +179,7 @@ void __init pci_acpi_crs_quirks(void)
 #ifdef	CONFIG_PCI_MMCONFIG
 static int check_segment(u16 seg, struct device *dev, char *estr)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (seg) {
 		dev_err(dev,
 			"%s can't access PCI configuration "
@@ -195,6 +208,7 @@ static int setup_mcfg_map(struct acpi_pci_root_info *ci)
 	struct acpi_pci_root *root = ci->root;
 	struct device *dev = &ci->bridge->dev;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	info = container_of(ci, struct pci_root_info, common);
 	info->start_bus = (u8)root->secondary.start;
 	info->end_bus = (u8)root->secondary.end;
@@ -203,22 +217,32 @@ static int setup_mcfg_map(struct acpi_pci_root_info *ci)
 
 	/* return success if MMCFG is not in use */
 	if (raw_pci_ext_ops && raw_pci_ext_ops != &pci_mmcfg)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	if (!(pci_probe & PCI_PROBE_MMCONF))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return check_segment(seg, dev, "MMCONFIG is disabled,");
+}
 
 	result = pci_mmconfig_insert(dev, seg, info->start_bus, info->end_bus,
 				     root->mcfg_addr);
 	if (result == 0) {
 		/* enable MMCFG if it hasn't been enabled yet */
 		if (raw_pci_ext_ops == NULL)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			raw_pci_ext_ops = &pci_mmcfg;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		info->mcfg_added = true;
 	} else if (result != -EEXIST)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return check_segment(seg, dev,
 			 "fail to add MMCONFIG information,");
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
@@ -226,6 +250,7 @@ static void teardown_mcfg_map(struct acpi_pci_root_info *ci)
 {
 	struct pci_root_info *info;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	info = container_of(ci, struct pci_root_info, common);
 	if (info->mcfg_added) {
 		pci_mmconfig_delete(info->sd.domain,
@@ -251,6 +276,7 @@ static int pci_acpi_root_get_node(struct acpi_pci_root *root)
 	int node = acpi_get_node(device->handle);
 
 	if (node == NUMA_NO_NODE) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		node = x86_pci_root_bus_node(busnum);
 		if (node != 0 && node != NUMA_NO_NODE)
 			dev_info(&device->dev, FW_BUG "no _PXM; falling back to node %d from hardware (may be inconsistent with ACPI node numbers)\n",
@@ -269,6 +295,7 @@ static int pci_acpi_root_init_info(struct acpi_pci_root_info *ci)
 
 static void pci_acpi_root_release_info(struct acpi_pci_root_info *ci)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	teardown_mcfg_map(ci);
 	kfree(container_of(ci, struct pci_root_info, common));
 }
@@ -305,14 +332,18 @@ static int pci_acpi_root_prepare_resources(struct acpi_pci_root_info *ci)
 		resource_list_for_each_entry_safe(entry, tmp, &ci->resources)
 			if (resource_is_pcicfg_ioport(entry->res))
 				resource_list_destroy_entry(entry);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return status;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	resource_list_for_each_entry_safe(entry, tmp, &ci->resources) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		dev_printk(KERN_DEBUG, &device->dev,
 			   "host bridge window %pR (ignored)\n", entry->res);
 		resource_list_destroy_entry(entry);
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	x86_pci_root_bus_resources(busnum, &ci->resources);
 
 	return 0;
@@ -333,9 +364,12 @@ struct pci_bus *pci_acpi_scan_root(struct acpi_pci_root *root)
 	struct pci_bus *bus;
 
 	if (pci_ignore_seg)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		root->segment = domain = 0;
+}
 
 	if (domain && !pci_domains_supported) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		printk(KERN_WARNING "pci_bus %04x:%02x: "
 		       "ignored (multiple domains not supported)\n",
 		       domain, busnum);
@@ -354,15 +388,18 @@ struct pci_bus *pci_acpi_scan_root(struct acpi_pci_root *root)
 			.companion = root->device
 		};
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		memcpy(bus->sysdata, &sd, sizeof(sd));
 	} else {
 		struct pci_root_info *info;
 
 		info = kzalloc_node(sizeof(*info), GFP_KERNEL, node);
 		if (!info)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			dev_err(&root->device->dev,
 				"pci_bus %04x:%02x: ignored (out of memory)\n",
 				domain, busnum);
+}
 		else {
 			info->sd.domain = domain;
 			info->sd.node = node;
@@ -381,6 +418,7 @@ struct pci_bus *pci_acpi_scan_root(struct acpi_pci_root *root)
 			pcie_bus_configure_settings(child);
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return bus;
 }
 
@@ -404,7 +442,9 @@ int __init pci_acpi_init(void)
 	struct pci_dev *dev = NULL;
 
 	if (acpi_noirq)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -ENODEV;
+}
 
 	printk(KERN_INFO "PCI: Using ACPI for IRQ routing\n");
 	acpi_irq_penalty_init();
@@ -419,9 +459,11 @@ int __init pci_acpi_init(void)
 		 * don't use pci_enable_device().
 		 */
 		printk(KERN_INFO "PCI: Routing PCI interrupts for all devices because \"pci=routeirq\" specified\n");
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		for_each_pci_dev(dev)
 			acpi_pci_irq_enable(dev);
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
diff --git a/arch/x86/pci/amd_bus.c b/arch/x86/pci/amd_bus.c
index 649bdde..4b3232d 100644
--- a/arch/x86/pci/amd_bus.c
+++ b/arch/x86/pci/amd_bus.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 #include <linux/init.h>
 #include <linux/pci.h>
@@ -79,8 +81,11 @@ static int __init early_root_info_init(void)
 	u64 fam10h_mmconf_end;
 
 	if (!early_pci_allowed())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -1;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	found = false;
 	for (i = 0; i < ARRAY_SIZE(hb_probes); i++) {
 		u32 id;
@@ -96,14 +101,18 @@ static int __init early_root_info_init(void)
 		if (vendor != PCI_VENDOR_ID_AMD)
 			continue;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (hb_probes[i].device == device) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			found = true;
 			break;
 		}
 	}
 
 	if (!found)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	/*
 	 * We should learn topology and routing information from _PXM and
@@ -120,6 +129,7 @@ static int __init early_root_info_init(void)
 		if ((reg & 7) != 3)
 			continue;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		min_bus = (reg >> 16) & 0xff;
 		max_bus = (reg >> 24) & 0xff;
 		node = (reg >> 4) & 0x07;
@@ -137,7 +147,9 @@ static int __init early_root_info_init(void)
 	 * newer systems.
 	 */
 	if (boot_cpu_data.x86 > 0x11)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	/* get the default node and link for left over res */
 	reg = read_pci_config(bus, slot, 0, AMD_NB_F0_NODE_ID);
@@ -149,10 +161,12 @@ static int __init early_root_info_init(void)
 	add_range(range, RANGE_NUM, 0, 0, 0xffff + 1);
 	/* io port resource */
 	for (i = 0; i < 4; i++) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		reg = read_pci_config(bus, slot, 1, 0xc0 + (i << 3));
 		if (!(reg & 3))
 			continue;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		start = reg & 0xfff000;
 		reg = read_pci_config(bus, slot, 1, 0xc4 + (i << 3));
 		node = reg & 0x07;
@@ -163,12 +177,16 @@ static int __init early_root_info_init(void)
 		if (!info)
 			continue; /* not found */
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		printk(KERN_DEBUG "node %d link %d: io port [%llx, %llx]\n",
 		       node, link, start, end);
 
 		/* kernel only handle 16 bit only */
 		if (end > 0xffff)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			end = 0xffff;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		update_res(info, start, end, IORESOURCE_IO, 1);
 		subtract_range(range, RANGE_NUM, start, end + 1);
 	}
@@ -176,15 +194,19 @@ static int __init early_root_info_init(void)
 	/* find the position */
 	info = find_pci_root_info(def_node, def_link);
 	if (info) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		for (i = 0; i < RANGE_NUM; i++) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			if (!range[i].end)
 				continue;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			update_res(info, range[i].start, range[i].end - 1,
 				   IORESOURCE_IO, 1);
 		}
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	memset(range, 0, sizeof(range));
 	/* 0xfd00000000-0xffffffffff for HT */
 	end = cap_resource((0xfdULL<<32) - 1);
@@ -197,28 +219,34 @@ static int __init early_root_info_init(void)
 	end = (val & 0xffffff800000ULL);
 	printk(KERN_INFO "TOM: %016llx aka %lldM\n", end, end>>20);
 	if (end < (1ULL<<32))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		subtract_range(range, RANGE_NUM, 0, end);
+}
 
 	/* get mmconfig */
 	fam10h_mmconf = amd_get_mmconfig_range(&fam10h_mmconf_res);
 	/* need to take out mmconf range */
 	if (fam10h_mmconf) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		printk(KERN_DEBUG "Fam 10h mmconf %pR\n", fam10h_mmconf);
 		fam10h_mmconf_start = fam10h_mmconf->start;
 		fam10h_mmconf_end = fam10h_mmconf->end;
 		subtract_range(range, RANGE_NUM, fam10h_mmconf_start,
 				 fam10h_mmconf_end + 1);
 	} else {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		fam10h_mmconf_start = 0;
 		fam10h_mmconf_end = 0;
 	}
 
 	/* mmio resource */
 	for (i = 0; i < 8; i++) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		reg = read_pci_config(bus, slot, 1, 0x80 + (i << 3));
 		if (!(reg & 3))
 			continue;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		start = reg & 0xffffff00; /* 39:16 on 31:8*/
 		start <<= 8;
 		reg = read_pci_config(bus, slot, 1, 0x84 + (i << 3));
@@ -233,6 +261,7 @@ static int __init early_root_info_init(void)
 		if (!info)
 			continue;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		printk(KERN_DEBUG "node %d link %d: mmio [%llx, %llx]",
 		       node, link, start, end);
 		/*
@@ -244,16 +273,20 @@ static int __init early_root_info_init(void)
 			u64 endx = 0;
 			if (start >= fam10h_mmconf_start &&
 			    start <= fam10h_mmconf_end) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				start = fam10h_mmconf_end + 1;
 				changed = 1;
 			}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			if (end >= fam10h_mmconf_start &&
 			    end <= fam10h_mmconf_end) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				end = fam10h_mmconf_start - 1;
 				changed = 1;
 			}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			if (start < fam10h_mmconf_start &&
 			    end > fam10h_mmconf_end) {
 				/* we got a hole */
@@ -265,16 +298,21 @@ static int __init early_root_info_init(void)
 				start = fam10h_mmconf_end + 1;
 				changed = 1;
 			}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			if (changed) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				if (start <= end) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 					printk(KERN_CONT " %s [%llx, %llx]", endx ? "and" : "==>", start, end);
 				} else {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 					printk(KERN_CONT "%s\n", endx?"":" ==> none");
 					continue;
 				}
 			}
 		}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		update_res(info, cap_resource(start), cap_resource(end),
 				 IORESOURCE_MEM, 1);
 		subtract_range(range, RANGE_NUM, start, end + 1);
@@ -301,16 +339,20 @@ static int __init early_root_info_init(void)
 	 */
 	info = find_pci_root_info(def_node, def_link);
 	if (info) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		for (i = 0; i < RANGE_NUM; i++) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			if (!range[i].end)
 				continue;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			update_res(info, cap_resource(range[i].start),
 				   cap_resource(range[i].end - 1),
 				   IORESOURCE_MEM, 1);
 		}
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	list_for_each_entry(info, &pci_root_infos, list) {
 		int busnum;
 		struct pci_root_res *root_res;
@@ -318,11 +360,13 @@ static int __init early_root_info_init(void)
 		busnum = info->busn.start;
 		printk(KERN_DEBUG "bus: %pR on node %x link %x\n",
 		       &info->busn, info->node, info->link);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		list_for_each_entry(root_res, &info->resources, list)
 			printk(KERN_DEBUG "bus: %02x %pR\n",
 				       busnum, &root_res->res);
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
@@ -334,6 +378,7 @@ static int amd_bus_cpu_online(unsigned int cpu)
 
 	rdmsrl(MSR_AMD64_NB_CFG, reg);
 	if (!(reg & ENABLE_CF8_EXT_CFG)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		reg |= ENABLE_CF8_EXT_CFG;
 		wrmsrl(MSR_AMD64_NB_CFG, reg);
 	}
@@ -345,6 +390,7 @@ static void __init pci_enable_pci_io_ecs(void)
 #ifdef CONFIG_AMD_NB
 	unsigned int i, n;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (n = i = 0; !n && amd_nb_bus_dev_ranges[i].dev_limit; ++i) {
 		u8 bus = amd_nb_bus_dev_ranges[i].bus;
 		u8 slot = amd_nb_bus_dev_ranges[i].dev_base;
@@ -373,14 +419,20 @@ static int __init pci_io_ecs_init(void)
 
 	/* assume all cpus from fam10h have IO ECS */
 	if (boot_cpu_data.x86 < 0x10)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	/* Try the PCI method first. */
 	if (early_pci_allowed())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pci_enable_pci_io_ecs();
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	ret = cpuhp_setup_state(CPUHP_AP_ONLINE_DYN, "pci/amd_bus:online",
 				amd_bus_cpu_online, NULL);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WARN_ON(ret < 0);
 
 	pci_probe |= PCI_HAS_IO_ECS;
@@ -391,7 +443,9 @@ static int __init pci_io_ecs_init(void)
 static int __init amd_postcore_init(void)
 {
 	if (boot_cpu_data.x86_vendor != X86_VENDOR_AMD)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	early_root_info_init();
 	pci_io_ecs_init();
diff --git a/arch/x86/pci/common.c b/arch/x86/pci/common.c
index 7a5350d..59cf364 100644
--- a/arch/x86/pci/common.c
+++ b/arch/x86/pci/common.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  *	Low-Level PCI Support for PC
  *
@@ -43,6 +45,7 @@ int raw_pci_read(unsigned int domain, unsigned int bus, unsigned int devfn,
 		return raw_pci_ops->read(domain, bus, devfn, reg, len, val);
 	if (raw_pci_ext_ops)
 		return raw_pci_ext_ops->read(domain, bus, devfn, reg, len, val);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return -EINVAL;
 }
 
@@ -51,8 +54,12 @@ int raw_pci_write(unsigned int domain, unsigned int bus, unsigned int devfn,
 {
 	if (domain == 0 && reg < 256 && raw_pci_ops)
 		return raw_pci_ops->write(domain, bus, devfn, reg, len, val);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (raw_pci_ext_ops)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return raw_pci_ext_ops->write(domain, bus, devfn, reg, len, val);
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return -EINVAL;
 }
 
@@ -81,6 +88,7 @@ DEFINE_RAW_SPINLOCK(pci_config_lock);
 
 static int __init can_skip_ioresource_align(const struct dmi_system_id *d)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pci_probe |= PCI_CAN_SKIP_ISA_ALIGN;
 	printk(KERN_INFO "PCI: %s detected, can skip ISA alignment\n", d->ident);
 	return 0;
@@ -136,8 +144,11 @@ static void pcibios_fixup_device_resources(struct pci_dev *dev)
 		* it later on in pci_assign_unassigned_resources
 		*/
 		for (bar = 0; bar <= PCI_STD_RESOURCE_END; bar++) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			bar_r = &dev->resource[bar];
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			if (bar_r->start == 0 && bar_r->end != 0) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				bar_r->flags = 0;
 				bar_r->end = 0;
 			}
@@ -145,12 +156,17 @@ static void pcibios_fixup_device_resources(struct pci_dev *dev)
 	}
 
 	if (pci_probe & PCI_NOASSIGN_ROMS) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (rom_r->parent)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (rom_r->start) {
 			/* we deal with BIOS assigned ROM later */
 			return;
 		}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		rom_r->start = rom_r->end = rom_r->flags = 0;
 	}
 }
@@ -176,6 +192,7 @@ void pcibios_add_bus(struct pci_bus *bus)
 
 void pcibios_remove_bus(struct pci_bus *bus)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	acpi_pci_remove_bus(bus);
 }
 
@@ -186,6 +203,7 @@ void pcibios_remove_bus(struct pci_bus *bus)
 
 static int __init set_bf_sort(const struct dmi_system_id *d)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (pci_bf_sort == pci_bf_sort_default) {
 		pci_bf_sort = pci_dmi_bf;
 		printk(KERN_INFO "PCI: %s detected, enabling pci=bfsort.\n", d->ident);
@@ -199,13 +217,16 @@ static void __init read_dmi_type_b1(const struct dmi_header *dm,
 	u8 *data = (u8 *)dm + 4;
 
 	if (dm->type != 0xB1)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 	if ((((*(u32 *)data) >> 9) & 0x03) == 0x01)
 		set_bf_sort((const struct dmi_system_id *)private_data);
 }
 
 static int __init find_sort_method(const struct dmi_system_id *d)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	dmi_walk(read_dmi_type_b1, (void *)d);
 	return 0;
 }
@@ -225,6 +246,7 @@ static int __init assign_all_busses(const struct dmi_system_id *d)
 
 static int __init set_scan_all(const struct dmi_system_id *d)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	printk(KERN_INFO "PCI: %s detected, enabling pci=pcie_scan_all\n",
 	       d->ident);
 	pci_add_flags(PCI_SCAN_ALL_PCIE_DEVS);
@@ -462,6 +484,7 @@ void pcibios_scan_root(int busnum)
 
 	sd = kzalloc(sizeof(*sd), GFP_KERNEL);
 	if (!sd) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		printk(KERN_ERR "PCI: OOM, skipping PCI bus %02x\n", busnum);
 		return;
 	}
@@ -492,6 +515,7 @@ void __init pcibios_set_cache_line_size(void)
 		printk(KERN_DEBUG "PCI: pci_cache_line_size set to %d bytes\n",
 			pci_dfl_cache_line_size << 2);
 	} else {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
  		pci_dfl_cache_line_size = 32 >> 2;
 		printk(KERN_DEBUG "PCI: Unknown cacheline size. Setting to 32 bytes\n");
 	}
@@ -500,6 +524,7 @@ void __init pcibios_set_cache_line_size(void)
 int __init pcibios_init(void)
 {
 	if (!raw_pci_ops && !raw_pci_ext_ops) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		printk(KERN_WARNING "PCI: System does not support PCI\n");
 		return 0;
 	}
@@ -508,12 +533,16 @@ int __init pcibios_init(void)
 	pcibios_resource_survey();
 
 	if (pci_bf_sort >= pci_force_bf)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pci_sort_breadthfirst();
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
 char *__init pcibios_setup(char *str)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!strcmp(str, "off")) {
 		pci_probe = 0;
 		return NULL;
@@ -620,6 +649,7 @@ char *__init pcibios_setup(char *str)
 
 unsigned int pcibios_assign_all_busses(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return (pci_probe & PCI_ASSIGN_ALL_BUSSES) ? 1 : 0;
 }
 
@@ -629,6 +659,7 @@ static DEFINE_SPINLOCK(dma_domain_list_lock);
 
 void add_dma_domain(struct dma_domain *domain)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_lock(&dma_domain_list_lock);
 	list_add(&domain->node, &dma_domain_list);
 	spin_unlock(&dma_domain_list_lock);
@@ -637,6 +668,7 @@ EXPORT_SYMBOL_GPL(add_dma_domain);
 
 void del_dma_domain(struct dma_domain *domain)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_lock(&dma_domain_list_lock);
 	list_del(&domain->node);
 	spin_unlock(&dma_domain_list_lock);
@@ -649,11 +681,14 @@ static void set_dma_domain_ops(struct pci_dev *pdev)
 
 	spin_lock(&dma_domain_list_lock);
 	list_for_each_entry(domain, &dma_domain_list, node) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (pci_domain_nr(pdev->bus) == domain->domain_nr) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			pdev->dev.dma_ops = domain->dma_ops;
 			break;
 		}
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_unlock(&dma_domain_list_lock);
 }
 #else
diff --git a/arch/x86/pci/direct.c b/arch/x86/pci/direct.c
index 2d95033..4ee0763 100644
--- a/arch/x86/pci/direct.c
+++ b/arch/x86/pci/direct.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 /*
  * direct.c - Low-level direct PCI config space access
@@ -24,6 +26,7 @@ static int pci_conf1_read(unsigned int seg, unsigned int bus,
 	unsigned long flags;
 
 	if (seg || (bus > 255) || (devfn > 255) || (reg > 4095)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		*value = -1;
 		return -EINVAL;
 	}
@@ -55,7 +58,9 @@ static int pci_conf1_write(unsigned int seg, unsigned int bus,
 	unsigned long flags;
 
 	if (seg || (bus > 255) || (devfn > 255) || (reg > 4095))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
 	raw_spin_lock_irqsave(&pci_config_lock, flags);
 
@@ -98,6 +103,7 @@ static int pci_conf2_read(unsigned int seg, unsigned int bus,
 	unsigned long flags;
 	int dev, fn;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WARN_ON(seg);
 	if ((bus > 255) || (devfn > 255) || (reg > 255)) {
 		*value = -1;
@@ -140,6 +146,7 @@ static int pci_conf2_write(unsigned int seg, unsigned int bus,
 	unsigned long flags;
 	int dev, fn;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WARN_ON(seg);
 	if ((bus > 255) || (devfn > 255) || (reg > 255)) 
 		return -EINVAL;
@@ -198,26 +205,41 @@ static int __init pci_sanity_check(const struct pci_raw_ops *o)
 	int year, devfn;
 
 	if (pci_probe & PCI_NO_CHECKS)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 1;
+}
 	/* Assume Type 1 works for newer systems.
 	   This handles machines that don't have anything on PCI Bus 0. */
 	dmi_get_date(DMI_BIOS_DATE, &year, NULL, NULL);
 	if (year >= 2001)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 1;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (devfn = 0; devfn < 0x100; devfn++) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (o->read(0, 0, devfn, PCI_CLASS_DEVICE, 2, &x))
 			continue;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (x == PCI_CLASS_BRIDGE_HOST || x == PCI_CLASS_DISPLAY_VGA)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return 1;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (o->read(0, 0, devfn, PCI_VENDOR_ID, 2, &x))
 			continue;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (x == PCI_VENDOR_ID_INTEL || x == PCI_VENDOR_ID_COMPAQ)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return 1;
+}
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	DBG(KERN_WARNING "PCI: Sanity check failed\n");
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
@@ -229,12 +251,15 @@ static int __init pci_check_type1(void)
 
 	local_irq_save(flags);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	outb(0x01, 0xCFB);
 	tmp = inl(0xCF8);
 	outl(0x80000000, 0xCF8);
 	if (inl(0xCF8) == 0x80000000 && pci_sanity_check(&pci_direct_conf1)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		works = 1;
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	outl(tmp, 0xCF8);
 	local_irq_restore(flags);
 
@@ -246,6 +271,7 @@ static int __init pci_check_type2(void)
 	unsigned long flags;
 	int works = 0;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	local_irq_save(flags);
 
 	outb(0x00, 0xCFB);
@@ -264,20 +290,29 @@ static int __init pci_check_type2(void)
 void __init pci_direct_init(int type)
 {
 	if (type == 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 	printk(KERN_INFO "PCI: Using configuration type %d for base access\n",
 		 type);
 	if (type == 1) {
 		raw_pci_ops = &pci_direct_conf1;
 		if (raw_pci_ext_ops)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (!(pci_probe & PCI_HAS_IO_ECS))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		printk(KERN_INFO "PCI: Using configuration type 1 "
 		       "for extended access\n");
 		raw_pci_ext_ops = &pci_direct_conf1;
 		return;
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	raw_pci_ops = &pci_direct_conf2;
 }
 
@@ -293,22 +328,32 @@ int __init pci_direct_probe(void)
 		port_cf9_safe = true;
 		return 1;
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	release_region(0xCF8, 8);
 
  type2:
 	if ((pci_probe & PCI_PROBE_CONF2) == 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!request_region(0xCF8, 4, "PCI conf2"))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!request_region(0xC000, 0x1000, "PCI conf2"))
 		goto fail2;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (pci_check_type2()) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		raw_pci_ops = &pci_direct_conf2;
 		port_cf9_safe = true;
 		return 2;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	release_region(0xC000, 0x1000);
  fail2:
 	release_region(0xCF8, 4);
diff --git a/arch/x86/pci/early.c b/arch/x86/pci/early.c
index f011400..fa4f583 100644
--- a/arch/x86/pci/early.c
+++ b/arch/x86/pci/early.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 #include <linux/kernel.h>
 #include <linux/pci.h>
@@ -35,18 +37,21 @@ u16 read_pci_config_16(u8 bus, u8 slot, u8 func, u8 offset)
 void write_pci_config(u8 bus, u8 slot, u8 func, u8 offset,
 				    u32 val)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	outl(0x80000000 | (bus<<16) | (slot<<11) | (func<<8) | offset, 0xcf8);
 	outl(val, 0xcfc);
 }
 
 void write_pci_config_byte(u8 bus, u8 slot, u8 func, u8 offset, u8 val)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	outl(0x80000000 | (bus<<16) | (slot<<11) | (func<<8) | offset, 0xcf8);
 	outb(val, 0xcfc + (offset&3));
 }
 
 void write_pci_config_16(u8 bus, u8 slot, u8 func, u8 offset, u16 val)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	outl(0x80000000 | (bus<<16) | (slot<<11) | (func<<8) | offset, 0xcf8);
 	outw(val, 0xcfc + (offset&2));
 }
@@ -66,6 +71,7 @@ void early_dump_pci_device(u8 bus, u8 slot, u8 func)
 	printk(KERN_INFO "pci 0000:%02x:%02x.%d config space:",
 	       bus, slot, func);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (i = 0; i < 256; i += 4) {
 		if (!(i & 0x0f))
 			printk("\n  %02x:",i);
@@ -84,7 +90,9 @@ void early_dump_pci_devices(void)
 	unsigned bus, slot, func;
 
 	if (!early_pci_allowed())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	for (bus = 0; bus < 256; bus++) {
 		for (slot = 0; slot < 32; slot++) {
diff --git a/arch/x86/pci/fixup.c b/arch/x86/pci/fixup.c
index 4210da7..7af332c 100644
--- a/arch/x86/pci/fixup.c
+++ b/arch/x86/pci/fixup.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 /*
  * Exceptions for specific devices. Usually work-arounds for fatal design flaws.
@@ -20,6 +22,7 @@ static void pci_fixup_i450nx(struct pci_dev *d)
 
 	dev_warn(&d->dev, "Searching for i450NX host bridges\n");
 	reg = 0xd0;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for(pxb = 0; pxb < 2; pxb++) {
 		pci_read_config_byte(d, reg++, &busno);
 		pci_read_config_byte(d, reg++, &suba);
@@ -58,6 +61,7 @@ static void pci_fixup_umc_ide(struct pci_dev *d)
 	int i;
 
 	dev_warn(&d->dev, "Fixing base address flags\n");
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for(i = 0; i < 4; i++)
 		d->resource[i].flags |= PCI_BASE_ADDRESS_SPACE_IO;
 }
@@ -153,6 +157,7 @@ DECLARE_PCI_FIXUP_RESUME(PCI_VENDOR_ID_VIA, PCI_DEVICE_ID_VIA_8367_0, pci_fixup_
  */
 static void pci_fixup_transparent_bridge(struct pci_dev *dev)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if ((dev->device & 0xff00) == 0x2400)
 		dev->transparent = 1;
 }
@@ -189,6 +194,7 @@ static void pci_fixup_nforce2(struct pci_dev *dev)
 	 * Apply fixup if needed, but don't touch disconnect state
 	 */
 	if ((val & 0x00FF0000) != 0x00010000) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		dev_warn(&dev->dev, "nForce2 C1 Halt Disconnect fixup\n");
 		pci_write_config_dword(dev, 0x6c, (val & 0xFF00FFFF) | 0x00010000);
 	}
@@ -204,6 +210,7 @@ static int quirk_aspm_offset[MAX_PCIEROOT << 3];
 
 static int quirk_pcie_aspm_read(struct pci_bus *bus, unsigned int devfn, int where, int size, u32 *value)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return raw_pci_read(pci_domain_nr(bus), bus->number,
 						devfn, where, size, value);
 }
@@ -218,6 +225,7 @@ static int quirk_pcie_aspm_write(struct pci_bus *bus, unsigned int devfn, int wh
 
 	offset = quirk_aspm_offset[GET_INDEX(bus->self->device, devfn)];
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if ((offset) && (where == offset))
 		value = value & ~PCI_EXP_LNKCTL_ASPMC;
 
@@ -245,7 +253,9 @@ static void pcie_rootport_aspm_quirk(struct pci_dev *pdev)
 	struct pci_dev *dev;
 
 	if ((pbus = pdev->subordinate) == NULL)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	/*
 	 * Check if the DID of pdev matches one of the six root ports. This
@@ -328,13 +338,17 @@ static void pci_fixup_video(struct pci_dev *pdev)
 		 * PCI header type NORMAL.
 		 */
 		if (bridge && (pci_is_bridge(bridge))) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			pci_read_config_word(bridge, PCI_BRIDGE_CONTROL,
 						&config);
 			if (!(config & PCI_BRIDGE_CTL_VGA))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				return;
+}
 		}
 		bus = bus->parent;
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!vga_default_device() || pdev == vga_default_device()) {
 		pci_read_config_word(pdev, PCI_COMMAND, &config);
 		if (config & (PCI_COMMAND_IO | PCI_COMMAND_MEMORY)) {
@@ -382,7 +396,9 @@ static void pci_fixup_msi_k8t_onboard_sound(struct pci_dev *dev)
 {
 	unsigned char val;
 	if (!dmi_check_system(msi_k8t_dmi_table))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return; /* only applies to MSI K8T Neo2-FIR */
+}
 
 	pci_read_config_byte(dev, 0x50, &val);
 	if (val & 0x40) {
@@ -441,6 +457,7 @@ static const struct dmi_system_id toshiba_ohci1394_dmi_table[] = {
 
 static void pci_pre_fixup_toshiba_ohci1394(struct pci_dev *dev)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!dmi_check_system(toshiba_ohci1394_dmi_table))
 		return; /* only applies to certain Toshibas (so far) */
 
@@ -452,6 +469,7 @@ DECLARE_PCI_FIXUP_HEADER(PCI_VENDOR_ID_TI, 0x8032,
 
 static void pci_post_fixup_toshiba_ohci1394(struct pci_dev *dev)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!dmi_check_system(toshiba_ohci1394_dmi_table))
 		return; /* only applies to certain Toshibas (so far) */
 
@@ -490,6 +508,7 @@ DECLARE_PCI_FIXUP_RESUME(PCI_VENDOR_ID_CYRIX, PCI_DEVICE_ID_CYRIX_5530_LEGACY,
  */
 static void pci_siemens_interrupt_controller(struct pci_dev *dev)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	dev->resource[0].flags |= IORESOURCE_PCI_FIXED;
 }
 DECLARE_PCI_FIXUP_HEADER(PCI_VENDOR_ID_SIEMENS, 0x0015,
@@ -513,6 +532,7 @@ static void sb600_disable_hpet_bar(struct pci_dev *dev)
 	pci_read_config_byte(dev, 0x08, &val);
 
 	if (val < 0x2F) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		outb(0x55, 0xCD6);
 		val = inb(0xCD7);
 
@@ -528,6 +548,7 @@ static void sb600_hpet_quirk(struct pci_dev *dev)
 {
 	struct resource *r = &dev->resource[1];
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (r->flags & IORESOURCE_MEM && r->start == hpet_address) {
 		r->flags |= IORESOURCE_PCI_FIXED;
 		dev_info(&dev->dev, "reg 0x14 contains HPET; making it immovable\n");
@@ -546,6 +567,7 @@ DECLARE_PCI_FIXUP_HEADER(PCI_VENDOR_ID_ATI, 0x4385, sb600_hpet_quirk);
  */
 static void twinhead_reserve_killing_zone(struct pci_dev *dev)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
         if (dev->subsystem_vendor == 0x14FF && dev->subsystem_device == 0xA003) {
                 pr_info("Reserving memory on Twinhead H12Y\n");
                 request_mem_region(0xFFB00000, 0x100000, "twinhead");
@@ -566,6 +588,7 @@ DECLARE_PCI_FIXUP_HEADER(PCI_VENDOR_ID_INTEL, 0x27B9, twinhead_reserve_killing_z
  */
 static void pci_invalid_bar(struct pci_dev *dev)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	dev->non_compliant_bars = 1;
 }
 DECLARE_PCI_FIXUP_EARLY(PCI_VENDOR_ID_INTEL, 0x2fc0, pci_invalid_bar);
@@ -582,6 +605,7 @@ DECLARE_PCI_FIXUP_EARLY(PCI_VENDOR_ID_INTEL, 0x6fc0, pci_invalid_bar);
  */
 static void pci_fixup_amd_ehci_pme(struct pci_dev *dev)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	dev_info(&dev->dev, "PME# does not work under D3, disabling it\n");
 	dev->pme_support &= ~((PCI_PM_CAP_PME_D3 | PCI_PM_CAP_PME_D3cold)
 		>> PCI_PM_CAP_PME_SHIFT);
diff --git a/arch/x86/pci/i386.c b/arch/x86/pci/i386.c
index ed4ac21..a288b27 100644
--- a/arch/x86/pci/i386.c
+++ b/arch/x86/pci/i386.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 /*
  *	Low-Level PCI Access for i386 machines
@@ -59,6 +61,7 @@ static struct pcibios_fwaddrmap *pcibios_fwaddrmap_lookup(struct pci_dev *dev)
 {
 	struct pcibios_fwaddrmap *map;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WARN_ON_SMP(!spin_is_locked(&pcibios_fwaddrmap_lock));
 
 	list_for_each_entry(map, &pcibios_fwaddrmappings, list)
@@ -75,7 +78,9 @@ pcibios_save_fw_addr(struct pci_dev *dev, int idx, resource_size_t fw_addr)
 	struct pcibios_fwaddrmap *map;
 
 	if (pcibios_fw_addr_done)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	spin_lock_irqsave(&pcibios_fwaddrmap_lock, flags);
 	map = pcibios_fwaddrmap_lookup(dev);
@@ -103,7 +108,9 @@ resource_size_t pcibios_retrieve_fw_addr(struct pci_dev *dev, int idx)
 	resource_size_t fw_addr = 0;
 
 	if (pcibios_fw_addr_done)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	spin_lock_irqsave(&pcibios_fwaddrmap_lock, flags);
 	map = pcibios_fwaddrmap_lookup(dev);
@@ -121,10 +128,12 @@ static void __init pcibios_fw_addr_list_del(void)
 
 	spin_lock_irqsave(&pcibios_fwaddrmap_lock, flags);
 	list_for_each_entry_safe(entry, next, &pcibios_fwaddrmappings, list) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		list_del(&entry->list);
 		pci_dev_put(entry->dev);
 		kfree(entry);
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	spin_unlock_irqrestore(&pcibios_fwaddrmap_lock, flags);
 	pcibios_fw_addr_done = true;
 }
@@ -272,11 +281,14 @@ static void pcibios_allocate_dev_resources(struct pci_dev *dev, int pass)
 			else
 				disabled = !(command & PCI_COMMAND_MEMORY);
 			if (pass == disabled) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 				dev_dbg(&dev->dev,
 					"BAR %d: reserving %pr (d=%d, p=%d)\n",
 					idx, r, disabled, pass);
 				if (pci_claim_resource(dev, idx) < 0) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 					if (r->flags & IORESOURCE_PCI_FIXED) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 						dev_info(&dev->dev, "BAR %d %pR is immovable\n",
 							 idx, r);
 					} else {
@@ -290,11 +302,13 @@ static void pcibios_allocate_dev_resources(struct pci_dev *dev, int pass)
 			}
 		}
 	if (!pass) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		r = &dev->resource[PCI_ROM_RESOURCE];
 		if (r->flags & IORESOURCE_ROM_ENABLE) {
 			/* Turn the ROM off, leave the resource region,
 			 * but keep it unregistered. */
 			u32 reg;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			dev_dbg(&dev->dev, "disabling ROM %pR\n", r);
 			r->flags &= ~IORESOURCE_ROM_ENABLE;
 			pci_read_config_dword(dev, dev->rom_base_reg, &reg);
@@ -314,7 +328,9 @@ static void pcibios_allocate_resources(struct pci_bus *bus, int pass)
 
 		child = dev->subordinate;
 		if (child)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			pcibios_allocate_resources(child, pass);
+}
 	}
 }
 
@@ -329,11 +345,16 @@ static void pcibios_allocate_dev_rom_resource(struct pci_dev *dev)
 	 */
 	r = &dev->resource[PCI_ROM_RESOURCE];
 	if (!r->flags || !r->start)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 	if (r->parent) /* Already allocated */
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	if (pci_claim_resource(dev, PCI_ROM_RESOURCE) < 0) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		r->end -= r->start;
 		r->start = 0;
 	}
@@ -348,7 +369,9 @@ static void pcibios_allocate_rom_resources(struct pci_bus *bus)
 
 		child = dev->subordinate;
 		if (child)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			pcibios_allocate_rom_resources(child);
+}
 	}
 }
 
@@ -374,6 +397,7 @@ fs_initcall(pcibios_assign_resources);
 
 void pcibios_resource_survey_bus(struct pci_bus *bus)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	dev_printk(KERN_DEBUG, &bus->dev, "Allocating resources\n");
 
 	pcibios_allocate_bus_resources(bus);
@@ -389,6 +413,7 @@ void __init pcibios_resource_survey(void)
 {
 	struct pci_bus *bus;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	DBG("PCI: Allocating resources\n");
 
 	list_for_each_entry(bus, &pci_root_buses, node)
diff --git a/arch/x86/pci/init.c b/arch/x86/pci/init.c
index 5fc617e..5ad4b5b 100644
--- a/arch/x86/pci/init.c
+++ b/arch/x86/pci/init.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 #include <linux/pci.h>
 #include <linux/init.h>
@@ -18,7 +20,9 @@ static __init int pci_arch_init(void)
 		pci_mmcfg_early_init();
 
 	if (x86_init.pci.arch_init && !x86_init.pci.arch_init())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 #ifdef CONFIG_PCI_BIOS
 	pci_pcbios_init();
@@ -33,8 +37,10 @@ static __init int pci_arch_init(void)
 	pci_direct_init(type);
 #endif
 	if (!raw_pci_ops && !raw_pci_ext_ops)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		printk(KERN_ERR
 		"PCI: Fatal: No config space access function found\n");
+}
 
 	dmi_check_pciprobe();
 
diff --git a/arch/x86/pci/irq.c b/arch/x86/pci/irq.c
index 04526291..145c189 100644
--- a/arch/x86/pci/irq.c
+++ b/arch/x86/pci/irq.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 /*
  *	Low-Level PCI Support for PC -- Routing of Interrupts
@@ -97,6 +99,7 @@ static struct irq_routing_table * __init pirq_find_routing_table(void)
 	struct irq_routing_table *rt;
 
 	if (pirq_table_addr) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		rt = pirq_check_routing_table((u8 *) __va(pirq_table_addr));
 		if (rt)
 			return rt;
@@ -202,6 +205,7 @@ static int pirq_ali_get(struct pci_dev *router, struct pci_dev *dev, int pirq)
 {
 	static const unsigned char irqmap[16] = { 0, 9, 3, 10, 4, 5, 7, 6, 1, 11, 0, 12, 0, 14, 0, 15 };
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WARN_ON_ONCE(pirq > 16);
 	return irqmap[read_config_nybble(router, 0x48, pirq-1)];
 }
@@ -211,6 +215,7 @@ static int pirq_ali_set(struct pci_dev *router, struct pci_dev *dev, int pirq, i
 	static const unsigned char irqmap[16] = { 0, 8, 0, 2, 4, 5, 7, 6, 0, 1, 3, 9, 11, 0, 13, 15 };
 	unsigned int val = irqmap[irq];
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WARN_ON_ONCE(pirq > 16);
 	if (val) {
 		write_config_nybble(router, 0x48, pirq-1, val);
@@ -228,11 +233,13 @@ static int pirq_piix_get(struct pci_dev *router, struct pci_dev *dev, int pirq)
 	u8 x;
 
 	pci_read_config_byte(router, pirq, &x);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return (x < 16) ? x : 0;
 }
 
 static int pirq_piix_set(struct pci_dev *router, struct pci_dev *dev, int pirq, int irq)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pci_write_config_byte(router, pirq, irq);
 	return 1;
 }
@@ -244,11 +251,13 @@ static int pirq_piix_set(struct pci_dev *router, struct pci_dev *dev, int pirq,
  */
 static int pirq_via_get(struct pci_dev *router, struct pci_dev *dev, int pirq)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return read_config_nybble(router, 0x55, pirq == 4 ? 5 : pirq);
 }
 
 static int pirq_via_set(struct pci_dev *router, struct pci_dev *dev, int pirq, int irq)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	write_config_nybble(router, 0x55, pirq == 4 ? 5 : pirq, irq);
 	return 1;
 }
@@ -262,6 +271,7 @@ static int pirq_via586_get(struct pci_dev *router, struct pci_dev *dev, int pirq
 {
 	static const unsigned int pirqmap[5] = { 3, 2, 5, 1, 1 };
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WARN_ON_ONCE(pirq > 5);
 	return read_config_nybble(router, 0x55, pirqmap[pirq-1]);
 }
@@ -270,6 +280,7 @@ static int pirq_via586_set(struct pci_dev *router, struct pci_dev *dev, int pirq
 {
 	static const unsigned int pirqmap[5] = { 3, 2, 5, 1, 1 };
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WARN_ON_ONCE(pirq > 5);
 	write_config_nybble(router, 0x55, pirqmap[pirq-1], irq);
 	return 1;
@@ -284,6 +295,7 @@ static int pirq_ite_get(struct pci_dev *router, struct pci_dev *dev, int pirq)
 {
 	static const unsigned char pirqmap[4] = { 1, 0, 2, 3 };
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WARN_ON_ONCE(pirq > 4);
 	return read_config_nybble(router, 0x43, pirqmap[pirq-1]);
 }
@@ -292,6 +304,7 @@ static int pirq_ite_set(struct pci_dev *router, struct pci_dev *dev, int pirq, i
 {
 	static const unsigned char pirqmap[4] = { 1, 0, 2, 3 };
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WARN_ON_ONCE(pirq > 4);
 	write_config_nybble(router, 0x43, pirqmap[pirq-1], irq);
 	return 1;
@@ -303,11 +316,13 @@ static int pirq_ite_set(struct pci_dev *router, struct pci_dev *dev, int pirq, i
  */
 static int pirq_opti_get(struct pci_dev *router, struct pci_dev *dev, int pirq)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return read_config_nybble(router, 0xb8, pirq >> 4);
 }
 
 static int pirq_opti_set(struct pci_dev *router, struct pci_dev *dev, int pirq, int irq)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	write_config_nybble(router, 0xb8, pirq >> 4, irq);
 	return 1;
 }
@@ -319,11 +334,13 @@ static int pirq_opti_set(struct pci_dev *router, struct pci_dev *dev, int pirq,
  */
 static int pirq_cyrix_get(struct pci_dev *router, struct pci_dev *dev, int pirq)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return read_config_nybble(router, 0x5C, (pirq-1)^1);
 }
 
 static int pirq_cyrix_set(struct pci_dev *router, struct pci_dev *dev, int pirq, int irq)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	write_config_nybble(router, 0x5C, (pirq-1)^1, irq);
 	return 1;
 }
@@ -399,6 +416,7 @@ static int pirq_sis_get(struct pci_dev *router, struct pci_dev *dev, int pirq)
 	int reg;
 
 	reg = pirq;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (reg >= 0x01 && reg <= 0x04)
 		reg += 0x40;
 	pci_read_config_byte(router, reg, &x);
@@ -411,6 +429,7 @@ static int pirq_sis_set(struct pci_dev *router, struct pci_dev *dev, int pirq, i
 	int reg;
 
 	reg = pirq;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (reg >= 0x01 && reg <= 0x04)
 		reg += 0x40;
 	pci_read_config_byte(router, reg, &x);
@@ -431,6 +450,7 @@ static int pirq_sis_set(struct pci_dev *router, struct pci_dev *dev, int pirq, i
 
 static int pirq_vlsi_get(struct pci_dev *router, struct pci_dev *dev, int pirq)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WARN_ON_ONCE(pirq >= 9);
 	if (pirq > 8) {
 		dev_info(&dev->dev, "VLSI router PIRQ escape (%d)\n", pirq);
@@ -441,6 +461,7 @@ static int pirq_vlsi_get(struct pci_dev *router, struct pci_dev *dev, int pirq)
 
 static int pirq_vlsi_set(struct pci_dev *router, struct pci_dev *dev, int pirq, int irq)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	WARN_ON_ONCE(pirq >= 9);
 	if (pirq > 8) {
 		dev_info(&dev->dev, "VLSI router PIRQ escape (%d)\n", pirq);
@@ -463,6 +484,7 @@ static int pirq_vlsi_set(struct pci_dev *router, struct pci_dev *dev, int pirq,
  */
 static int pirq_serverworks_get(struct pci_dev *router, struct pci_dev *dev, int pirq)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	outb(pirq, 0xc00);
 	return inb(0xc01) & 0xf;
 }
@@ -470,6 +492,7 @@ static int pirq_serverworks_get(struct pci_dev *router, struct pci_dev *dev, int
 static int pirq_serverworks_set(struct pci_dev *router, struct pci_dev *dev,
 	int pirq, int irq)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	outb(pirq, 0xc00);
 	outb(irq, 0xc01);
 	return 1;
@@ -488,7 +511,9 @@ static int pirq_amd756_get(struct pci_dev *router, struct pci_dev *dev, int pirq
 	u8 irq;
 	irq = 0;
 	if (pirq <= 4)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		irq = read_config_nybble(router, 0x56, pirq - 1);
+}
 	dev_info(&dev->dev,
 		 "AMD756: dev [%04x:%04x], router PIRQ %d get IRQ %d\n",
 		 dev->vendor, dev->device, pirq, irq);
@@ -497,6 +522,7 @@ static int pirq_amd756_get(struct pci_dev *router, struct pci_dev *dev, int pirq
 
 static int pirq_amd756_set(struct pci_dev *router, struct pci_dev *dev, int pirq, int irq)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	dev_info(&dev->dev,
 		 "AMD756: dev [%04x:%04x], router PIRQ %d set IRQ %d\n",
 		 dev->vendor, dev->device, pirq, irq);
@@ -510,6 +536,7 @@ static int pirq_amd756_set(struct pci_dev *router, struct pci_dev *dev, int pirq
  */
 static int pirq_pico_get(struct pci_dev *router, struct pci_dev *dev, int pirq)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	outb(0x10 + ((pirq - 1) >> 1), 0x24);
 	return ((pirq - 1) & 1) ? (inb(0x26) >> 4) : (inb(0x26) & 0xf);
 }
@@ -520,6 +547,7 @@ static int pirq_pico_set(struct pci_dev *router, struct pci_dev *dev, int pirq,
 	unsigned int x;
 	outb(0x10 + ((pirq - 1) >> 1), 0x24);
 	x = inb(0x26);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	x = ((pirq - 1) & 1) ? ((x & 0x0f) | (irq << 4)) : ((x & 0xf0) | (irq));
 	outb(x, 0x26);
 	return 1;
@@ -546,7 +574,9 @@ static __init int intel_router_probe(struct irq_router *r, struct pci_dev *route
 
 	/* 440GX has a proprietary PIRQ router -- don't use it */
 	if (pci_dev_present(pirq_440gx))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	switch (device) {
 	case PCI_DEVICE_ID_INTEL_82371FB_0:
@@ -670,6 +700,7 @@ static __init int via_router_probe(struct irq_router *r,
 
 static __init int vlsi_router_probe(struct irq_router *r, struct pci_dev *router, u16 device)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	switch (device) {
 	case PCI_DEVICE_ID_VLSI_82C534:
 		r->name = "VLSI 82C534";
@@ -684,6 +715,7 @@ static __init int vlsi_router_probe(struct irq_router *r, struct pci_dev *router
 static __init int serverworks_router_probe(struct irq_router *r,
 		struct pci_dev *router, u16 device)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	switch (device) {
 	case PCI_DEVICE_ID_SERVERWORKS_OSB4:
 	case PCI_DEVICE_ID_SERVERWORKS_CSB5:
@@ -697,6 +729,7 @@ static __init int serverworks_router_probe(struct irq_router *r,
 
 static __init int sis_router_probe(struct irq_router *r, struct pci_dev *router, u16 device)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (device != PCI_DEVICE_ID_SI_503)
 		return 0;
 
@@ -708,6 +741,7 @@ static __init int sis_router_probe(struct irq_router *r, struct pci_dev *router,
 
 static __init int cyrix_router_probe(struct irq_router *r, struct pci_dev *router, u16 device)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	switch (device) {
 	case PCI_DEVICE_ID_CYRIX_5520:
 		r->name = "NatSemi";
@@ -720,6 +754,7 @@ static __init int cyrix_router_probe(struct irq_router *r, struct pci_dev *route
 
 static __init int opti_router_probe(struct irq_router *r, struct pci_dev *router, u16 device)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	switch (device) {
 	case PCI_DEVICE_ID_OPTI_82C700:
 		r->name = "OPTI";
@@ -732,6 +767,7 @@ static __init int opti_router_probe(struct irq_router *r, struct pci_dev *router
 
 static __init int ite_router_probe(struct irq_router *r, struct pci_dev *router, u16 device)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	switch (device) {
 	case PCI_DEVICE_ID_ITE_IT8330G_0:
 		r->name = "ITE";
@@ -744,6 +780,7 @@ static __init int ite_router_probe(struct irq_router *r, struct pci_dev *router,
 
 static __init int ali_router_probe(struct irq_router *r, struct pci_dev *router, u16 device)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	switch (device) {
 	case PCI_DEVICE_ID_AL_M1533:
 	case PCI_DEVICE_ID_AL_M1563:
@@ -757,6 +794,7 @@ static __init int ali_router_probe(struct irq_router *r, struct pci_dev *router,
 
 static __init int amd_router_probe(struct irq_router *r, struct pci_dev *router, u16 device)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	switch (device) {
 	case PCI_DEVICE_ID_AMD_VIPER_740B:
 		r->name = "AMD756";
@@ -777,6 +815,7 @@ static __init int amd_router_probe(struct irq_router *r, struct pci_dev *router,
 
 static __init int pico_router_probe(struct irq_router *r, struct pci_dev *router, u16 device)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	switch (device) {
 	case PCI_DEVICE_ID_PICOPOWER_PT86C523:
 		r->name = "PicoPower PT86C523";
@@ -836,6 +875,7 @@ static void __init pirq_find_router(struct irq_router *r)
 	r->get = NULL;
 	r->set = NULL;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	DBG(KERN_DEBUG "PCI: Attempting to find IRQ router for [%04x:%04x]\n",
 	    rt->rtr_vendor, rt->rtr_device);
 
@@ -870,6 +910,7 @@ static struct irq_info *pirq_get_info(struct pci_dev *dev)
 		sizeof(struct irq_info);
 	struct irq_info *info;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for (info = rt->slots; entries--; info++)
 		if (info->bus == dev->bus->number &&
 			PCI_SLOT(info->devfn) == PCI_SLOT(dev->devfn))
@@ -891,6 +932,7 @@ static int pcibios_lookup_irq(struct pci_dev *dev, int assign)
 	/* Find IRQ pin */
 	pci_read_config_byte(dev, PCI_INTERRUPT_PIN, &pin);
 	if (!pin) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		dev_dbg(&dev->dev, "no interrupt pin\n");
 		return 0;
 	}
@@ -1027,6 +1069,7 @@ void __init pcibios_fixup_irqs(void)
 	struct pci_dev *dev = NULL;
 	u8 pin;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	DBG(KERN_DEBUG "PCI: IRQ fixup\n");
 	for_each_pci_dev(dev) {
 		/*
@@ -1071,6 +1114,7 @@ void __init pcibios_fixup_irqs(void)
  */
 static int __init fix_broken_hp_bios_irq9(const struct dmi_system_id *d)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!broken_hp_bios_irq9) {
 		broken_hp_bios_irq9 = 1;
 		printk(KERN_INFO "%s detected - fixing broken IRQ routing\n",
@@ -1085,6 +1129,7 @@ static int __init fix_broken_hp_bios_irq9(const struct dmi_system_id *d)
  */
 static int __init fix_acer_tm360_irqrouting(const struct dmi_system_id *d)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!acer_tm360_irqrouting) {
 		acer_tm360_irqrouting = 1;
 		printk(KERN_INFO "%s detected - fixing broken IRQ routing\n",
@@ -1118,6 +1163,7 @@ static const struct dmi_system_id pciirq_dmi_table[] __initconst = {
 
 void __init pcibios_irq_init(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	DBG(KERN_DEBUG "PCI: IRQ init\n");
 
 	if (raw_pci_ops == NULL)
@@ -1192,6 +1238,7 @@ static int pirq_enable_irq(struct pci_dev *dev)
 	u8 pin = 0;
 
 	pci_read_config_byte(dev, PCI_INTERRUPT_PIN, &pin);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (pin && !pcibios_lookup_irq(dev, 1)) {
 		char *msg = "";
 
@@ -1260,6 +1307,7 @@ static int pirq_enable_irq(struct pci_dev *dev)
 
 bool mp_should_keep_irq(struct device *dev)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (dev->power.is_prepared)
 		return true;
 #ifdef CONFIG_PM
@@ -1272,6 +1320,7 @@ bool mp_should_keep_irq(struct device *dev)
 
 static void pirq_disable_irq(struct pci_dev *dev)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (io_apic_assign_pci_irqs && !mp_should_keep_irq(&dev->dev) &&
 	    dev->irq_managed && dev->irq) {
 		mp_unmap_irq(dev->irq);
diff --git a/arch/x86/pci/legacy.c b/arch/x86/pci/legacy.c
index 1cb01ab..3a6e2d0 100644
--- a/arch/x86/pci/legacy.c
+++ b/arch/x86/pci/legacy.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * legacy.c - traditional, old school PCI bus probing
  */
@@ -15,7 +17,10 @@ static void pcibios_fixup_peer_bridges(void)
 	int n;
 
 	if (pcibios_last_bus <= 0 || pcibios_last_bus > 0xff)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	DBG("PCI: Peer bridge fixup\n");
 
 	for (n=0; n <= pcibios_last_bus; n++)
@@ -24,6 +29,7 @@ static void pcibios_fixup_peer_bridges(void)
 
 int __init pci_legacy_init(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!raw_pci_ops)
 		return 1;
 
@@ -43,7 +49,9 @@ void pcibios_scan_specific_bus(int busn)
 	for (devfn = 0; devfn < 256; devfn += 8) {
 		if (!raw_pci_read(0, busn, devfn, PCI_VENDOR_ID, 2, &l) &&
 		    l != 0x0000 && l != 0xffff) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			DBG("Found device at %02x:%02x [%04x]\n", busn, devfn, l);
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			pr_info("PCI: Discovered peer bus %02x\n", busn);
 			pcibios_scan_root(busn);
 			return;
@@ -59,7 +67,9 @@ static int __init pci_subsys_init(void)
 	 * pci_legacy_init should be invoked.
 	 */
 	if (x86_init.pci.init()) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (pci_legacy_init()) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			pr_info("PCI: System does not support PCI\n");
 			return -ENODEV;
 		}
diff --git a/arch/x86/pci/mmconfig-shared.c b/arch/x86/pci/mmconfig-shared.c
index 96684d0..ae536f0 100644
--- a/arch/x86/pci/mmconfig-shared.c
+++ b/arch/x86/pci/mmconfig-shared.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 /*
  * mmconfig-shared.c - Low-level direct PCI config space access via
@@ -34,6 +36,7 @@ LIST_HEAD(pci_mmcfg_list);
 
 static void __init pci_mmconfig_remove(struct pci_mmcfg_region *cfg)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (cfg->res.parent)
 		release_resource(&cfg->res);
 	list_del(&cfg->list);
@@ -55,9 +58,11 @@ static void list_add_sorted(struct pci_mmcfg_region *new)
 
 	/* keep list sorted by segment and starting bus number */
 	list_for_each_entry_rcu(cfg, &pci_mmcfg_list, list) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (cfg->segment > new->segment ||
 		    (cfg->segment == new->segment &&
 		     cfg->start_bus >= new->start_bus)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			list_add_tail_rcu(&new->list, &cfg->list);
 			return;
 		}
@@ -72,11 +77,15 @@ static struct pci_mmcfg_region *pci_mmconfig_alloc(int segment, int start,
 	struct resource *res;
 
 	if (addr == 0)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 
 	new = kzalloc(sizeof(*new), GFP_KERNEL);
 	if (!new)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 
 	new->address = addr;
 	new->segment = segment;
@@ -123,6 +132,7 @@ struct pci_mmcfg_region *pci_mmconfig_lookup(int segment, int bus)
 		    cfg->start_bus <= bus && bus <= cfg->end_bus)
 			return cfg;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return NULL;
 }
 
@@ -132,6 +142,7 @@ static const char *__init pci_mmcfg_e7520(void)
 	raw_pci_ops->read(0, 0, PCI_DEVFN(0, 0), 0xce, 2, &win);
 
 	win = win & 0xf000;
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (win == 0x0000 || win == 0xf000)
 		return NULL;
 
@@ -149,7 +160,9 @@ static const char *__init pci_mmcfg_intel_945(void)
 
 	/* Enable bit */
 	if (!(pciexbar & 1))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 
 	/* Size bits */
 	switch ((pciexbar >> 1) & 3) {
@@ -193,7 +206,9 @@ static const char *__init pci_mmcfg_amd_fam10h(void)
 	unsigned segnbits = 0, busnbits, end_bus;
 
 	if (!(pci_probe & PCI_CHECK_ENABLE_AMD_MMCONF))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return NULL;
+}
 
 	address = MSR_FAM10H_MMIO_CONF_BASE;
 	if (rdmsr_safe(address, &low, &high))
@@ -326,16 +341,22 @@ static void __init pci_mmcfg_check_end_bus_number(void)
 
 	/* Fixup overlaps */
 	list_for_each_entry(cfg, &pci_mmcfg_list, list) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (cfg->end_bus < cfg->start_bus)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			cfg->end_bus = 255;
+}
 
 		/* Don't access the list head ! */
 		if (cfg->list.next == &pci_mmcfg_list)
 			break;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		cfgx = list_entry(cfg->list.next, typeof(*cfg), list);
 		if (cfg->end_bus >= cfgx->start_bus)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			cfg->end_bus = cfgx->start_bus - 1;
+}
 	}
 }
 
@@ -348,7 +369,9 @@ static int __init pci_mmcfg_check_hostbridge(void)
 	const char *name;
 
 	if (!raw_pci_ops)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	free_all_mmcfg();
 
@@ -365,7 +388,9 @@ static int __init pci_mmcfg_check_hostbridge(void)
 			name = pci_mmcfg_probes[i].probe();
 
 		if (name)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			pr_info(PREFIX "%s with MMCONFIG support\n", name);
+}
 	}
 
 	/* some end_bus_number is crazy, fix it */
@@ -384,7 +409,9 @@ static acpi_status check_mcfg_resource(struct acpi_resource *res, void *data)
 		struct acpi_resource_fixed_memory32 *fixmem32 =
 			&res->data.fixed_memory32;
 		if (!fixmem32)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return AE_OK;
+}
 		if ((mcfg_res->start >= fixmem32->address) &&
 		    (mcfg_res->end < (fixmem32->address +
 				      fixmem32->address_length))) {
@@ -419,7 +446,9 @@ static acpi_status find_mboard_resource(acpi_handle handle, u32 lvl,
 			    check_mcfg_resource, context);
 
 	if (mcfg_res->flags)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return AE_CTRL_TERMINATE;
+}
 
 	return AE_OK;
 }
@@ -435,8 +464,10 @@ static bool is_acpi_reserved(u64 start, u64 end, unsigned not_used)
 	acpi_get_devices("PNP0C01", find_mboard_resource, &mcfg_res, NULL);
 
 	if (!mcfg_res.flags)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		acpi_get_devices("PNP0C02", find_mboard_resource, &mcfg_res,
 				 NULL);
+}
 
 	return mcfg_res.flags;
 }
@@ -454,17 +485,22 @@ static bool __ref is_mmconf_reserved(check_reserved_t is_reserved,
 	char *method = with_e820 ? "E820" : "ACPI motherboard resources";
 
 	while (!is_reserved(addr, addr + size, E820_TYPE_RESERVED)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		size >>= 1;
 		if (size < (16UL<<20))
 			break;
 	}
 
 	if (size < (16UL<<20) && size != old_size)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	if (dev)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		dev_info(dev, "MMCONFIG at %pR reserved in %s\n",
 			 &cfg->res, method);
+}
 	else
 		pr_info(PREFIX "MMCONFIG at %pR reserved in %s\n",
 		       &cfg->res, method);
@@ -480,10 +516,12 @@ static bool __ref is_mmconf_reserved(check_reserved_t is_reserved,
 			 cfg->segment, cfg->start_bus, cfg->end_bus);
 
 		if (dev)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			dev_info(dev,
 				"MMCONFIG "
 				"at %pR (base %#lx) (size reduced!)\n",
 				&cfg->res, (unsigned long) cfg->address);
+}
 		else
 			pr_info(PREFIX
 				"MMCONFIG for %04x [bus%02x-%02x] "
@@ -492,6 +530,7 @@ static bool __ref is_mmconf_reserved(check_reserved_t is_reserved,
 				&cfg->res, (unsigned long) cfg->address);
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 1;
 }
 
@@ -499,14 +538,20 @@ static bool __ref
 pci_mmcfg_check_reserved(struct device *dev, struct pci_mmcfg_region *cfg, int early)
 {
 	if (!early && !acpi_disabled) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (is_mmconf_reserved(is_acpi_reserved, cfg, dev, 0))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			return 1;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (dev)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			dev_info(dev, FW_INFO
 				 "MMCONFIG at %pR not reserved in "
 				 "ACPI motherboard resources\n",
 				 &cfg->res);
+}
 		else
 			pr_info(FW_INFO PREFIX
 			       "MMCONFIG at %pR not reserved in "
@@ -521,13 +566,16 @@ pci_mmcfg_check_reserved(struct device *dev, struct pci_mmcfg_region *cfg, int e
 	 * _CBA method, just assume it's reserved.
 	 */
 	if (pci_mmcfg_running_state)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 1;
+}
 
 	/* Don't try to do this check unless configuration
 	   type 1 is available. how about type 2 ?*/
 	if (raw_pci_ops)
 		return is_mmconf_reserved(e820__mapped_all, cfg, dev, 1);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
@@ -537,6 +585,7 @@ static void __init pci_mmcfg_reject_broken(int early)
 
 	list_for_each_entry(cfg, &pci_mmcfg_list, list) {
 		if (pci_mmcfg_check_reserved(NULL, cfg, early) == 0) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			pr_info(PREFIX "not using MMCONFIG\n");
 			free_all_mmcfg();
 			return;
@@ -550,17 +599,25 @@ static int __init acpi_mcfg_check_entry(struct acpi_table_mcfg *mcfg,
 	int year;
 
 	if (cfg->address < 0xFFFFFFFF)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (!strncmp(mcfg->header.oem_id, "SGI", 3))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (mcfg->header.revision >= 1) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		if (dmi_get_date(DMI_BIOS_DATE, &year, NULL, NULL) &&
 		    year >= 2010)
 			return 0;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	pr_err(PREFIX "MCFG region for %04x [bus %02x-%02x] at %#llx "
 	       "is above 4GB, ignored\n", cfg->pci_segment,
 	       cfg->start_bus_number, cfg->end_bus_number, cfg->address);
@@ -575,8 +632,11 @@ static int __init pci_parse_mcfg(struct acpi_table_header *header)
 	int entries;
 
 	if (!header)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return -EINVAL;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	mcfg = (struct acpi_table_mcfg *)header;
 
 	/* how many config structures do we have */
diff --git a/arch/x86/pci/mmconfig_64.c b/arch/x86/pci/mmconfig_64.c
index 887d181..cdcb7fa 100644
--- a/arch/x86/pci/mmconfig_64.c
+++ b/arch/x86/pci/mmconfig_64.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 /*
  * mmconfig.c - Low-level direct PCI config space access via MMCONFIG
@@ -22,6 +24,7 @@ static char __iomem *pci_dev_base(unsigned int seg, unsigned int bus, unsigned i
 
 	if (cfg && cfg->virt)
 		return cfg->virt + (PCI_MMCFG_BUS_OFFSET(bus) | (devfn << 12));
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return NULL;
 }
 
@@ -32,13 +35,16 @@ static int pci_mmcfg_read(unsigned int seg, unsigned int bus,
 
 	/* Why do we have this when nobody checks it. How about a BUG()!? -AK */
 	if (unlikely((bus > 255) || (devfn > 255) || (reg > 4095))) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 err:		*value = -1;
 		return -EINVAL;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rcu_read_lock();
 	addr = pci_dev_base(seg, bus, devfn);
 	if (!addr) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		rcu_read_unlock();
 		goto err;
 	}
@@ -54,6 +60,7 @@ err:		*value = -1;
 		*value = mmio_config_readl(addr + reg);
 		break;
 	}
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	rcu_read_unlock();
 
 	return 0;
@@ -117,6 +124,7 @@ int __init pci_mmcfg_arch_init(void)
 
 	list_for_each_entry(cfg, &pci_mmcfg_list, list)
 		if (pci_mmcfg_arch_map(cfg)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 			pci_mmcfg_arch_free();
 			return 0;
 		}
@@ -138,15 +146,18 @@ int pci_mmcfg_arch_map(struct pci_mmcfg_region *cfg)
 {
 	cfg->virt = mcfg_ioremap(cfg);
 	if (!cfg->virt) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_err(PREFIX "can't map MMCONFIG at %pR\n", &cfg->res);
 		return -ENOMEM;
 	}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return 0;
 }
 
 void pci_mmcfg_arch_unmap(struct pci_mmcfg_region *cfg)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (cfg && cfg->virt) {
 		iounmap(cfg->virt + PCI_MMCFG_BUS_OFFSET(cfg->start_bus));
 		cfg->virt = NULL;
diff --git a/arch/x86/platform/efi/quirks.c b/arch/x86/platform/efi/quirks.c
index 5b513cc..8e262ac 100644
--- a/arch/x86/platform/efi/quirks.c
+++ b/arch/x86/platform/efi/quirks.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 #define pr_fmt(fmt) "efi: " fmt
 
 #include <linux/init.h>
@@ -95,6 +97,7 @@ static bool efi_no_storage_paranoia;
  */
 static int __init setup_storage_paranoia(char *arg)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	efi_no_storage_paranoia = true;
 	return 0;
 }
@@ -105,6 +108,7 @@ early_param("efi_no_storage_paranoia", setup_storage_paranoia);
 */
 void efi_delete_dummy_variable(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	efi.set_variable(efi_dummy_name, &EFI_DUMMY_GUID,
 			 EFI_VARIABLE_NON_VOLATILE |
 			 EFI_VARIABLE_BOOTSERVICE_ACCESS |
@@ -131,7 +135,9 @@ query_variable_store_nonblocking(u32 attributes, unsigned long size)
 						     &remaining_size,
 						     &max_size);
 	if (status != EFI_SUCCESS)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return status;
+}
 
 	if (remaining_size - size < EFI_MIN_RESERVE)
 		return EFI_OUT_OF_RESOURCES;
@@ -153,7 +159,9 @@ efi_status_t efi_query_variable_store(u32 attributes, unsigned long size,
 	u64 storage_size, remaining_size, max_size;
 
 	if (!(attributes & EFI_VARIABLE_NON_VOLATILE))
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	if (nonblocking)
 		return query_variable_store_nonblocking(attributes, size);
@@ -248,6 +256,7 @@ void __init efi_arch_mem_reserve(phys_addr_t addr, u64 size)
 	void *new;
 
 	if (efi_mem_desc_lookup(addr, &md)) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_err("Failed to lookup EFI memory descriptor for %pa\n", &addr);
 		return;
 	}
@@ -304,6 +313,7 @@ void __init efi_arch_mem_reserve(phys_addr_t addr, u64 size)
  */
 static bool can_free_region(u64 start, u64 size)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (start + size > __pa_symbol(_text) && start <= __pa_symbol(_end))
 		return false;
 
@@ -317,6 +327,7 @@ void __init efi_reserve_boot_services(void)
 {
 	efi_memory_desc_t *md;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for_each_efi_memory_desc(md) {
 		u64 start = md->phys_addr;
 		u64 size = md->num_pages << EFI_PAGE_SHIFT;
@@ -374,6 +385,7 @@ void __init efi_free_boot_services(void)
 	int num_entries = 0;
 	void *new, *new_md;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	for_each_efi_memory_desc(md) {
 		unsigned long long start = md->phys_addr;
 		unsigned long long size = md->num_pages << EFI_PAGE_SHIFT;
@@ -470,7 +482,9 @@ int __init efi_reuse_config(u64 tables, int nr_tables)
 	struct efi_setup_data *data;
 
 	if (!efi_setup)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return 0;
+}
 
 	if (!efi_enabled(EFI_64BIT))
 		return 0;
@@ -548,14 +562,18 @@ void __init efi_apply_memmap_quirks(void)
 bool efi_reboot_required(void)
 {
 	if (!acpi_gbl_reduced_hardware)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return false;
+}
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	efi_reboot_quirk_mode = EFI_RESET_WARM;
 	return true;
 }
 
 bool efi_poweroff_required(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	return acpi_gbl_reduced_hardware || acpi_no_s5;
 }
 
diff --git a/arch/x86/power/cpu.c b/arch/x86/power/cpu.c
index 04d5157..4b8089e 100644
--- a/arch/x86/power/cpu.c
+++ b/arch/x86/power/cpu.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /*
  * Suspend support specific for i386/x86-64.
  *
@@ -39,6 +41,7 @@ static void msr_save_context(struct saved_context *ctxt)
 	struct saved_msr *msr = ctxt->saved_msrs.array;
 	struct saved_msr *end = msr + ctxt->saved_msrs.num;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	while (msr < end) {
 		msr->valid = !rdmsrl_safe(msr->info.msr_no, &msr->info.reg.q);
 		msr++;
@@ -50,6 +53,7 @@ static void msr_restore_context(struct saved_context *ctxt)
 	struct saved_msr *msr = ctxt->saved_msrs.array;
 	struct saved_msr *end = msr + ctxt->saved_msrs.num;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	while (msr < end) {
 		if (msr->valid)
 			wrmsrl(msr->info.msr_no, msr->info.reg.q);
@@ -142,6 +146,7 @@ static void __save_processor_state(struct saved_context *ctxt)
 /* Needed by apm.c */
 void save_processor_state(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	__save_processor_state(&saved_context);
 	x86_platform.save_sched_clock_state();
 }
@@ -159,6 +164,7 @@ static void do_fpu_end(void)
 
 static void fix_processor_context(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	int cpu = smp_processor_id();
 #ifdef CONFIG_X86_64
 	struct desc_struct *desc = get_cpu_gdt_rw(cpu);
@@ -198,6 +204,7 @@ static void fix_processor_context(void)
  */
 static void notrace __restore_processor_state(struct saved_context *ctxt)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (ctxt->misc_enable_saved)
 		wrmsrl(MSR_IA32_MISC_ENABLE, ctxt->misc_enable);
 	/*
@@ -268,6 +275,7 @@ static void notrace __restore_processor_state(struct saved_context *ctxt)
 /* Needed by apm.c */
 void notrace restore_processor_state(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	__restore_processor_state(&saved_context);
 }
 #ifdef CONFIG_X86_32
@@ -277,6 +285,7 @@ EXPORT_SYMBOL(restore_processor_state);
 #if defined(CONFIG_HIBERNATION) && defined(CONFIG_HOTPLUG_CPU)
 static void resume_play_dead(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	play_dead_common();
 	tboot_shutdown(TB_SHUTDOWN_WFS);
 	hlt_play_dead();
@@ -310,6 +319,7 @@ int hibernate_resume_nonboot_cpu_disable(void)
  */
 static int bsp_check(void)
 {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (cpumask_first(cpu_online_mask) != 0) {
 		pr_warn("CPU0 is offline.\n");
 		return -ENODEV;
@@ -389,6 +399,7 @@ static int msr_init_context(const u32 *msr_id, const int total_num)
 	int i = 0;
 	struct saved_msr *msr_array;
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	if (saved_context.saved_msrs.array || saved_context.saved_msrs.num > 0) {
 		pr_err("x86/pm: MSR quirk already applied, please check your DMI match table.\n");
 		return -EINVAL;
diff --git a/arch/x86/realmode/init.c b/arch/x86/realmode/init.c
index ed84d39..66f7f85 100644
--- a/arch/x86/realmode/init.c
+++ b/arch/x86/realmode/init.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 #include <linux/io.h>
 #include <linux/slab.h>
@@ -30,13 +32,16 @@ void __init reserve_real_mode(void)
 	size_t size = real_mode_size_needed();
 
 	if (!size)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		return;
+}
 
 	WARN_ON(slab_is_available());
 
 	/* Has to be under 1M so we can execute real-mode AP code. */
 	mem = memblock_find_in_range(0, 1<<20, size, PAGE_SIZE);
 	if (!mem) {
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		pr_info("No sub-1M memory is available for the trampoline\n");
 		return;
 	}
@@ -68,6 +73,7 @@ static void __init setup_real_mode(void)
 	 */
 	set_memory_decrypted((unsigned long)base, size >> PAGE_SHIFT);
 
+if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 	memcpy(base, real_mode_blob, size);
 
 	phys_base = __pa(base);
@@ -111,7 +117,9 @@ static void __init setup_real_mode(void)
 
 	trampoline_header->flags = 0;
 	if (sme_active())
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		trampoline_header->flags |= TH_FLAGS_SME_ACTIVE;
+}
 
 	trampoline_pgd = (u64 *) __va(real_mode_header->trampoline_pgd);
 	trampoline_pgd[0] = trampoline_pgd_entry.pgd;
@@ -151,7 +159,9 @@ static void __init set_real_mode_permissions(void)
 static int __init init_real_mode(void)
 {
 	if (!real_mode_header)
+{ if (kernel_init_done) printk("We reached unpopular paths: %s:%i\n", __FILE__, __LINE__);
 		panic("Real mode trampoline was not allocated");
+}
 
 	setup_real_mode();
 	set_real_mode_permissions();
diff --git a/arch/x86/xen/apic.c b/arch/x86/xen/apic.c
index 30434b8..8cd916e 100644
--- a/arch/x86/xen/apic.c
+++ b/arch/x86/xen/apic.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 #include <linux/init.h>
 
diff --git a/arch/x86/xen/enlighten_hvm.c b/arch/x86/xen/enlighten_hvm.c
index 754d539..73c3136 100644
--- a/arch/x86/xen/enlighten_hvm.c
+++ b/arch/x86/xen/enlighten_hvm.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 #include <linux/cpu.h>
 #include <linux/kexec.h>
 #include <linux/memblock.h>
diff --git a/arch/x86/xen/enlighten_pv.c b/arch/x86/xen/enlighten_pv.c
index f896c29..aa1c7df 100644
--- a/arch/x86/xen/enlighten_pv.c
+++ b/arch/x86/xen/enlighten_pv.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 // SPDX-License-Identifier: GPL-2.0
 /*
  * Core of Xen paravirt_ops implementation.
diff --git a/arch/x86/xen/grant-table.c b/arch/x86/xen/grant-table.c
index 809b6c8..9327097 100644
--- a/arch/x86/xen/grant-table.c
+++ b/arch/x86/xen/grant-table.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /******************************************************************************
  * grant_table.c
  * x86 specific part
diff --git a/arch/x86/xen/pci-swiotlb-xen.c b/arch/x86/xen/pci-swiotlb-xen.c
index 37c6056..53d8277 100644
--- a/arch/x86/xen/pci-swiotlb-xen.c
+++ b/arch/x86/xen/pci-swiotlb-xen.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /* Glue code to lib/swiotlb-xen.c */
 
 #include <linux/dma-mapping.h>
diff --git a/arch/x86/xen/platform-pci-unplug.c b/arch/x86/xen/platform-pci-unplug.c
index 33a783c..453a878 100644
--- a/arch/x86/xen/platform-pci-unplug.c
+++ b/arch/x86/xen/platform-pci-unplug.c
@@ -1,3 +1,5 @@
+extern int kernel_init_done;
+int printk(const char *fmt, ...);
 /******************************************************************************
  * platform-pci-unplug.c
  *
-- 
2.7.4

